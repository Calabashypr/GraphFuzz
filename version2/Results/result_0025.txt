
final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:16
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:0

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:3
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:18
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]
torch exception:
{'id': 0, 'name': 'maxpool2d', 'frame_work': 'torch', 'input_datas': tensor([[[[[ 59.,  43.,  50.,  ..., 158., 152., 148.],
           [ 16.,   0.,  18.,  ..., 123., 119., 122.],
           [ 25.,  16.,  49.,  ..., 118., 120., 109.],
           ...,
           [208., 201., 198.,  ..., 160.,  56.,  53.],
           [180., 173., 186.,  ..., 184.,  97.,  83.],
           [177., 168., 179.,  ..., 216., 151., 123.]],

          [[ 62.,  46.,  48.,  ..., 132., 125., 124.],
           [ 20.,   0.,   8.,  ...,  88.,  83.,  87.],
           [ 24.,   7.,  27.,  ...,  84.,  84.,  73.],
           ...,
           [170., 153., 161.,  ..., 133.,  31.,  34.],
           [139., 123., 144.,  ..., 148.,  62.,  53.],
           [144., 129., 142.,  ..., 184., 118.,  92.]],

          [[ 63.,  45.,  43.,  ..., 108., 102., 103.],
           [ 20.,   0.,   0.,  ...,  55.,  50.,  57.],
           [ 21.,   0.,   8.,  ...,  50.,  50.,  42.],
           ...,
           [ 96.,  34.,  26.,  ...,  70.,   7.,  20.],
           [ 96.,  42.,  30.,  ...,  94.,  34.,  34.],
           [116.,  94.,  87.,  ..., 140.,  84.,  72.]]]]])}
pad should be smaller than or equal to half of kernel size, but got padW = 1, padH = 1, kW = 1, kH = 1

generate models:1

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
maxpool2d:1
mindspore --> 
torch --> 
maxpool2d:1

generate models:1

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:1
mindspore --> 
torch --> 

generate models:1

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:1
mindspore --> 
torch --> 

generate models:1

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:1
mindspore --> 
torch --> 

generate models:1

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:1
mindspore --> 
torch --> 

generate models:1

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:4
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:2
mindspore --> 
torch --> 

generate models:2

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:2
mindspore --> 
torch --> 

generate models:2

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:3
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:4
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:20
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:1
mindspore --> 
torch --> 

generate models:1

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:2
mindspore --> 
torch --> 

generate models:2

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:2
mindspore --> 
torch --> 

generate models:2

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:4

analyse the exceptions in iter:6
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:5

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:5
mindspore --> 
torch --> 

generate models:5

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:5
mindspore --> 
torch --> 

generate models:5

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:4

analyse the exceptions in iter:6
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:5

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:6

final statics:
total operators:28
tensorflow --> nums:6,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:6
mindspore --> 
torch --> 

generate models:6

final statics:
total operators:28
tensorflow --> nums:6,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:6
mindspore --> 
torch --> 

generate models:6

final statics:
total operators:28
tensorflow --> nums:6,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:6
mindspore --> 
torch --> 

generate models:6

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:2

analyse the exceptions in iter:6
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:3

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
maxpool2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:3
mindspore --> 
torch --> 

generate models:3

analyse the exceptions in iter:11
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:15
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:20
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:21
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

final statics:
total operators:28
tensorflow --> nums:7,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:7
mindspore --> 
torch --> 

generate models:7

final statics:
total operators:28
tensorflow --> nums:7,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:7
mindspore --> 
torch --> 

generate models:7

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:5
mindspore --> 
torch --> 

generate models:5

analyse the exceptions in iter:14
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:19
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:48
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:8
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:5
mindspore --> 
torch --> 

generate models:5

analyse the exceptions in iter:14
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:17
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:38
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:77
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 44.,  47.,  51., ...,  75.,  72.,  74.],
          [ 52.,  47.,  51., ...,  73.,  74.,  76.],
          [ 65.,  57.,  54., ...,  73.,  73.,  75.],
          ...,
          [ 56.,  49.,  49., ...,  53.,  52.,  53.],
          [ 41.,  56.,  52., ...,  52.,  52.,  49.],
          [ 24.,  49.,  40., ...,  54.,  55.,  46.]],

         [[ 73.,  77.,  81., ..., 107., 104., 106.],
          [ 85.,  79.,  82., ..., 105., 106., 108.],
          [100.,  91.,  87., ..., 105., 105., 108.],
          ...,
          [ 82.,  75.,  74., ...,  77.,  77.,  77.],
          [ 64.,  79.,  75., ...,  74.,  74.,  72.],
          [ 44.,  69.,  60., ...,  74.,  74.,  66.]],

         [[ 49.,  53.,  57., ...,  83.,  80.,  82.],
          [ 55.,  54.,  60., ...,  81.,  82.,  84.],
          [ 67.,  65.,  66., ...,  81.,  81.,  82.],
          ...,
          [ 48.,  41.,  41., ...,  49.,  48.,  49.],
          [ 35.,  50.,  46., ...,  49.,  49.,  46.],
          [ 19.,  44.,  36., ...,  51.,  52.,  43.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:6
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:4
mindspore --> 
torch --> 

generate models:4

analyse the exceptions in iter:10
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:19
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:25
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:39
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:5
mindspore --> 
torch --> 

generate models:5

analyse the exceptions in iter:10
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:17
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:32
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:37
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

final statics:
total operators:28
tensorflow --> nums:6,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:6
mindspore --> 
torch --> 

generate models:6

analyse the exceptions in iter:15
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:20
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:8
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

analyse the exceptions in iter:9
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

final statics:
total operators:28
tensorflow --> nums:10,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:10
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:10
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:11
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:12
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:13
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:15
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:17
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:18
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:19
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:20
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:22
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:24
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:25
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:26
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:27
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:28
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:30
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:32
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:33
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:34
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:35
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

final statics:
total operators:28
tensorflow --> nums:30,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:30
mindspore --> 
torch --> 

generate models:30

analyse the exceptions in iter:0
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:8
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

analyse the exceptions in iter:9
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

final statics:
total operators:28
tensorflow --> nums:10,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:10
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:10
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:11
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:12
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:13
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:14
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:15
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:16
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:17
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:18
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:19
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:20
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:22
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:23
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:24
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:25
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:26
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:27
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:28
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:30
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:32
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:33
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:34
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:36
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 131., 193., ..., 172., 169., 166.],
          [165., 127., 189., ..., 172., 169., 166.],
          [163., 126., 186., ..., 173., 170., 168.],
          ...,
          [147., 139., 145., ..., 220., 218., 219.],
          [146., 143., 152., ..., 221., 220., 219.],
          [148., 143., 146., ..., 223., 221., 220.]],

         [[122., 108., 196., ..., 187., 183., 181.],
          [119., 104., 192., ..., 186., 183., 180.],
          [117., 103., 189., ..., 187., 184., 182.],
          ...,
          [ 93.,  85.,  91., ..., 220., 218., 219.],
          [ 87.,  83.,  94., ..., 221., 220., 219.],
          [ 87.,  82.,  85., ..., 223., 221., 220.]],

         [[ 65.,  75., 192., ..., 187., 183., 181.],
          [ 62.,  72., 187., ..., 186., 183., 180.],
          [ 60.,  71., 185., ..., 187., 184., 182.],
          ...,
          [ 35.,  39.,  42., ..., 220., 218., 219.],
          [ 31.,  39.,  43., ..., 222., 220., 219.],
          [ 28.,  31.,  30., ..., 223., 221., 220.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:37
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:38
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:39
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:40
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:41
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:42
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[127., 148., 192., ..., 112., 144., 153.],
          [ 89., 111., 151., ..., 161., 166., 163.],
          [ 98.,  94., 110., ..., 173., 169., 173.],
          ...,
          [156., 151., 149., ..., 150., 149., 142.],
          [163., 162., 161., ..., 135., 141., 138.],
          [160., 160., 163., ..., 138., 143., 151.]],

         [[126., 144., 181., ..., 102., 135., 142.],
          [ 90., 110., 141., ..., 152., 158., 154.],
          [ 94.,  94., 109., ..., 159., 154., 157.],
          ...,
          [152., 145., 144., ..., 144., 148., 143.],
          [158., 155., 151., ..., 131., 137., 134.],
          [152., 151., 153., ..., 121., 131., 135.]],

         [[129., 144., 175., ...,  98., 123., 130.],
          [ 94., 116., 137., ..., 129., 132., 128.],
          [ 94.,  99., 118., ..., 132., 129., 132.],
          ...,
          [115., 107., 104., ..., 110., 114., 104.],
          [122., 120., 118., ...,  99., 109., 103.],
          [122., 120., 120., ..., 103., 107., 117.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

analyse the exceptions in iter:43
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

analyse the exceptions in iter:44
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:41

analyse the exceptions in iter:45
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 54.,  59.,  56., ..., 133., 131., 132.],
          [ 59.,  62.,  55., ..., 193., 200., 197.],
          [ 41.,  41.,  36., ..., 202., 196., 190.],
          ...,
          [105.,  97.,  96., ...,  98., 100., 100.],
          [ 86.,  96.,  97., ...,  94.,  98., 100.],
          [ 70.,  92., 113., ...,  98.,  96.,  92.]],

         [[ 31.,  34.,  37., ...,  92.,  89.,  94.],
          [ 38.,  39.,  36., ..., 135., 144., 142.],
          [ 26.,  25.,  21., ..., 144., 141., 136.],
          ...,
          [161., 163., 170., ..., 145., 138., 130.],
          [149., 157., 164., ..., 127., 126., 124.],
          [136., 146., 169., ..., 121., 117., 112.]],

         [[ 18.,  19.,  22., ...,  53.,  49.,  53.],
          [ 26.,  26.,  25., ...,  77.,  86.,  86.],
          [ 18.,  16.,  13., ...,  84.,  81.,  79.],
          ...,
          [157., 162., 164., ..., 144., 135., 123.],
          [143., 156., 160., ..., 122., 120., 114.],
          [128., 145., 168., ..., 111., 106., 101.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:42

analyse the exceptions in iter:46
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:43

analyse the exceptions in iter:47
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 77.,  76.,  78., ...,  68.,  58.,  48.],
          [ 71.,  67.,  69., ...,  57.,  44.,  36.],
          [ 55.,  52.,  58., ...,  62.,  53.,  48.],
          ...,
          [ 63.,  62.,  67., ...,  63.,  58.,  55.],
          [ 89.,  91.,  89., ...,  65.,  68.,  66.],
          [103., 107.,  92., ...,  69.,  77.,  77.]],

         [[113., 112., 114., ..., 104.,  94.,  84.],
          [107., 102., 105., ...,  93.,  80.,  72.],
          [ 91.,  88.,  94., ...,  98.,  89.,  84.],
          ...,
          [ 97.,  92.,  97., ...,  97.,  92.,  89.],
          [118., 116., 114., ...,  99., 102., 101.],
          [129., 131., 119., ..., 104., 111., 112.]],

         [[137., 136., 139., ..., 128., 118., 108.],
          [131., 126., 130., ..., 116., 104.,  96.],
          [115., 112., 119., ..., 122., 113., 108.],
          ...,
          [119., 115., 121., ..., 123., 118., 115.],
          [136., 135., 136., ..., 122., 125., 124.],
          [144., 147., 138., ..., 127., 134., 135.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:44

analyse the exceptions in iter:48
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:45

final statics:
total operators:28
tensorflow --> nums:45,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:45
mindspore --> 
torch --> 

generate models:45

analyse the exceptions in iter:50
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 16.,  17.,  17., ...,  62.,  55.,  51.],
          [ 16.,  16.,  15., ...,  62.,  58.,  52.],
          [ 16.,  15.,  15., ...,  57.,  59.,  56.],
          ...,
          [ 96., 114., 119., ..., 128., 120., 117.],
          [118., 100., 114., ..., 139., 131., 121.],
          [144., 136., 105., ..., 145., 137., 131.]],

         [[ 76.,  77.,  77., ..., 106.,  99.,  94.],
          [ 76.,  76.,  75., ..., 109., 105., 100.],
          [ 76.,  75.,  75., ..., 110., 111., 109.],
          ...,
          [110., 127., 132., ..., 135., 130., 131.],
          [132., 113., 126., ..., 146., 140., 134.],
          [148., 140., 114., ..., 151., 144., 141.]],

         [[ 74.,  75.,  75., ...,  87.,  80.,  75.],
          [ 74.,  74.,  74., ...,  84.,  80.,  75.],
          [ 74.,  73.,  73., ...,  79.,  80.,  78.],
          ...,
          [138., 159., 167., ..., 153., 145., 142.],
          [159., 145., 163., ..., 159., 153., 147.],
          [173., 168., 143., ..., 170., 163., 158.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:46

analyse the exceptions in iter:51
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:47

analyse the exceptions in iter:52
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:48

analyse the exceptions in iter:53
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[157., 156., 157., ..., 177., 177., 175.],
          [162., 162., 162., ..., 187., 182., 179.],
          [165., 164., 165., ..., 211., 204., 191.],
          ...,
          [172., 168., 166., ..., 203., 203., 200.],
          [177., 175., 172., ..., 203., 203., 200.],
          [182., 182., 179., ..., 203., 203., 200.]],

         [[159., 158., 159., ..., 183., 180., 179.],
          [164., 164., 164., ..., 194., 187., 183.],
          [167., 166., 167., ..., 220., 210., 196.],
          ...,
          [174., 170., 167., ..., 205., 205., 202.],
          [179., 177., 173., ..., 205., 205., 202.],
          [184., 183., 180., ..., 205., 205., 202.]],

         [[146., 145., 146., ..., 185., 183., 179.],
          [151., 151., 151., ..., 200., 193., 186.],
          [154., 153., 154., ..., 226., 219., 201.],
          ...,
          [161., 158., 158., ..., 201., 201., 199.],
          [166., 166., 164., ..., 202., 202., 199.],
          [171., 174., 173., ..., 202., 202., 199.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:49

analyse the exceptions in iter:54
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  47.,  48., ...,  50.,  47.,  46.],
          [ 45.,  47.,  48., ...,  55.,  51.,  51.],
          [ 45.,  46.,  47., ...,  60.,  56.,  55.],
          ...,
          [ 50.,  50.,  51., ...,  97.,  79.,  76.],
          [ 50.,  49.,  51., ...,  81., 103.,  72.],
          [ 50.,  50.,  51., ...,  83.,  90.,  88.]],

         [[ 73.,  75.,  76., ...,  73.,  69.,  70.],
          [ 72.,  74.,  75., ...,  77.,  74.,  75.],
          [ 71.,  72.,  73., ...,  83.,  80.,  80.],
          ...,
          [ 76.,  78.,  78., ..., 118., 112., 104.],
          [ 76.,  77.,  78., ...,  92., 121., 101.],
          [ 75.,  78.,  77., ...,  91., 100., 110.]],

         [[ 28.,  30.,  33., ...,  28.,  29.,  31.],
          [ 27.,  29.,  32., ...,  32.,  31.,  32.],
          [ 29.,  30.,  31., ...,  36.,  34.,  34.],
          ...,
          [ 34.,  34.,  35., ...,  99.,  50.,  49.],
          [ 34.,  34.,  35., ..., 105., 100.,  44.],
          [ 35.,  33.,  35., ..., 100., 106.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:50

analyse the exceptions in iter:55
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[156., 167., 169., ..., 243., 230., 208.],
          [174., 192., 172., ..., 237., 213., 186.],
          [192., 194., 174., ..., 226., 198., 195.],
          ...,
          [187., 211., 231., ..., 210., 217., 203.],
          [231., 220., 200., ..., 183., 189., 186.],
          [238., 238., 229., ..., 141., 151., 157.]],

         [[194., 212., 215., ..., 247., 235., 215.],
          [210., 229., 204., ..., 243., 221., 193.],
          [234., 230., 201., ..., 231., 208., 200.],
          ...,
          [211., 234., 244., ..., 204., 208., 192.],
          [238., 236., 219., ..., 170., 175., 169.],
          [242., 247., 239., ..., 126., 137., 141.]],

         [[129., 127., 129., ..., 226., 206., 180.],
          [147., 159., 163., ..., 223., 200., 169.],
          [145., 178., 194., ..., 218., 186., 165.],
          ...,
          [151., 180., 221., ..., 199., 210., 192.],
          [218., 209., 177., ..., 153., 160., 153.],
          [224., 232., 217., ..., 106., 117., 118.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:51

analyse the exceptions in iter:56
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[141., 139., 136., ..., 228., 228., 229.],
          [148., 150., 148., ..., 228., 228., 228.],
          [149., 149., 148., ..., 230., 229., 229.],
          ...,
          [125., 124., 139., ..., 220., 199., 208.],
          [126., 116., 135., ..., 246., 226., 196.],
          [143., 145., 169., ..., 254., 255., 227.]],

         [[ 70.,  61.,  55., ..., 198., 199., 200.],
          [ 71.,  67.,  64., ..., 197., 196., 197.],
          [ 72.,  66.,  64., ..., 197., 197., 197.],
          ...,
          [100., 102., 110., ..., 169., 143., 149.],
          [101.,  93., 107., ..., 205., 181., 145.],
          [105., 107., 127., ..., 208., 206., 174.]],

         [[  8.,   2.,   0., ..., 155., 156., 157.],
          [ 10.,   5.,   2., ..., 153., 152., 153.],
          [ 17.,   7.,   4., ..., 151., 151., 151.],
          ...,
          [ 73.,  80.,  75., ..., 109.,  86.,  93.],
          [ 75.,  71.,  73., ..., 144., 121.,  87.],
          [ 67.,  71.,  83., ..., 141., 138., 105.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:52

analyse the exceptions in iter:57
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 66.,  71.,  88., ...,  85.,  86.,  79.],
          [ 75.,  79.,  95., ...,  85.,  87.,  78.],
          [ 80.,  84.,  97., ...,  81.,  82.,  74.],
          ...,
          [ 79.,  87.,  60., ...,  35.,  26.,  20.],
          [ 77.,  70.,  37., ...,  79.,  77.,  66.],
          [ 78.,  63.,  31., ..., 140., 135., 128.]],

         [[ 73.,  77.,  86., ...,  80.,  81.,  73.],
          [ 81.,  84.,  92., ...,  79.,  80.,  72.],
          [ 85.,  88.,  93., ...,  75.,  74.,  68.],
          ...,
          [ 74.,  84.,  58., ...,  35.,  26.,  21.],
          [ 74.,  68.,  37., ...,  68.,  66.,  55.],
          [ 74.,  61.,  32., ..., 122., 117., 113.]],

         [[ 33.,  40.,  62., ...,  55.,  62.,  54.],
          [ 40.,  45.,  66., ...,  56.,  62.,  54.],
          [ 44.,  50.,  68., ...,  48.,  53.,  51.],
          ...,
          [ 59.,  69.,  43., ...,  22.,  14.,  10.],
          [ 59.,  53.,  22., ...,  60.,  58.,  50.],
          [ 58.,  44.,  15., ..., 116., 113., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:53

analyse the exceptions in iter:58
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 97.,  96., 108., ..., 130., 117., 115.],
          [111., 104., 111., ..., 138., 128., 124.],
          [135., 132., 128., ..., 136., 130., 121.],
          ...,
          [124., 120., 126., ..., 114., 118., 119.],
          [126., 123., 125., ...,  96., 102., 102.],
          [124., 124., 126., ...,  97.,  96.,  81.]],

         [[ 83.,  84.,  98., ..., 113., 100., 100.],
          [ 97.,  91.,  99., ..., 121., 112., 111.],
          [120., 116., 113., ..., 119., 113., 109.],
          ...,
          [109., 104., 109., ...,  99., 105., 104.],
          [108., 106., 108., ...,  82.,  89.,  88.],
          [106., 107., 109., ...,  83.,  84.,  69.]],

         [[ 41.,  46.,  56., ...,  60.,  48.,  48.],
          [ 49.,  45.,  49., ...,  66.,  57.,  57.],
          [ 68.,  65.,  57., ...,  63.,  58.,  54.],
          ...,
          [ 55.,  51.,  57., ...,  57.,  61.,  55.],
          [ 54.,  52.,  53., ...,  44.,  49.,  46.],
          [ 52.,  53.,  55., ...,  42.,  45.,  36.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:54

analyse the exceptions in iter:59
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 255., 194., ..., 255., 255., 253.],
          [251., 255., 211., ..., 246., 249., 251.],
          [251., 255., 218., ..., 249., 250., 252.],
          ...,
          [ 57.,  30.,  73., ...,  23.,  26., 112.],
          [ 89.,  16.,  26., ...,  21.,  32., 149.],
          [185.,  94.,  54., ...,  60., 129., 221.]],

         [[251., 255., 212., ..., 254., 253., 252.],
          [249., 255., 234., ..., 255., 255., 252.],
          [250., 255., 235., ..., 255., 254., 253.],
          ...,
          [111.,  86.,  88., ...,  60.,  81., 149.],
          [134.,  77.,  74., ...,  75.,  83., 174.],
          [208., 134.,  99., ..., 104., 159., 232.]],

         [[249., 255., 224., ..., 253., 252., 252.],
          [246., 254., 240., ..., 251., 252., 251.],
          [249., 255., 240., ..., 254., 252., 252.],
          ...,
          [159., 138., 110., ..., 100., 139., 186.],
          [177., 144., 136., ..., 140., 145., 198.],
          [229., 182., 159., ..., 159., 197., 240.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:55

analyse the exceptions in iter:60
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[201., 191., 194., ...,  83.,  39.,  36.],
          [ 57.,  62., 134., ...,  79.,  48.,  35.],
          [ 74., 123., 138., ..., 162., 132.,  56.],
          ...,
          [ 67.,  62.,  55., ...,  69.,  72.,  72.],
          [ 73.,  67.,  59., ...,  72.,  72.,  71.],
          [ 74.,  71.,  67., ...,  61.,  58.,  63.]],

         [[209., 204., 207., ...,  88.,  48.,  47.],
          [ 73.,  78., 148., ...,  91.,  59.,  45.],
          [ 99., 142., 153., ..., 175., 139.,  61.],
          ...,
          [ 80.,  72.,  62., ...,  78.,  80.,  82.],
          [ 87.,  77.,  67., ...,  81.,  81.,  81.],
          [ 89.,  84.,  79., ...,  73.,  69.,  75.]],

         [[211., 210., 216., ...,  82.,  33.,  24.],
          [ 79.,  92., 161., ...,  96.,  57.,  32.],
          [110., 165., 169., ..., 186., 145.,  56.],
          ...,
          [ 89.,  82.,  73., ...,  93.,  95.,  98.],
          [ 95.,  87.,  77., ...,  96.,  96.,  96.],
          [100.,  95.,  89., ...,  88.,  85.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:56

analyse the exceptions in iter:61
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[114., 117., 120., ..., 165., 125., 103.],
          [111., 116., 121., ..., 162., 127., 103.],
          [114., 121., 128., ..., 167., 132., 106.],
          ...,
          [165., 170., 175., ..., 185., 207., 201.],
          [175., 175., 180., ..., 187., 200., 193.],
          [173., 171., 177., ..., 205., 210., 202.]],

         [[119., 122., 126., ..., 166., 126., 103.],
          [116., 121., 126., ..., 163., 128., 103.],
          [119., 125., 132., ..., 168., 133., 108.],
          ...,
          [166., 171., 176., ..., 179., 199., 193.],
          [176., 176., 181., ..., 182., 194., 186.],
          [174., 172., 178., ..., 200., 204., 195.]],

         [[125., 126., 129., ..., 160., 121., 110.],
          [122., 127., 133., ..., 157., 123., 109.],
          [125., 136., 142., ..., 162., 126., 102.],
          ...,
          [161., 167., 171., ..., 168., 194., 185.],
          [171., 171., 176., ..., 162., 181., 178.],
          [169., 167., 173., ..., 182., 192., 187.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:57

analyse the exceptions in iter:62
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 76.,  73.,  69., ...,  75.,  72.,  70.],
          [ 76.,  71.,  66., ...,  79.,  76.,  75.],
          [ 71.,  65.,  62., ...,  80.,  77.,  76.],
          ...,
          [ 11.,   9.,   6., ...,  31.,  32.,  29.],
          [  0.,   0.,   0., ...,  12.,  12.,  13.],
          [ 87.,  83.,  81., ...,  99.,  99., 102.]],

         [[118., 118., 116., ..., 135., 134., 135.],
          [122., 119., 117., ..., 136., 135., 137.],
          [120., 117., 116., ..., 133., 132., 135.],
          ...,
          [ 36.,  32.,  32., ...,  61.,  62.,  59.],
          [ 19.,  13.,   7., ...,  38.,  37.,  38.],
          [100.,  92.,  86., ..., 116., 115., 119.]],

         [[167., 164., 162., ..., 180., 178., 179.],
          [170., 166., 163., ..., 178., 177., 179.],
          [170., 165., 164., ..., 173., 172., 174.],
          ...,
          [ 66.,  61.,  61., ...,  79.,  80.,  77.],
          [ 46.,  40.,  36., ...,  55.,  55.,  56.],
          [115., 108., 103., ..., 127., 127., 130.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:58

analyse the exceptions in iter:63
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  70.,  76., ...,  33.,  59.,  62.],
          [ 71.,  78.,  87., ...,  23.,  65.,  74.],
          [ 69.,  77.,  82., ...,  19.,  67.,  83.],
          ...,
          [ 14.,  14.,  14., ...,  54.,  54.,  52.],
          [ 14.,  14.,  14., ...,  53.,  45.,  38.],
          [ 14.,  14.,  14., ...,  49.,  31.,  21.]],

         [[114., 121., 129., ...,  47.,  62.,  66.],
          [120., 129., 140., ...,  30.,  62.,  72.],
          [118., 129., 137., ...,  20.,  57.,  73.],
          ...,
          [ 14.,  14.,  14., ...,  76.,  80.,  81.],
          [ 14.,  14.,  14., ...,  76.,  69.,  63.],
          [ 14.,  14.,  14., ...,  72.,  51.,  39.]],

         [[ 54.,  62.,  71., ...,  42.,  53.,  56.],
          [ 57.,  65.,  75., ...,  24.,  51.,  57.],
          [ 53.,  60.,  63., ...,  13.,  49.,  66.],
          ...,
          [ 14.,  14.,  14., ...,  45.,  42.,  46.],
          [ 14.,  14.,  14., ...,  46.,  37.,  34.],
          [ 14.,  14.,  14., ...,  45.,  30.,  21.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:59

analyse the exceptions in iter:64
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  67.,  69., ...,  93., 108., 102.],
          [ 65.,  65.,  69., ..., 104., 122., 132.],
          [ 62.,  63.,  68., ..., 122., 146., 140.],
          ...,
          [ 88.,  90.,  95., ...,  83.,  89.,  92.],
          [ 90.,  94.,  98., ...,  75.,  78.,  85.],
          [ 95., 102., 104., ...,  74.,  79.,  84.]],

         [[ 29.,  32.,  35., ...,  73.,  87.,  81.],
          [ 29.,  30.,  34., ...,  83.,  97., 106.],
          [ 27.,  28.,  32., ...,  99., 118., 114.],
          ...,
          [ 76.,  79.,  85., ...,  85.,  93.,  97.],
          [ 79.,  83.,  87., ...,  66.,  74.,  86.],
          [ 84.,  90.,  94., ...,  62.,  70.,  78.]],

         [[ 29.,  30.,  33., ...,  70.,  82.,  74.],
          [ 29.,  28.,  32., ...,  78.,  90.,  98.],
          [ 25.,  24.,  30., ...,  93., 110., 104.],
          ...,
          [ 84.,  86.,  92., ...,  99., 108., 111.],
          [ 85.,  90.,  95., ...,  71.,  83.,  97.],
          [ 92.,  98., 102., ...,  62.,  73.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:60

analyse the exceptions in iter:65
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[148., 132., 134., ..., 124., 108., 124.],
          [197., 168., 176., ..., 176., 162., 141.],
          [199., 199., 213., ..., 182., 178., 153.],
          ...,
          [179., 183., 182., ..., 164., 147., 136.],
          [162., 146., 127., ..., 118., 118., 132.],
          [150., 143., 123., ..., 124., 126., 157.]],

         [[141., 128., 135., ..., 131., 109., 127.],
          [181., 151., 166., ..., 178., 157., 133.],
          [194., 191., 209., ..., 186., 175., 141.],
          ...,
          [170., 165., 166., ..., 144., 127., 119.],
          [156., 133., 116., ..., 100.,  99., 116.],
          [148., 141., 125., ..., 119., 121., 154.]],

         [[174., 173., 187., ..., 186., 166., 171.],
          [214., 185., 199., ..., 213., 191., 162.],
          [207., 193., 209., ..., 193., 178., 156.],
          ...,
          [170., 148., 145., ..., 121., 106., 130.],
          [173., 140., 122., ..., 106., 108., 138.],
          [184., 176., 161., ..., 162., 162., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:61

analyse the exceptions in iter:66
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[212., 208., 210., ..., 201., 195., 181.],
          [158., 141., 149., ..., 133., 120., 112.],
          [154., 135., 144., ..., 120., 117., 123.],
          ...,
          [124., 109., 106., ...,  99.,  94., 104.],
          [121., 103.,  97., ...,  81.,  79.,  94.],
          [188., 176., 170., ..., 182., 181., 187.]],

         [[189., 182., 183., ..., 190., 182., 166.],
          [135., 116., 122., ..., 125., 106.,  96.],
          [135., 119., 126., ..., 113., 105., 111.],
          ...,
          [146., 138., 136., ..., 127., 122., 126.],
          [149., 135., 128., ..., 115., 113., 119.],
          [189., 180., 175., ..., 182., 181., 185.]],

         [[148., 146., 146., ..., 146., 144., 135.],
          [102.,  91.,  96., ...,  90.,  80.,  75.],
          [102.,  90.,  91., ...,  83.,  87.,  87.],
          ...,
          [148., 143., 142., ..., 134., 132., 134.],
          [140., 142., 134., ..., 123., 123., 125.],
          [155., 152., 148., ..., 156., 154., 159.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:62

analyse the exceptions in iter:67
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[221., 214., 216., ..., 213., 211., 211.],
          [206., 201., 222., ..., 217., 215., 216.],
          [199., 205., 226., ..., 219., 218., 218.],
          ...,
          [167., 152., 152., ..., 134., 135., 140.],
          [149., 143., 142., ..., 141., 142., 142.],
          [134., 129., 129., ..., 138., 137., 135.]],

         [[208., 203., 209., ..., 206., 204., 204.],
          [192., 190., 214., ..., 211., 209., 209.],
          [184., 192., 216., ..., 213., 212., 212.],
          ...,
          [135., 117., 111., ...,  96.,  97., 102.],
          [115., 106., 103., ..., 103., 104., 104.],
          [ 98.,  93.,  92., ..., 101.,  99.,  98.]],

         [[248., 243., 247., ..., 248., 246., 246.],
          [230., 227., 250., ..., 251., 249., 249.],
          [219., 226., 249., ..., 249., 247., 248.],
          ...,
          [163., 149., 148., ..., 136., 138., 143.],
          [144., 139., 140., ..., 143., 145., 145.],
          [127., 125., 128., ..., 141., 140., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:63

analyse the exceptions in iter:68
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 103., 104., ..., 102.,  94.,  99.],
          [125., 119., 120., ..., 108., 104., 110.],
          [113.,  73.,  80., ...,  47.,  78., 103.],
          ...,
          [102., 125., 190., ...,  86.,  69.,  92.],
          [120., 141., 194., ...,  81.,  85., 109.],
          [159., 166., 163., ...,  98., 110., 100.]],

         [[125., 128., 130., ..., 121., 121., 120.],
          [151., 157., 160., ..., 137., 144., 145.],
          [136., 102., 107., ...,  72., 117., 141.],
          ...,
          [ 77.,  88., 159., ...,  72.,  57.,  70.],
          [ 92., 100., 163., ...,  68.,  77., 101.],
          [133., 127., 132., ...,  85., 105., 102.]],

         [[141., 147., 145., ..., 130., 132., 129.],
          [167., 181., 185., ..., 145., 155., 156.],
          [148., 122., 127., ...,  76., 124., 151.],
          ...,
          [ 37.,  49., 132., ...,  48.,  37.,  40.],
          [ 49.,  52., 124., ...,  34.,  39.,  59.],
          [ 96.,  79.,  90., ...,  57.,  64.,  67.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:64

analyse the exceptions in iter:69
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[151., 150., 151., ..., 151., 151., 151.],
          [153., 152., 153., ..., 153., 153., 153.],
          [152., 151., 152., ..., 152., 151., 151.],
          ...,
          [100.,  99., 103., ...,  93.,  98.,  98.],
          [ 96.,  94.,  93., ...,  98.,  99.,  99.],
          [ 94.,  94.,  92., ..., 100., 100., 101.]],

         [[158., 157., 158., ..., 158., 157., 157.],
          [160., 159., 160., ..., 160., 160., 160.],
          [159., 158., 159., ..., 159., 158., 158.],
          ...,
          [106., 105., 109., ...,  99., 104., 104.],
          [102., 100.,  99., ..., 104., 105., 105.],
          [100., 100.,  98., ..., 106., 106., 107.]],

         [[168., 167., 167., ..., 164., 163., 163.],
          [170., 169., 170., ..., 166., 166., 166.],
          [169., 168., 168., ..., 164., 164., 164.],
          ...,
          [102., 101., 105., ...,  95., 100., 100.],
          [ 98.,  96.,  95., ..., 100., 101., 101.],
          [ 96.,  96.,  94., ..., 102., 102., 103.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:65

analyse the exceptions in iter:70
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 159., 165., ..., 129., 125., 122.],
          [156., 160., 163., ..., 118., 120., 118.],
          [146., 130., 128., ..., 118., 112., 107.],
          ...,
          [125., 126., 124., ..., 123., 126., 131.],
          [125., 127., 125., ..., 120., 128., 129.],
          [119., 121., 135., ..., 132., 136., 146.]],

         [[179., 183., 189., ..., 161., 158., 155.],
          [177., 180., 184., ..., 150., 152., 150.],
          [169., 152., 151., ..., 150., 144., 139.],
          ...,
          [146., 147., 146., ..., 141., 140., 144.],
          [145., 148., 146., ..., 137., 142., 141.],
          [136., 138., 153., ..., 148., 149., 157.]],

         [[152., 157., 162., ..., 137., 133., 131.],
          [152., 155., 159., ..., 126., 128., 126.],
          [143., 126., 125., ..., 126., 120., 115.],
          ...,
          [129., 127., 124., ..., 117., 118., 122.],
          [127., 128., 124., ..., 119., 125., 125.],
          [120., 119., 132., ..., 135., 137., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:66

analyse the exceptions in iter:71
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 104.,  81., ..., 163., 210., 250.],
          [103.,   5.,   0., ...,  27.,  68., 185.],
          [163.,  23.,   1., ...,  69.,  90., 159.],
          ...,
          [235., 165., 104., ...,  55.,  87., 162.],
          [255., 231., 147., ...,  35.,  60., 189.],
          [255., 252., 240., ...,  87., 120., 215.]],

         [[170., 109.,  88., ..., 169., 214., 250.],
          [104.,   8.,   0., ...,  29.,  69., 185.],
          [163.,  25.,   3., ...,  67.,  88., 158.],
          ...,
          [235., 167., 108., ...,  60.,  91., 165.],
          [255., 231., 149., ...,  39.,  63., 191.],
          [255., 252., 240., ...,  89., 122., 216.]],

         [[164.,  98.,  82., ..., 159., 201., 242.],
          [ 93.,   0.,   0., ...,  21.,  56., 174.],
          [150.,  18.,   1., ...,  59.,  76., 147.],
          ...,
          [232., 153.,  83., ...,  28.,  63., 149.],
          [255., 226., 136., ...,  21.,  44., 179.],
          [255., 251., 237., ...,  82., 111., 207.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:67

analyse the exceptions in iter:72
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[229., 227., 208., ..., 230., 230., 213.],
          [221., 214., 145., ..., 236., 231., 201.],
          [213., 173.,  64., ..., 242., 222., 187.],
          ...,
          [224., 218., 229., ..., 190., 159., 176.],
          [224., 207., 226., ..., 162., 132., 170.],
          [233., 217., 221., ..., 153., 141., 167.]],

         [[232., 232., 214., ..., 231., 232., 218.],
          [226., 221., 150., ..., 238., 233., 207.],
          [223., 181.,  67., ..., 243., 225., 195.],
          ...,
          [224., 218., 229., ..., 193., 163., 183.],
          [224., 207., 226., ..., 165., 136., 178.],
          [233., 217., 221., ..., 156., 145., 175.]],

         [[235., 232., 219., ..., 231., 236., 223.],
          [234., 225., 157., ..., 237., 237., 214.],
          [232., 187.,  69., ..., 243., 229., 203.],
          ...,
          [222., 217., 229., ..., 199., 173., 194.],
          [223., 207., 226., ..., 173., 147., 189.],
          [233., 217., 221., ..., 164., 154., 184.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:68

analyse the exceptions in iter:73
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 64.,  72.,  73., ...,  73.,  52.,  51.],
          [ 77.,  78.,  64., ...,  56.,  42.,  43.],
          [ 90.,  87.,  69., ...,  60.,  47.,  45.],
          ...,
          [154., 159., 159., ..., 129., 131., 126.],
          [144., 143., 138., ..., 160., 159., 153.],
          [ 93.,  94.,  92., ..., 116., 115., 110.]],

         [[ 45.,  52.,  60., ...,  70.,  53.,  45.],
          [ 55.,  58.,  50., ...,  52.,  44.,  40.],
          [ 71.,  74.,  61., ...,  57.,  50.,  44.],
          ...,
          [137., 143., 142., ..., 128., 130., 126.],
          [141., 141., 136., ..., 157., 154., 149.],
          [ 93.,  94.,  90., ..., 107., 106., 102.]],

         [[ 13.,  23.,  41., ...,  30.,  20.,  31.],
          [ 28.,  36.,  38., ...,  24.,  18.,  25.],
          [ 35.,  46.,  40., ...,  40.,  30.,  30.],
          ...,
          [109., 115., 114., ...,  77.,  84.,  76.],
          [131., 131., 127., ..., 141., 144., 136.],
          [ 77.,  75.,  74., ...,  90.,  90.,  81.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:69

analyse the exceptions in iter:74
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[195., 165., 150., ..., 135., 120., 120.],
          [174., 117., 145., ..., 134., 103., 117.],
          [125.,  97., 131., ..., 129., 100., 104.],
          ...,
          [122., 125., 118., ...,  91.,  83.,  73.],
          [132., 130., 136., ...,  85.,  86.,  91.],
          [143., 137., 143., ...,  85., 107., 145.]],

         [[208., 177., 161., ..., 189., 185., 184.],
          [190., 134., 159., ..., 182., 162., 188.],
          [143., 120., 150., ..., 167., 146., 165.],
          ...,
          [146., 149., 142., ..., 118., 111.,  96.],
          [157., 155., 160., ..., 111., 113., 113.],
          [172., 165., 169., ..., 107., 127., 160.]],

         [[166., 138., 140., ..., 143., 119., 118.],
          [160., 115., 154., ..., 125.,  96., 129.],
          [125., 115., 150., ..., 120.,  97., 123.],
          ...,
          [146., 149., 142., ..., 122., 114.,  93.],
          [158., 155., 161., ..., 113., 115., 109.],
          [179., 167., 174., ..., 107., 125., 154.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:70

analyse the exceptions in iter:75
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  76., 188., ..., 146., 162., 150.],
          [ 37.,  68., 187., ..., 148., 137., 161.],
          [ 31.,  67., 177., ..., 139., 143., 178.],
          ...,
          [114., 114., 113., ..., 106., 107., 109.],
          [106., 106., 106., ..., 107., 107., 108.],
          [ 99., 105., 110., ..., 106., 107., 108.]],

         [[ 64.,  78., 187., ..., 117., 135., 130.],
          [ 41.,  70., 185., ..., 117., 115., 155.],
          [ 37.,  73., 175., ..., 110., 121., 143.],
          ...,
          [114., 114., 114., ..., 106., 107., 109.],
          [106., 106., 106., ..., 107., 107., 108.],
          [ 99., 104., 110., ..., 106., 107., 108.]],

         [[ 58.,  73., 185., ..., 110., 130., 122.],
          [ 42.,  72., 182., ..., 106., 112., 149.],
          [ 42.,  67., 169., ...,  97., 102., 134.],
          ...,
          [115., 114., 112., ..., 106., 107., 109.],
          [110., 109., 108., ..., 107., 107., 109.],
          [102., 107., 114., ..., 107., 108., 110.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:71

analyse the exceptions in iter:76
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[118., 110., 118., ..., 114., 114., 113.],
          [ 84.,  88., 120., ..., 113., 114., 115.],
          [ 85.,  99., 131., ..., 120., 120., 119.],
          ...,
          [155., 152., 151., ..., 105.,  82., 127.],
          [154., 155., 156., ..., 150., 142., 139.],
          [153., 152., 154., ..., 145., 148., 146.]],

         [[157., 162., 172., ..., 161., 161., 161.],
          [120., 136., 173., ..., 165., 164., 163.],
          [117., 141., 183., ..., 168., 168., 167.],
          ...,
          [158., 156., 155., ..., 106.,  84., 129.],
          [155., 157., 158., ..., 152., 145., 142.],
          [155., 155., 156., ..., 147., 150., 149.]],

         [[187., 196., 219., ..., 207., 207., 207.],
          [147., 168., 218., ..., 217., 216., 212.],
          [142., 171., 225., ..., 216., 215., 213.],
          ...,
          [142., 136., 133., ...,  87.,  63., 105.],
          [138., 137., 136., ..., 130., 120., 113.],
          [143., 139., 139., ..., 128., 127., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:72

analyse the exceptions in iter:77
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 44.,  47.,  51., ...,  75.,  72.,  74.],
          [ 52.,  47.,  51., ...,  73.,  74.,  76.],
          [ 65.,  57.,  54., ...,  73.,  73.,  75.],
          ...,
          [ 56.,  49.,  49., ...,  53.,  52.,  53.],
          [ 41.,  56.,  52., ...,  52.,  52.,  49.],
          [ 24.,  49.,  40., ...,  54.,  55.,  46.]],

         [[ 73.,  77.,  81., ..., 107., 104., 106.],
          [ 85.,  79.,  82., ..., 105., 106., 108.],
          [100.,  91.,  87., ..., 105., 105., 108.],
          ...,
          [ 82.,  75.,  74., ...,  77.,  77.,  77.],
          [ 64.,  79.,  75., ...,  74.,  74.,  72.],
          [ 44.,  69.,  60., ...,  74.,  74.,  66.]],

         [[ 49.,  53.,  57., ...,  83.,  80.,  82.],
          [ 55.,  54.,  60., ...,  81.,  82.,  84.],
          [ 67.,  65.,  66., ...,  81.,  81.,  82.],
          ...,
          [ 48.,  41.,  41., ...,  49.,  48.,  49.],
          [ 35.,  50.,  46., ...,  49.,  49.,  46.],
          [ 19.,  44.,  36., ...,  51.,  52.,  43.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:73

analyse the exceptions in iter:79
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[248., 248., 250., ..., 253., 239., 169.],
          [246., 248., 249., ..., 251., 249., 102.],
          [228., 237., 213., ..., 252., 247., 103.],
          ...,
          [251., 248., 243., ..., 254., 252., 101.],
          [249., 250., 250., ..., 255., 251., 101.],
          [ 90.,  65.,  67., ...,  64.,  63.,  25.]],

         [[248., 248., 250., ..., 253., 239., 169.],
          [246., 248., 249., ..., 251., 249., 102.],
          [228., 237., 212., ..., 251., 247., 103.],
          ...,
          [251., 248., 243., ..., 254., 252., 101.],
          [249., 250., 250., ..., 255., 251., 101.],
          [ 90.,  65.,  67., ...,  64.,  63.,  25.]],

         [[247., 247., 248., ..., 253., 239., 169.],
          [245., 248., 250., ..., 251., 249., 102.],
          [227., 238., 216., ..., 252., 247., 103.],
          ...,
          [251., 248., 243., ..., 254., 252., 101.],
          [249., 250., 250., ..., 255., 251., 101.],
          [ 90.,  65.,  67., ...,  64.,  63.,  25.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:74

analyse the exceptions in iter:80
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 76.,  78.,  79., ..., 104., 105., 106.],
          [ 78.,  79.,  79., ..., 109., 110., 111.],
          [ 97.,  88.,  85., ..., 114., 114., 115.],
          ...,
          [101., 116., 121., ..., 186., 178., 176.],
          [134., 145., 150., ..., 176., 179., 175.],
          [150., 153., 154., ..., 178., 179., 179.]],

         [[112., 114., 114., ..., 135., 136., 137.],
          [114., 118., 119., ..., 138., 139., 140.],
          [119., 118., 119., ..., 142., 142., 143.],
          ...,
          [101., 116., 121., ..., 181., 171., 168.],
          [134., 146., 150., ..., 172., 174., 170.],
          [150., 153., 154., ..., 174., 175., 175.]],

         [[159., 162., 161., ..., 182., 183., 183.],
          [159., 161., 160., ..., 183., 183., 184.],
          [155., 161., 168., ..., 185., 186., 186.],
          ...,
          [112., 126., 130., ..., 176., 168., 166.],
          [140., 150., 154., ..., 169., 172., 169.],
          [150., 153., 154., ..., 172., 175., 176.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:75

analyse the exceptions in iter:82
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[121., 134., 135., ...,  95.,  92.,  95.],
          [ 84., 113., 125., ...,  91.,  87.,  90.],
          [ 68., 101., 114., ...,  92.,  98.,  94.],
          ...,
          [112.,  87.,  93., ..., 112., 116., 125.],
          [ 83.,  88.,  87., ..., 122., 129., 113.],
          [ 82., 102.,  85., ..., 112., 104.,  94.]],

         [[154., 163., 166., ..., 125., 126., 128.],
          [119., 142., 152., ..., 123., 121., 123.],
          [107., 135., 146., ..., 126., 130., 128.],
          ...,
          [141., 118., 127., ..., 124., 140., 148.],
          [115., 122., 117., ..., 131., 152., 137.],
          [119., 137., 109., ..., 131., 126., 120.]],

         [[106., 130., 137., ...,  67.,  72.,  72.],
          [ 85., 115., 110., ...,  65.,  64.,  64.],
          [ 60.,  89.,  74., ...,  63.,  64.,  59.],
          ...,
          [117.,  87.,  78., ..., 103.,  74.,  93.],
          [ 91.,  90.,  59., ...,  98.,  75.,  83.],
          [ 89., 104.,  60., ...,  79.,  91.,  79.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:76

analyse the exceptions in iter:83
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 87.,  95.,  95., ..., 103., 114.,  93.],
          [ 85.,  92.,  93., ..., 105., 115.,  92.],
          [ 82.,  89.,  89., ..., 107., 115.,  90.],
          ...,
          [ 50.,  51.,  50., ...,  45.,  49.,  37.],
          [ 53.,  53.,  52., ...,  49.,  56.,  40.],
          [ 52.,  54.,  55., ...,  69.,  71.,  51.]],

         [[145., 157., 156., ..., 163., 172., 138.],
          [141., 153., 154., ..., 166., 174., 138.],
          [137., 148., 149., ..., 166., 174., 137.],
          ...,
          [ 82.,  84.,  83., ...,  71.,  70.,  51.],
          [ 85.,  87.,  86., ...,  69.,  71.,  51.],
          [ 81.,  86.,  87., ...,  92.,  91.,  67.]],

         [[207., 221., 220., ..., 221., 233., 185.],
          [207., 220., 220., ..., 221., 235., 185.],
          [204., 216., 217., ..., 223., 231., 182.],
          ...,
          [132., 136., 135., ...,  99.,  78.,  52.],
          [126., 129., 128., ...,  82.,  62.,  41.],
          [113., 119., 121., ...,  93.,  82.,  58.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:77

analyse the exceptions in iter:84
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[103.,  89.,  78., ..., 112., 124., 144.],
          [ 95.,  76.,  52., ..., 126., 127., 147.],
          [ 78.,  70.,  41., ..., 160., 146., 158.],
          ...,
          [161., 154., 155., ..., 121., 120., 119.],
          [124., 122., 128., ..., 125., 139., 149.],
          [142., 144., 143., ..., 158., 165., 172.]],

         [[ 93.,  84.,  79., ..., 114., 120., 126.],
          [ 81.,  67.,  50., ..., 119., 114., 121.],
          [ 69.,  64.,  37., ..., 158., 142., 140.],
          ...,
          [176., 173., 173., ..., 141., 136., 126.],
          [143., 147., 151., ..., 130., 143., 149.],
          [138., 144., 142., ..., 160., 168., 175.]],

         [[ 68.,  59.,  59., ...,  79.,  91., 112.],
          [ 59.,  52.,  44., ...,  81.,  82., 109.],
          [ 58.,  62.,  44., ..., 103.,  91., 109.],
          ...,
          [105.,  96.,  97., ...,  86.,  85.,  82.],
          [ 89.,  87.,  98., ...,  79.,  91.,  98.],
          [ 90.,  92.,  93., ..., 105., 111., 113.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:78

analyse the exceptions in iter:85
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 1.,  1.,  1., ..., 12.,  6.,  4.],
          [ 1.,  1.,  1., ...,  9.,  2.,  1.],
          [ 1.,  1.,  1., ...,  5.,  1.,  1.],
          ...,
          [ 1.,  0., 51., ..., 48., 48., 45.],
          [ 1.,  0., 63., ..., 49., 48., 47.],
          [ 2.,  0., 43., ..., 47., 46., 48.]],

         [[ 1.,  1.,  1., ..., 15.,  7.,  4.],
          [ 1.,  1.,  1., ..., 12.,  3.,  1.],
          [ 1.,  1.,  1., ...,  8.,  2.,  1.],
          ...,
          [ 4.,  0., 34., ..., 42., 40., 36.],
          [ 2.,  0., 41., ..., 43., 40., 38.],
          [ 2.,  0., 25., ..., 42., 38., 39.]],

         [[ 1.,  1.,  1., ..., 20.,  8.,  4.],
          [ 1.,  1.,  1., ..., 17.,  5.,  1.],
          [ 1.,  1.,  1., ..., 12.,  3.,  1.],
          ...,
          [ 0.,  0., 34., ..., 40., 41., 37.],
          [ 1.,  0., 43., ..., 41., 40., 39.],
          [ 3.,  0., 27., ..., 39., 38., 40.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:79

analyse the exceptions in iter:86
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[107.,  67.,  26., ...,  89.,  72.,  73.],
          [107.,  63.,  28., ...,  93.,  81.,  91.],
          [106.,  67.,  42., ...,  88.,  84.,  93.],
          ...,
          [148., 155., 159., ..., 142., 144., 144.],
          [146., 147., 150., ..., 151., 147., 145.],
          [141., 139., 136., ..., 149., 148., 147.]],

         [[104.,  65.,  33., ..., 102.,  70.,  69.],
          [ 98.,  59.,  33., ..., 104.,  86.,  93.],
          [103.,  63.,  48., ...,  96.,  91.,  94.],
          ...,
          [172., 176., 177., ..., 165., 166., 163.],
          [171., 173., 172., ..., 176., 173., 169.],
          [165., 164., 162., ..., 173., 172., 171.]],

         [[ 85.,  53.,  23., ...,  74.,  55.,  57.],
          [ 94.,  53.,  27., ...,  75.,  62.,  73.],
          [ 85.,  57.,  39., ...,  66.,  66.,  76.],
          ...,
          [119., 128., 132., ..., 113., 113., 114.],
          [116., 120., 122., ..., 119., 112., 114.],
          [112., 111., 105., ..., 116., 118., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:80

analyse the exceptions in iter:87
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 39.,  40.,  41., ...,  25.,  25.,  31.],
          [ 37.,  42.,  44., ...,  28.,  30.,  29.],
          [ 34.,  38.,  44., ...,  32.,  33.,  36.],
          ...,
          [169., 164., 171., ..., 172., 162., 173.],
          [166., 157., 169., ..., 178., 176., 178.],
          [167., 171., 175., ..., 186., 186., 182.]],

         [[ 50.,  55.,  59., ...,  29.,  29.,  37.],
          [ 48.,  56.,  63., ...,  36.,  38.,  39.],
          [ 44.,  52.,  63., ...,  46.,  47.,  51.],
          ...,
          [190., 185., 194., ..., 187., 178., 191.],
          [187., 179., 191., ..., 195., 193., 196.],
          [188., 193., 197., ..., 203., 203., 199.]],

         [[ 25.,  28.,  31., ...,  17.,  18.,  19.],
          [ 25.,  30.,  33., ...,  23.,  26.,  21.],
          [ 26.,  27.,  31., ...,  27.,  29.,  28.],
          ...,
          [ 86.,  78.,  82., ...,  92.,  78.,  86.],
          [ 81.,  70.,  77., ...,  94.,  89.,  90.],
          [ 82.,  84.,  83., ...,  98.,  98.,  95.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:81

analyse the exceptions in iter:89
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[163., 161., 167., ..., 148., 132., 127.],
          [197., 198., 197., ..., 184., 171., 178.],
          [206., 201., 206., ..., 208., 209., 213.],
          ...,
          [100.,  97.,  94., ...,  97.,  95.,  95.],
          [101.,  94.,  94., ..., 100.,  98.,  98.],
          [101.,  94.,  94., ...,  99.,  95.,  97.]],

         [[161., 160., 166., ..., 147., 133., 130.],
          [191., 193., 193., ..., 185., 173., 180.],
          [201., 194., 196., ..., 207., 208., 212.],
          ...,
          [100.,  98.,  95., ...,  95.,  94.,  94.],
          [100.,  93.,  93., ..., 100.,  98.,  97.],
          [100.,  93.,  93., ...,  98.,  94.,  95.]],

         [[130., 107., 100., ..., 117.,  91.,  77.],
          [145., 134., 125., ..., 139., 121., 124.],
          [139., 137., 142., ..., 144., 144., 147.],
          ...,
          [ 99.,  95.,  91., ...,  95.,  88.,  88.],
          [107.,  98.,  98., ...,  90.,  86.,  89.],
          [106.,  99.,  98., ...,  96.,  94.,  97.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:82

analyse the exceptions in iter:90
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[216., 201., 210., ..., 172., 196., 202.],
          [202., 222., 211., ..., 164., 173., 176.],
          [190., 186., 222., ..., 143., 145., 133.],
          ...,
          [138., 150., 152., ...,  10.,  13.,  32.],
          [140., 134., 171., ...,  22.,  28.,  28.],
          [123., 132., 159., ...,  33.,  42.,  30.]],

         [[195., 178., 184., ..., 149., 177., 189.],
          [179., 197., 184., ..., 139., 152., 160.],
          [165., 159., 193., ..., 115., 122., 115.],
          ...,
          [119., 131., 132., ...,   5.,   8.,  25.],
          [116., 113., 153., ...,  18.,  24.,  24.],
          [ 99., 111., 141., ...,  29.,  38.,  26.]],

         [[180., 160., 164., ..., 130., 153., 166.],
          [164., 179., 165., ..., 119., 128., 137.],
          [150., 142., 174., ...,  94.,  96.,  90.],
          ...,
          [ 95., 110., 114., ...,   3.,   5.,  21.],
          [ 95.,  92., 131., ...,  11.,  16.,  16.],
          [ 78.,  90., 119., ...,  20.,  29.,  17.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:83

analyse the exceptions in iter:91
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 60.,  67.,  70., ...,  53.,  44.,  36.],
          [ 57.,  82., 124., ...,  48.,  42.,  39.],
          [ 53.,  63., 125., ...,  46.,  40.,  35.],
          ...,
          [ 21.,  27.,  30., ...,  83.,  71.,  64.],
          [ 26.,  32.,  35., ...,  93.,  77.,  56.],
          [ 27.,  33.,  35., ...,  70.,  51.,  30.]],

         [[ 90.,  88.,  89., ...,  93.,  84.,  81.],
          [ 83.,  91., 121., ...,  84.,  78.,  79.],
          [ 79.,  69., 107., ...,  82.,  76.,  74.],
          ...,
          [ 40.,  42.,  46., ...,  36.,  38.,  60.],
          [ 47.,  46.,  49., ...,  52.,  43.,  48.],
          [ 45.,  43.,  45., ...,  57.,  50.,  48.]],

         [[134., 133., 131., ..., 148., 142., 139.],
          [123., 122., 137., ..., 146., 143., 144.],
          [125., 101., 119., ..., 138., 135., 134.],
          ...,
          [ 89.,  94.,  94., ...,  28.,  42.,  93.],
          [ 93.,  94.,  92., ...,  47.,  44.,  76.],
          [ 91.,  91.,  87., ...,  72.,  76.,  95.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:84

analyse the exceptions in iter:92
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[106., 105., 108., ..., 109., 109., 105.],
          [104., 100., 101., ..., 116., 112., 106.],
          [107., 100., 104., ..., 114., 114., 111.],
          ...,
          [138., 137., 138., ..., 121., 126., 127.],
          [134., 136., 142., ..., 140., 147., 147.],
          [141., 144., 143., ..., 144., 148., 151.]],

         [[162., 163., 162., ..., 163., 162., 161.],
          [163., 162., 161., ..., 170., 166., 163.],
          [166., 162., 164., ..., 169., 167., 168.],
          ...,
          [175., 173., 174., ..., 166., 175., 168.],
          [174., 176., 181., ..., 160., 175., 182.],
          [177., 178., 178., ..., 169., 176., 181.]],

         [[194., 195., 198., ..., 197., 194., 195.],
          [197., 197., 198., ..., 204., 198., 197.],
          [200., 198., 203., ..., 203., 200., 202.],
          ...,
          [192., 193., 196., ..., 185., 200., 195.],
          [193., 197., 205., ..., 175., 195., 204.],
          [192., 196., 197., ..., 183., 192., 196.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:85

analyse the exceptions in iter:93
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[138., 135., 135., ..., 143., 143., 143.],
          [126., 115., 109., ..., 145., 145., 145.],
          [ 87.,  78.,  75., ..., 147., 148., 147.],
          ...,
          [ 70.,  70.,  72., ...,  65.,  65.,  66.],
          [ 71.,  73.,  74., ...,  68.,  70.,  69.],
          [ 93.,  91.,  92., ...,  87.,  87.,  87.]],

         [[141., 137., 136., ..., 147., 147., 147.],
          [129., 121., 116., ..., 149., 149., 149.],
          [ 95.,  91.,  91., ..., 148., 148., 149.],
          ...,
          [ 70.,  69.,  70., ...,  65.,  65.,  65.],
          [ 72.,  71.,  71., ...,  69.,  72.,  70.],
          [ 81.,  79.,  79., ...,  83.,  83.,  84.]],

         [[148., 142., 141., ..., 146., 146., 146.],
          [136., 128., 123., ..., 148., 148., 148.],
          [106., 101.,  99., ..., 147., 147., 147.],
          ...,
          [ 15.,  17.,  19., ...,  11.,  13.,  13.],
          [ 37.,  37.,  38., ...,  35.,  37.,  33.],
          [ 65.,  63.,  63., ...,  64.,  64.,  61.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:86

analyse the exceptions in iter:94
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[227., 158., 172., ..., 252., 250., 248.],
          [237., 219., 219., ..., 249., 246., 230.],
          [233., 238., 212., ..., 212., 211., 189.],
          ...,
          [ 89.,  80.,  70., ..., 133., 134., 128.],
          [ 93.,  86.,  76., ..., 136., 140., 138.],
          [ 98.,  95.,  84., ..., 147., 153., 150.]],

         [[234., 165., 174., ..., 248., 248., 251.],
          [244., 226., 216., ..., 248., 250., 240.],
          [240., 242., 205., ..., 216., 219., 203.],
          ...,
          [ 93.,  83.,  73., ..., 123., 125., 122.],
          [ 97.,  89.,  78., ..., 125., 127., 128.],
          [101.,  97.,  86., ..., 133., 135., 136.]],

         [[241., 172., 172., ..., 252., 251., 253.],
          [248., 231., 215., ..., 251., 252., 247.],
          [242., 245., 203., ..., 218., 223., 214.],
          ...,
          [ 76.,  70.,  63., ...,  79.,  81.,  80.],
          [ 76.,  73.,  64., ...,  80.,  83.,  85.],
          [ 76.,  77.,  68., ...,  87.,  90.,  92.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:87

analyse the exceptions in iter:95
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[246., 252., 249., ..., 252., 250., 254.],
          [244., 253., 253., ..., 250., 249., 253.],
          [237., 251., 255., ..., 251., 251., 255.],
          ...,
          [ 50.,  46.,  93., ..., 246., 244., 251.],
          [ 61.,  58., 103., ..., 241., 245., 247.],
          [ 80.,  81., 120., ..., 244., 245., 243.]],

         [[254., 250., 252., ..., 250., 251., 254.],
          [254., 249., 248., ..., 251., 250., 254.],
          [255., 251., 249., ..., 252., 253., 255.],
          ...,
          [246., 239., 247., ..., 229., 215., 214.],
          [247., 239., 248., ..., 219., 222., 226.],
          [248., 243., 249., ..., 218., 226., 231.]],

         [[119., 170., 189., ...,  71.,  73.,  95.],
          [121., 173., 197., ...,  57.,  64.,  88.],
          [118., 169., 196., ...,  52.,  67.,  93.],
          ...,
          [117., 108., 100., ..., 146., 137., 137.],
          [122., 111., 113., ..., 140., 143., 146.],
          [124., 115., 124., ..., 143., 149., 150.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:88

analyse the exceptions in iter:96
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[106., 107., 108., ..., 125., 122., 100.],
          [107., 108., 108., ..., 134., 118.,  74.],
          [106., 107., 107., ..., 130., 106.,  72.],
          ...,
          [ 97.,  93.,  82., ...,  94.,  95.,  99.],
          [ 99.,  82.,  73., ...,  91.,  89.,  93.],
          [ 95.,  89.,  76., ...,  91.,  88.,  82.]],

         [[109., 110., 113., ..., 160., 153., 124.],
          [110., 111., 113., ..., 165., 144.,  92.],
          [108., 109., 112., ..., 154., 125.,  85.],
          ...,
          [ 86.,  82.,  74., ..., 101., 102., 106.],
          [ 87.,  74.,  66., ...,  98.,  97., 103.],
          [ 84.,  81.,  69., ...,  98.,  96.,  95.]],

         [[116., 117., 119., ..., 201., 191., 146.],
          [117., 118., 119., ..., 203., 171.,  92.],
          [115., 116., 118., ..., 181., 141.,  83.],
          ...,
          [ 72.,  65.,  61., ...,  59.,  59.,  62.],
          [ 72.,  61.,  55., ...,  54.,  55.,  58.],
          [ 71.,  68.,  56., ...,  54.,  53.,  52.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:89

analyse the exceptions in iter:97
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 33.,  29.,  32., ..., 157., 162., 160.],
          [ 25.,  24.,  23., ..., 174., 167., 165.],
          [ 55.,  47.,  53., ..., 129., 110., 123.],
          ...,
          [106., 103.,  85., ...,  78.,  54.,  44.],
          [ 97.,  92.,  88., ...,  96.,  81.,  71.],
          [106., 128., 142., ..., 100.,  81.,  71.]],

         [[ 44.,  44.,  45., ..., 197., 199., 194.],
          [ 40.,  40.,  36., ..., 209., 199., 198.],
          [ 56.,  56.,  61., ..., 162., 137., 153.],
          ...,
          [ 97.,  91., 100., ...,  91.,  64.,  56.],
          [ 91.,  97., 108., ..., 107.,  94.,  88.],
          [119., 141., 158., ..., 108.,  94.,  90.]],

         [[ 27.,  31.,  34., ..., 221., 216., 213.],
          [ 24.,  27.,  29., ..., 227., 217., 220.],
          [ 47.,  46.,  52., ..., 165., 133., 154.],
          ...,
          [ 60.,  58.,  53., ...,  52.,  36.,  31.],
          [ 59.,  57.,  61., ...,  59.,  47.,  41.],
          [ 91., 115., 137., ...,  63.,  47.,  40.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:90

analyse the exceptions in iter:98
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 90.,  94.,  87., ...,  46.,  53.,  57.],
          [ 96., 101.,  95., ...,  60.,  72.,  71.],
          [ 85., 113., 115., ...,  90.,  96.,  91.],
          ...,
          [102.,  61.,  69., ..., 157., 152., 169.],
          [101.,  69.,  64., ..., 131., 123., 115.],
          [ 91.,  78.,  87., ..., 135., 120., 102.]],

         [[ 77.,  81.,  81., ...,  44.,  45.,  46.],
          [ 92.,  84.,  80., ...,  51.,  60.,  56.],
          [ 87., 102., 101., ...,  84.,  87.,  79.],
          ...,
          [105.,  69.,  74., ..., 142., 137., 152.],
          [ 96.,  66.,  68., ..., 125., 117., 109.],
          [ 86.,  72.,  86., ..., 126., 116.,  96.]],

         [[ 59.,  64.,  65., ...,  35.,  38.,  38.],
          [ 68.,  63.,  66., ...,  44.,  50.,  45.],
          [ 66.,  75.,  76., ...,  57.,  60.,  55.],
          ...,
          [ 88.,  47.,  53., ...,  95.,  94.,  95.],
          [ 69.,  52.,  53., ..., 100.,  91.,  79.],
          [ 61.,  58.,  68., ...,  85.,  81.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:91

analyse the exceptions in iter:99
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 62.,  50.,  46., ..., 167., 183., 137.],
          [ 63.,  55.,  52., ..., 163., 171., 145.],
          [ 58.,  64.,  56., ..., 153., 150., 123.],
          ...,
          [172., 143., 130., ...,  94., 141., 139.],
          [183., 150.,  80., ...,  81., 135., 143.],
          [209., 182., 139., ...,  59., 130., 169.]],

         [[ 64.,  50.,  44., ..., 172., 184., 136.],
          [ 65.,  53.,  50., ..., 169., 174., 146.],
          [ 62.,  66.,  60., ..., 155., 154., 128.],
          ...,
          [135., 110.,  56., ...,  75., 108., 105.],
          [146., 118.,  64., ...,  72., 118., 125.],
          [174., 151., 109., ...,  54., 119., 156.]],

         [[ 44.,  26.,  19., ...,  69.,  76.,  72.],
          [ 37.,  26.,  27., ...,  61.,  75.,  77.],
          [ 36.,  37.,  37., ...,  62.,  64.,  57.],
          ...,
          [ 99.,  84.,  42., ...,  56.,  86.,  81.],
          [117.,  95.,  44., ...,  60.,  98., 110.],
          [144., 123.,  83., ...,  47., 111., 160.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:92

final statics:
total operators:28
tensorflow --> nums:92,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:92
mindspore --> 
torch --> 

generate models:92

analyse the exceptions in iter:100
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 211., 211., ..., 151., 151., 149.],
          [214., 212., 212., ..., 152., 152., 151.],
          [216., 214., 213., ..., 153., 153., 151.],
          ...,
          [145., 136., 143., ..., 216., 196., 183.],
          [139., 129., 129., ..., 227., 223., 209.],
          [137., 143., 136., ..., 209., 217., 228.]],

         [[229., 227., 227., ..., 174., 174., 172.],
          [229., 227., 227., ..., 175., 175., 174.],
          [229., 227., 227., ..., 176., 176., 174.],
          ...,
          [159., 148., 152., ..., 217., 197., 183.],
          [153., 142., 139., ..., 228., 224., 209.],
          [152., 155., 145., ..., 209., 217., 228.]],

         [[242., 240., 240., ..., 206., 206., 204.],
          [241., 239., 239., ..., 207., 207., 205.],
          [239., 237., 237., ..., 206., 206., 204.],
          ...,
          [165., 154., 158., ..., 206., 191., 182.],
          [159., 148., 145., ..., 219., 219., 209.],
          [157., 161., 152., ..., 203., 213., 226.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:93

analyse the exceptions in iter:101
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[155., 153., 159., ...,   8.,   8.,  18.],
          [163., 159., 161., ...,   8.,   8.,  19.],
          [169., 166., 165., ...,   9.,   6.,  20.],
          ...,
          [144., 146., 145., ...,  33.,  25.,  33.],
          [139., 142., 143., ...,  32.,  60.,  69.],
          [135., 138., 143., ...,  64.,  88.,  81.]],

         [[156., 154., 157., ...,   8.,   7.,  16.],
          [166., 160., 161., ...,   8.,   8.,  14.],
          [172., 168., 166., ...,   9.,   6.,  13.],
          ...,
          [145., 147., 149., ...,  35.,  27.,  35.],
          [140., 143., 146., ...,  36.,  65.,  76.],
          [136., 139., 144., ...,  72.,  97.,  89.]],

         [[158., 148., 152., ...,   8.,   7.,  13.],
          [170., 158., 155., ...,   8.,   8.,  12.],
          [180., 170., 160., ...,   9.,   5.,   9.],
          ...,
          [148., 148., 148., ...,  30.,  22.,  31.],
          [143., 144., 146., ...,  30.,  60.,  71.],
          [138., 141., 150., ...,  67.,  93.,  85.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:94

analyse the exceptions in iter:102
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[150., 151., 152., ..., 147., 144., 141.],
          [158., 159., 161., ..., 157., 153., 150.],
          [164., 163., 167., ..., 163., 159., 155.],
          ...,
          [174., 178., 162., ..., 195., 180., 189.],
          [185., 173., 166., ..., 199., 186., 173.],
          [178., 161., 168., ..., 189., 191., 154.]],

         [[183., 185., 188., ..., 184., 181., 177.],
          [190., 192., 195., ..., 192., 188., 184.],
          [193., 195., 197., ..., 194., 191., 187.],
          ...,
          [146., 151., 138., ..., 168., 154., 166.],
          [159., 148., 142., ..., 172., 158., 149.],
          [155., 137., 142., ..., 162., 164., 130.]],

         [[202., 201., 201., ..., 201., 197., 195.],
          [206., 205., 204., ..., 206., 203., 199.],
          [203., 202., 203., ..., 206., 203., 200.],
          ...,
          [103., 108.,  93., ..., 120., 105., 121.],
          [115., 101.,  91., ..., 126., 111., 108.],
          [111.,  90.,  92., ..., 119., 120.,  94.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:95

analyse the exceptions in iter:103
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 3.,  3.,  2., ...,  1.,  1.,  1.],
          [ 3.,  1.,  1., ...,  1.,  1.,  1.],
          [ 1.,  1.,  1., ...,  1.,  1.,  1.],
          ...,
          [ 1.,  1.,  1., ..., 22.,  1.,  0.],
          [ 1.,  1.,  1., ...,  5.,  2.,  1.],
          [ 1.,  1.,  1., ...,  2.,  2.,  1.]],

         [[ 1.,  0.,  1., ...,  1.,  1.,  1.],
          [ 0.,  3.,  4., ...,  1.,  1.,  1.],
          [ 2.,  5.,  1., ...,  1.,  1.,  1.],
          ...,
          [ 1.,  1.,  1., ..., 13.,  1.,  2.],
          [ 1.,  1.,  1., ...,  3.,  2.,  2.],
          [ 1.,  1.,  1., ...,  1.,  2.,  1.]],

         [[ 1.,  2.,  2., ...,  1.,  1.,  1.],
          [ 4.,  4.,  5., ...,  1.,  1.,  1.],
          [ 5.,  3.,  0., ...,  1.,  1.,  1.],
          ...,
          [ 1.,  1.,  1., ..., 13.,  1.,  3.],
          [ 1.,  1.,  1., ...,  4.,  2.,  1.],
          [ 1.,  1.,  1., ...,  3.,  2.,  0.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:96

analyse the exceptions in iter:104
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  0.,   0.,   0., ...,   5.,   0.,   1.],
          [  0.,   0.,   0., ...,   3.,   0.,   1.],
          [  1.,   1.,   0., ...,   1.,   0.,   1.],
          ...,
          [  0.,   0.,   0., ...,  44.,  66.,  25.],
          [  0.,   0.,   0., ...,  46.,  38.,   5.],
          [  0.,   0.,   0., ...,  39.,  28.,   3.]],

         [[  0.,   0.,   0., ...,   2.,   4.,   2.],
          [  0.,   0.,   0., ...,   1.,   2.,   2.],
          [  1.,   1.,   0., ...,   0.,   1.,   1.],
          ...,
          [  0.,   0.,   0., ..., 135., 119.,  46.],
          [  0.,   0.,   0., ..., 127.,  76.,   8.],
          [  0.,   0.,   0., ..., 113.,  60.,   3.]],

         [[  0.,   0.,   0., ...,   0.,   1.,   0.],
          [  0.,   0.,   0., ...,   0.,   2.,   1.],
          [  1.,   1.,   0., ...,   1.,   4.,   3.],
          ...,
          [  0.,   0.,   0., ...,  41.,  64.,  33.],
          [  0.,   0.,   0., ...,  34.,  32.,   7.],
          [  0.,   0.,   0., ...,  25.,  22.,   1.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:97

analyse the exceptions in iter:105
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          ...,
          [254., 253., 253., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.]],

         [[254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          ...,
          [254., 253., 253., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.]],

         [[254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          ...,
          [254., 253., 253., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.],
          [254., 254., 254., ..., 254., 254., 254.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:98

analyse the exceptions in iter:106
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[107., 106., 106., ..., 112., 112., 112.],
          [107., 105., 105., ..., 113., 113., 113.],
          [109., 106., 106., ..., 113., 113., 114.],
          ...,
          [111., 113., 115., ...,  94.,  93.,  93.],
          [108., 109., 111., ..., 101., 101., 102.],
          [108., 108., 108., ..., 110., 109., 107.]],

         [[141., 140., 140., ..., 144., 144., 144.],
          [141., 139., 139., ..., 145., 145., 145.],
          [143., 140., 140., ..., 146., 146., 147.],
          ...,
          [114., 116., 118., ..., 103., 102., 102.],
          [111., 112., 114., ..., 106., 106., 107.],
          [110., 110., 110., ..., 113., 111., 110.]],

         [[179., 178., 178., ..., 184., 183., 183.],
          [179., 176., 177., ..., 183., 183., 182.],
          [182., 178., 178., ..., 182., 182., 183.],
          ...,
          [122., 124., 125., ..., 112., 111., 111.],
          [120., 121., 123., ..., 115., 115., 115.],
          [122., 122., 122., ..., 119., 118., 117.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:99

analyse the exceptions in iter:107
tensorflow exception:
{'id': 0, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 97., 104., 107., ..., 141., 141., 139.],
          [ 87.,  92.,  98., ..., 126., 125., 122.],
          [119., 120., 125., ..., 137., 133., 123.],
          ...,
          [ 82.,  22.,  35., ..., 122., 123., 120.],
          [ 79.,  21.,  62., ..., 134., 131., 129.],
          [ 61.,  15.,  53., ..., 133., 131., 128.]],

         [[ 51.,  58.,  61., ...,  95.,  95.,  93.],
          [ 42.,  46.,  53., ...,  79.,  79.,  75.],
          [ 75.,  76.,  80., ...,  91.,  86.,  77.],
          ...,
          [ 53.,  11.,  25., ...,  78.,  78.,  76.],
          [ 51.,  10.,  49., ...,  89.,  87.,  85.],
          [ 36.,   6.,  40., ...,  87.,  86.,  84.]],

         [[ 31.,  38.,  40., ...,  71.,  71.,  69.],
          [ 24.,  29.,  35., ...,  59.,  58.,  54.],
          [ 51.,  52.,  56., ...,  72.,  67.,  58.],
          ...,
          [ 33.,   4.,  25., ...,  54.,  53.,  50.],
          [ 33.,   4.,  51., ...,  65.,  63.,  61.],
          [ 20.,   1.,  40., ...,  66.,  65.,  63.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:100

final statics:
total operators:28
tensorflow --> nums:100,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:100
mindspore --> 
torch --> 

generate models:100

analyse the exceptions in iter:0
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:8
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

analyse the exceptions in iter:9
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

final statics:
total operators:28
tensorflow --> nums:10,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:10
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:14
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:15
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:16
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:17
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:18
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:21
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:23
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:24
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:25
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:26
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:28
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:33
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:34
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:35
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:36
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 131., 193., ..., 172., 169., 166.],
          [165., 127., 189., ..., 172., 169., 166.],
          [163., 126., 186., ..., 173., 170., 168.],
          ...,
          [147., 139., 145., ..., 220., 218., 219.],
          [146., 143., 152., ..., 221., 220., 219.],
          [148., 143., 146., ..., 223., 221., 220.]],

         [[122., 108., 196., ..., 187., 183., 181.],
          [119., 104., 192., ..., 186., 183., 180.],
          [117., 103., 189., ..., 187., 184., 182.],
          ...,
          [ 93.,  85.,  91., ..., 220., 218., 219.],
          [ 87.,  83.,  94., ..., 221., 220., 219.],
          [ 87.,  82.,  85., ..., 223., 221., 220.]],

         [[ 65.,  75., 192., ..., 187., 183., 181.],
          [ 62.,  72., 187., ..., 186., 183., 180.],
          [ 60.,  71., 185., ..., 187., 184., 182.],
          ...,
          [ 35.,  39.,  42., ..., 220., 218., 219.],
          [ 31.,  39.,  43., ..., 222., 220., 219.],
          [ 28.,  31.,  30., ..., 223., 221., 220.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:37
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:38
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:39
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:40
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:41
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:43
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:44
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:47
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 77.,  76.,  78., ...,  68.,  58.,  48.],
          [ 71.,  67.,  69., ...,  57.,  44.,  36.],
          [ 55.,  52.,  58., ...,  62.,  53.,  48.],
          ...,
          [ 63.,  62.,  67., ...,  63.,  58.,  55.],
          [ 89.,  91.,  89., ...,  65.,  68.,  66.],
          [103., 107.,  92., ...,  69.,  77.,  77.]],

         [[113., 112., 114., ..., 104.,  94.,  84.],
          [107., 102., 105., ...,  93.,  80.,  72.],
          [ 91.,  88.,  94., ...,  98.,  89.,  84.],
          ...,
          [ 97.,  92.,  97., ...,  97.,  92.,  89.],
          [118., 116., 114., ...,  99., 102., 101.],
          [129., 131., 119., ..., 104., 111., 112.]],

         [[137., 136., 139., ..., 128., 118., 108.],
          [131., 126., 130., ..., 116., 104.,  96.],
          [115., 112., 119., ..., 122., 113., 108.],
          ...,
          [119., 115., 121., ..., 123., 118., 115.],
          [136., 135., 136., ..., 122., 125., 124.],
          [144., 147., 138., ..., 127., 134., 135.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:48
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

final statics:
total operators:28
tensorflow --> nums:36,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:36
mindspore --> 
torch --> 

generate models:36

analyse the exceptions in iter:50
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 16.,  17.,  17., ...,  62.,  55.,  51.],
          [ 16.,  16.,  15., ...,  62.,  58.,  52.],
          [ 16.,  15.,  15., ...,  57.,  59.,  56.],
          ...,
          [ 96., 114., 119., ..., 128., 120., 117.],
          [118., 100., 114., ..., 139., 131., 121.],
          [144., 136., 105., ..., 145., 137., 131.]],

         [[ 76.,  77.,  77., ..., 106.,  99.,  94.],
          [ 76.,  76.,  75., ..., 109., 105., 100.],
          [ 76.,  75.,  75., ..., 110., 111., 109.],
          ...,
          [110., 127., 132., ..., 135., 130., 131.],
          [132., 113., 126., ..., 146., 140., 134.],
          [148., 140., 114., ..., 151., 144., 141.]],

         [[ 74.,  75.,  75., ...,  87.,  80.,  75.],
          [ 74.,  74.,  74., ...,  84.,  80.,  75.],
          [ 74.,  73.,  73., ...,  79.,  80.,  78.],
          ...,
          [138., 159., 167., ..., 153., 145., 142.],
          [159., 145., 163., ..., 159., 153., 147.],
          [173., 168., 143., ..., 170., 163., 158.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:51
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:52
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

analyse the exceptions in iter:53
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[157., 156., 157., ..., 177., 177., 175.],
          [162., 162., 162., ..., 187., 182., 179.],
          [165., 164., 165., ..., 211., 204., 191.],
          ...,
          [172., 168., 166., ..., 203., 203., 200.],
          [177., 175., 172., ..., 203., 203., 200.],
          [182., 182., 179., ..., 203., 203., 200.]],

         [[159., 158., 159., ..., 183., 180., 179.],
          [164., 164., 164., ..., 194., 187., 183.],
          [167., 166., 167., ..., 220., 210., 196.],
          ...,
          [174., 170., 167., ..., 205., 205., 202.],
          [179., 177., 173., ..., 205., 205., 202.],
          [184., 183., 180., ..., 205., 205., 202.]],

         [[146., 145., 146., ..., 185., 183., 179.],
          [151., 151., 151., ..., 200., 193., 186.],
          [154., 153., 154., ..., 226., 219., 201.],
          ...,
          [161., 158., 158., ..., 201., 201., 199.],
          [166., 166., 164., ..., 202., 202., 199.],
          [171., 174., 173., ..., 202., 202., 199.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

analyse the exceptions in iter:55
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[156., 167., 169., ..., 243., 230., 208.],
          [174., 192., 172., ..., 237., 213., 186.],
          [192., 194., 174., ..., 226., 198., 195.],
          ...,
          [187., 211., 231., ..., 210., 217., 203.],
          [231., 220., 200., ..., 183., 189., 186.],
          [238., 238., 229., ..., 141., 151., 157.]],

         [[194., 212., 215., ..., 247., 235., 215.],
          [210., 229., 204., ..., 243., 221., 193.],
          [234., 230., 201., ..., 231., 208., 200.],
          ...,
          [211., 234., 244., ..., 204., 208., 192.],
          [238., 236., 219., ..., 170., 175., 169.],
          [242., 247., 239., ..., 126., 137., 141.]],

         [[129., 127., 129., ..., 226., 206., 180.],
          [147., 159., 163., ..., 223., 200., 169.],
          [145., 178., 194., ..., 218., 186., 165.],
          ...,
          [151., 180., 221., ..., 199., 210., 192.],
          [218., 209., 177., ..., 153., 160., 153.],
          [224., 232., 217., ..., 106., 117., 118.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:41

analyse the exceptions in iter:56
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[141., 139., 136., ..., 228., 228., 229.],
          [148., 150., 148., ..., 228., 228., 228.],
          [149., 149., 148., ..., 230., 229., 229.],
          ...,
          [125., 124., 139., ..., 220., 199., 208.],
          [126., 116., 135., ..., 246., 226., 196.],
          [143., 145., 169., ..., 254., 255., 227.]],

         [[ 70.,  61.,  55., ..., 198., 199., 200.],
          [ 71.,  67.,  64., ..., 197., 196., 197.],
          [ 72.,  66.,  64., ..., 197., 197., 197.],
          ...,
          [100., 102., 110., ..., 169., 143., 149.],
          [101.,  93., 107., ..., 205., 181., 145.],
          [105., 107., 127., ..., 208., 206., 174.]],

         [[  8.,   2.,   0., ..., 155., 156., 157.],
          [ 10.,   5.,   2., ..., 153., 152., 153.],
          [ 17.,   7.,   4., ..., 151., 151., 151.],
          ...,
          [ 73.,  80.,  75., ..., 109.,  86.,  93.],
          [ 75.,  71.,  73., ..., 144., 121.,  87.],
          [ 67.,  71.,  83., ..., 141., 138., 105.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]
torch exception:
{'id': 12, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([205290.6250], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:42

analyse the exceptions in iter:57
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 66.,  71.,  88., ...,  85.,  86.,  79.],
          [ 75.,  79.,  95., ...,  85.,  87.,  78.],
          [ 80.,  84.,  97., ...,  81.,  82.,  74.],
          ...,
          [ 79.,  87.,  60., ...,  35.,  26.,  20.],
          [ 77.,  70.,  37., ...,  79.,  77.,  66.],
          [ 78.,  63.,  31., ..., 140., 135., 128.]],

         [[ 73.,  77.,  86., ...,  80.,  81.,  73.],
          [ 81.,  84.,  92., ...,  79.,  80.,  72.],
          [ 85.,  88.,  93., ...,  75.,  74.,  68.],
          ...,
          [ 74.,  84.,  58., ...,  35.,  26.,  21.],
          [ 74.,  68.,  37., ...,  68.,  66.,  55.],
          [ 74.,  61.,  32., ..., 122., 117., 113.]],

         [[ 33.,  40.,  62., ...,  55.,  62.,  54.],
          [ 40.,  45.,  66., ...,  56.,  62.,  54.],
          [ 44.,  50.,  68., ...,  48.,  53.,  51.],
          ...,
          [ 59.,  69.,  43., ...,  22.,  14.,  10.],
          [ 59.,  53.,  22., ...,  60.,  58.,  50.],
          [ 58.,  44.,  15., ..., 116., 113., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:43

analyse the exceptions in iter:60
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[201., 191., 194., ...,  83.,  39.,  36.],
          [ 57.,  62., 134., ...,  79.,  48.,  35.],
          [ 74., 123., 138., ..., 162., 132.,  56.],
          ...,
          [ 67.,  62.,  55., ...,  69.,  72.,  72.],
          [ 73.,  67.,  59., ...,  72.,  72.,  71.],
          [ 74.,  71.,  67., ...,  61.,  58.,  63.]],

         [[209., 204., 207., ...,  88.,  48.,  47.],
          [ 73.,  78., 148., ...,  91.,  59.,  45.],
          [ 99., 142., 153., ..., 175., 139.,  61.],
          ...,
          [ 80.,  72.,  62., ...,  78.,  80.,  82.],
          [ 87.,  77.,  67., ...,  81.,  81.,  81.],
          [ 89.,  84.,  79., ...,  73.,  69.,  75.]],

         [[211., 210., 216., ...,  82.,  33.,  24.],
          [ 79.,  92., 161., ...,  96.,  57.,  32.],
          [110., 165., 169., ..., 186., 145.,  56.],
          ...,
          [ 89.,  82.,  73., ...,  93.,  95.,  98.],
          [ 95.,  87.,  77., ...,  96.,  96.,  96.],
          [100.,  95.,  89., ...,  88.,  85.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:44

analyse the exceptions in iter:61
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[114., 117., 120., ..., 165., 125., 103.],
          [111., 116., 121., ..., 162., 127., 103.],
          [114., 121., 128., ..., 167., 132., 106.],
          ...,
          [165., 170., 175., ..., 185., 207., 201.],
          [175., 175., 180., ..., 187., 200., 193.],
          [173., 171., 177., ..., 205., 210., 202.]],

         [[119., 122., 126., ..., 166., 126., 103.],
          [116., 121., 126., ..., 163., 128., 103.],
          [119., 125., 132., ..., 168., 133., 108.],
          ...,
          [166., 171., 176., ..., 179., 199., 193.],
          [176., 176., 181., ..., 182., 194., 186.],
          [174., 172., 178., ..., 200., 204., 195.]],

         [[125., 126., 129., ..., 160., 121., 110.],
          [122., 127., 133., ..., 157., 123., 109.],
          [125., 136., 142., ..., 162., 126., 102.],
          ...,
          [161., 167., 171., ..., 168., 194., 185.],
          [171., 171., 176., ..., 162., 181., 178.],
          [169., 167., 173., ..., 182., 192., 187.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:45

analyse the exceptions in iter:62
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 76.,  73.,  69., ...,  75.,  72.,  70.],
          [ 76.,  71.,  66., ...,  79.,  76.,  75.],
          [ 71.,  65.,  62., ...,  80.,  77.,  76.],
          ...,
          [ 11.,   9.,   6., ...,  31.,  32.,  29.],
          [  0.,   0.,   0., ...,  12.,  12.,  13.],
          [ 87.,  83.,  81., ...,  99.,  99., 102.]],

         [[118., 118., 116., ..., 135., 134., 135.],
          [122., 119., 117., ..., 136., 135., 137.],
          [120., 117., 116., ..., 133., 132., 135.],
          ...,
          [ 36.,  32.,  32., ...,  61.,  62.,  59.],
          [ 19.,  13.,   7., ...,  38.,  37.,  38.],
          [100.,  92.,  86., ..., 116., 115., 119.]],

         [[167., 164., 162., ..., 180., 178., 179.],
          [170., 166., 163., ..., 178., 177., 179.],
          [170., 165., 164., ..., 173., 172., 174.],
          ...,
          [ 66.,  61.,  61., ...,  79.,  80.,  77.],
          [ 46.,  40.,  36., ...,  55.,  55.,  56.],
          [115., 108., 103., ..., 127., 127., 130.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:46

analyse the exceptions in iter:64
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  67.,  69., ...,  93., 108., 102.],
          [ 65.,  65.,  69., ..., 104., 122., 132.],
          [ 62.,  63.,  68., ..., 122., 146., 140.],
          ...,
          [ 88.,  90.,  95., ...,  83.,  89.,  92.],
          [ 90.,  94.,  98., ...,  75.,  78.,  85.],
          [ 95., 102., 104., ...,  74.,  79.,  84.]],

         [[ 29.,  32.,  35., ...,  73.,  87.,  81.],
          [ 29.,  30.,  34., ...,  83.,  97., 106.],
          [ 27.,  28.,  32., ...,  99., 118., 114.],
          ...,
          [ 76.,  79.,  85., ...,  85.,  93.,  97.],
          [ 79.,  83.,  87., ...,  66.,  74.,  86.],
          [ 84.,  90.,  94., ...,  62.,  70.,  78.]],

         [[ 29.,  30.,  33., ...,  70.,  82.,  74.],
          [ 29.,  28.,  32., ...,  78.,  90.,  98.],
          [ 25.,  24.,  30., ...,  93., 110., 104.],
          ...,
          [ 84.,  86.,  92., ...,  99., 108., 111.],
          [ 85.,  90.,  95., ...,  71.,  83.,  97.],
          [ 92.,  98., 102., ...,  62.,  73.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:47

analyse the exceptions in iter:65
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[148., 132., 134., ..., 124., 108., 124.],
          [197., 168., 176., ..., 176., 162., 141.],
          [199., 199., 213., ..., 182., 178., 153.],
          ...,
          [179., 183., 182., ..., 164., 147., 136.],
          [162., 146., 127., ..., 118., 118., 132.],
          [150., 143., 123., ..., 124., 126., 157.]],

         [[141., 128., 135., ..., 131., 109., 127.],
          [181., 151., 166., ..., 178., 157., 133.],
          [194., 191., 209., ..., 186., 175., 141.],
          ...,
          [170., 165., 166., ..., 144., 127., 119.],
          [156., 133., 116., ..., 100.,  99., 116.],
          [148., 141., 125., ..., 119., 121., 154.]],

         [[174., 173., 187., ..., 186., 166., 171.],
          [214., 185., 199., ..., 213., 191., 162.],
          [207., 193., 209., ..., 193., 178., 156.],
          ...,
          [170., 148., 145., ..., 121., 106., 130.],
          [173., 140., 122., ..., 106., 108., 138.],
          [184., 176., 161., ..., 162., 162., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:48

analyse the exceptions in iter:68
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 103., 104., ..., 102.,  94.,  99.],
          [125., 119., 120., ..., 108., 104., 110.],
          [113.,  73.,  80., ...,  47.,  78., 103.],
          ...,
          [102., 125., 190., ...,  86.,  69.,  92.],
          [120., 141., 194., ...,  81.,  85., 109.],
          [159., 166., 163., ...,  98., 110., 100.]],

         [[125., 128., 130., ..., 121., 121., 120.],
          [151., 157., 160., ..., 137., 144., 145.],
          [136., 102., 107., ...,  72., 117., 141.],
          ...,
          [ 77.,  88., 159., ...,  72.,  57.,  70.],
          [ 92., 100., 163., ...,  68.,  77., 101.],
          [133., 127., 132., ...,  85., 105., 102.]],

         [[141., 147., 145., ..., 130., 132., 129.],
          [167., 181., 185., ..., 145., 155., 156.],
          [148., 122., 127., ...,  76., 124., 151.],
          ...,
          [ 37.,  49., 132., ...,  48.,  37.,  40.],
          [ 49.,  52., 124., ...,  34.,  39.,  59.],
          [ 96.,  79.,  90., ...,  57.,  64.,  67.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:49

analyse the exceptions in iter:70
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 159., 165., ..., 129., 125., 122.],
          [156., 160., 163., ..., 118., 120., 118.],
          [146., 130., 128., ..., 118., 112., 107.],
          ...,
          [125., 126., 124., ..., 123., 126., 131.],
          [125., 127., 125., ..., 120., 128., 129.],
          [119., 121., 135., ..., 132., 136., 146.]],

         [[179., 183., 189., ..., 161., 158., 155.],
          [177., 180., 184., ..., 150., 152., 150.],
          [169., 152., 151., ..., 150., 144., 139.],
          ...,
          [146., 147., 146., ..., 141., 140., 144.],
          [145., 148., 146., ..., 137., 142., 141.],
          [136., 138., 153., ..., 148., 149., 157.]],

         [[152., 157., 162., ..., 137., 133., 131.],
          [152., 155., 159., ..., 126., 128., 126.],
          [143., 126., 125., ..., 126., 120., 115.],
          ...,
          [129., 127., 124., ..., 117., 118., 122.],
          [127., 128., 124., ..., 119., 125., 125.],
          [120., 119., 132., ..., 135., 137., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:50

analyse the exceptions in iter:71
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 104.,  81., ..., 163., 210., 250.],
          [103.,   5.,   0., ...,  27.,  68., 185.],
          [163.,  23.,   1., ...,  69.,  90., 159.],
          ...,
          [235., 165., 104., ...,  55.,  87., 162.],
          [255., 231., 147., ...,  35.,  60., 189.],
          [255., 252., 240., ...,  87., 120., 215.]],

         [[170., 109.,  88., ..., 169., 214., 250.],
          [104.,   8.,   0., ...,  29.,  69., 185.],
          [163.,  25.,   3., ...,  67.,  88., 158.],
          ...,
          [235., 167., 108., ...,  60.,  91., 165.],
          [255., 231., 149., ...,  39.,  63., 191.],
          [255., 252., 240., ...,  89., 122., 216.]],

         [[164.,  98.,  82., ..., 159., 201., 242.],
          [ 93.,   0.,   0., ...,  21.,  56., 174.],
          [150.,  18.,   1., ...,  59.,  76., 147.],
          ...,
          [232., 153.,  83., ...,  28.,  63., 149.],
          [255., 226., 136., ...,  21.,  44., 179.],
          [255., 251., 237., ...,  82., 111., 207.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:51

analyse the exceptions in iter:74
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[195., 165., 150., ..., 135., 120., 120.],
          [174., 117., 145., ..., 134., 103., 117.],
          [125.,  97., 131., ..., 129., 100., 104.],
          ...,
          [122., 125., 118., ...,  91.,  83.,  73.],
          [132., 130., 136., ...,  85.,  86.,  91.],
          [143., 137., 143., ...,  85., 107., 145.]],

         [[208., 177., 161., ..., 189., 185., 184.],
          [190., 134., 159., ..., 182., 162., 188.],
          [143., 120., 150., ..., 167., 146., 165.],
          ...,
          [146., 149., 142., ..., 118., 111.,  96.],
          [157., 155., 160., ..., 111., 113., 113.],
          [172., 165., 169., ..., 107., 127., 160.]],

         [[166., 138., 140., ..., 143., 119., 118.],
          [160., 115., 154., ..., 125.,  96., 129.],
          [125., 115., 150., ..., 120.,  97., 123.],
          ...,
          [146., 149., 142., ..., 122., 114.,  93.],
          [158., 155., 161., ..., 113., 115., 109.],
          [179., 167., 174., ..., 107., 125., 154.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:52

analyse the exceptions in iter:76
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[118., 110., 118., ..., 114., 114., 113.],
          [ 84.,  88., 120., ..., 113., 114., 115.],
          [ 85.,  99., 131., ..., 120., 120., 119.],
          ...,
          [155., 152., 151., ..., 105.,  82., 127.],
          [154., 155., 156., ..., 150., 142., 139.],
          [153., 152., 154., ..., 145., 148., 146.]],

         [[157., 162., 172., ..., 161., 161., 161.],
          [120., 136., 173., ..., 165., 164., 163.],
          [117., 141., 183., ..., 168., 168., 167.],
          ...,
          [158., 156., 155., ..., 106.,  84., 129.],
          [155., 157., 158., ..., 152., 145., 142.],
          [155., 155., 156., ..., 147., 150., 149.]],

         [[187., 196., 219., ..., 207., 207., 207.],
          [147., 168., 218., ..., 217., 216., 212.],
          [142., 171., 225., ..., 216., 215., 213.],
          ...,
          [142., 136., 133., ...,  87.,  63., 105.],
          [138., 137., 136., ..., 130., 120., 113.],
          [143., 139., 139., ..., 128., 127., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:53

analyse the exceptions in iter:77
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 44.,  47.,  51., ...,  75.,  72.,  74.],
          [ 52.,  47.,  51., ...,  73.,  74.,  76.],
          [ 65.,  57.,  54., ...,  73.,  73.,  75.],
          ...,
          [ 56.,  49.,  49., ...,  53.,  52.,  53.],
          [ 41.,  56.,  52., ...,  52.,  52.,  49.],
          [ 24.,  49.,  40., ...,  54.,  55.,  46.]],

         [[ 73.,  77.,  81., ..., 107., 104., 106.],
          [ 85.,  79.,  82., ..., 105., 106., 108.],
          [100.,  91.,  87., ..., 105., 105., 108.],
          ...,
          [ 82.,  75.,  74., ...,  77.,  77.,  77.],
          [ 64.,  79.,  75., ...,  74.,  74.,  72.],
          [ 44.,  69.,  60., ...,  74.,  74.,  66.]],

         [[ 49.,  53.,  57., ...,  83.,  80.,  82.],
          [ 55.,  54.,  60., ...,  81.,  82.,  84.],
          [ 67.,  65.,  66., ...,  81.,  81.,  82.],
          ...,
          [ 48.,  41.,  41., ...,  49.,  48.,  49.],
          [ 35.,  50.,  46., ...,  49.,  49.,  46.],
          [ 19.,  44.,  36., ...,  51.,  52.,  43.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:54

analyse the exceptions in iter:78
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[114.,  95., 104., ..., 192., 177., 136.],
          [ 76.,  45.,  53., ..., 170., 157., 107.],
          [ 63.,  49.,  51., ..., 175., 164., 109.],
          ...,
          [ 46.,  39.,  56., ..., 133., 120.,  95.],
          [ 28.,  31.,  43., ..., 123., 113.,  85.],
          [ 48.,  40.,  44., ...,  82.,  76.,  84.]],

         [[122., 102., 112., ..., 192., 177., 136.],
          [ 89.,  57.,  65., ..., 170., 157., 107.],
          [ 72.,  58.,  60., ..., 175., 164., 109.],
          ...,
          [ 56.,  49.,  67., ..., 133., 120.,  96.],
          [ 34.,  38.,  50., ..., 123., 114.,  86.],
          [ 51.,  42.,  47., ...,  82.,  76.,  85.]],

         [[ 95.,  76.,  86., ..., 192., 177., 136.],
          [ 60.,  30.,  38., ..., 170., 157., 107.],
          [ 44.,  31.,  33., ..., 175., 164., 109.],
          ...,
          [ 35.,  29.,  46., ..., 133., 118.,  92.],
          [ 19.,  23.,  35., ..., 123., 111.,  82.],
          [ 43.,  34.,  38., ...,  82.,  74.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:55

analyse the exceptions in iter:80
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 76.,  78.,  79., ..., 104., 105., 106.],
          [ 78.,  79.,  79., ..., 109., 110., 111.],
          [ 97.,  88.,  85., ..., 114., 114., 115.],
          ...,
          [101., 116., 121., ..., 186., 178., 176.],
          [134., 145., 150., ..., 176., 179., 175.],
          [150., 153., 154., ..., 178., 179., 179.]],

         [[112., 114., 114., ..., 135., 136., 137.],
          [114., 118., 119., ..., 138., 139., 140.],
          [119., 118., 119., ..., 142., 142., 143.],
          ...,
          [101., 116., 121., ..., 181., 171., 168.],
          [134., 146., 150., ..., 172., 174., 170.],
          [150., 153., 154., ..., 174., 175., 175.]],

         [[159., 162., 161., ..., 182., 183., 183.],
          [159., 161., 160., ..., 183., 183., 184.],
          [155., 161., 168., ..., 185., 186., 186.],
          ...,
          [112., 126., 130., ..., 176., 168., 166.],
          [140., 150., 154., ..., 169., 172., 169.],
          [150., 153., 154., ..., 172., 175., 176.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:56

analyse the exceptions in iter:0
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:8
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]
torch exception:
{'id': 11, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([932672.], grad_fn=<MeanBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]
torch exception:
{'id': 18, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([-0.9283], grad_fn=<CosBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:2,distinct_bugs:1
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 
flatten:2

generate models:9

analyse the exceptions in iter:12
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:13
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:14
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:15
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:17
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:21
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:23
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:24
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:25
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:28
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:29
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:31
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[236., 233., 234., ..., 148., 147., 140.],
          [243., 242., 243., ..., 163., 161., 159.],
          [245., 242., 245., ..., 163., 161., 157.],
          ...,
          [ 79.,  70.,  72., ...,  38.,  36.,  33.],
          [ 81.,  78.,  74., ...,  47.,  31.,  24.],
          [ 80.,  80.,  74., ...,  40.,  28.,  22.]],

         [[242., 239., 240., ..., 145., 145., 137.],
          [249., 247., 250., ..., 162., 160., 158.],
          [251., 248., 251., ..., 162., 160., 157.],
          ...,
          [ 74.,  65.,  68., ...,  31.,  29.,  25.],
          [ 79.,  73.,  68., ...,  38.,  24.,  17.],
          [ 80.,  77.,  67., ...,  30.,  21.,  15.]],

         [[238., 235., 236., ..., 140., 139., 131.],
          [245., 244., 246., ..., 162., 160., 158.],
          [247., 244., 247., ..., 166., 164., 161.],
          ...,
          [ 60.,  47.,  45., ...,  25.,  23.,  19.],
          [ 62.,  56.,  49., ...,  29.,  17.,  10.],
          [ 63.,  61.,  52., ...,  20.,  12.,   8.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:32
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:33
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:35
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:36
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 131., 193., ..., 172., 169., 166.],
          [165., 127., 189., ..., 172., 169., 166.],
          [163., 126., 186., ..., 173., 170., 168.],
          ...,
          [147., 139., 145., ..., 220., 218., 219.],
          [146., 143., 152., ..., 221., 220., 219.],
          [148., 143., 146., ..., 223., 221., 220.]],

         [[122., 108., 196., ..., 187., 183., 181.],
          [119., 104., 192., ..., 186., 183., 180.],
          [117., 103., 189., ..., 187., 184., 182.],
          ...,
          [ 93.,  85.,  91., ..., 220., 218., 219.],
          [ 87.,  83.,  94., ..., 221., 220., 219.],
          [ 87.,  82.,  85., ..., 223., 221., 220.]],

         [[ 65.,  75., 192., ..., 187., 183., 181.],
          [ 62.,  72., 187., ..., 186., 183., 180.],
          [ 60.,  71., 185., ..., 187., 184., 182.],
          ...,
          [ 35.,  39.,  42., ..., 220., 218., 219.],
          [ 31.,  39.,  43., ..., 222., 220., 219.],
          [ 28.,  31.,  30., ..., 223., 221., 220.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:37
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:38
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:39
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:40
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:41
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:42
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[127., 148., 192., ..., 112., 144., 153.],
          [ 89., 111., 151., ..., 161., 166., 163.],
          [ 98.,  94., 110., ..., 173., 169., 173.],
          ...,
          [156., 151., 149., ..., 150., 149., 142.],
          [163., 162., 161., ..., 135., 141., 138.],
          [160., 160., 163., ..., 138., 143., 151.]],

         [[126., 144., 181., ..., 102., 135., 142.],
          [ 90., 110., 141., ..., 152., 158., 154.],
          [ 94.,  94., 109., ..., 159., 154., 157.],
          ...,
          [152., 145., 144., ..., 144., 148., 143.],
          [158., 155., 151., ..., 131., 137., 134.],
          [152., 151., 153., ..., 121., 131., 135.]],

         [[129., 144., 175., ...,  98., 123., 130.],
          [ 94., 116., 137., ..., 129., 132., 128.],
          [ 94.,  99., 118., ..., 132., 129., 132.],
          ...,
          [115., 107., 104., ..., 110., 114., 104.],
          [122., 120., 118., ...,  99., 109., 103.],
          [122., 120., 120., ..., 103., 107., 117.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:43
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:44
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:45
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 54.,  59.,  56., ..., 133., 131., 132.],
          [ 59.,  62.,  55., ..., 193., 200., 197.],
          [ 41.,  41.,  36., ..., 202., 196., 190.],
          ...,
          [105.,  97.,  96., ...,  98., 100., 100.],
          [ 86.,  96.,  97., ...,  94.,  98., 100.],
          [ 70.,  92., 113., ...,  98.,  96.,  92.]],

         [[ 31.,  34.,  37., ...,  92.,  89.,  94.],
          [ 38.,  39.,  36., ..., 135., 144., 142.],
          [ 26.,  25.,  21., ..., 144., 141., 136.],
          ...,
          [161., 163., 170., ..., 145., 138., 130.],
          [149., 157., 164., ..., 127., 126., 124.],
          [136., 146., 169., ..., 121., 117., 112.]],

         [[ 18.,  19.,  22., ...,  53.,  49.,  53.],
          [ 26.,  26.,  25., ...,  77.,  86.,  86.],
          [ 18.,  16.,  13., ...,  84.,  81.,  79.],
          ...,
          [157., 162., 164., ..., 144., 135., 123.],
          [143., 156., 160., ..., 122., 120., 114.],
          [128., 145., 168., ..., 111., 106., 101.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:49
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

final statics:
total operators:28
tensorflow --> nums:35,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:2,distinct_bugs:1
tensorflow --> 
conv2d:35
mindspore --> 
torch --> 
flatten:2

generate models:35

analyse the exceptions in iter:52
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:53
tensorflow exception:
{'id': 40, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[157., 156., 157., ..., 177., 177., 175.],
          [162., 162., 162., ..., 187., 182., 179.],
          [165., 164., 165., ..., 211., 204., 191.],
          ...,
          [172., 168., 166., ..., 203., 203., 200.],
          [177., 175., 172., ..., 203., 203., 200.],
          [182., 182., 179., ..., 203., 203., 200.]],

         [[159., 158., 159., ..., 183., 180., 179.],
          [164., 164., 164., ..., 194., 187., 183.],
          [167., 166., 167., ..., 220., 210., 196.],
          ...,
          [174., 170., 167., ..., 205., 205., 202.],
          [179., 177., 173., ..., 205., 205., 202.],
          [184., 183., 180., ..., 205., 205., 202.]],

         [[146., 145., 146., ..., 185., 183., 179.],
          [151., 151., 151., ..., 200., 193., 186.],
          [154., 153., 154., ..., 226., 219., 201.],
          ...,
          [161., 158., 158., ..., 201., 201., 199.],
          [166., 166., 164., ..., 202., 202., 199.],
          [171., 174., 173., ..., 202., 202., 199.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:0
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:6
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:7
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:8
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:10
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:13
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:15
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:17
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:19
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:20
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:21
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:26
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:28
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:29
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:30
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:31
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[236., 233., 234., ..., 148., 147., 140.],
          [243., 242., 243., ..., 163., 161., 159.],
          [245., 242., 245., ..., 163., 161., 157.],
          ...,
          [ 79.,  70.,  72., ...,  38.,  36.,  33.],
          [ 81.,  78.,  74., ...,  47.,  31.,  24.],
          [ 80.,  80.,  74., ...,  40.,  28.,  22.]],

         [[242., 239., 240., ..., 145., 145., 137.],
          [249., 247., 250., ..., 162., 160., 158.],
          [251., 248., 251., ..., 162., 160., 157.],
          ...,
          [ 74.,  65.,  68., ...,  31.,  29.,  25.],
          [ 79.,  73.,  68., ...,  38.,  24.,  17.],
          [ 80.,  77.,  67., ...,  30.,  21.,  15.]],

         [[238., 235., 236., ..., 140., 139., 131.],
          [245., 244., 246., ..., 162., 160., 158.],
          [247., 244., 247., ..., 166., 164., 161.],
          ...,
          [ 60.,  47.,  45., ...,  25.,  23.,  19.],
          [ 62.,  56.,  49., ...,  29.,  17.,  10.],
          [ 63.,  61.,  52., ...,  20.,  12.,   8.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:0
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:8
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:10
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:13
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:14
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:17
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:18
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:20
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:21
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:22
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:23
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:24
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:25
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:26
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:27
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:30
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:33
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:34
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:35
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:37
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:39
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:41
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:42
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[127., 148., 192., ..., 112., 144., 153.],
          [ 89., 111., 151., ..., 161., 166., 163.],
          [ 98.,  94., 110., ..., 173., 169., 173.],
          ...,
          [156., 151., 149., ..., 150., 149., 142.],
          [163., 162., 161., ..., 135., 141., 138.],
          [160., 160., 163., ..., 138., 143., 151.]],

         [[126., 144., 181., ..., 102., 135., 142.],
          [ 90., 110., 141., ..., 152., 158., 154.],
          [ 94.,  94., 109., ..., 159., 154., 157.],
          ...,
          [152., 145., 144., ..., 144., 148., 143.],
          [158., 155., 151., ..., 131., 137., 134.],
          [152., 151., 153., ..., 121., 131., 135.]],

         [[129., 144., 175., ...,  98., 123., 130.],
          [ 94., 116., 137., ..., 129., 132., 128.],
          [ 94.,  99., 118., ..., 132., 129., 132.],
          ...,
          [115., 107., 104., ..., 110., 114., 104.],
          [122., 120., 118., ...,  99., 109., 103.],
          [122., 120., 120., ..., 103., 107., 117.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:43
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:46
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:48
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:49
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

final statics:
total operators:28
tensorflow --> nums:36,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:36
mindspore --> 
torch --> 

generate models:36

analyse the exceptions in iter:50
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 16.,  17.,  17., ...,  62.,  55.,  51.],
          [ 16.,  16.,  15., ...,  62.,  58.,  52.],
          [ 16.,  15.,  15., ...,  57.,  59.,  56.],
          ...,
          [ 96., 114., 119., ..., 128., 120., 117.],
          [118., 100., 114., ..., 139., 131., 121.],
          [144., 136., 105., ..., 145., 137., 131.]],

         [[ 76.,  77.,  77., ..., 106.,  99.,  94.],
          [ 76.,  76.,  75., ..., 109., 105., 100.],
          [ 76.,  75.,  75., ..., 110., 111., 109.],
          ...,
          [110., 127., 132., ..., 135., 130., 131.],
          [132., 113., 126., ..., 146., 140., 134.],
          [148., 140., 114., ..., 151., 144., 141.]],

         [[ 74.,  75.,  75., ...,  87.,  80.,  75.],
          [ 74.,  74.,  74., ...,  84.,  80.,  75.],
          [ 74.,  73.,  73., ...,  79.,  80.,  78.],
          ...,
          [138., 159., 167., ..., 153., 145., 142.],
          [159., 145., 163., ..., 159., 153., 147.],
          [173., 168., 143., ..., 170., 163., 158.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:51
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:52
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

analyse the exceptions in iter:54
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  47.,  48., ...,  50.,  47.,  46.],
          [ 45.,  47.,  48., ...,  55.,  51.,  51.],
          [ 45.,  46.,  47., ...,  60.,  56.,  55.],
          ...,
          [ 50.,  50.,  51., ...,  97.,  79.,  76.],
          [ 50.,  49.,  51., ...,  81., 103.,  72.],
          [ 50.,  50.,  51., ...,  83.,  90.,  88.]],

         [[ 73.,  75.,  76., ...,  73.,  69.,  70.],
          [ 72.,  74.,  75., ...,  77.,  74.,  75.],
          [ 71.,  72.,  73., ...,  83.,  80.,  80.],
          ...,
          [ 76.,  78.,  78., ..., 118., 112., 104.],
          [ 76.,  77.,  78., ...,  92., 121., 101.],
          [ 75.,  78.,  77., ...,  91., 100., 110.]],

         [[ 28.,  30.,  33., ...,  28.,  29.,  31.],
          [ 27.,  29.,  32., ...,  32.,  31.,  32.],
          [ 29.,  30.,  31., ...,  36.,  34.,  34.],
          ...,
          [ 34.,  34.,  35., ...,  99.,  50.,  49.],
          [ 34.,  34.,  35., ..., 105., 100.,  44.],
          [ 35.,  33.,  35., ..., 100., 106.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

analyse the exceptions in iter:55
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[156., 167., 169., ..., 243., 230., 208.],
          [174., 192., 172., ..., 237., 213., 186.],
          [192., 194., 174., ..., 226., 198., 195.],
          ...,
          [187., 211., 231., ..., 210., 217., 203.],
          [231., 220., 200., ..., 183., 189., 186.],
          [238., 238., 229., ..., 141., 151., 157.]],

         [[194., 212., 215., ..., 247., 235., 215.],
          [210., 229., 204., ..., 243., 221., 193.],
          [234., 230., 201., ..., 231., 208., 200.],
          ...,
          [211., 234., 244., ..., 204., 208., 192.],
          [238., 236., 219., ..., 170., 175., 169.],
          [242., 247., 239., ..., 126., 137., 141.]],

         [[129., 127., 129., ..., 226., 206., 180.],
          [147., 159., 163., ..., 223., 200., 169.],
          [145., 178., 194., ..., 218., 186., 165.],
          ...,
          [151., 180., 221., ..., 199., 210., 192.],
          [218., 209., 177., ..., 153., 160., 153.],
          [224., 232., 217., ..., 106., 117., 118.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:41

analyse the exceptions in iter:56
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[141., 139., 136., ..., 228., 228., 229.],
          [148., 150., 148., ..., 228., 228., 228.],
          [149., 149., 148., ..., 230., 229., 229.],
          ...,
          [125., 124., 139., ..., 220., 199., 208.],
          [126., 116., 135., ..., 246., 226., 196.],
          [143., 145., 169., ..., 254., 255., 227.]],

         [[ 70.,  61.,  55., ..., 198., 199., 200.],
          [ 71.,  67.,  64., ..., 197., 196., 197.],
          [ 72.,  66.,  64., ..., 197., 197., 197.],
          ...,
          [100., 102., 110., ..., 169., 143., 149.],
          [101.,  93., 107., ..., 205., 181., 145.],
          [105., 107., 127., ..., 208., 206., 174.]],

         [[  8.,   2.,   0., ..., 155., 156., 157.],
          [ 10.,   5.,   2., ..., 153., 152., 153.],
          [ 17.,   7.,   4., ..., 151., 151., 151.],
          ...,
          [ 73.,  80.,  75., ..., 109.,  86.,  93.],
          [ 75.,  71.,  73., ..., 144., 121.,  87.],
          [ 67.,  71.,  83., ..., 141., 138., 105.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:42

analyse the exceptions in iter:57
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 66.,  71.,  88., ...,  85.,  86.,  79.],
          [ 75.,  79.,  95., ...,  85.,  87.,  78.],
          [ 80.,  84.,  97., ...,  81.,  82.,  74.],
          ...,
          [ 79.,  87.,  60., ...,  35.,  26.,  20.],
          [ 77.,  70.,  37., ...,  79.,  77.,  66.],
          [ 78.,  63.,  31., ..., 140., 135., 128.]],

         [[ 73.,  77.,  86., ...,  80.,  81.,  73.],
          [ 81.,  84.,  92., ...,  79.,  80.,  72.],
          [ 85.,  88.,  93., ...,  75.,  74.,  68.],
          ...,
          [ 74.,  84.,  58., ...,  35.,  26.,  21.],
          [ 74.,  68.,  37., ...,  68.,  66.,  55.],
          [ 74.,  61.,  32., ..., 122., 117., 113.]],

         [[ 33.,  40.,  62., ...,  55.,  62.,  54.],
          [ 40.,  45.,  66., ...,  56.,  62.,  54.],
          [ 44.,  50.,  68., ...,  48.,  53.,  51.],
          ...,
          [ 59.,  69.,  43., ...,  22.,  14.,  10.],
          [ 59.,  53.,  22., ...,  60.,  58.,  50.],
          [ 58.,  44.,  15., ..., 116., 113., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:43

analyse the exceptions in iter:58
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 97.,  96., 108., ..., 130., 117., 115.],
          [111., 104., 111., ..., 138., 128., 124.],
          [135., 132., 128., ..., 136., 130., 121.],
          ...,
          [124., 120., 126., ..., 114., 118., 119.],
          [126., 123., 125., ...,  96., 102., 102.],
          [124., 124., 126., ...,  97.,  96.,  81.]],

         [[ 83.,  84.,  98., ..., 113., 100., 100.],
          [ 97.,  91.,  99., ..., 121., 112., 111.],
          [120., 116., 113., ..., 119., 113., 109.],
          ...,
          [109., 104., 109., ...,  99., 105., 104.],
          [108., 106., 108., ...,  82.,  89.,  88.],
          [106., 107., 109., ...,  83.,  84.,  69.]],

         [[ 41.,  46.,  56., ...,  60.,  48.,  48.],
          [ 49.,  45.,  49., ...,  66.,  57.,  57.],
          [ 68.,  65.,  57., ...,  63.,  58.,  54.],
          ...,
          [ 55.,  51.,  57., ...,  57.,  61.,  55.],
          [ 54.,  52.,  53., ...,  44.,  49.,  46.],
          [ 52.,  53.,  55., ...,  42.,  45.,  36.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:44

analyse the exceptions in iter:63
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  70.,  76., ...,  33.,  59.,  62.],
          [ 71.,  78.,  87., ...,  23.,  65.,  74.],
          [ 69.,  77.,  82., ...,  19.,  67.,  83.],
          ...,
          [ 14.,  14.,  14., ...,  54.,  54.,  52.],
          [ 14.,  14.,  14., ...,  53.,  45.,  38.],
          [ 14.,  14.,  14., ...,  49.,  31.,  21.]],

         [[114., 121., 129., ...,  47.,  62.,  66.],
          [120., 129., 140., ...,  30.,  62.,  72.],
          [118., 129., 137., ...,  20.,  57.,  73.],
          ...,
          [ 14.,  14.,  14., ...,  76.,  80.,  81.],
          [ 14.,  14.,  14., ...,  76.,  69.,  63.],
          [ 14.,  14.,  14., ...,  72.,  51.,  39.]],

         [[ 54.,  62.,  71., ...,  42.,  53.,  56.],
          [ 57.,  65.,  75., ...,  24.,  51.,  57.],
          [ 53.,  60.,  63., ...,  13.,  49.,  66.],
          ...,
          [ 14.,  14.,  14., ...,  45.,  42.,  46.],
          [ 14.,  14.,  14., ...,  46.,  37.,  34.],
          [ 14.,  14.,  14., ...,  45.,  30.,  21.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:45

analyse the exceptions in iter:64
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  67.,  69., ...,  93., 108., 102.],
          [ 65.,  65.,  69., ..., 104., 122., 132.],
          [ 62.,  63.,  68., ..., 122., 146., 140.],
          ...,
          [ 88.,  90.,  95., ...,  83.,  89.,  92.],
          [ 90.,  94.,  98., ...,  75.,  78.,  85.],
          [ 95., 102., 104., ...,  74.,  79.,  84.]],

         [[ 29.,  32.,  35., ...,  73.,  87.,  81.],
          [ 29.,  30.,  34., ...,  83.,  97., 106.],
          [ 27.,  28.,  32., ...,  99., 118., 114.],
          ...,
          [ 76.,  79.,  85., ...,  85.,  93.,  97.],
          [ 79.,  83.,  87., ...,  66.,  74.,  86.],
          [ 84.,  90.,  94., ...,  62.,  70.,  78.]],

         [[ 29.,  30.,  33., ...,  70.,  82.,  74.],
          [ 29.,  28.,  32., ...,  78.,  90.,  98.],
          [ 25.,  24.,  30., ...,  93., 110., 104.],
          ...,
          [ 84.,  86.,  92., ...,  99., 108., 111.],
          [ 85.,  90.,  95., ...,  71.,  83.,  97.],
          [ 92.,  98., 102., ...,  62.,  73.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:46

analyse the exceptions in iter:65
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[148., 132., 134., ..., 124., 108., 124.],
          [197., 168., 176., ..., 176., 162., 141.],
          [199., 199., 213., ..., 182., 178., 153.],
          ...,
          [179., 183., 182., ..., 164., 147., 136.],
          [162., 146., 127., ..., 118., 118., 132.],
          [150., 143., 123., ..., 124., 126., 157.]],

         [[141., 128., 135., ..., 131., 109., 127.],
          [181., 151., 166., ..., 178., 157., 133.],
          [194., 191., 209., ..., 186., 175., 141.],
          ...,
          [170., 165., 166., ..., 144., 127., 119.],
          [156., 133., 116., ..., 100.,  99., 116.],
          [148., 141., 125., ..., 119., 121., 154.]],

         [[174., 173., 187., ..., 186., 166., 171.],
          [214., 185., 199., ..., 213., 191., 162.],
          [207., 193., 209., ..., 193., 178., 156.],
          ...,
          [170., 148., 145., ..., 121., 106., 130.],
          [173., 140., 122., ..., 106., 108., 138.],
          [184., 176., 161., ..., 162., 162., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:47

analyse the exceptions in iter:68
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 103., 104., ..., 102.,  94.,  99.],
          [125., 119., 120., ..., 108., 104., 110.],
          [113.,  73.,  80., ...,  47.,  78., 103.],
          ...,
          [102., 125., 190., ...,  86.,  69.,  92.],
          [120., 141., 194., ...,  81.,  85., 109.],
          [159., 166., 163., ...,  98., 110., 100.]],

         [[125., 128., 130., ..., 121., 121., 120.],
          [151., 157., 160., ..., 137., 144., 145.],
          [136., 102., 107., ...,  72., 117., 141.],
          ...,
          [ 77.,  88., 159., ...,  72.,  57.,  70.],
          [ 92., 100., 163., ...,  68.,  77., 101.],
          [133., 127., 132., ...,  85., 105., 102.]],

         [[141., 147., 145., ..., 130., 132., 129.],
          [167., 181., 185., ..., 145., 155., 156.],
          [148., 122., 127., ...,  76., 124., 151.],
          ...,
          [ 37.,  49., 132., ...,  48.,  37.,  40.],
          [ 49.,  52., 124., ...,  34.,  39.,  59.],
          [ 96.,  79.,  90., ...,  57.,  64.,  67.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:48

analyse the exceptions in iter:0
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:8
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

analyse the exceptions in iter:9
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

final statics:
total operators:28
tensorflow --> nums:10,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:10
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:10
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:11
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:12
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:13
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:14
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:16
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:17
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:19
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:20
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:21
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:22
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:23
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:24
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:28
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:29
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:30
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:32
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:33
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:35
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:38
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:39
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:40
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:44
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:46
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:47
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 77.,  76.,  78., ...,  68.,  58.,  48.],
          [ 71.,  67.,  69., ...,  57.,  44.,  36.],
          [ 55.,  52.,  58., ...,  62.,  53.,  48.],
          ...,
          [ 63.,  62.,  67., ...,  63.,  58.,  55.],
          [ 89.,  91.,  89., ...,  65.,  68.,  66.],
          [103., 107.,  92., ...,  69.,  77.,  77.]],

         [[113., 112., 114., ..., 104.,  94.,  84.],
          [107., 102., 105., ...,  93.,  80.,  72.],
          [ 91.,  88.,  94., ...,  98.,  89.,  84.],
          ...,
          [ 97.,  92.,  97., ...,  97.,  92.,  89.],
          [118., 116., 114., ...,  99., 102., 101.],
          [129., 131., 119., ..., 104., 111., 112.]],

         [[137., 136., 139., ..., 128., 118., 108.],
          [131., 126., 130., ..., 116., 104.,  96.],
          [115., 112., 119., ..., 122., 113., 108.],
          ...,
          [119., 115., 121., ..., 123., 118., 115.],
          [136., 135., 136., ..., 122., 125., 124.],
          [144., 147., 138., ..., 127., 134., 135.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

final statics:
total operators:28
tensorflow --> nums:35,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:35
mindspore --> 
torch --> 

generate models:35

analyse the exceptions in iter:50
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 16.,  17.,  17., ...,  62.,  55.,  51.],
          [ 16.,  16.,  15., ...,  62.,  58.,  52.],
          [ 16.,  15.,  15., ...,  57.,  59.,  56.],
          ...,
          [ 96., 114., 119., ..., 128., 120., 117.],
          [118., 100., 114., ..., 139., 131., 121.],
          [144., 136., 105., ..., 145., 137., 131.]],

         [[ 76.,  77.,  77., ..., 106.,  99.,  94.],
          [ 76.,  76.,  75., ..., 109., 105., 100.],
          [ 76.,  75.,  75., ..., 110., 111., 109.],
          ...,
          [110., 127., 132., ..., 135., 130., 131.],
          [132., 113., 126., ..., 146., 140., 134.],
          [148., 140., 114., ..., 151., 144., 141.]],

         [[ 74.,  75.,  75., ...,  87.,  80.,  75.],
          [ 74.,  74.,  74., ...,  84.,  80.,  75.],
          [ 74.,  73.,  73., ...,  79.,  80.,  78.],
          ...,
          [138., 159., 167., ..., 153., 145., 142.],
          [159., 145., 163., ..., 159., 153., 147.],
          [173., 168., 143., ..., 170., 163., 158.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:51
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:52
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:53
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[157., 156., 157., ..., 177., 177., 175.],
          [162., 162., 162., ..., 187., 182., 179.],
          [165., 164., 165., ..., 211., 204., 191.],
          ...,
          [172., 168., 166., ..., 203., 203., 200.],
          [177., 175., 172., ..., 203., 203., 200.],
          [182., 182., 179., ..., 203., 203., 200.]],

         [[159., 158., 159., ..., 183., 180., 179.],
          [164., 164., 164., ..., 194., 187., 183.],
          [167., 166., 167., ..., 220., 210., 196.],
          ...,
          [174., 170., 167., ..., 205., 205., 202.],
          [179., 177., 173., ..., 205., 205., 202.],
          [184., 183., 180., ..., 205., 205., 202.]],

         [[146., 145., 146., ..., 185., 183., 179.],
          [151., 151., 151., ..., 200., 193., 186.],
          [154., 153., 154., ..., 226., 219., 201.],
          ...,
          [161., 158., 158., ..., 201., 201., 199.],
          [166., 166., 164., ..., 202., 202., 199.],
          [171., 174., 173., ..., 202., 202., 199.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

analyse the exceptions in iter:56
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[141., 139., 136., ..., 228., 228., 229.],
          [148., 150., 148., ..., 228., 228., 228.],
          [149., 149., 148., ..., 230., 229., 229.],
          ...,
          [125., 124., 139., ..., 220., 199., 208.],
          [126., 116., 135., ..., 246., 226., 196.],
          [143., 145., 169., ..., 254., 255., 227.]],

         [[ 70.,  61.,  55., ..., 198., 199., 200.],
          [ 71.,  67.,  64., ..., 197., 196., 197.],
          [ 72.,  66.,  64., ..., 197., 197., 197.],
          ...,
          [100., 102., 110., ..., 169., 143., 149.],
          [101.,  93., 107., ..., 205., 181., 145.],
          [105., 107., 127., ..., 208., 206., 174.]],

         [[  8.,   2.,   0., ..., 155., 156., 157.],
          [ 10.,   5.,   2., ..., 153., 152., 153.],
          [ 17.,   7.,   4., ..., 151., 151., 151.],
          ...,
          [ 73.,  80.,  75., ..., 109.,  86.,  93.],
          [ 75.,  71.,  73., ..., 144., 121.,  87.],
          [ 67.,  71.,  83., ..., 141., 138., 105.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

analyse the exceptions in iter:0
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:8
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:15
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:16
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:17
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:18
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:19
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:20
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:22
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:23
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:25
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:26
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:28
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:29
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:30
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:34
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:35
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:36
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 131., 193., ..., 172., 169., 166.],
          [165., 127., 189., ..., 172., 169., 166.],
          [163., 126., 186., ..., 173., 170., 168.],
          ...,
          [147., 139., 145., ..., 220., 218., 219.],
          [146., 143., 152., ..., 221., 220., 219.],
          [148., 143., 146., ..., 223., 221., 220.]],

         [[122., 108., 196., ..., 187., 183., 181.],
          [119., 104., 192., ..., 186., 183., 180.],
          [117., 103., 189., ..., 187., 184., 182.],
          ...,
          [ 93.,  85.,  91., ..., 220., 218., 219.],
          [ 87.,  83.,  94., ..., 221., 220., 219.],
          [ 87.,  82.,  85., ..., 223., 221., 220.]],

         [[ 65.,  75., 192., ..., 187., 183., 181.],
          [ 62.,  72., 187., ..., 186., 183., 180.],
          [ 60.,  71., 185., ..., 187., 184., 182.],
          ...,
          [ 35.,  39.,  42., ..., 220., 218., 219.],
          [ 31.,  39.,  43., ..., 222., 220., 219.],
          [ 28.,  31.,  30., ..., 223., 221., 220.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:37
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:38
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:40
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:41
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:44
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:46
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:47
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 77.,  76.,  78., ...,  68.,  58.,  48.],
          [ 71.,  67.,  69., ...,  57.,  44.,  36.],
          [ 55.,  52.,  58., ...,  62.,  53.,  48.],
          ...,
          [ 63.,  62.,  67., ...,  63.,  58.,  55.],
          [ 89.,  91.,  89., ...,  65.,  68.,  66.],
          [103., 107.,  92., ...,  69.,  77.,  77.]],

         [[113., 112., 114., ..., 104.,  94.,  84.],
          [107., 102., 105., ...,  93.,  80.,  72.],
          [ 91.,  88.,  94., ...,  98.,  89.,  84.],
          ...,
          [ 97.,  92.,  97., ...,  97.,  92.,  89.],
          [118., 116., 114., ...,  99., 102., 101.],
          [129., 131., 119., ..., 104., 111., 112.]],

         [[137., 136., 139., ..., 128., 118., 108.],
          [131., 126., 130., ..., 116., 104.,  96.],
          [115., 112., 119., ..., 122., 113., 108.],
          ...,
          [119., 115., 121., ..., 123., 118., 115.],
          [136., 135., 136., ..., 122., 125., 124.],
          [144., 147., 138., ..., 127., 134., 135.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

final statics:
total operators:28
tensorflow --> nums:32,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:32
mindspore --> 
torch --> 

generate models:32

analyse the exceptions in iter:50
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 16.,  17.,  17., ...,  62.,  55.,  51.],
          [ 16.,  16.,  15., ...,  62.,  58.,  52.],
          [ 16.,  15.,  15., ...,  57.,  59.,  56.],
          ...,
          [ 96., 114., 119., ..., 128., 120., 117.],
          [118., 100., 114., ..., 139., 131., 121.],
          [144., 136., 105., ..., 145., 137., 131.]],

         [[ 76.,  77.,  77., ..., 106.,  99.,  94.],
          [ 76.,  76.,  75., ..., 109., 105., 100.],
          [ 76.,  75.,  75., ..., 110., 111., 109.],
          ...,
          [110., 127., 132., ..., 135., 130., 131.],
          [132., 113., 126., ..., 146., 140., 134.],
          [148., 140., 114., ..., 151., 144., 141.]],

         [[ 74.,  75.,  75., ...,  87.,  80.,  75.],
          [ 74.,  74.,  74., ...,  84.,  80.,  75.],
          [ 74.,  73.,  73., ...,  79.,  80.,  78.],
          ...,
          [138., 159., 167., ..., 153., 145., 142.],
          [159., 145., 163., ..., 159., 153., 147.],
          [173., 168., 143., ..., 170., 163., 158.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:52
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:54
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  47.,  48., ...,  50.,  47.,  46.],
          [ 45.,  47.,  48., ...,  55.,  51.,  51.],
          [ 45.,  46.,  47., ...,  60.,  56.,  55.],
          ...,
          [ 50.,  50.,  51., ...,  97.,  79.,  76.],
          [ 50.,  49.,  51., ...,  81., 103.,  72.],
          [ 50.,  50.,  51., ...,  83.,  90.,  88.]],

         [[ 73.,  75.,  76., ...,  73.,  69.,  70.],
          [ 72.,  74.,  75., ...,  77.,  74.,  75.],
          [ 71.,  72.,  73., ...,  83.,  80.,  80.],
          ...,
          [ 76.,  78.,  78., ..., 118., 112., 104.],
          [ 76.,  77.,  78., ...,  92., 121., 101.],
          [ 75.,  78.,  77., ...,  91., 100., 110.]],

         [[ 28.,  30.,  33., ...,  28.,  29.,  31.],
          [ 27.,  29.,  32., ...,  32.,  31.,  32.],
          [ 29.,  30.,  31., ...,  36.,  34.,  34.],
          ...,
          [ 34.,  34.,  35., ...,  99.,  50.,  49.],
          [ 34.,  34.,  35., ..., 105., 100.,  44.],
          [ 35.,  33.,  35., ..., 100., 106.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:55
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[156., 167., 169., ..., 243., 230., 208.],
          [174., 192., 172., ..., 237., 213., 186.],
          [192., 194., 174., ..., 226., 198., 195.],
          ...,
          [187., 211., 231., ..., 210., 217., 203.],
          [231., 220., 200., ..., 183., 189., 186.],
          [238., 238., 229., ..., 141., 151., 157.]],

         [[194., 212., 215., ..., 247., 235., 215.],
          [210., 229., 204., ..., 243., 221., 193.],
          [234., 230., 201., ..., 231., 208., 200.],
          ...,
          [211., 234., 244., ..., 204., 208., 192.],
          [238., 236., 219., ..., 170., 175., 169.],
          [242., 247., 239., ..., 126., 137., 141.]],

         [[129., 127., 129., ..., 226., 206., 180.],
          [147., 159., 163., ..., 223., 200., 169.],
          [145., 178., 194., ..., 218., 186., 165.],
          ...,
          [151., 180., 221., ..., 199., 210., 192.],
          [218., 209., 177., ..., 153., 160., 153.],
          [224., 232., 217., ..., 106., 117., 118.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:56
tensorflow exception:
{'id': 38, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[141., 139., 136., ..., 228., 228., 229.],
          [148., 150., 148., ..., 228., 228., 228.],
          [149., 149., 148., ..., 230., 229., 229.],
          ...,
          [125., 124., 139., ..., 220., 199., 208.],
          [126., 116., 135., ..., 246., 226., 196.],
          [143., 145., 169., ..., 254., 255., 227.]],

         [[ 70.,  61.,  55., ..., 198., 199., 200.],
          [ 71.,  67.,  64., ..., 197., 196., 197.],
          [ 72.,  66.,  64., ..., 197., 197., 197.],
          ...,
          [100., 102., 110., ..., 169., 143., 149.],
          [101.,  93., 107., ..., 205., 181., 145.],
          [105., 107., 127., ..., 208., 206., 174.]],

         [[  8.,   2.,   0., ..., 155., 156., 157.],
          [ 10.,   5.,   2., ..., 153., 152., 153.],
          [ 17.,   7.,   4., ..., 151., 151., 151.],
          ...,
          [ 73.,  80.,  75., ..., 109.,  86.,  93.],
          [ 75.,  71.,  73., ..., 144., 121.,  87.],
          [ 67.,  71.,  83., ..., 141., 138., 105.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:0
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:8
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:9
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:8
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:10
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

analyse the exceptions in iter:12
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:14
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:15
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:16
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:17
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:18
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:21
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:22
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:23
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:24
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:25
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:26
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:27
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:28
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:29
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]
torch exception:
{'id': 22, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:24

analyse the exceptions in iter:30
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 122., 126., ..., 124., 120., 117.],
          [122., 119., 121., ..., 124., 122., 117.],
          [122., 121., 121., ..., 126., 123., 121.],
          ...,
          [126., 126., 128., ..., 133., 122., 114.],
          [125., 126., 127., ..., 128., 121., 114.],
          [123., 123., 126., ..., 128., 126., 121.]],

         [[118., 115., 119., ..., 118., 114., 111.],
          [115., 112., 114., ..., 118., 116., 111.],
          [115., 114., 114., ..., 120., 117., 115.],
          ...,
          [118., 118., 120., ..., 125., 114., 106.],
          [117., 118., 119., ..., 120., 113., 106.],
          [115., 115., 118., ..., 119., 118., 113.]],

         [[110., 108., 111., ..., 106., 102.,  99.],
          [107., 104., 106., ..., 106., 104.,  99.],
          [107., 106., 106., ..., 108., 105., 103.],
          ...,
          [107., 107., 109., ..., 114., 103.,  95.],
          [106., 107., 108., ..., 109., 102.,  95.],
          [104., 104., 107., ..., 109., 107., 102.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:31
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[236., 233., 234., ..., 148., 147., 140.],
          [243., 242., 243., ..., 163., 161., 159.],
          [245., 242., 245., ..., 163., 161., 157.],
          ...,
          [ 79.,  70.,  72., ...,  38.,  36.,  33.],
          [ 81.,  78.,  74., ...,  47.,  31.,  24.],
          [ 80.,  80.,  74., ...,  40.,  28.,  22.]],

         [[242., 239., 240., ..., 145., 145., 137.],
          [249., 247., 250., ..., 162., 160., 158.],
          [251., 248., 251., ..., 162., 160., 157.],
          ...,
          [ 74.,  65.,  68., ...,  31.,  29.,  25.],
          [ 79.,  73.,  68., ...,  38.,  24.,  17.],
          [ 80.,  77.,  67., ...,  30.,  21.,  15.]],

         [[238., 235., 236., ..., 140., 139., 131.],
          [245., 244., 246., ..., 162., 160., 158.],
          [247., 244., 247., ..., 166., 164., 161.],
          ...,
          [ 60.,  47.,  45., ...,  25.,  23.,  19.],
          [ 62.,  56.,  49., ...,  29.,  17.,  10.],
          [ 63.,  61.,  52., ...,  20.,  12.,   8.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:32
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:33
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:34
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:37
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:39
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:40
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:41
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:42
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[127., 148., 192., ..., 112., 144., 153.],
          [ 89., 111., 151., ..., 161., 166., 163.],
          [ 98.,  94., 110., ..., 173., 169., 173.],
          ...,
          [156., 151., 149., ..., 150., 149., 142.],
          [163., 162., 161., ..., 135., 141., 138.],
          [160., 160., 163., ..., 138., 143., 151.]],

         [[126., 144., 181., ..., 102., 135., 142.],
          [ 90., 110., 141., ..., 152., 158., 154.],
          [ 94.,  94., 109., ..., 159., 154., 157.],
          ...,
          [152., 145., 144., ..., 144., 148., 143.],
          [158., 155., 151., ..., 131., 137., 134.],
          [152., 151., 153., ..., 121., 131., 135.]],

         [[129., 144., 175., ...,  98., 123., 130.],
          [ 94., 116., 137., ..., 129., 132., 128.],
          [ 94.,  99., 118., ..., 132., 129., 132.],
          ...,
          [115., 107., 104., ..., 110., 114., 104.],
          [122., 120., 118., ...,  99., 109., 103.],
          [122., 120., 120., ..., 103., 107., 117.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:43
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:44
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:45
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 54.,  59.,  56., ..., 133., 131., 132.],
          [ 59.,  62.,  55., ..., 193., 200., 197.],
          [ 41.,  41.,  36., ..., 202., 196., 190.],
          ...,
          [105.,  97.,  96., ...,  98., 100., 100.],
          [ 86.,  96.,  97., ...,  94.,  98., 100.],
          [ 70.,  92., 113., ...,  98.,  96.,  92.]],

         [[ 31.,  34.,  37., ...,  92.,  89.,  94.],
          [ 38.,  39.,  36., ..., 135., 144., 142.],
          [ 26.,  25.,  21., ..., 144., 141., 136.],
          ...,
          [161., 163., 170., ..., 145., 138., 130.],
          [149., 157., 164., ..., 127., 126., 124.],
          [136., 146., 169., ..., 121., 117., 112.]],

         [[ 18.,  19.,  22., ...,  53.,  49.,  53.],
          [ 26.,  26.,  25., ...,  77.,  86.,  86.],
          [ 18.,  16.,  13., ...,  84.,  81.,  79.],
          ...,
          [157., 162., 164., ..., 144., 135., 123.],
          [143., 156., 160., ..., 122., 120., 114.],
          [128., 145., 168., ..., 111., 106., 101.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:46
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:48
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

analyse the exceptions in iter:49
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

final statics:
total operators:28
tensorflow --> nums:40,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
conv2d:40
mindspore --> 
torch --> 
flatten:1

generate models:40

analyse the exceptions in iter:51
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:41

analyse the exceptions in iter:0
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:10
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:13
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:14
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:15
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:16
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:18
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:20
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:23
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:24
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:25
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:26
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:27
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:28
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:29
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:31
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[236., 233., 234., ..., 148., 147., 140.],
          [243., 242., 243., ..., 163., 161., 159.],
          [245., 242., 245., ..., 163., 161., 157.],
          ...,
          [ 79.,  70.,  72., ...,  38.,  36.,  33.],
          [ 81.,  78.,  74., ...,  47.,  31.,  24.],
          [ 80.,  80.,  74., ...,  40.,  28.,  22.]],

         [[242., 239., 240., ..., 145., 145., 137.],
          [249., 247., 250., ..., 162., 160., 158.],
          [251., 248., 251., ..., 162., 160., 157.],
          ...,
          [ 74.,  65.,  68., ...,  31.,  29.,  25.],
          [ 79.,  73.,  68., ...,  38.,  24.,  17.],
          [ 80.,  77.,  67., ...,  30.,  21.,  15.]],

         [[238., 235., 236., ..., 140., 139., 131.],
          [245., 244., 246., ..., 162., 160., 158.],
          [247., 244., 247., ..., 166., 164., 161.],
          ...,
          [ 60.,  47.,  45., ...,  25.,  23.,  19.],
          [ 62.,  56.,  49., ...,  29.,  17.,  10.],
          [ 63.,  61.,  52., ...,  20.,  12.,   8.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:32
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:33
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:36
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 131., 193., ..., 172., 169., 166.],
          [165., 127., 189., ..., 172., 169., 166.],
          [163., 126., 186., ..., 173., 170., 168.],
          ...,
          [147., 139., 145., ..., 220., 218., 219.],
          [146., 143., 152., ..., 221., 220., 219.],
          [148., 143., 146., ..., 223., 221., 220.]],

         [[122., 108., 196., ..., 187., 183., 181.],
          [119., 104., 192., ..., 186., 183., 180.],
          [117., 103., 189., ..., 187., 184., 182.],
          ...,
          [ 93.,  85.,  91., ..., 220., 218., 219.],
          [ 87.,  83.,  94., ..., 221., 220., 219.],
          [ 87.,  82.,  85., ..., 223., 221., 220.]],

         [[ 65.,  75., 192., ..., 187., 183., 181.],
          [ 62.,  72., 187., ..., 186., 183., 180.],
          [ 60.,  71., 185., ..., 187., 184., 182.],
          ...,
          [ 35.,  39.,  42., ..., 220., 218., 219.],
          [ 31.,  39.,  43., ..., 222., 220., 219.],
          [ 28.,  31.,  30., ..., 223., 221., 220.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:37
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:38
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:39
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:41
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:43
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:44
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[139., 144., 146., ..., 132., 131., 129.],
          [139., 124., 128., ..., 110., 108., 114.],
          [172., 126., 116., ...,  67.,  68., 113.],
          ...,
          [ 95.,  93.,  91., ...,  81., 104., 107.],
          [132., 124., 119., ..., 114., 131., 132.],
          [110., 124., 129., ..., 129., 128., 112.]],

         [[154., 160., 162., ..., 140., 142., 141.],
          [148., 137., 149., ..., 114., 112., 127.],
          [162., 114., 109., ...,  71.,  68., 119.],
          ...,
          [ 88.,  82.,  84., ...,  94., 103., 102.],
          [109., 105., 104., ..., 104., 112., 110.],
          [108., 116., 116., ..., 117., 114., 105.]],

         [[188., 192., 192., ...,  77.,  76.,  70.],
          [180., 167., 178., ...,  81.,  76.,  68.],
          [172., 121., 129., ...,  50.,  58.,  78.],
          ...,
          [ 44.,  45.,  44., ...,  30.,  51.,  53.],
          [ 74.,  69.,  61., ...,  59.,  74.,  70.],
          [ 52.,  67.,  67., ...,  80.,  75.,  59.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:46
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:47
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 77.,  76.,  78., ...,  68.,  58.,  48.],
          [ 71.,  67.,  69., ...,  57.,  44.,  36.],
          [ 55.,  52.,  58., ...,  62.,  53.,  48.],
          ...,
          [ 63.,  62.,  67., ...,  63.,  58.,  55.],
          [ 89.,  91.,  89., ...,  65.,  68.,  66.],
          [103., 107.,  92., ...,  69.,  77.,  77.]],

         [[113., 112., 114., ..., 104.,  94.,  84.],
          [107., 102., 105., ...,  93.,  80.,  72.],
          [ 91.,  88.,  94., ...,  98.,  89.,  84.],
          ...,
          [ 97.,  92.,  97., ...,  97.,  92.,  89.],
          [118., 116., 114., ...,  99., 102., 101.],
          [129., 131., 119., ..., 104., 111., 112.]],

         [[137., 136., 139., ..., 128., 118., 108.],
          [131., 126., 130., ..., 116., 104.,  96.],
          [115., 112., 119., ..., 122., 113., 108.],
          ...,
          [119., 115., 121., ..., 123., 118., 115.],
          [136., 135., 136., ..., 122., 125., 124.],
          [144., 147., 138., ..., 127., 134., 135.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:48
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:49
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

final statics:
total operators:28
tensorflow --> nums:39,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:39
mindspore --> 
torch --> 

generate models:39

analyse the exceptions in iter:51
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

analyse the exceptions in iter:57
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 66.,  71.,  88., ...,  85.,  86.,  79.],
          [ 75.,  79.,  95., ...,  85.,  87.,  78.],
          [ 80.,  84.,  97., ...,  81.,  82.,  74.],
          ...,
          [ 79.,  87.,  60., ...,  35.,  26.,  20.],
          [ 77.,  70.,  37., ...,  79.,  77.,  66.],
          [ 78.,  63.,  31., ..., 140., 135., 128.]],

         [[ 73.,  77.,  86., ...,  80.,  81.,  73.],
          [ 81.,  84.,  92., ...,  79.,  80.,  72.],
          [ 85.,  88.,  93., ...,  75.,  74.,  68.],
          ...,
          [ 74.,  84.,  58., ...,  35.,  26.,  21.],
          [ 74.,  68.,  37., ...,  68.,  66.,  55.],
          [ 74.,  61.,  32., ..., 122., 117., 113.]],

         [[ 33.,  40.,  62., ...,  55.,  62.,  54.],
          [ 40.,  45.,  66., ...,  56.,  62.,  54.],
          [ 44.,  50.,  68., ...,  48.,  53.,  51.],
          ...,
          [ 59.,  69.,  43., ...,  22.,  14.,  10.],
          [ 59.,  53.,  22., ...,  60.,  58.,  50.],
          [ 58.,  44.,  15., ..., 116., 113., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:41

analyse the exceptions in iter:58
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 97.,  96., 108., ..., 130., 117., 115.],
          [111., 104., 111., ..., 138., 128., 124.],
          [135., 132., 128., ..., 136., 130., 121.],
          ...,
          [124., 120., 126., ..., 114., 118., 119.],
          [126., 123., 125., ...,  96., 102., 102.],
          [124., 124., 126., ...,  97.,  96.,  81.]],

         [[ 83.,  84.,  98., ..., 113., 100., 100.],
          [ 97.,  91.,  99., ..., 121., 112., 111.],
          [120., 116., 113., ..., 119., 113., 109.],
          ...,
          [109., 104., 109., ...,  99., 105., 104.],
          [108., 106., 108., ...,  82.,  89.,  88.],
          [106., 107., 109., ...,  83.,  84.,  69.]],

         [[ 41.,  46.,  56., ...,  60.,  48.,  48.],
          [ 49.,  45.,  49., ...,  66.,  57.,  57.],
          [ 68.,  65.,  57., ...,  63.,  58.,  54.],
          ...,
          [ 55.,  51.,  57., ...,  57.,  61.,  55.],
          [ 54.,  52.,  53., ...,  44.,  49.,  46.],
          [ 52.,  53.,  55., ...,  42.,  45.,  36.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:42

analyse the exceptions in iter:59
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 255., 194., ..., 255., 255., 253.],
          [251., 255., 211., ..., 246., 249., 251.],
          [251., 255., 218., ..., 249., 250., 252.],
          ...,
          [ 57.,  30.,  73., ...,  23.,  26., 112.],
          [ 89.,  16.,  26., ...,  21.,  32., 149.],
          [185.,  94.,  54., ...,  60., 129., 221.]],

         [[251., 255., 212., ..., 254., 253., 252.],
          [249., 255., 234., ..., 255., 255., 252.],
          [250., 255., 235., ..., 255., 254., 253.],
          ...,
          [111.,  86.,  88., ...,  60.,  81., 149.],
          [134.,  77.,  74., ...,  75.,  83., 174.],
          [208., 134.,  99., ..., 104., 159., 232.]],

         [[249., 255., 224., ..., 253., 252., 252.],
          [246., 254., 240., ..., 251., 252., 251.],
          [249., 255., 240., ..., 254., 252., 252.],
          ...,
          [159., 138., 110., ..., 100., 139., 186.],
          [177., 144., 136., ..., 140., 145., 198.],
          [229., 182., 159., ..., 159., 197., 240.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:43

analyse the exceptions in iter:60
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[201., 191., 194., ...,  83.,  39.,  36.],
          [ 57.,  62., 134., ...,  79.,  48.,  35.],
          [ 74., 123., 138., ..., 162., 132.,  56.],
          ...,
          [ 67.,  62.,  55., ...,  69.,  72.,  72.],
          [ 73.,  67.,  59., ...,  72.,  72.,  71.],
          [ 74.,  71.,  67., ...,  61.,  58.,  63.]],

         [[209., 204., 207., ...,  88.,  48.,  47.],
          [ 73.,  78., 148., ...,  91.,  59.,  45.],
          [ 99., 142., 153., ..., 175., 139.,  61.],
          ...,
          [ 80.,  72.,  62., ...,  78.,  80.,  82.],
          [ 87.,  77.,  67., ...,  81.,  81.,  81.],
          [ 89.,  84.,  79., ...,  73.,  69.,  75.]],

         [[211., 210., 216., ...,  82.,  33.,  24.],
          [ 79.,  92., 161., ...,  96.,  57.,  32.],
          [110., 165., 169., ..., 186., 145.,  56.],
          ...,
          [ 89.,  82.,  73., ...,  93.,  95.,  98.],
          [ 95.,  87.,  77., ...,  96.,  96.,  96.],
          [100.,  95.,  89., ...,  88.,  85.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:44

analyse the exceptions in iter:64
tensorflow exception:
{'id': 36, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 65.,  67.,  69., ...,  93., 108., 102.],
          [ 65.,  65.,  69., ..., 104., 122., 132.],
          [ 62.,  63.,  68., ..., 122., 146., 140.],
          ...,
          [ 88.,  90.,  95., ...,  83.,  89.,  92.],
          [ 90.,  94.,  98., ...,  75.,  78.,  85.],
          [ 95., 102., 104., ...,  74.,  79.,  84.]],

         [[ 29.,  32.,  35., ...,  73.,  87.,  81.],
          [ 29.,  30.,  34., ...,  83.,  97., 106.],
          [ 27.,  28.,  32., ...,  99., 118., 114.],
          ...,
          [ 76.,  79.,  85., ...,  85.,  93.,  97.],
          [ 79.,  83.,  87., ...,  66.,  74.,  86.],
          [ 84.,  90.,  94., ...,  62.,  70.,  78.]],

         [[ 29.,  30.,  33., ...,  70.,  82.,  74.],
          [ 29.,  28.,  32., ...,  78.,  90.,  98.],
          [ 25.,  24.,  30., ...,  93., 110., 104.],
          ...,
          [ 84.,  86.,  92., ...,  99., 108., 111.],
          [ 85.,  90.,  95., ...,  71.,  83.,  97.],
          [ 92.,  98., 102., ...,  62.,  73.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:45

analyse the exceptions in iter:0
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:5
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:6
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:7
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:8
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:11
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:12
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:13
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 17.,  17.,  17., ...,  23.,  22.,  19.],
          [ 18.,  18.,  18., ...,  24.,  23.,  22.],
          [ 18.,  18.,  19., ...,  24.,  23.,  23.],
          ...,
          [217., 226., 210., ...,  33.,  32.,  33.],
          [219., 222., 214., ...,  35.,  34.,  33.],
          [210., 221., 215., ...,  36.,  34.,  32.]],

         [[  3.,   3.,   2., ...,  13.,  12.,   9.],
          [  4.,   4.,   4., ...,  14.,  13.,  12.],
          [  4.,   4.,   5., ...,  14.,  13.,  13.],
          ...,
          [214., 219., 201., ...,  24.,  23.,  24.],
          [215., 215., 208., ...,  26.,  25.,  24.],
          [208., 216., 212., ...,  27.,  25.,  23.]],

         [[  2.,   2.,   1., ...,  11.,  10.,   7.],
          [  3.,   3.,   3., ...,  12.,  11.,  10.],
          [  3.,   3.,   4., ...,  12.,  11.,  11.],
          ...,
          [223., 227., 213., ...,  17.,  16.,  17.],
          [230., 229., 225., ...,  19.,  18.,  17.],
          [223., 229., 227., ...,  20.,  18.,  16.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:14
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:17
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:18
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:19
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:21
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:22
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:23
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:24
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:26
tensorflow exception:
{'id': 37, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:0
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[170., 168., 177., ..., 162., 158., 157.],
          [168., 172., 171., ..., 159., 156., 154.],
          [154., 149., 129., ..., 161., 157., 154.],
          ...,
          [ 74.,  76.,  78., ...,  71.,  68.,  61.],
          [ 68.,  69.,  72., ...,  76.,  71.,  71.],
          [ 67.,  68.,  69., ...,  75.,  71.,  73.]],

         [[180., 178., 185., ..., 179., 178., 177.],
          [181., 185., 183., ..., 177., 176., 174.],
          [170., 165., 144., ..., 178., 177., 174.],
          ...,
          [ 84.,  85.,  85., ...,  75.,  72.,  65.],
          [ 76.,  77.,  79., ...,  80.,  75.,  75.],
          [ 75.,  76.,  75., ...,  79.,  75.,  77.]],

         [[198., 196., 203., ..., 215., 214., 212.],
          [198., 201., 200., ..., 212., 211., 209.],
          [186., 181., 162., ..., 214., 212., 209.],
          ...,
          [ 80.,  81.,  82., ...,  78.,  75.,  68.],
          [ 77.,  78.,  78., ...,  83.,  78.,  78.],
          [ 78.,  79.,  76., ...,  82.,  78.,  80.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:5
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:6
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:7
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:8
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

analyse the exceptions in iter:9
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

final statics:
total operators:28
tensorflow --> nums:10,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:10
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:14
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:15
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:16
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:17
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:19
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:20
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:21
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:22
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:23
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:24
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:25
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[162., 164., 169., ..., 184., 190., 202.],
          [153., 158., 164., ..., 178., 189., 201.],
          [157., 161., 164., ..., 178., 190., 202.],
          ...,
          [214., 213., 213., ..., 240., 241., 242.],
          [218., 209., 208., ..., 232., 236., 239.],
          [216., 207., 201., ..., 231., 233., 235.]],

         [[164., 167., 171., ..., 176., 186., 198.],
          [151., 156., 163., ..., 171., 184., 198.],
          [151., 156., 160., ..., 170., 186., 199.],
          ...,
          [205., 193., 185., ..., 207., 206., 209.],
          [209., 188., 180., ..., 195., 196., 200.],
          [204., 189., 174., ..., 192., 194., 198.]],

         [[130., 128., 131., ..., 137., 146., 161.],
          [119., 120., 124., ..., 131., 143., 158.],
          [120., 121., 122., ..., 131., 142., 156.],
          ...,
          [193., 181., 174., ..., 193., 194., 196.],
          [198., 176., 169., ..., 182., 185., 187.],
          [197., 178., 156., ..., 178., 181., 183.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:27
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:29
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:31
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[236., 233., 234., ..., 148., 147., 140.],
          [243., 242., 243., ..., 163., 161., 159.],
          [245., 242., 245., ..., 163., 161., 157.],
          ...,
          [ 79.,  70.,  72., ...,  38.,  36.,  33.],
          [ 81.,  78.,  74., ...,  47.,  31.,  24.],
          [ 80.,  80.,  74., ...,  40.,  28.,  22.]],

         [[242., 239., 240., ..., 145., 145., 137.],
          [249., 247., 250., ..., 162., 160., 158.],
          [251., 248., 251., ..., 162., 160., 157.],
          ...,
          [ 74.,  65.,  68., ...,  31.,  29.,  25.],
          [ 79.,  73.,  68., ...,  38.,  24.,  17.],
          [ 80.,  77.,  67., ...,  30.,  21.,  15.]],

         [[238., 235., 236., ..., 140., 139., 131.],
          [245., 244., 246., ..., 162., 160., 158.],
          [247., 244., 247., ..., 166., 164., 161.],
          ...,
          [ 60.,  47.,  45., ...,  25.,  23.,  19.],
          [ 62.,  56.,  49., ...,  29.,  17.,  10.],
          [ 63.,  61.,  52., ...,  20.,  12.,   8.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:32
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 50.,  51.,  42., ...,  48.,  18.,  14.],
          [ 86.,  92.,  82., ...,  46.,  17.,  11.],
          [ 43.,  43.,  51., ...,  42.,  10.,   6.],
          ...,
          [220., 209., 199., ..., 177., 176., 175.],
          [188., 182., 182., ..., 176., 175., 174.],
          [188., 184., 186., ..., 176., 176., 173.]],

         [[ 64.,  63.,  55., ...,  45.,  18.,  15.],
          [107., 110.,  99., ...,  43.,  17.,  12.],
          [ 60.,  56.,  65., ...,  39.,  10.,   6.],
          ...,
          [165., 174., 172., ..., 171., 170., 168.],
          [178., 170., 161., ..., 168., 167., 166.],
          [167., 163., 167., ..., 169., 168., 165.]],

         [[ 37.,  41.,  41., ...,  42.,  14.,  12.],
          [ 67.,  76.,  67., ...,  41.,  14.,  10.],
          [ 42.,  41.,  46., ...,  37.,   9.,   5.],
          ...,
          [151., 165., 164., ..., 168., 167., 166.],
          [162., 162., 157., ..., 166., 165., 164.],
          [162., 157., 160., ..., 166., 166., 162.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:33
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[  7.,   7.,   5., ...,  82.,  80.,  69.],
          [  6.,   6.,   5., ...,  85.,  86.,  81.],
          [  1.,   7.,   8., ...,  98.,  96.,  86.],
          ...,
          [150., 135., 129., ...,  72.,  45.,  26.],
          [156., 153., 138., ...,  57.,  23.,  38.],
          [183., 191., 182., ...,  83.,  67., 114.]],

         [[  5.,   5.,   4., ...,  84.,  85.,  73.],
          [  4.,   4.,   3., ...,  86.,  88.,  80.],
          [  1.,   7.,   8., ...,  96.,  96.,  84.],
          ...,
          [153., 136., 129., ...,  72.,  51.,  32.],
          [156., 151., 136., ...,  58.,  32.,  45.],
          [193., 199., 189., ...,  83.,  74., 120.]],

         [[  8.,   8.,   6., ...,  78.,  81.,  68.],
          [  8.,   9.,   8., ...,  77.,  81.,  72.],
          [  6.,  12.,  13., ...,  83.,  85.,  73.],
          ...,
          [139., 121., 113., ...,  69.,  63.,  51.],
          [139., 130., 110., ...,  56.,  48.,  64.],
          [183., 185., 171., ...,  76.,  81., 119.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:34
tensorflow exception:
{'id': 39, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:0
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 59.,  43.,  50., ..., 158., 152., 148.],
          [ 16.,   0.,  18., ..., 123., 119., 122.],
          [ 25.,  16.,  49., ..., 118., 120., 109.],
          ...,
          [208., 201., 198., ..., 160.,  56.,  53.],
          [180., 173., 186., ..., 184.,  97.,  83.],
          [177., 168., 179., ..., 216., 151., 123.]],

         [[ 62.,  46.,  48., ..., 132., 125., 124.],
          [ 20.,   0.,   8., ...,  88.,  83.,  87.],
          [ 24.,   7.,  27., ...,  84.,  84.,  73.],
          ...,
          [170., 153., 161., ..., 133.,  31.,  34.],
          [139., 123., 144., ..., 148.,  62.,  53.],
          [144., 129., 142., ..., 184., 118.,  92.]],

         [[ 63.,  45.,  43., ..., 108., 102., 103.],
          [ 20.,   0.,   0., ...,  55.,  50.,  57.],
          [ 21.,   0.,   8., ...,  50.,  50.,  42.],
          ...,
          [ 96.,  34.,  26., ...,  70.,   7.,  20.],
          [ 96.,  42.,  30., ...,  94.,  34.,  34.],
          [116.,  94.,  87., ..., 140.,  84.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:1

analyse the exceptions in iter:1
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[154., 126., 105., ...,  91.,  87.,  79.],
          [140., 145., 125., ...,  96.,  77.,  71.],
          [140., 139., 115., ...,  79.,  68.,  67.],
          ...,
          [175., 156., 154., ...,  42.,  61.,  93.],
          [165., 156., 159., ..., 103., 123., 131.],
          [163., 158., 163., ..., 143., 143., 143.]],

         [[177., 137., 104., ...,  95.,  90.,  81.],
          [160., 153., 125., ...,  99.,  80.,  73.],
          [155., 146., 115., ...,  82.,  70.,  69.],
          ...,
          [167., 154., 160., ...,  34.,  53.,  83.],
          [154., 152., 161., ...,  93., 114., 121.],
          [148., 148., 156., ..., 133., 134., 133.]],

         [[187., 136.,  95., ...,  71.,  71.,  70.],
          [169., 154., 118., ...,  78.,  62.,  61.],
          [164., 149., 112., ...,  64.,  55.,  55.],
          ...,
          [166., 160., 170., ...,  36.,  57.,  91.],
          [128., 130., 142., ...,  96., 120., 131.],
          [120., 122., 133., ..., 139., 142., 144.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:2

analyse the exceptions in iter:2
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [113., 111., 105., ...,  72.,  72.,  72.],
          [111., 104.,  99., ...,  68.,  70.,  78.],
          [106.,  99.,  95., ...,  78.,  79.,  80.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [120., 118., 112., ...,  81.,  80.,  80.],
          [118., 111., 106., ...,  75.,  76.,  84.],
          [113., 106., 102., ...,  85.,  85.,  86.]],

         [[255., 253., 253., ..., 253., 253., 253.],
          [255., 255., 255., ..., 255., 255., 255.],
          [255., 254., 254., ..., 254., 254., 254.],
          ...,
          [112., 111., 106., ...,  80.,  79.,  79.],
          [110., 104.,  98., ...,  73.,  75.,  82.],
          [105.,  98.,  94., ...,  83.,  83.,  84.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:3

analyse the exceptions in iter:3
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  37.,  38., ...,  76.,  81.,  85.],
          [ 33.,  34.,  32., ...,  95.,  96.,  85.],
          [ 39.,  40.,  57., ...,  93., 107.,  95.],
          ...,
          [ 83.,  87.,  84., ...,  99.,  90.,  81.],
          [ 88.,  90.,  93., ...,  80.,  76.,  82.],
          [ 97.,  94.,  93., ...,  54.,  63.,  72.]],

         [[ 25.,  34.,  35., ...,  67.,  72.,  76.],
          [ 28.,  30.,  27., ...,  82.,  82.,  72.],
          [ 32.,  33.,  50., ...,  76.,  89.,  77.],
          ...,
          [ 73.,  77.,  74., ...,  93.,  84.,  75.],
          [ 72.,  74.,  77., ...,  74.,  70.,  76.],
          [ 78.,  75.,  75., ...,  47.,  56.,  65.]],

         [[ 10.,  19.,  20., ...,  39.,  43.,  47.],
          [ 13.,  14.,  12., ...,  55.,  56.,  45.],
          [ 15.,  17.,  33., ...,  52.,  66.,  54.],
          ...,
          [ 52.,  56.,  52., ...,  70.,  61.,  52.],
          [ 51.,  52.,  56., ...,  53.,  49.,  55.],
          [ 56.,  53.,  53., ...,  28.,  37.,  46.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:4

analyse the exceptions in iter:5
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[159., 150., 153., ...,  91.,  74.,  76.],
          [142., 146., 155., ..., 127., 122.,  86.],
          [109.,  99., 105., ..., 137., 163.,  93.],
          ...,
          [244., 240., 241., ..., 156., 179., 200.],
          [246., 243., 243., ..., 162., 178., 192.],
          [246., 243., 244., ..., 166., 173., 182.]],

         [[102.,  91.,  95., ...,  71.,  63.,  58.],
          [ 75.,  72.,  76., ..., 105., 111.,  69.],
          [ 67.,  58.,  59., ..., 112., 132.,  72.],
          ...,
          [129., 123., 122., ...,  42.,  59.,  73.],
          [133., 128., 127., ...,  44.,  56.,  65.],
          [139., 133., 132., ...,  47.,  51.,  57.]],

         [[101.,  95.,  97., ...,  56.,  55.,  55.],
          [ 68.,  66.,  65., ...,  71.,  93.,  61.],
          [ 75.,  60.,  52., ...,  80., 105.,  71.],
          ...,
          [ 70.,  65.,  65., ...,  15.,  26.,  36.],
          [ 74.,  72.,  70., ...,  14.,  22.,  27.],
          [ 82.,  78.,  77., ...,  14.,  17.,  19.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:5

analyse the exceptions in iter:6
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 105., 118., ..., 109., 108.,  91.],
          [167., 116.,  72., ..., 105., 105.,  89.],
          [140., 142., 119., ..., 104.,  84.,  78.],
          ...,
          [139., 142., 135., ...,  89.,  97., 126.],
          [163., 153., 146., ...,  85.,  98., 127.],
          [183., 176., 154., ...,  94.,  91., 122.]],

         [[206., 140., 148., ..., 147., 147., 129.],
          [213., 160., 109., ..., 142., 142., 127.],
          [191., 193., 163., ..., 139., 120., 115.],
          ...,
          [148., 155., 156., ..., 134., 148., 176.],
          [157., 164., 164., ..., 130., 148., 178.],
          [153., 182., 154., ..., 134., 133., 170.]],

         [[ 84.,  61., 101., ...,  73.,  69.,  57.],
          [ 84.,  49.,  43., ...,  79.,  72.,  57.],
          [ 65.,  66.,  79., ...,  84.,  58.,  49.],
          ...,
          [ 81.,  74.,  72., ...,  28.,  24.,  49.],
          [ 85.,  82.,  90., ...,  19.,  27.,  48.],
          [102., 116., 100., ...,  29.,  26.,  44.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:6

analyse the exceptions in iter:7
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 28.,  30.,  33., ...,  43.,  52.,  46.],
          [ 27.,  27.,  21., ..., 112., 117., 115.],
          [ 34.,  33.,  24., ..., 175., 177., 176.],
          ...,
          [142., 142., 150., ..., 134., 128., 134.],
          [140., 145., 150., ..., 131., 130., 122.],
          [134., 136., 136., ..., 106., 104., 101.]],

         [[ 35.,  34.,  44., ...,  56.,  64.,  58.],
          [ 30.,  28.,  31., ..., 136., 140., 138.],
          [ 36.,  33.,  30., ..., 208., 209., 208.],
          ...,
          [176., 176., 184., ..., 175., 168., 175.],
          [176., 180., 186., ..., 170., 170., 162.],
          [171., 171., 171., ..., 144., 142., 140.]],

         [[ 39.,  44.,  47., ...,  45.,  53.,  47.],
          [ 38.,  41.,  39., ...,  97., 101., 100.],
          [ 42.,  43.,  40., ..., 143., 144., 143.],
          ...,
          [118., 118., 127., ..., 119., 112., 119.],
          [124., 129., 134., ..., 119., 119., 111.],
          [123., 124., 124., ..., 100.,  99.,  96.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:7

analyse the exceptions in iter:8
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[134., 131., 128., ..., 127., 127., 128.],
          [133., 129., 128., ..., 127., 127., 128.],
          [128., 127., 128., ..., 126., 126., 126.],
          ...,
          [174., 171., 155., ...,  27.,  29.,  28.],
          [194., 189., 159., ...,  30.,  30.,  30.],
          [193., 181., 168., ...,  31.,  32.,  32.]],

         [[186., 184., 182., ..., 181., 181., 182.],
          [189., 186., 186., ..., 183., 183., 184.],
          [185., 182., 182., ..., 181., 181., 180.],
          ...,
          [208., 206., 189., ...,  94.,  96.,  94.],
          [221., 215., 196., ...,  95.,  96.,  95.],
          [217., 208., 201., ...,  94.,  94.,  94.]],

         [[223., 220., 218., ..., 222., 222., 223.],
          [228., 224., 224., ..., 224., 224., 225.],
          [226., 223., 223., ..., 222., 222., 221.],
          ...,
          [235., 229., 216., ..., 136., 137., 136.],
          [244., 239., 225., ..., 138., 139., 140.],
          [237., 230., 227., ..., 136., 137., 138.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[125., 110., 102., ..., 202., 200., 202.],
          [142., 146., 176., ..., 195., 198., 204.],
          [180., 143., 156., ..., 122., 139., 158.],
          ...,
          [104., 101., 101., ..., 126., 126., 125.],
          [104., 105., 109., ..., 138., 137., 137.],
          [105., 108., 115., ..., 143., 143., 144.]],

         [[125., 101.,  90., ..., 207., 205., 208.],
          [146., 144., 172., ..., 201., 205., 211.],
          [185., 146., 157., ..., 111., 128., 147.],
          ...,
          [ 82.,  80.,  81., ..., 103., 103., 101.],
          [ 81.,  84.,  88., ..., 113., 113., 112.],
          [ 83.,  87.,  94., ..., 117., 116., 116.]],

         [[116.,  91.,  83., ..., 214., 212., 214.],
          [142., 139., 170., ..., 205., 209., 215.],
          [183., 146., 157., ..., 113., 131., 150.],
          ...,
          [ 41.,  39.,  38., ...,  67.,  69.,  68.],
          [ 40.,  41.,  43., ...,  78.,  80.,  81.],
          [ 42.,  45.,  50., ...,  82.,  84.,  86.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:9

final statics:
total operators:28
tensorflow --> nums:9,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:9
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:10
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[53., 54., 56., ..., 47., 41., 24.],
          [46., 53., 54., ..., 42., 39., 28.],
          [45., 50., 46., ..., 38., 36., 29.],
          ...,
          [71., 74., 80., ..., 51., 46., 49.],
          [75., 79., 81., ..., 61., 64., 48.],
          [85., 85., 86., ..., 61., 64., 49.]],

         [[65., 63., 60., ..., 51., 45., 28.],
          [59., 62., 59., ..., 46., 43., 32.],
          [59., 60., 52., ..., 42., 40., 33.],
          ...,
          [83., 83., 85., ..., 54., 49., 50.],
          [82., 85., 85., ..., 65., 67., 50.],
          [83., 84., 86., ..., 65., 67., 50.]],

         [[53., 52., 50., ..., 50., 44., 27.],
          [41., 45., 44., ..., 45., 42., 31.],
          [38., 41., 34., ..., 41., 39., 32.],
          ...,
          [66., 66., 67., ..., 33., 34., 41.],
          [67., 69., 67., ..., 41., 48., 41.],
          [71., 71., 70., ..., 39., 46., 41.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[142., 172., 176., ..., 216., 198., 205.],
          [191., 196., 174., ..., 229., 222., 217.],
          [220., 217., 192., ..., 224., 225., 218.],
          ...,
          [197., 196., 201., ..., 200., 199., 205.],
          [196., 191., 193., ..., 198., 199., 201.],
          [186., 182., 174., ..., 158., 158., 163.]],

         [[149., 172., 168., ..., 212., 194., 202.],
          [190., 192., 166., ..., 222., 215., 210.],
          [212., 209., 183., ..., 214., 214., 208.],
          ...,
          [152., 152., 156., ..., 165., 165., 164.],
          [157., 152., 154., ..., 164., 165., 161.],
          [150., 147., 139., ..., 124., 125., 125.]],

         [[152., 167., 154., ..., 211., 193., 200.],
          [192., 190., 159., ..., 220., 213., 207.],
          [212., 208., 182., ..., 209., 210., 203.],
          ...,
          [136., 135., 140., ..., 146., 146., 150.],
          [139., 135., 136., ..., 144., 145., 146.],
          [133., 130., 121., ..., 105., 106., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[164., 162., 162., ..., 157., 153., 153.],
          [168., 166., 166., ..., 164., 160., 158.],
          [172., 170., 171., ..., 168., 165., 163.],
          ...,
          [123., 117., 112., ..., 117.,  95., 120.],
          [120., 116., 112., ..., 126., 120., 120.],
          [121., 120., 116., ..., 124., 124., 120.]],

         [[215., 212., 212., ..., 210., 208., 203.],
          [218., 215., 215., ..., 212., 209., 205.],
          [220., 217., 218., ..., 212., 208., 207.],
          ...,
          [160., 154., 149., ..., 136., 115., 149.],
          [156., 151., 147., ..., 149., 144., 152.],
          [154., 152., 148., ..., 152., 154., 154.]],

         [[244., 240., 240., ..., 237., 235., 234.],
          [245., 242., 242., ..., 238., 236., 235.],
          [246., 243., 244., ..., 238., 235., 236.],
          ...,
          [105., 102.,  99., ..., 100.,  79., 100.],
          [100.,  99.,  96., ..., 110., 103., 101.],
          [ 96.,  99.,  97., ..., 108., 107., 100.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:12

analyse the exceptions in iter:14
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100.,  98.,  99., ..., 165., 163., 165.],
          [101., 100., 100., ..., 164., 163., 159.],
          [105., 104., 104., ..., 156., 136., 114.],
          ...,
          [166., 166., 168., ..., 137., 137., 147.],
          [161., 162., 167., ..., 131., 138., 137.],
          [164., 162., 164., ..., 153., 157., 156.]],

         [[146., 144., 144., ..., 165., 163., 165.],
          [145., 143., 143., ..., 161., 162., 161.],
          [147., 145., 145., ..., 150., 133., 117.],
          ...,
          [156., 156., 157., ..., 127., 126., 136.],
          [152., 153., 158., ..., 125., 133., 132.],
          [158., 156., 158., ..., 146., 151., 150.]],

         [[192., 189., 189., ..., 165., 163., 165.],
          [188., 186., 186., ..., 159., 159., 157.],
          [189., 186., 187., ..., 147., 129., 111.],
          ...,
          [150., 151., 152., ..., 112., 114., 127.],
          [149., 150., 155., ..., 117., 124., 120.],
          [155., 153., 155., ..., 139., 141., 137.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:13

analyse the exceptions in iter:15
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[100., 100., 101., ...,  95.,  94.,  95.],
          [103., 103., 104., ...,  97.,  97.,  97.],
          [107., 106., 106., ..., 100., 100., 101.],
          ...,
          [165., 159., 167., ...,  75.,  75.,  72.],
          [158., 173., 182., ...,  76.,  75.,  77.],
          [161., 162., 160., ...,  98., 129., 162.]],

         [[168., 168., 167., ..., 165., 165., 167.],
          [170., 168., 168., ..., 167., 166., 168.],
          [174., 172., 173., ..., 170., 170., 172.],
          ...,
          [178., 170., 177., ..., 117., 120., 120.],
          [174., 186., 193., ..., 119., 119., 121.],
          [176., 176., 171., ..., 137., 160., 185.]],

         [[231., 229., 230., ..., 231., 228., 229.],
          [230., 228., 226., ..., 229., 227., 229.],
          [233., 230., 229., ..., 230., 230., 232.],
          ...,
          [177., 167., 170., ..., 154., 157., 158.],
          [172., 182., 188., ..., 154., 153., 154.],
          [174., 172., 169., ..., 167., 183., 202.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:14

analyse the exceptions in iter:16
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[235., 235., 237., ..., 233., 227., 223.],
          [231., 232., 234., ..., 231., 225., 221.],
          [231., 233., 237., ..., 232., 225., 221.],
          ...,
          [125., 126., 143., ...,  66.,  65.,  68.],
          [127., 141., 149., ...,  63.,  67.,  62.],
          [137., 142., 149., ...,  62.,  61.,  51.]],

         [[236., 236., 238., ..., 234., 230., 228.],
          [232., 233., 235., ..., 232., 228., 225.],
          [232., 234., 238., ..., 233., 228., 226.],
          ...,
          [124., 125., 142., ...,  89.,  86.,  83.],
          [125., 140., 148., ...,  89.,  88.,  79.],
          [135., 140., 147., ...,  90.,  84.,  68.]],

         [[238., 238., 240., ..., 236., 233., 232.],
          [234., 235., 237., ..., 234., 232., 233.],
          [234., 236., 240., ..., 235., 232., 233.],
          ...,
          [122., 123., 140., ...,  23.,  23.,  37.],
          [125., 139., 148., ...,  24.,  26.,  29.],
          [136., 141., 148., ...,  27.,  23.,  14.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:15

analyse the exceptions in iter:17
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 142., 151., ...,  39.,  40.,  38.],
          [109., 141., 152., ...,  36.,  40.,  36.],
          [105., 142., 151., ...,  39.,  44.,  39.],
          ...,
          [ 62.,  39.,  60., ...,  42.,  46.,  47.],
          [ 62.,  52.,  58., ...,  43.,  47.,  49.],
          [ 55.,  60.,  56., ...,  45.,  47.,  51.]],

         [[104., 135., 146., ...,  39.,  40.,  38.],
          [103., 133., 147., ...,  36.,  40.,  36.],
          [ 98., 133., 145., ...,  39.,  44.,  39.],
          ...,
          [ 59.,  38.,  64., ...,  44.,  44.,  44.],
          [ 57.,  51.,  61., ...,  46.,  45.,  46.],
          [ 51.,  60.,  60., ...,  48.,  46.,  48.]],

         [[ 97., 118., 120., ...,  39.,  40.,  38.],
          [ 95., 115., 119., ...,  37.,  40.,  36.],
          [ 90., 114., 117., ...,  41.,  45.,  40.],
          ...,
          [ 60.,  49.,  81., ...,  56.,  55.,  55.],
          [ 56.,  61.,  78., ...,  58.,  58.,  60.],
          [ 50.,  71.,  78., ...,  60.,  60.,  62.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:16

analyse the exceptions in iter:18
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[197., 198., 201., ..., 217., 217., 217.],
          [193., 195., 198., ..., 216., 215., 214.],
          [192., 194., 197., ..., 217., 216., 215.],
          ...,
          [156., 156., 156., ...,  98., 117., 128.],
          [158., 159., 154., ..., 131., 117.,  91.],
          [152., 151., 145., ...,  91.,  90.,  79.]],

         [[187., 188., 191., ..., 201., 201., 201.],
          [183., 185., 188., ..., 200., 200., 198.],
          [182., 184., 187., ..., 201., 200., 199.],
          ...,
          [146., 146., 146., ...,  79.,  96., 105.],
          [148., 149., 144., ..., 110.,  99.,  75.],
          [142., 141., 135., ...,  72.,  73.,  65.]],

         [[188., 189., 192., ..., 204., 204., 204.],
          [184., 186., 189., ..., 203., 202., 201.],
          [183., 185., 188., ..., 204., 203., 202.],
          ...,
          [147., 147., 147., ...,  65.,  82.,  89.],
          [149., 150., 145., ...,  96.,  86.,  64.],
          [143., 142., 136., ...,  61.,  63.,  57.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:17

analyse the exceptions in iter:19
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 23.,  47.,  52., ..., 131., 182., 215.],
          [ 32.,  51.,  56., ..., 149., 204., 209.],
          [ 41.,  59.,  60., ..., 138., 196., 203.],
          ...,
          [167., 177., 182., ..., 199., 176., 145.],
          [166., 165., 165., ..., 183., 183., 189.],
          [175., 173., 173., ..., 190., 188., 192.]],

         [[ 27.,  49.,  46., ..., 130., 180., 212.],
          [ 31.,  49.,  49., ..., 148., 206., 217.],
          [ 37.,  57.,  59., ..., 138., 200., 217.],
          ...,
          [167., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 187.],
          [175., 173., 173., ..., 187., 186., 189.]],

         [[ 22.,  41.,  30., ..., 117., 174., 230.],
          [ 24.,  38.,  34., ..., 133., 197., 232.],
          [ 25.,  47.,  51., ..., 125., 194., 233.],
          ...,
          [168., 177., 182., ..., 192., 171., 140.],
          [166., 165., 165., ..., 181., 182., 188.],
          [175., 173., 173., ..., 184., 183., 186.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:18

analyse the exceptions in iter:20
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[153., 174., 155., ..., 122., 138.,  97.],
          [160., 164., 150., ..., 137., 160., 103.],
          [140., 147., 136., ..., 104., 125.,  93.],
          ...,
          [175., 170., 170., ..., 193., 197., 199.],
          [174., 173., 171., ..., 200., 202., 208.],
          [168., 164., 166., ..., 204., 204., 206.]],

         [[157., 180., 165., ..., 125., 143., 101.],
          [163., 170., 159., ..., 135., 161., 109.],
          [143., 152., 145., ..., 103., 128., 102.],
          ...,
          [177., 172., 172., ..., 203., 206., 204.],
          [177., 176., 174., ..., 208., 209., 212.],
          [173., 169., 171., ..., 209., 208., 210.]],

         [[155., 188., 172., ..., 123., 141.,  97.],
          [165., 180., 169., ..., 129., 157., 107.],
          [147., 166., 158., ...,  99., 125., 101.],
          ...,
          [179., 174., 174., ..., 212., 214., 213.],
          [181., 180., 178., ..., 216., 218., 221.],
          [180., 175., 177., ..., 217., 217., 219.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:19

analyse the exceptions in iter:21
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 249., 250., ..., 251., 251., 251.],
          [255., 252., 253., ..., 255., 255., 254.],
          [253., 250., 250., ..., 254., 254., 252.],
          ...,
          [254., 252., 253., ..., 252., 253., 252.],
          [250., 252., 255., ..., 254., 255., 254.],
          [236., 249., 250., ..., 250., 250., 251.]],

         [[  8.,  15.,   8., ...,   1.,   0.,   1.],
          [  7.,  15.,  13., ...,   1.,   0.,   4.],
          [  6.,  16.,  24., ...,   1.,   0.,   9.],
          ...,
          [ 66.,  62.,  64., ...,  70.,  69.,  70.],
          [ 49.,  53.,  59., ...,  70.,  68.,  59.],
          [ 37.,  48.,  42., ...,  78.,  74.,  58.]],

         [[ 42.,  42.,  39., ...,  11.,  15.,  30.],
          [ 43.,  44.,  42., ...,  11.,  18.,  33.],
          [ 42.,  42.,  43., ...,  10.,  20.,  37.],
          ...,
          [ 94.,  92.,  93., ..., 101., 103., 104.],
          [ 81.,  82.,  86., ..., 103., 100.,  89.],
          [ 68.,  76.,  73., ..., 113., 109.,  88.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:20

analyse the exceptions in iter:22
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 86.,  96., 115., ...,  84.,  95.,  79.],
          [125.,  99.,  71., ...,  78.,  88.,  93.],
          [112.,  87.,  58., ...,  89.,  88.,  85.],
          ...,
          [ 66.,  56.,  46., ...,  70.,  61.,  47.],
          [108.,  96.,  86., ...,  57.,  57.,  46.],
          [130., 120.,  98., ...,  44.,  44.,  45.]],

         [[ 74.,  83., 109., ...,  72.,  84.,  68.],
          [110.,  83.,  61., ...,  74.,  82.,  82.],
          [ 95.,  69.,  45., ...,  88.,  84.,  77.],
          ...,
          [ 61.,  53.,  46., ...,  79.,  74.,  57.],
          [100.,  91.,  82., ...,  60.,  65.,  51.],
          [117., 110.,  90., ...,  43.,  46.,  45.]],

         [[ 62.,  65.,  83., ...,  50.,  61.,  45.],
          [104.,  74.,  46., ...,  44.,  51.,  53.],
          [ 89.,  62.,  35., ...,  54.,  50.,  45.],
          ...,
          [ 39.,  33.,  28., ...,  46.,  42.,  31.],
          [ 73.,  66.,  59., ...,  38.,  41.,  31.],
          [ 91.,  86.,  67., ...,  30.,  32.,  32.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:21

analyse the exceptions in iter:23
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[126., 102., 117., ...,  96., 113., 107.],
          [135., 113., 121., ..., 115., 114., 115.],
          [126., 124., 128., ..., 134., 115., 114.],
          ...,
          [141., 155., 134., ..., 149., 147., 122.],
          [153., 164., 146., ..., 163., 189., 184.],
          [125., 129., 124., ..., 133., 180., 168.]],

         [[100.,  76.,  93., ...,  74.,  90.,  84.],
          [109.,  86.,  94., ...,  89.,  89.,  90.],
          [102.,  97., 101., ..., 109.,  90.,  90.],
          ...,
          [111., 123., 102., ..., 140., 133., 106.],
          [122., 132., 119., ..., 156., 178., 174.],
          [100., 106., 102., ..., 127., 173., 162.]],

         [[ 71.,  49.,  60., ...,  42.,  58.,  52.],
          [ 73.,  52.,  56., ...,  58.,  55.,  53.],
          [ 61.,  59.,  60., ...,  77.,  55.,  50.],
          ...,
          [ 85.,  87.,  65., ..., 118., 116.,  94.],
          [ 83.,  89.,  81., ..., 147., 174., 173.],
          [ 56.,  64.,  68., ..., 124., 174., 164.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:22

analyse the exceptions in iter:24
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 73.,  71.,  77., ..., 183., 180., 185.],
          [ 73.,  75.,  78., ..., 181., 172., 174.],
          [ 77.,  94.,  99., ..., 175., 191., 185.],
          ...,
          [ 84.,  86., 118., ...,  79., 159., 117.],
          [ 76.,  81., 103., ...,  56.,  69., 104.],
          [102.,  91.,  95., ..., 100.,  72.,  48.]],

         [[ 77.,  68.,  69., ..., 210., 214., 225.],
          [ 74.,  68.,  64., ..., 229., 220., 218.],
          [ 72.,  82.,  81., ..., 213., 230., 226.],
          ...,
          [106., 105., 133., ...,  95., 177., 133.],
          [ 96.,  98., 116., ...,  80.,  90., 120.],
          [120., 109., 110., ..., 134.,  97.,  59.]],

         [[ 58.,  50.,  44., ..., 149., 143., 144.],
          [ 52.,  55.,  50., ..., 139., 129., 127.],
          [ 64.,  79.,  73., ..., 139., 152., 142.],
          ...,
          [ 56.,  58.,  84., ...,  78., 137.,  94.],
          [ 60.,  56.,  73., ...,  36.,  40.,  69.],
          [ 92.,  62.,  62., ...,  55.,  38.,  29.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:23

analyse the exceptions in iter:26
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[131., 124., 116., ..., 184., 185., 184.],
          [127., 124., 116., ..., 177., 180., 186.],
          [123., 121., 113., ..., 179., 187., 194.],
          ...,
          [ 99.,  83.,  54., ..., 138., 155., 165.],
          [ 97.,  77.,  43., ..., 140., 154., 163.],
          [ 96.,  71.,  35., ..., 140., 156., 164.]],

         [[ 81.,  76.,  70., ..., 152., 153., 152.],
          [ 76.,  75.,  69., ..., 142., 146., 152.],
          [ 73.,  73.,  67., ..., 142., 150., 158.],
          ...,
          [ 50.,  42.,  27., ..., 103., 113., 118.],
          [ 50.,  39.,  21., ..., 105., 112., 116.],
          [ 49.,  36.,  16., ..., 104., 114., 118.]],

         [[ 32.,  27.,  20., ..., 114., 117., 120.],
          [ 27.,  26.,  19., ..., 106., 110., 116.],
          [ 23.,  24.,  17., ..., 106., 114., 118.],
          ...,
          [ 10.,   5.,   5., ...,  68.,  72.,  74.],
          [ 10.,   5.,   4., ...,  69.,  71.,  71.],
          [ 10.,   4.,   3., ...,  69.,  73.,  73.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:24

analyse the exceptions in iter:27
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 45.,  42.,  35., ...,  93.,  51.,  39.],
          [ 46.,  42.,  40., ..., 105.,  66.,  48.],
          [ 43.,  40.,  48., ...,  88.,  77.,  58.],
          ...,
          [ 55.,  67.,  73., ...,  93., 101., 103.],
          [ 55.,  62.,  68., ...,  69.,  81.,  99.],
          [ 58.,  59.,  58., ...,  77.,  66.,  83.]],

         [[ 20.,  21.,  17., ...,  86.,  47.,  36.],
          [ 22.,  22.,  22., ...,  93.,  53.,  39.],
          [ 22.,  21.,  32., ...,  74.,  59.,  44.],
          ...,
          [ 54.,  57.,  64., ...,  87., 116., 123.],
          [ 54.,  53.,  59., ...,  62.,  93., 117.],
          [ 53.,  46.,  45., ...,  68.,  75.,  99.]],

         [[ 19.,  18.,  13., ...,  81.,  42.,  32.],
          [ 20.,  18.,  18., ...,  92.,  52.,  36.],
          [ 19.,  17.,  27., ...,  77.,  60.,  43.],
          ...,
          [ 51.,  54.,  57., ...,  49.,  34.,  30.],
          [ 51.,  50.,  52., ...,  38.,  29.,  35.],
          [ 51.,  44.,  40., ...,  53.,  29.,  31.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:25

analyse the exceptions in iter:28
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[128., 121., 138., ..., 130., 101., 122.],
          [133., 125., 136., ..., 131., 106., 127.],
          [141., 126., 141., ..., 132., 114., 126.],
          ...,
          [191., 186., 175., ..., 190., 182., 195.],
          [210., 207., 198., ..., 194., 184., 192.],
          [209., 206., 207., ..., 201., 193., 196.]],

         [[141., 134., 151., ..., 150., 121., 141.],
          [146., 138., 149., ..., 151., 126., 147.],
          [155., 139., 154., ..., 152., 134., 146.],
          ...,
          [178., 174., 160., ..., 179., 175., 188.],
          [195., 197., 179., ..., 179., 178., 186.],
          [194., 195., 189., ..., 187., 187., 190.]],

         [[123., 116., 133., ..., 138., 109., 129.],
          [128., 120., 131., ..., 139., 114., 135.],
          [136., 121., 136., ..., 140., 122., 134.],
          ...,
          [126., 124., 112., ..., 138., 137., 145.],
          [143., 144., 129., ..., 138., 133., 142.],
          [142., 143., 138., ..., 145., 142., 146.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:26

analyse the exceptions in iter:29
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[202., 202., 204., ..., 207., 205., 203.],
          [206., 206., 207., ..., 210., 208., 206.],
          [210., 211., 212., ..., 214., 212., 210.],
          ...,
          [218., 210., 194., ..., 243., 244., 243.],
          [219., 217., 216., ..., 241., 241., 241.],
          [217., 216., 217., ..., 239., 239., 240.]],

         [[204., 204., 206., ..., 208., 206., 204.],
          [208., 208., 209., ..., 211., 209., 207.],
          [212., 213., 214., ..., 214., 213., 211.],
          ...,
          [217., 209., 194., ..., 242., 242., 243.],
          [218., 216., 216., ..., 240., 240., 240.],
          [216., 215., 216., ..., 238., 238., 238.]],

         [[199., 199., 201., ..., 200., 199., 198.],
          [203., 203., 204., ..., 205., 203., 201.],
          [207., 208., 210., ..., 210., 208., 206.],
          ...,
          [222., 214., 198., ..., 247., 247., 247.],
          [223., 221., 220., ..., 245., 245., 245.],
          [221., 220., 221., ..., 243., 243., 243.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:27

analyse the exceptions in iter:31
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[236., 233., 234., ..., 148., 147., 140.],
          [243., 242., 243., ..., 163., 161., 159.],
          [245., 242., 245., ..., 163., 161., 157.],
          ...,
          [ 79.,  70.,  72., ...,  38.,  36.,  33.],
          [ 81.,  78.,  74., ...,  47.,  31.,  24.],
          [ 80.,  80.,  74., ...,  40.,  28.,  22.]],

         [[242., 239., 240., ..., 145., 145., 137.],
          [249., 247., 250., ..., 162., 160., 158.],
          [251., 248., 251., ..., 162., 160., 157.],
          ...,
          [ 74.,  65.,  68., ...,  31.,  29.,  25.],
          [ 79.,  73.,  68., ...,  38.,  24.,  17.],
          [ 80.,  77.,  67., ...,  30.,  21.,  15.]],

         [[238., 235., 236., ..., 140., 139., 131.],
          [245., 244., 246., ..., 162., 160., 158.],
          [247., 244., 247., ..., 166., 164., 161.],
          ...,
          [ 60.,  47.,  45., ...,  25.,  23.,  19.],
          [ 62.,  56.,  49., ...,  29.,  17.,  10.],
          [ 63.,  61.,  52., ...,  20.,  12.,   8.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:28

analyse the exceptions in iter:34
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[172., 171., 168., ..., 158., 156., 147.],
          [169., 168., 168., ..., 158., 152., 145.],
          [174., 169., 170., ..., 157., 149., 146.],
          ...,
          [150., 157., 162., ..., 158., 147., 139.],
          [143., 149., 155., ..., 148., 143., 140.],
          [148., 146., 149., ..., 137., 134., 136.]],

         [[187., 186., 182., ..., 170., 169., 163.],
          [185., 183., 184., ..., 175., 170., 165.],
          [190., 185., 186., ..., 177., 170., 168.],
          ...,
          [163., 168., 170., ..., 168., 160., 154.],
          [154., 158., 161., ..., 157., 153., 153.],
          [158., 155., 157., ..., 143., 139., 143.]],

         [[130., 130., 126., ..., 113., 113., 107.],
          [123., 122., 123., ..., 114., 110., 107.],
          [126., 122., 123., ..., 115., 108., 109.],
          ...,
          [100., 103., 104., ..., 108.,  99.,  90.],
          [ 89.,  90.,  96., ...,  99.,  92.,  88.],
          [ 93.,  89.,  92., ...,  86.,  80.,  82.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:29

analyse the exceptions in iter:35
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[251., 247., 247., ..., 229., 244., 251.],
          [249., 246., 246., ..., 233., 249., 252.],
          [167., 167., 167., ..., 217., 217., 220.],
          ...,
          [133., 123., 124., ..., 118., 114., 115.],
          [123., 124., 126., ..., 112., 108., 104.],
          [125., 129., 126., ..., 118., 112., 105.]],

         [[249., 245., 245., ..., 190., 231., 241.],
          [248., 244., 245., ..., 188., 237., 242.],
          [165., 164., 164., ..., 182., 211., 213.],
          ...,
          [130., 127., 130., ..., 125., 122., 125.],
          [125., 127., 129., ..., 122., 119., 119.],
          [128., 132., 130., ..., 128., 122., 121.]],

         [[250., 247., 247., ..., 146., 224., 241.],
          [248., 244., 244., ..., 141., 233., 241.],
          [148., 148., 149., ..., 139., 203., 208.],
          ...,
          [ 39.,  36.,  35., ...,  30.,  26.,  27.],
          [ 36.,  36.,  32., ...,  26.,  27.,  22.],
          [ 42.,  43.,  36., ...,  35.,  33.,  26.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:30

analyse the exceptions in iter:36
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[169., 131., 193., ..., 172., 169., 166.],
          [165., 127., 189., ..., 172., 169., 166.],
          [163., 126., 186., ..., 173., 170., 168.],
          ...,
          [147., 139., 145., ..., 220., 218., 219.],
          [146., 143., 152., ..., 221., 220., 219.],
          [148., 143., 146., ..., 223., 221., 220.]],

         [[122., 108., 196., ..., 187., 183., 181.],
          [119., 104., 192., ..., 186., 183., 180.],
          [117., 103., 189., ..., 187., 184., 182.],
          ...,
          [ 93.,  85.,  91., ..., 220., 218., 219.],
          [ 87.,  83.,  94., ..., 221., 220., 219.],
          [ 87.,  82.,  85., ..., 223., 221., 220.]],

         [[ 65.,  75., 192., ..., 187., 183., 181.],
          [ 62.,  72., 187., ..., 186., 183., 180.],
          [ 60.,  71., 185., ..., 187., 184., 182.],
          ...,
          [ 35.,  39.,  42., ..., 220., 218., 219.],
          [ 31.,  39.,  43., ..., 222., 220., 219.],
          [ 28.,  31.,  30., ..., 223., 221., 220.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:31

analyse the exceptions in iter:37
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 95.,  88.,  86., ..., 101.,  91., 105.],
          [ 82.,  75.,  76., ...,  94.,  51.,  84.],
          [ 77.,  74.,  71., ...,  71.,  47.,  88.],
          ...,
          [ 97.,  92.,  97., ...,  86.,  94.,  90.],
          [ 95.,  84.,  89., ...,  96., 102.,  97.],
          [ 91.,  83.,  82., ..., 100., 105., 108.]],

         [[105.,  97.,  96., ..., 116., 108., 124.],
          [ 90.,  83.,  84., ..., 102.,  61.,  97.],
          [ 85.,  81.,  78., ...,  74.,  52.,  95.],
          ...,
          [ 95.,  92.,  93., ...,  91.,  97.,  97.],
          [ 90.,  86.,  89., ...,  97.,  96.,  94.],
          [ 84.,  81.,  81., ...,  96.,  97., 102.]],

         [[127., 120., 118., ..., 144., 136., 157.],
          [110., 104., 104., ..., 123.,  80., 122.],
          [103.,  98.,  95., ...,  86.,  63., 111.],
          ...,
          [ 72.,  69.,  70., ...,  65.,  72.,  71.],
          [ 65.,  59.,  62., ...,  76.,  77.,  73.],
          [ 63.,  57.,  55., ...,  78.,  80.,  83.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:32

analyse the exceptions in iter:38
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[110., 223., 243., ...,   7.,   0.,   0.],
          [102., 213., 244., ...,  98.,  80.,  31.],
          [ 99., 204., 248., ..., 221., 198.,  89.],
          ...,
          [ 58.,  58.,  51., ...,   8.,   9.,   6.],
          [ 69.,  54.,  49., ...,  48.,  52.,  35.],
          [ 81.,  52.,  50., ...,  15.,  16.,  13.]],

         [[ 90., 197., 215., ...,   2.,   0.,   0.],
          [ 83., 187., 217., ...,  90.,  74.,  27.],
          [ 78., 179., 221., ..., 209., 188.,  81.],
          ...,
          [ 63.,  70.,  69., ...,   8.,  10.,   8.],
          [ 72.,  64.,  65., ...,  44.,  47.,  32.],
          [ 80.,  58.,  63., ...,   5.,   5.,   3.]],

         [[ 84., 185., 201., ...,   3.,   0.,   0.],
          [ 77., 176., 203., ...,  92.,  75.,  28.],
          [ 72., 167., 207., ..., 213., 191.,  83.],
          ...,
          [ 87., 100., 103., ...,  10.,   7.,   5.],
          [ 94.,  92.,  98., ...,  43.,  44.,  30.],
          [100.,  84.,  93., ...,   5.,   5.,   4.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:33

analyse the exceptions in iter:39
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 98., 119., 109., ...,  75.,  60.,  61.],
          [ 44.,  75.,  69., ...,  81.,  55.,  65.],
          [ 73.,  94., 111., ...,  77.,  60.,  58.],
          ...,
          [ 96., 100., 129., ...,  72.,  68.,  85.],
          [124., 114., 110., ...,  84.,  81.,  73.],
          [ 93.,  98.,  95., ...,  73.,  55.,  72.]],

         [[110., 132., 122., ...,  97.,  82.,  84.],
          [ 56.,  86.,  80., ..., 103.,  77.,  87.],
          [ 84., 105., 122., ...,  99.,  82.,  82.],
          ...,
          [ 98., 100., 126., ...,  73.,  71.,  93.],
          [137., 124., 117., ...,  92.,  89.,  81.],
          [110., 112., 106., ...,  82.,  63.,  79.]],

         [[ 96., 117., 107., ...,  76.,  62.,  67.],
          [ 46.,  76.,  70., ...,  82.,  57.,  74.],
          [ 77.,  98., 115., ...,  78.,  61.,  61.],
          ...,
          [ 99., 100., 124., ...,  69.,  67.,  85.],
          [135., 121., 111., ...,  85.,  84.,  74.],
          [107., 107.,  99., ...,  75.,  58.,  72.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:34

analyse the exceptions in iter:40
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[101.,  94.,  98., ..., 121., 127., 143.],
          [120., 131., 124., ..., 115., 121., 144.],
          [120., 139., 140., ..., 105., 107., 121.],
          ...,
          [ 48.,  31.,  37., ..., 188., 159., 125.],
          [ 52.,  42.,  44., ..., 173., 165., 150.],
          [ 41.,  38.,  42., ..., 164., 145., 155.]],

         [[114., 116., 112., ..., 119., 130., 136.],
          [122., 132., 119., ..., 116., 126., 141.],
          [126., 140., 139., ...,  97., 103., 121.],
          ...,
          [ 45.,  31.,  37., ..., 157., 130., 106.],
          [ 46.,  40.,  45., ..., 135., 136., 132.],
          [ 42.,  38.,  41., ..., 130., 120., 134.]],

         [[ 35.,  48.,  42., ...,  58.,  66.,  90.],
          [ 64.,  98.,  74., ...,  53.,  63.,  77.],
          [ 50.,  82.,  82., ...,  56.,  61.,  65.],
          ...,
          [ 40.,  24.,  27., ..., 103.,  93.,  60.],
          [ 41.,  32.,  32., ..., 102.,  99.,  92.],
          [ 32.,  33.,  33., ...,  98.,  79.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:35

analyse the exceptions in iter:41
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[145., 145., 148., ..., 237., 230., 224.],
          [147., 150., 168., ..., 231., 221., 214.],
          [145., 150., 178., ..., 229., 230., 232.],
          ...,
          [231., 230., 227., ..., 235., 234., 231.],
          [224., 231., 231., ..., 240., 228., 223.],
          [125., 225., 232., ..., 224., 216., 228.]],

         [[125., 126., 130., ..., 210., 202., 199.],
          [126., 132., 147., ..., 203., 192., 190.],
          [124., 130., 155., ..., 201., 201., 205.],
          ...,
          [202., 202., 198., ..., 209., 207., 203.],
          [199., 200., 202., ..., 213., 201., 199.],
          [120., 200., 204., ..., 197., 189., 203.]],

         [[ 83.,  82.,  82., ..., 170., 161., 158.],
          [ 83.,  84., 107., ..., 163., 151., 149.],
          [ 79.,  84., 110., ..., 161., 160., 166.],
          ...,
          [169., 170., 166., ..., 172., 170., 167.],
          [163., 167., 170., ..., 177., 162., 162.],
          [ 98., 166., 170., ..., 160., 150., 167.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:36

analyse the exceptions in iter:43
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 99.,  98., 100., ..., 129., 132., 130.],
          [100., 100., 102., ..., 122., 135., 132.],
          [104., 104., 106., ..., 165., 149., 140.],
          ...,
          [195., 199., 221., ..., 209., 209., 208.],
          [197., 201., 211., ..., 208., 210., 209.],
          [199., 197., 204., ..., 208., 210., 209.]],

         [[166., 165., 167., ..., 186., 190., 188.],
          [166., 164., 167., ..., 152., 189., 188.],
          [169., 167., 170., ..., 165., 189., 189.],
          ...,
          [173., 177., 194., ..., 191., 190., 188.],
          [173., 178., 184., ..., 190., 191., 191.],
          [173., 172., 174., ..., 189., 191., 190.]],

         [[198., 196., 199., ..., 212., 215., 213.],
          [195., 194., 197., ..., 169., 213., 214.],
          [197., 195., 198., ..., 160., 205., 212.],
          ...,
          [149., 153., 166., ..., 169., 171., 173.],
          [149., 149., 147., ..., 171., 173., 175.],
          [149., 144., 137., ..., 174., 177., 175.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:37

analyse the exceptions in iter:45
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 54.,  59.,  56., ..., 133., 131., 132.],
          [ 59.,  62.,  55., ..., 193., 200., 197.],
          [ 41.,  41.,  36., ..., 202., 196., 190.],
          ...,
          [105.,  97.,  96., ...,  98., 100., 100.],
          [ 86.,  96.,  97., ...,  94.,  98., 100.],
          [ 70.,  92., 113., ...,  98.,  96.,  92.]],

         [[ 31.,  34.,  37., ...,  92.,  89.,  94.],
          [ 38.,  39.,  36., ..., 135., 144., 142.],
          [ 26.,  25.,  21., ..., 144., 141., 136.],
          ...,
          [161., 163., 170., ..., 145., 138., 130.],
          [149., 157., 164., ..., 127., 126., 124.],
          [136., 146., 169., ..., 121., 117., 112.]],

         [[ 18.,  19.,  22., ...,  53.,  49.,  53.],
          [ 26.,  26.,  25., ...,  77.,  86.,  86.],
          [ 18.,  16.,  13., ...,  84.,  81.,  79.],
          ...,
          [157., 162., 164., ..., 144., 135., 123.],
          [143., 156., 160., ..., 122., 120., 114.],
          [128., 145., 168., ..., 111., 106., 101.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:38

analyse the exceptions in iter:46
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 94.,  72.,  60., ...,  72.,  71.,  77.],
          [ 85.,  67.,  52., ...,  67.,  72.,  77.],
          [ 82.,  54.,  41., ...,  70.,  71.,  78.],
          ...,
          [ 78.,  54.,  37., ...,  51.,  44.,  52.],
          [133., 117.,  98., ...,  62.,  53.,  60.],
          [140., 137., 138., ...,  85.,  79.,  69.]],

         [[ 91.,  71.,  68., ...,  78.,  75.,  82.],
          [ 83.,  66.,  57., ...,  73.,  78.,  85.],
          [ 82.,  53.,  44., ...,  76.,  77.,  85.],
          ...,
          [ 79.,  54.,  37., ...,  49.,  47.,  50.],
          [127., 111.,  92., ...,  58.,  56.,  59.],
          [129., 126., 126., ...,  68.,  71.,  63.]],

         [[ 62.,  42.,  35., ...,  43.,  39.,  41.],
          [ 55.,  38.,  29., ...,  41.,  37.,  39.],
          [ 53.,  24.,  19., ...,  53.,  37.,  39.],
          ...,
          [ 86.,  63.,  46., ...,  28.,  20.,  28.],
          [129., 115.,  98., ...,  35.,  28.,  36.],
          [126., 125., 129., ...,  46.,  46.,  42.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:39

analyse the exceptions in iter:47
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 77.,  76.,  78., ...,  68.,  58.,  48.],
          [ 71.,  67.,  69., ...,  57.,  44.,  36.],
          [ 55.,  52.,  58., ...,  62.,  53.,  48.],
          ...,
          [ 63.,  62.,  67., ...,  63.,  58.,  55.],
          [ 89.,  91.,  89., ...,  65.,  68.,  66.],
          [103., 107.,  92., ...,  69.,  77.,  77.]],

         [[113., 112., 114., ..., 104.,  94.,  84.],
          [107., 102., 105., ...,  93.,  80.,  72.],
          [ 91.,  88.,  94., ...,  98.,  89.,  84.],
          ...,
          [ 97.,  92.,  97., ...,  97.,  92.,  89.],
          [118., 116., 114., ...,  99., 102., 101.],
          [129., 131., 119., ..., 104., 111., 112.]],

         [[137., 136., 139., ..., 128., 118., 108.],
          [131., 126., 130., ..., 116., 104.,  96.],
          [115., 112., 119., ..., 122., 113., 108.],
          ...,
          [119., 115., 121., ..., 123., 118., 115.],
          [136., 135., 136., ..., 122., 125., 124.],
          [144., 147., 138., ..., 127., 134., 135.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:40

analyse the exceptions in iter:48
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[191., 190., 190., ..., 135., 142., 146.],
          [187., 184., 179., ..., 147., 152., 153.],
          [181., 176., 165., ..., 154., 162., 158.],
          ...,
          [220., 221., 222., ..., 211., 214., 224.],
          [212., 220., 225., ..., 216., 216., 221.],
          [201., 212., 217., ..., 220., 217., 217.]],

         [[191., 192., 193., ..., 143., 149., 150.],
          [188., 187., 183., ..., 154., 158., 158.],
          [183., 178., 169., ..., 161., 167., 163.],
          ...,
          [245., 245., 244., ..., 238., 240., 248.],
          [238., 245., 247., ..., 242., 241., 244.],
          [226., 239., 243., ..., 242., 240., 238.]],

         [[168., 172., 174., ..., 123., 126., 127.],
          [165., 166., 163., ..., 134., 135., 134.],
          [160., 157., 148., ..., 140., 143., 139.],
          ...,
          [198., 199., 202., ..., 189., 193., 203.],
          [190., 198., 204., ..., 194., 195., 201.],
          [178., 190., 196., ..., 197., 196., 195.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:41

analyse the exceptions in iter:49
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]],

         [[255., 255., 255., ..., 255., 255., 255.],
          [255., 252., 255., ..., 254., 254., 254.],
          [255., 252., 255., ..., 254., 254., 254.],
          ...,
          [255., 254., 254., ..., 254., 254., 254.],
          [255., 253., 254., ..., 254., 254., 254.],
          [255., 255., 255., ..., 255., 255., 255.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:42

final statics:
total operators:28
tensorflow --> nums:42,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
conv2d:42
mindspore --> 
torch --> 

generate models:42

analyse the exceptions in iter:50
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 16.,  17.,  17., ...,  62.,  55.,  51.],
          [ 16.,  16.,  15., ...,  62.,  58.,  52.],
          [ 16.,  15.,  15., ...,  57.,  59.,  56.],
          ...,
          [ 96., 114., 119., ..., 128., 120., 117.],
          [118., 100., 114., ..., 139., 131., 121.],
          [144., 136., 105., ..., 145., 137., 131.]],

         [[ 76.,  77.,  77., ..., 106.,  99.,  94.],
          [ 76.,  76.,  75., ..., 109., 105., 100.],
          [ 76.,  75.,  75., ..., 110., 111., 109.],
          ...,
          [110., 127., 132., ..., 135., 130., 131.],
          [132., 113., 126., ..., 146., 140., 134.],
          [148., 140., 114., ..., 151., 144., 141.]],

         [[ 74.,  75.,  75., ...,  87.,  80.,  75.],
          [ 74.,  74.,  74., ...,  84.,  80.,  75.],
          [ 74.,  73.,  73., ...,  79.,  80.,  78.],
          ...,
          [138., 159., 167., ..., 153., 145., 142.],
          [159., 145., 163., ..., 159., 153., 147.],
          [173., 168., 143., ..., 170., 163., 158.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:43

analyse the exceptions in iter:51
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[213., 119.,  58., ..., 143., 140., 117.],
          [214., 128.,  62., ..., 138., 136., 111.],
          [215., 139.,  75., ..., 136., 134., 107.],
          ...,
          [118., 122., 129., ..., 158., 151., 145.],
          [111., 117., 128., ..., 153., 147., 141.],
          [110., 116., 127., ..., 141., 136., 139.]],

         [[221., 127.,  71., ..., 158., 142., 101.],
          [223., 137.,  75., ..., 152., 138.,  95.],
          [224., 148.,  88., ..., 151., 136.,  91.],
          ...,
          [ 45.,  45.,  46., ...,  65.,  68.,  67.],
          [ 38.,  42.,  47., ...,  62.,  59.,  63.],
          [ 38.,  40.,  48., ...,  55.,  52.,  58.]],

         [[221., 122.,  81., ..., 150., 136.,  87.],
          [220., 130.,  83., ..., 145., 133.,  82.],
          [219., 139.,  94., ..., 143., 131.,  77.],
          ...,
          [ 37.,  40.,  42., ...,  54.,  55.,  55.],
          [ 32.,  36.,  41., ...,  53.,  49.,  51.],
          [ 32.,  34.,  41., ...,  46.,  43.,  47.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:44

analyse the exceptions in iter:52
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 63.,  77.,  66., ...,  76.,  86., 114.],
          [ 72.,  70.,  64., ...,  84.,  81.,  88.],
          [ 56.,  70.,  54., ..., 139., 104.,  77.],
          ...,
          [118., 152., 175., ..., 102., 128., 179.],
          [137., 148., 148., ..., 121., 170., 203.],
          [171., 173., 153., ..., 167., 187., 174.]],

         [[ 70.,  88.,  88., ...,  91.,  94., 116.],
          [ 71.,  83.,  85., ...,  94.,  91.,  97.],
          [ 65.,  82.,  76., ..., 142., 114.,  93.],
          ...,
          [107., 135., 155., ...,  79., 105., 150.],
          [123., 129., 129., ...,  94., 142., 168.],
          [145., 146., 130., ..., 136., 157., 143.]],

         [[ 37.,  63.,  63., ...,  65.,  71.,  95.],
          [ 39.,  58.,  58., ...,  71.,  67.,  73.],
          [ 34.,  53.,  48., ..., 120.,  90.,  71.],
          ...,
          [ 85., 111., 133., ...,  63.,  85., 114.],
          [101., 109., 105., ...,  74., 116., 130.],
          [108., 107.,  96., ..., 107., 129., 115.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:45

analyse the exceptions in iter:55
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[156., 167., 169., ..., 243., 230., 208.],
          [174., 192., 172., ..., 237., 213., 186.],
          [192., 194., 174., ..., 226., 198., 195.],
          ...,
          [187., 211., 231., ..., 210., 217., 203.],
          [231., 220., 200., ..., 183., 189., 186.],
          [238., 238., 229., ..., 141., 151., 157.]],

         [[194., 212., 215., ..., 247., 235., 215.],
          [210., 229., 204., ..., 243., 221., 193.],
          [234., 230., 201., ..., 231., 208., 200.],
          ...,
          [211., 234., 244., ..., 204., 208., 192.],
          [238., 236., 219., ..., 170., 175., 169.],
          [242., 247., 239., ..., 126., 137., 141.]],

         [[129., 127., 129., ..., 226., 206., 180.],
          [147., 159., 163., ..., 223., 200., 169.],
          [145., 178., 194., ..., 218., 186., 165.],
          ...,
          [151., 180., 221., ..., 199., 210., 192.],
          [218., 209., 177., ..., 153., 160., 153.],
          [224., 232., 217., ..., 106., 117., 118.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:46

analyse the exceptions in iter:57
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 66.,  71.,  88., ...,  85.,  86.,  79.],
          [ 75.,  79.,  95., ...,  85.,  87.,  78.],
          [ 80.,  84.,  97., ...,  81.,  82.,  74.],
          ...,
          [ 79.,  87.,  60., ...,  35.,  26.,  20.],
          [ 77.,  70.,  37., ...,  79.,  77.,  66.],
          [ 78.,  63.,  31., ..., 140., 135., 128.]],

         [[ 73.,  77.,  86., ...,  80.,  81.,  73.],
          [ 81.,  84.,  92., ...,  79.,  80.,  72.],
          [ 85.,  88.,  93., ...,  75.,  74.,  68.],
          ...,
          [ 74.,  84.,  58., ...,  35.,  26.,  21.],
          [ 74.,  68.,  37., ...,  68.,  66.,  55.],
          [ 74.,  61.,  32., ..., 122., 117., 113.]],

         [[ 33.,  40.,  62., ...,  55.,  62.,  54.],
          [ 40.,  45.,  66., ...,  56.,  62.,  54.],
          [ 44.,  50.,  68., ...,  48.,  53.,  51.],
          ...,
          [ 59.,  69.,  43., ...,  22.,  14.,  10.],
          [ 59.,  53.,  22., ...,  60.,  58.,  50.],
          [ 58.,  44.,  15., ..., 116., 113., 111.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:47

analyse the exceptions in iter:58
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 97.,  96., 108., ..., 130., 117., 115.],
          [111., 104., 111., ..., 138., 128., 124.],
          [135., 132., 128., ..., 136., 130., 121.],
          ...,
          [124., 120., 126., ..., 114., 118., 119.],
          [126., 123., 125., ...,  96., 102., 102.],
          [124., 124., 126., ...,  97.,  96.,  81.]],

         [[ 83.,  84.,  98., ..., 113., 100., 100.],
          [ 97.,  91.,  99., ..., 121., 112., 111.],
          [120., 116., 113., ..., 119., 113., 109.],
          ...,
          [109., 104., 109., ...,  99., 105., 104.],
          [108., 106., 108., ...,  82.,  89.,  88.],
          [106., 107., 109., ...,  83.,  84.,  69.]],

         [[ 41.,  46.,  56., ...,  60.,  48.,  48.],
          [ 49.,  45.,  49., ...,  66.,  57.,  57.],
          [ 68.,  65.,  57., ...,  63.,  58.,  54.],
          ...,
          [ 55.,  51.,  57., ...,  57.,  61.,  55.],
          [ 54.,  52.,  53., ...,  44.,  49.,  46.],
          [ 52.,  53.,  55., ...,  42.,  45.,  36.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:48

analyse the exceptions in iter:59
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[252., 255., 194., ..., 255., 255., 253.],
          [251., 255., 211., ..., 246., 249., 251.],
          [251., 255., 218., ..., 249., 250., 252.],
          ...,
          [ 57.,  30.,  73., ...,  23.,  26., 112.],
          [ 89.,  16.,  26., ...,  21.,  32., 149.],
          [185.,  94.,  54., ...,  60., 129., 221.]],

         [[251., 255., 212., ..., 254., 253., 252.],
          [249., 255., 234., ..., 255., 255., 252.],
          [250., 255., 235., ..., 255., 254., 253.],
          ...,
          [111.,  86.,  88., ...,  60.,  81., 149.],
          [134.,  77.,  74., ...,  75.,  83., 174.],
          [208., 134.,  99., ..., 104., 159., 232.]],

         [[249., 255., 224., ..., 253., 252., 252.],
          [246., 254., 240., ..., 251., 252., 251.],
          [249., 255., 240., ..., 254., 252., 252.],
          ...,
          [159., 138., 110., ..., 100., 139., 186.],
          [177., 144., 136., ..., 140., 145., 198.],
          [229., 182., 159., ..., 159., 197., 240.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:49

analyse the exceptions in iter:60
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[201., 191., 194., ...,  83.,  39.,  36.],
          [ 57.,  62., 134., ...,  79.,  48.,  35.],
          [ 74., 123., 138., ..., 162., 132.,  56.],
          ...,
          [ 67.,  62.,  55., ...,  69.,  72.,  72.],
          [ 73.,  67.,  59., ...,  72.,  72.,  71.],
          [ 74.,  71.,  67., ...,  61.,  58.,  63.]],

         [[209., 204., 207., ...,  88.,  48.,  47.],
          [ 73.,  78., 148., ...,  91.,  59.,  45.],
          [ 99., 142., 153., ..., 175., 139.,  61.],
          ...,
          [ 80.,  72.,  62., ...,  78.,  80.,  82.],
          [ 87.,  77.,  67., ...,  81.,  81.,  81.],
          [ 89.,  84.,  79., ...,  73.,  69.,  75.]],

         [[211., 210., 216., ...,  82.,  33.,  24.],
          [ 79.,  92., 161., ...,  96.,  57.,  32.],
          [110., 165., 169., ..., 186., 145.,  56.],
          ...,
          [ 89.,  82.,  73., ...,  93.,  95.,  98.],
          [ 95.,  87.,  77., ...,  96.,  96.,  96.],
          [100.,  95.,  89., ...,  88.,  85.,  91.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:50

analyse the exceptions in iter:61
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[114., 117., 120., ..., 165., 125., 103.],
          [111., 116., 121., ..., 162., 127., 103.],
          [114., 121., 128., ..., 167., 132., 106.],
          ...,
          [165., 170., 175., ..., 185., 207., 201.],
          [175., 175., 180., ..., 187., 200., 193.],
          [173., 171., 177., ..., 205., 210., 202.]],

         [[119., 122., 126., ..., 166., 126., 103.],
          [116., 121., 126., ..., 163., 128., 103.],
          [119., 125., 132., ..., 168., 133., 108.],
          ...,
          [166., 171., 176., ..., 179., 199., 193.],
          [176., 176., 181., ..., 182., 194., 186.],
          [174., 172., 178., ..., 200., 204., 195.]],

         [[125., 126., 129., ..., 160., 121., 110.],
          [122., 127., 133., ..., 157., 123., 109.],
          [125., 136., 142., ..., 162., 126., 102.],
          ...,
          [161., 167., 171., ..., 168., 194., 185.],
          [171., 171., 176., ..., 162., 181., 178.],
          [169., 167., 173., ..., 182., 192., 187.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:51

analyse the exceptions in iter:62
tensorflow exception:
{'id': 41, 'name': 'conv2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 3, 32, 32), dtype=float32, numpy=
array([[[[[ 76.,  73.,  69., ...,  75.,  72.,  70.],
          [ 76.,  71.,  66., ...,  79.,  76.,  75.],
          [ 71.,  65.,  62., ...,  80.,  77.,  76.],
          ...,
          [ 11.,   9.,   6., ...,  31.,  32.,  29.],
          [  0.,   0.,   0., ...,  12.,  12.,  13.],
          [ 87.,  83.,  81., ...,  99.,  99., 102.]],

         [[118., 118., 116., ..., 135., 134., 135.],
          [122., 119., 117., ..., 136., 135., 137.],
          [120., 117., 116., ..., 133., 132., 135.],
          ...,
          [ 36.,  32.,  32., ...,  61.,  62.,  59.],
          [ 19.,  13.,   7., ...,  38.,  37.,  38.],
          [100.,  92.,  86., ..., 116., 115., 119.]],

         [[167., 164., 162., ..., 180., 178., 179.],
          [170., 166., 163., ..., 178., 177., 179.],
          [170., 165., 164., ..., 173., 172., 174.],
          ...,
          [ 66.,  61.,  61., ...,  79.,  80.,  77.],
          [ 46.,  40.,  36., ...,  55.,  55.,  56.],
          [115., 108., 103., ..., 127., 127., 130.]]]]], dtype=float32)>}
The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW [Op:Conv2D]

generate models:52

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:6

analyse output arrays in iter:19

pre layer res:
12:pad
{'name': 'pad', 'output': array([[9.1326581e+14, 2.3826146e+15, 4.3299348e+15, ..., 0.0000000e+00,
        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'output_shape': TensorShape([1, 1048576]), 'from': [11], 'to': [22]}
tf node:
{'name': 'sin', 'output': array([[ 0.4114308 , -0.00672608,  0.62558836, ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': TensorShape([1, 1048576]), 'from': [12], 'to': [13]}
ms node:
{'name': 'sin', 'output': array([[-0.4300447 , -0.32020295,  0.90654594, ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': (1, 1048576), 'from': [12], 'to': [13]}
torch node:
{'name': 'sin', 'output': array([[-0.4300447 , -0.32020295,  0.90654594, ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [12], 'to': [13]}

generate models:12

analyse output arrays in iter:22

pre layer res:
6:empty_merge_operator
{'name': 'empty_merge_operator', 'output': array([[[[ 5701.381 ,  8493.99  ,  8189.3574, ...,  8120.4053,
           8235.945 ,  5520.805 ],
         [ 8536.547 , 12590.528 , 12083.012 , ..., 12237.28  ,
          12377.466 ,  8269.068 ],
         [ 8484.252 , 12366.5625, 11774.727 , ..., 12269.611 ,
          12370.369 ,  8243.978 ],
         ...,
         [ 7949.0405, 11870.55  , 11635.824 , ..., 11821.805 ,
          11714.305 ,  7719.5054],
         [ 8401.498 , 12434.448 , 12153.3955, ..., 11658.248 ,
          11446.74  ,  7586.6226],
         [ 5824.137 ,  8631.488 ,  8435.651 , ...,  7720.0415,
           7516.008 ,  5005.7773]],

        [[ 5701.381 ,  8493.99  ,  8189.3574, ...,  8120.4053,
           8235.945 ,  5520.805 ],
         [ 8536.547 , 12590.528 , 12083.012 , ..., 12237.28  ,
          12377.466 ,  8269.068 ],
         [ 8484.252 , 12366.5625, 11774.727 , ..., 12269.611 ,
          12370.369 ,  8243.978 ],
         ...,
         [ 7949.0405, 11870.55  , 11635.824 , ..., 11821.805 ,
          11714.305 ,  7719.5054],
         [ 8401.498 , 12434.448 , 12153.3955, ..., 11658.248 ,
          11446.74  ,  7586.6226],
         [ 5824.137 ,  8631.488 ,  8435.651 , ...,  7720.0415,
           7516.008 ,  5005.7773]],

        [[ 5701.381 ,  8493.99  ,  8189.3574, ...,  8120.4053,
           8235.945 ,  5520.805 ],
         [ 8536.547 , 12590.528 , 12083.012 , ..., 12237.28  ,
          12377.466 ,  8269.068 ],
         [ 8484.252 , 12366.5625, 11774.727 , ..., 12269.611 ,
          12370.369 ,  8243.978 ],
         ...,
         [ 7949.0405, 11870.55  , 11635.824 , ..., 11821.805 ,
          11714.305 ,  7719.5054],
         [ 8401.498 , 12434.448 , 12153.3955, ..., 11658.248 ,
          11446.74  ,  7586.6226],
         [ 5824.137 ,  8631.488 ,  8435.651 , ...,  7720.0415,
           7516.008 ,  5005.7773]],

        ...,

        [[ 5701.381 ,  8493.99  ,  8189.3574, ...,  8120.4053,
           8235.945 ,  5520.805 ],
         [ 8536.547 , 12590.528 , 12083.012 , ..., 12237.28  ,
          12377.466 ,  8269.068 ],
         [ 8484.252 , 12366.5625, 11774.727 , ..., 12269.611 ,
          12370.369 ,  8243.978 ],
         ...,
         [ 7949.0405, 11870.55  , 11635.824 , ..., 11821.805 ,
          11714.305 ,  7719.5054],
         [ 8401.498 , 12434.448 , 12153.3955, ..., 11658.248 ,
          11446.74  ,  7586.6226],
         [ 5824.137 ,  8631.488 ,  8435.651 , ...,  7720.0415,
           7516.008 ,  5005.7773]],

        [[ 5701.381 ,  8493.99  ,  8189.3574, ...,  8120.4053,
           8235.945 ,  5520.805 ],
         [ 8536.547 , 12590.528 , 12083.012 , ..., 12237.28  ,
          12377.466 ,  8269.068 ],
         [ 8484.252 , 12366.5625, 11774.727 , ..., 12269.611 ,
          12370.369 ,  8243.978 ],
         ...,
         [ 7949.0405, 11870.55  , 11635.824 , ..., 11821.805 ,
          11714.305 ,  7719.5054],
         [ 8401.498 , 12434.448 , 12153.3955, ..., 11658.248 ,
          11446.74  ,  7586.6226],
         [ 5824.137 ,  8631.488 ,  8435.651 , ...,  7720.0415,
           7516.008 ,  5005.7773]],

        [[ 5701.381 ,  8493.99  ,  8189.3574, ...,  8120.4053,
           8235.945 ,  5520.805 ],
         [ 8536.547 , 12590.528 , 12083.012 , ..., 12237.28  ,
          12377.466 ,  8269.068 ],
         [ 8484.252 , 12366.5625, 11774.727 , ..., 12269.611 ,
          12370.369 ,  8243.978 ],
         ...,
         [ 7949.0405, 11870.55  , 11635.824 , ..., 11821.805 ,
          11714.305 ,  7719.5054],
         [ 8401.498 , 12434.448 , 12153.3955, ..., 11658.248 ,
          11446.74  ,  7586.6226],
         [ 5824.137 ,  8631.488 ,  8435.651 , ...,  7720.0415,
           7516.008 ,  5005.7773]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [3, 2], 'to': [8, 4, 11]}
tf node:
{'name': 'cos', 'output': array([[[[-0.81975865,  0.6399978 , -0.7146827 , ..., -0.8186523 ,
           0.2572459 , -0.51748824],
         [-0.6677344 ,  0.5611388 ,  0.9020188 , ..., -0.7130989 ,
           0.9174256 ,  0.9224202 ],
         [-0.37184164,  0.31169924,  0.99930453, ...,  0.12092288,
           0.3410815 ,  0.9054252 ],
         ...,
         [ 0.68869126, -0.04195078,  0.8050894 , ..., -0.9999641 ,
          -0.76849043, -0.81837356],
         [ 0.6376973 ,  0.9996994 , -0.14382686, ..., -0.97960895,
           0.34045523, -0.9480651 ],
         [ 0.9302977 , -0.03752567, -0.8892505 , ..., -0.40998927,
           0.24993315, -0.3434142 ]],

        [[-0.81975865,  0.6399978 , -0.7146827 , ..., -0.8186523 ,
           0.2572459 , -0.51748824],
         [-0.6677344 ,  0.5611388 ,  0.9020188 , ..., -0.7130989 ,
           0.9174256 ,  0.9224202 ],
         [-0.37184164,  0.31169924,  0.99930453, ...,  0.12092288,
           0.3410815 ,  0.9054252 ],
         ...,
         [ 0.68869126, -0.04195078,  0.8050894 , ..., -0.9999641 ,
          -0.76849043, -0.81837356],
         [ 0.6376973 ,  0.9996994 , -0.14382686, ..., -0.97960895,
           0.34045523, -0.9480651 ],
         [ 0.9302977 , -0.03752567, -0.8892505 , ..., -0.40998927,
           0.24993315, -0.3434142 ]],

        [[-0.81975865,  0.6399978 , -0.7146827 , ..., -0.8186523 ,
           0.2572459 , -0.51748824],
         [-0.6677344 ,  0.5611388 ,  0.9020188 , ..., -0.7130989 ,
           0.9174256 ,  0.9224202 ],
         [-0.37184164,  0.31169924,  0.99930453, ...,  0.12092288,
           0.3410815 ,  0.9054252 ],
         ...,
         [ 0.68869126, -0.04195078,  0.8050894 , ..., -0.9999641 ,
          -0.76849043, -0.81837356],
         [ 0.6376973 ,  0.9996994 , -0.14382686, ..., -0.97960895,
           0.34045523, -0.9480651 ],
         [ 0.9302977 , -0.03752567, -0.8892505 , ..., -0.40998927,
           0.24993315, -0.3434142 ]],

        ...,

        [[-0.81975865,  0.6399978 , -0.7146827 , ..., -0.8186523 ,
           0.2572459 , -0.51748824],
         [-0.6677344 ,  0.5611388 ,  0.9020188 , ..., -0.7130989 ,
           0.9174256 ,  0.9224202 ],
         [-0.37184164,  0.31169924,  0.99930453, ...,  0.12092288,
           0.3410815 ,  0.9054252 ],
         ...,
         [ 0.68869126, -0.04195078,  0.8050894 , ..., -0.9999641 ,
          -0.76849043, -0.81837356],
         [ 0.6376973 ,  0.9996994 , -0.14382686, ..., -0.97960895,
           0.34045523, -0.9480651 ],
         [ 0.9302977 , -0.03752567, -0.8892505 , ..., -0.40998927,
           0.24993315, -0.3434142 ]],

        [[-0.81975865,  0.6399978 , -0.7146827 , ..., -0.8186523 ,
           0.2572459 , -0.51748824],
         [-0.6677344 ,  0.5611388 ,  0.9020188 , ..., -0.7130989 ,
           0.9174256 ,  0.9224202 ],
         [-0.37184164,  0.31169924,  0.99930453, ...,  0.12092288,
           0.3410815 ,  0.9054252 ],
         ...,
         [ 0.68869126, -0.04195078,  0.8050894 , ..., -0.9999641 ,
          -0.76849043, -0.81837356],
         [ 0.6376973 ,  0.9996994 , -0.14382686, ..., -0.97960895,
           0.34045523, -0.9480651 ],
         [ 0.9302977 , -0.03752567, -0.8892505 , ..., -0.40998927,
           0.24993315, -0.3434142 ]],

        [[-0.81975865,  0.6399978 , -0.7146827 , ..., -0.8186523 ,
           0.2572459 , -0.51748824],
         [-0.6677344 ,  0.5611388 ,  0.9020188 , ..., -0.7130989 ,
           0.9174256 ,  0.9224202 ],
         [-0.37184164,  0.31169924,  0.99930453, ...,  0.12092288,
           0.3410815 ,  0.9054252 ],
         ...,
         [ 0.68869126, -0.04195078,  0.8050894 , ..., -0.9999641 ,
          -0.76849043, -0.81837356],
         [ 0.6376973 ,  0.9996994 , -0.14382686, ..., -0.97960895,
           0.34045523, -0.9480651 ],
         [ 0.9302977 , -0.03752567, -0.8892505 , ..., -0.40998927,
           0.24993315, -0.3434142 ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [6], 'to': [7]}
ms node:
{'name': 'cos', 'output': array([[[[-0.81807727,  0.63774395, -0.7160474 , ..., -0.8161206 ,
           0.25157934, -0.51623416],
         [-0.67063713,  0.5619469 ,  0.9015968 , ..., -0.719233  ,
           0.91189986,  0.9254091 ],
         [-0.37002784,  0.31169924,  0.99926764, ...,  0.10734045,
           0.32265756,  0.909933  ],
         ...,
         [ 0.6862091 , -0.0390235 ,  0.8050894 , ..., -0.9998829 ,
          -0.76472807, -0.820333  ],
         [ 0.6376973 ,  0.9999301 , -0.13996013, ..., -0.9790161 ,
           0.34412554, -0.94790965],
         [ 0.93047667, -0.04240458, -0.8896968 , ..., -0.4113249 ,
           0.2508786 , -0.34433118]],

        [[-0.81807727,  0.63774395, -0.7160474 , ..., -0.8161206 ,
           0.25157934, -0.51623416],
         [-0.67063713,  0.5619469 ,  0.9015968 , ..., -0.719233  ,
           0.91189986,  0.9254091 ],
         [-0.37002784,  0.31169924,  0.99926764, ...,  0.10734045,
           0.32265756,  0.909933  ],
         ...,
         [ 0.6862091 , -0.0390235 ,  0.8050894 , ..., -0.9998829 ,
          -0.76472807, -0.820333  ],
         [ 0.6376973 ,  0.9999301 , -0.13996013, ..., -0.9790161 ,
           0.34412554, -0.94790965],
         [ 0.93047667, -0.04240458, -0.8896968 , ..., -0.4113249 ,
           0.2508786 , -0.34433118]],

        [[-0.81807727,  0.63774395, -0.7160474 , ..., -0.8161206 ,
           0.25157934, -0.51623416],
         [-0.67063713,  0.5619469 ,  0.9015968 , ..., -0.719233  ,
           0.91189986,  0.9254091 ],
         [-0.37002784,  0.31169924,  0.99926764, ...,  0.10734045,
           0.32265756,  0.909933  ],
         ...,
         [ 0.6862091 , -0.0390235 ,  0.8050894 , ..., -0.9998829 ,
          -0.76472807, -0.820333  ],
         [ 0.6376973 ,  0.9999301 , -0.13996013, ..., -0.9790161 ,
           0.34412554, -0.94790965],
         [ 0.93047667, -0.04240458, -0.8896968 , ..., -0.4113249 ,
           0.2508786 , -0.34433118]],

        ...,

        [[-0.81807727,  0.63774395, -0.7160474 , ..., -0.8161206 ,
           0.25157934, -0.51623416],
         [-0.67063713,  0.5619469 ,  0.9015968 , ..., -0.719233  ,
           0.91189986,  0.9254091 ],
         [-0.37002784,  0.31169924,  0.99926764, ...,  0.10734045,
           0.32265756,  0.909933  ],
         ...,
         [ 0.6862091 , -0.0390235 ,  0.8050894 , ..., -0.9998829 ,
          -0.76472807, -0.820333  ],
         [ 0.6376973 ,  0.9999301 , -0.13996013, ..., -0.9790161 ,
           0.34412554, -0.94790965],
         [ 0.93047667, -0.04240458, -0.8896968 , ..., -0.4113249 ,
           0.2508786 , -0.34433118]],

        [[-0.81807727,  0.63774395, -0.7160474 , ..., -0.8161206 ,
           0.25157934, -0.51623416],
         [-0.67063713,  0.5619469 ,  0.9015968 , ..., -0.719233  ,
           0.91189986,  0.9254091 ],
         [-0.37002784,  0.31169924,  0.99926764, ...,  0.10734045,
           0.32265756,  0.909933  ],
         ...,
         [ 0.6862091 , -0.0390235 ,  0.8050894 , ..., -0.9998829 ,
          -0.76472807, -0.820333  ],
         [ 0.6376973 ,  0.9999301 , -0.13996013, ..., -0.9790161 ,
           0.34412554, -0.94790965],
         [ 0.93047667, -0.04240458, -0.8896968 , ..., -0.4113249 ,
           0.2508786 , -0.34433118]],

        [[-0.81807727,  0.63774395, -0.7160474 , ..., -0.8161206 ,
           0.25157934, -0.51623416],
         [-0.67063713,  0.5619469 ,  0.9015968 , ..., -0.719233  ,
           0.91189986,  0.9254091 ],
         [-0.37002784,  0.31169924,  0.99926764, ...,  0.10734045,
           0.32265756,  0.909933  ],
         ...,
         [ 0.6862091 , -0.0390235 ,  0.8050894 , ..., -0.9998829 ,
          -0.76472807, -0.820333  ],
         [ 0.6376973 ,  0.9999301 , -0.13996013, ..., -0.9790161 ,
           0.34412554, -0.94790965],
         [ 0.93047667, -0.04240458, -0.8896968 , ..., -0.4113249 ,
           0.2508786 , -0.34433118]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [6], 'to': [7]}
torch node:
{'name': 'cos', 'output': array([[[[-0.8135593 ,  0.626393  , -0.7187687 , ..., -0.8239448 ,
           0.27325258, -0.50784594],
         [-0.6785667 ,  0.5779944 ,  0.8960326 , ..., -0.75549453,
           0.89033705,  0.9131164 ],
         [-0.36275864,  0.3320398 ,  0.9999597 , ...,  0.10442723,
           0.29572612,  0.90292233],
         ...,
         [ 0.68050534, -0.05073038,  0.8259916 , ..., -0.9999847 ,
          -0.7716056 , -0.80468076],
         [ 0.6140894 ,  0.99701744, -0.23583469, ..., -0.983699  ,
           0.38684312, -0.9505211 ],
         [ 0.9340099 , -0.00335479, -0.8773509 , ..., -0.39703324,
           0.24141349, -0.33330566]],

        [[-0.8135593 ,  0.626393  , -0.7187687 , ..., -0.8239448 ,
           0.27325258, -0.50784594],
         [-0.6785667 ,  0.5779944 ,  0.8960326 , ..., -0.75549453,
           0.89033705,  0.9131164 ],
         [-0.36275864,  0.3320398 ,  0.9999597 , ...,  0.10442723,
           0.29572612,  0.90292233],
         ...,
         [ 0.68050534, -0.05073038,  0.8259916 , ..., -0.9999847 ,
          -0.7716056 , -0.80468076],
         [ 0.6140894 ,  0.99701744, -0.23583469, ..., -0.983699  ,
           0.38684312, -0.9505211 ],
         [ 0.9340099 , -0.00335479, -0.8773509 , ..., -0.39703324,
           0.24141349, -0.33330566]],

        [[-0.8135593 ,  0.626393  , -0.7187687 , ..., -0.8239448 ,
           0.27325258, -0.50784594],
         [-0.6785667 ,  0.5779944 ,  0.8960326 , ..., -0.75549453,
           0.89033705,  0.9131164 ],
         [-0.36275864,  0.3320398 ,  0.9999597 , ...,  0.10442723,
           0.29572612,  0.90292233],
         ...,
         [ 0.68050534, -0.05073038,  0.8259916 , ..., -0.9999847 ,
          -0.7716056 , -0.80468076],
         [ 0.6140894 ,  0.99701744, -0.23583469, ..., -0.983699  ,
           0.38684312, -0.9505211 ],
         [ 0.9340099 , -0.00335479, -0.8773509 , ..., -0.39703324,
           0.24141349, -0.33330566]],

        ...,

        [[-0.8135593 ,  0.626393  , -0.7187687 , ..., -0.8239448 ,
           0.27325258, -0.50784594],
         [-0.6785667 ,  0.5779944 ,  0.8960326 , ..., -0.75549453,
           0.89033705,  0.9131164 ],
         [-0.36275864,  0.3320398 ,  0.9999597 , ...,  0.10442723,
           0.29572612,  0.90292233],
         ...,
         [ 0.68050534, -0.05073038,  0.8259916 , ..., -0.9999847 ,
          -0.7716056 , -0.80468076],
         [ 0.6140894 ,  0.99701744, -0.23583469, ..., -0.983699  ,
           0.38684312, -0.9505211 ],
         [ 0.9340099 , -0.00335479, -0.8773509 , ..., -0.39703324,
           0.24141349, -0.33330566]],

        [[-0.8135593 ,  0.626393  , -0.7187687 , ..., -0.8239448 ,
           0.27325258, -0.50784594],
         [-0.6785667 ,  0.5779944 ,  0.8960326 , ..., -0.75549453,
           0.89033705,  0.9131164 ],
         [-0.36275864,  0.3320398 ,  0.9999597 , ...,  0.10442723,
           0.29572612,  0.90292233],
         ...,
         [ 0.68050534, -0.05073038,  0.8259916 , ..., -0.9999847 ,
          -0.7716056 , -0.80468076],
         [ 0.6140894 ,  0.99701744, -0.23583469, ..., -0.983699  ,
           0.38684312, -0.9505211 ],
         [ 0.9340099 , -0.00335479, -0.8773509 , ..., -0.39703324,
           0.24141349, -0.33330566]],

        [[-0.8135593 ,  0.626393  , -0.7187687 , ..., -0.8239448 ,
           0.27325258, -0.50784594],
         [-0.6785667 ,  0.5779944 ,  0.8960326 , ..., -0.75549453,
           0.89033705,  0.9131164 ],
         [-0.36275864,  0.3320398 ,  0.9999597 , ...,  0.10442723,
           0.29572612,  0.90292233],
         ...,
         [ 0.68050534, -0.05073038,  0.8259916 , ..., -0.9999847 ,
          -0.7716056 , -0.80468076],
         [ 0.6140894 ,  0.99701744, -0.23583469, ..., -0.983699  ,
           0.38684312, -0.9505211 ],
         [ 0.9340099 , -0.00335479, -0.8773509 , ..., -0.39703324,
           0.24141349, -0.33330566]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [6], 'to': [7]}

generate models:15

analyse output arrays in iter:34

pre layer res:
1:conv2d
{'name': 'conv2d', 'output': array([[[[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        ...,

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [13], 'to': [3, 3]}
1:conv2d
{'name': 'conv2d', 'output': array([[[[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        ...,

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [13], 'to': [3, 3]}
tf node:
{'name': 'empty_merge_operator', 'output': array([[[[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        ...,

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [1, 1], 'to': [4, 20, 20]}
ms node:
{'name': 'empty_merge_operator', 'output': array([[[[58672.914, 58439.574, 57112.008, ..., 52927.387, 52552.254,
          50045.914],
         [57236.01 , 56767.855, 56995.355, ..., 53646.234, 51832.004,
          50045.914],
         [58799.293, 57112.008, 57487.965, ..., 53881.96 , 51237.97 ,
          50767.184],
         ...,
         [49552.055, 51365.414, 52325.04 , ..., 52083.555, 48714.637,
          45957.832],
         [46323.234, 47647.332, 49436.51 , ..., 48487.63 , 46552.   ,
          45713.9  ],
         [47879.86 , 46803.426, 47766.656, ..., 43928.   , 42367.273,
          43322.234]],

        [[58672.914, 58439.574, 57112.008, ..., 52927.387, 52552.254,
          50045.914],
         [57236.01 , 56767.855, 56995.355, ..., 53646.234, 51832.004,
          50045.914],
         [58799.293, 57112.008, 57487.965, ..., 53881.96 , 51237.97 ,
          50767.184],
         ...,
         [49552.055, 51365.414, 52325.04 , ..., 52083.555, 48714.637,
          45957.832],
         [46323.234, 47647.332, 49436.51 , ..., 48487.63 , 46552.   ,
          45713.9  ],
         [47879.86 , 46803.426, 47766.656, ..., 43928.   , 42367.273,
          43322.234]],

        [[58672.914, 58439.574, 57112.008, ..., 52927.387, 52552.254,
          50045.914],
         [57236.01 , 56767.855, 56995.355, ..., 53646.234, 51832.004,
          50045.914],
         [58799.293, 57112.008, 57487.965, ..., 53881.96 , 51237.97 ,
          50767.184],
         ...,
         [49552.055, 51365.414, 52325.04 , ..., 52083.555, 48714.637,
          45957.832],
         [46323.234, 47647.332, 49436.51 , ..., 48487.63 , 46552.   ,
          45713.9  ],
         [47879.86 , 46803.426, 47766.656, ..., 43928.   , 42367.273,
          43322.234]],

        ...,

        [[58672.914, 58439.574, 57112.008, ..., 52927.387, 52552.254,
          50045.914],
         [57236.01 , 56767.855, 56995.355, ..., 53646.234, 51832.004,
          50045.914],
         [58799.293, 57112.008, 57487.965, ..., 53881.96 , 51237.97 ,
          50767.184],
         ...,
         [49552.055, 51365.414, 52325.04 , ..., 52083.555, 48714.637,
          45957.832],
         [46323.234, 47647.332, 49436.51 , ..., 48487.63 , 46552.   ,
          45713.9  ],
         [47879.86 , 46803.426, 47766.656, ..., 43928.   , 42367.273,
          43322.234]],

        [[58672.914, 58439.574, 57112.008, ..., 52927.387, 52552.254,
          50045.914],
         [57236.01 , 56767.855, 56995.355, ..., 53646.234, 51832.004,
          50045.914],
         [58799.293, 57112.008, 57487.965, ..., 53881.96 , 51237.97 ,
          50767.184],
         ...,
         [49552.055, 51365.414, 52325.04 , ..., 52083.555, 48714.637,
          45957.832],
         [46323.234, 47647.332, 49436.51 , ..., 48487.63 , 46552.   ,
          45713.9  ],
         [47879.86 , 46803.426, 47766.656, ..., 43928.   , 42367.273,
          43322.234]],

        [[58672.914, 58439.574, 57112.008, ..., 52927.387, 52552.254,
          50045.914],
         [57236.01 , 56767.855, 56995.355, ..., 53646.234, 51832.004,
          50045.914],
         [58799.293, 57112.008, 57487.965, ..., 53881.96 , 51237.97 ,
          50767.184],
         ...,
         [49552.055, 51365.414, 52325.04 , ..., 52083.555, 48714.637,
          45957.832],
         [46323.234, 47647.332, 49436.51 , ..., 48487.63 , 46552.   ,
          45713.9  ],
         [47879.86 , 46803.426, 47766.656, ..., 43928.   , 42367.273,
          43322.234]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [1, 1], 'to': [4, 20, 20]}
torch node:
{'name': 'empty_merge_operator', 'output': array([[[[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        ...,

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]],

        [[-113.39651  ,   -6.7985406, -127.84839  , ...,  118.20411  ,
          -123.95142  ,   94.61239  ],
         [ -63.832    ,  125.68926  ,  -74.32131  , ...,   99.77416  ,
          -127.93847  ,   94.61239  ],
         [ -11.307363 , -127.84839  ,  127.44825  , ...,   31.38848  ,
           -32.485615 ,  114.932884 ],
         ...,
         [-127.08807  ,   86.62979  ,   80.62268  , ...,   56.84996  ,
           -85.792076 ,  -34.67219  ],
         [  51.71335  ,  117.31639  ,  -55.832527 , ...,  122.07912  ,
          -127.98851  ,  -97.610054 ],
         [  -2.2697036,   54.81092  ,  106.46491  , ...,  127.99883  ,
           116.39162  ,   35.7615   ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [1, 1], 'to': [4, 20, 20]}

generate models:20

analyse the exceptions in iter:35
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:21

analyse output arrays in iter:40

pre layer res:
15:softmax
{'name': 'softmax', 'output': array([[[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          3.93318235e-32, 2.83208426e-21, 2.68938094e-01],
         [0.00000000e+00, 1.18506485e-27, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 3.22134028e-27],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          4.35961013e-28, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          3.93318235e-32, 2.83208426e-21, 2.68938094e-01],
         [0.00000000e+00, 1.18506485e-27, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 3.22134028e-27],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          4.35961013e-28, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          3.93318235e-32, 2.83208426e-21, 2.68938094e-01],
         [0.00000000e+00, 1.18506485e-27, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 3.22134028e-27],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          4.35961013e-28, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        ...,

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          3.93318235e-32, 2.83208426e-21, 2.68938094e-01],
         [0.00000000e+00, 1.18506485e-27, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 3.22134028e-27],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          4.35961013e-28, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          3.93318235e-32, 2.83208426e-21, 2.68938094e-01],
         [0.00000000e+00, 1.18506485e-27, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 3.22134028e-27],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          4.35961013e-28, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          3.93318235e-32, 2.83208426e-21, 2.68938094e-01],
         [0.00000000e+00, 1.18506485e-27, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 3.22134028e-27],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          4.35961013e-28, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]],
      dtype=float32), 'output_shape': TensorShape([1, 128, 32, 32]), 'from': [0], 'to': [22]}
tf node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ..., -72.31328 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31328 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31328 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ..., -72.31328 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31328 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31328 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32, 32]), 'from': [15], 'to': [1]}
ms node:
{'name': 'log', 'output': array([[[[       -inf,        -inf,        -inf, ..., -72.31328  ,
          -47.31328  ,  -1.3132769],
         [       -inf, -62.       ,        -inf, ...,        -inf,
                 -inf, -61.       ],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         ...,
         [       -inf,        -inf,        -inf, ..., -63.       ,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]],

        [[       -inf,        -inf,        -inf, ..., -72.31328  ,
          -47.31328  ,  -1.3132769],
         [       -inf, -62.       ,        -inf, ...,        -inf,
                 -inf, -61.       ],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         ...,
         [       -inf,        -inf,        -inf, ..., -63.       ,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]],

        [[       -inf,        -inf,        -inf, ..., -72.31328  ,
          -47.31328  ,  -1.3132769],
         [       -inf, -62.       ,        -inf, ...,        -inf,
                 -inf, -61.       ],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         ...,
         [       -inf,        -inf,        -inf, ..., -63.       ,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]],

        ...,

        [[       -inf,        -inf,        -inf, ..., -72.31328  ,
          -47.31328  ,  -1.3132769],
         [       -inf, -62.       ,        -inf, ...,        -inf,
                 -inf, -61.       ],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         ...,
         [       -inf,        -inf,        -inf, ..., -63.       ,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]],

        [[       -inf,        -inf,        -inf, ..., -72.31328  ,
          -47.31328  ,  -1.3132769],
         [       -inf, -62.       ,        -inf, ...,        -inf,
                 -inf, -61.       ],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         ...,
         [       -inf,        -inf,        -inf, ..., -63.       ,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]],

        [[       -inf,        -inf,        -inf, ..., -72.31328  ,
          -47.31328  ,  -1.3132769],
         [       -inf, -62.       ,        -inf, ...,        -inf,
                 -inf, -61.       ],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         ...,
         [       -inf,        -inf,        -inf, ..., -63.       ,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf],
         [       -inf,        -inf,        -inf, ...,        -inf,
                 -inf,        -inf]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [15], 'to': [1]}
torch node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ..., -72.31327 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31327 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31327 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ..., -72.31327 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31327 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ..., -72.31327 ,
          -47.313274,  -1.313274],
         [      -inf, -62.      ,       -inf, ...,       -inf,
                -inf, -61.      ],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ..., -63.      ,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [15], 'to': [1]}

generate models:25

analyse the exceptions in iter:45
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[0.9155966 , 0.91585135, 0.91526353, ..., 0.91677606,
           0.9167311 , 0.9166755 ],
          [0.91572267, 0.9158927 , 0.9151936 , ..., 0.9167751 ,
           0.91676307, 0.9167366 ],
          [0.91576016, 0.91577226, 0.9148535 , ..., 0.9167822 ,
           0.9167742 , 0.9167988 ],
          ...,
          [0.91657907, 0.91675913, 0.9167822 , ..., 0.9167409 ,
           0.916688  , 0.91666967],
          [0.91655976, 0.9167822 , 0.9167715 , ..., 0.9167254 ,
           0.9166894 , 0.916653  ],
          [0.91658115, 0.9167778 , 0.91675913, ..., 0.9167012 ,
           0.91668105, 0.91663   ]],

         [[0.9155966 , 0.91585135, 0.91526353, ..., 0.91677606,
           0.9167311 , 0.9166755 ],
          [0.91572267, 0.9158927 , 0.9151936 , ..., 0.9167751 ,
           0.91676307, 0.9167366 ],
          [0.91576016, 0.91577226, 0.9148535 , ..., 0.9167822 ,
           0.9167742 , 0.9167988 ],
          ...,
          [0.91657907, 0.91675913, 0.9167822 , ..., 0.9167409 ,
           0.916688  , 0.91666967],
          [0.91655976, 0.9167822 , 0.9167715 , ..., 0.9167254 ,
           0.9166894 , 0.916653  ],
          [0.91658115, 0.9167778 , 0.91675913, ..., 0.9167012 ,
           0.91668105, 0.91663   ]],

         [[0.9155966 , 0.91585135, 0.91526353, ..., 0.91677606,
           0.9167311 , 0.9166755 ],
          [0.91572267, 0.9158927 , 0.9151936 , ..., 0.9167751 ,
           0.91676307, 0.9167366 ],
          [0.91576016, 0.91577226, 0.9148535 , ..., 0.9167822 ,
           0.9167742 , 0.9167988 ],
          ...,
          [0.91657907, 0.91675913, 0.9167822 , ..., 0.9167409 ,
           0.916688  , 0.91666967],
          [0.91655976, 0.9167822 , 0.9167715 , ..., 0.9167254 ,
           0.9166894 , 0.916653  ],
          [0.91658115, 0.9167778 , 0.91675913, ..., 0.9167012 ,
           0.91668105, 0.91663   ]],

         ...,

         [[0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          ...,
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ]],

         [[0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          ...,
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ]],

         [[0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          ...,
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ],
          [0.        , 0.        , 0.        , ..., 0.        ,
           0.        , 0.        ]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:28

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:4
mindspore --> nums:3,distinct_bugs:3
torch --> nums:2,distinct_bugs:2
tensorflow --> 
sin:1
cos:1
avgpool2d:2
log:1
mindspore --> 
cos:1
empty_merge_operator:1
log:1
torch --> 
cos:1
log:1

generate models:30

analyse the exceptions in iter:50
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[1.04611656e+12, 1.08427018e+12, 1.08427018e+12, ...,
           2.46852616e+12, 2.07869313e+12, 1.83740636e+12],
          [1.04611656e+12, 1.04611656e+12, 1.02106110e+12, ...,
           2.46852616e+12, 2.24166543e+12, 1.95619088e+12],
          [1.04611656e+12, 1.00864754e+12, 1.00864754e+12, ...,
           2.29735766e+12, 2.37267478e+12, 2.24166543e+12],
          ...,
          [4.49232765e+12, 6.07397872e+12, 6.63294050e+12, ...,
           6.56960913e+12, 5.92307867e+12, 5.77408388e+12],
          [6.35038178e+12, 4.86542252e+12, 6.16543184e+12, ...,
           7.48373410e+12, 6.82471719e+12, 6.13487529e+12],
          [8.20840235e+12, 7.48373410e+12, 4.97475335e+12, ...,
           8.24373569e+12, 7.48373410e+12, 7.01923905e+12]],

         [[1.04611656e+12, 1.08427018e+12, 1.08427018e+12, ...,
           2.46852616e+12, 2.07869313e+12, 1.83740636e+12],
          [1.04611656e+12, 1.04611656e+12, 1.02106110e+12, ...,
           2.46852616e+12, 2.24166543e+12, 1.95619088e+12],
          [1.04611656e+12, 1.00864754e+12, 1.00864754e+12, ...,
           2.29735766e+12, 2.37267478e+12, 2.24166543e+12],
          ...,
          [4.49232765e+12, 6.07397872e+12, 6.63294050e+12, ...,
           6.56960913e+12, 5.92307867e+12, 5.77408388e+12],
          [6.35038178e+12, 4.86542252e+12, 6.16543184e+12, ...,
           7.48373410e+12, 6.82471719e+12, 6.13487529e+12],
          [8.20840235e+12, 7.48373410e+12, 4.97475335e+12, ...,
           8.24373569e+12, 7.48373410e+12, 7.01923905e+12]],

         [[1.04611656e+12, 1.08427018e+12, 1.08427018e+12, ...,
           2.46852616e+12, 2.07869313e+12, 1.83740636e+12],
          [1.04611656e+12, 1.04611656e+12, 1.02106110e+12, ...,
           2.46852616e+12, 2.24166543e+12, 1.95619088e+12],
          [1.04611656e+12, 1.00864754e+12, 1.00864754e+12, ...,
           2.29735766e+12, 2.37267478e+12, 2.24166543e+12],
          ...,
          [4.49232765e+12, 6.07397872e+12, 6.63294050e+12, ...,
           6.56960913e+12, 5.92307867e+12, 5.77408388e+12],
          [6.35038178e+12, 4.86542252e+12, 6.16543184e+12, ...,
           7.48373410e+12, 6.82471719e+12, 6.13487529e+12],
          [8.20840235e+12, 7.48373410e+12, 4.97475335e+12, ...,
           8.24373569e+12, 7.48373410e+12, 7.01923905e+12]],

         ...,

         [[4.06346752e+09, 4.21166387e+09, 4.21166387e+09, ...,
           9.58858752e+09, 8.07434035e+09, 7.13709568e+09],
          [4.06346752e+09, 4.06346752e+09, 3.96614451e+09, ...,
           9.58858752e+09, 8.70737818e+09, 7.59849267e+09],
          [4.06346752e+09, 3.91792538e+09, 3.91792538e+09, ...,
           8.92369920e+09, 9.21625600e+09, 8.70737818e+09],
          ...,
          [1.74497055e+10, 2.35933696e+10, 2.57645302e+10, ...,
           2.55185715e+10, 2.30072279e+10, 2.24284570e+10],
          [2.46670049e+10, 1.88989174e+10, 2.39485952e+10, ...,
           2.90693407e+10, 2.65094840e+10, 2.38298911e+10],
          [3.18841487e+10, 2.90693407e+10, 1.93235948e+10, ...,
           3.20214323e+10, 2.90693407e+10, 2.72650547e+10]],

         [[4.06346752e+09, 4.21166387e+09, 4.21166387e+09, ...,
           9.58858752e+09, 8.07434035e+09, 7.13709568e+09],
          [4.06346752e+09, 4.06346752e+09, 3.96614451e+09, ...,
           9.58858752e+09, 8.70737818e+09, 7.59849267e+09],
          [4.06346752e+09, 3.91792538e+09, 3.91792538e+09, ...,
           8.92369920e+09, 9.21625600e+09, 8.70737818e+09],
          ...,
          [1.74497055e+10, 2.35933696e+10, 2.57645302e+10, ...,
           2.55185715e+10, 2.30072279e+10, 2.24284570e+10],
          [2.46670049e+10, 1.88989174e+10, 2.39485952e+10, ...,
           2.90693407e+10, 2.65094840e+10, 2.38298911e+10],
          [3.18841487e+10, 2.90693407e+10, 1.93235948e+10, ...,
           3.20214323e+10, 2.90693407e+10, 2.72650547e+10]],

         [[4.06346752e+09, 4.21166387e+09, 4.21166387e+09, ...,
           9.58858752e+09, 8.07434035e+09, 7.13709568e+09],
          [4.06346752e+09, 4.06346752e+09, 3.96614451e+09, ...,
           9.58858752e+09, 8.70737818e+09, 7.59849267e+09],
          [4.06346752e+09, 3.91792538e+09, 3.91792538e+09, ...,
           8.92369920e+09, 9.21625600e+09, 8.70737818e+09],
          ...,
          [1.74497055e+10, 2.35933696e+10, 2.57645302e+10, ...,
           2.55185715e+10, 2.30072279e+10, 2.24284570e+10],
          [2.46670049e+10, 1.88989174e+10, 2.39485952e+10, ...,
           2.90693407e+10, 2.65094840e+10, 2.38298911e+10],
          [3.18841487e+10, 2.90693407e+10, 1.93235948e+10, ...,
           3.20214323e+10, 2.90693407e+10, 2.72650547e+10]]]]],
      dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:31

analyse output arrays in iter:53

pre layer res:
9:add
{'name': 'add', 'output': array([[[[4444928., 4550656., 4688000., ..., 4856576., 4993024.,
          5070208.],
         [4521728., 4642816., 4764800., ..., 5040896., 5105664.,
          5147008.],
         [4567808., 4673536., 4810880., ..., 5430016., 5469184.,
          5351808.],
         ...,
         [4675328., 4740096., 4836480., ..., 5184256., 5346304.,
          5418368.],
         [4752128., 4852736., 4928640., ..., 5189376., 5351424.,
          5418368.],
         [4828928., 4960256., 5046400., ..., 5189376., 5351424.,
          5418368.]],

        [[4444928., 4550656., 4688000., ..., 4856576., 4993024.,
          5070208.],
         [4521728., 4642816., 4764800., ..., 5040896., 5105664.,
          5147008.],
         [4567808., 4673536., 4810880., ..., 5430016., 5469184.,
          5351808.],
         ...,
         [4675328., 4740096., 4836480., ..., 5184256., 5346304.,
          5418368.],
         [4752128., 4852736., 4928640., ..., 5189376., 5351424.,
          5418368.],
         [4828928., 4960256., 5046400., ..., 5189376., 5351424.,
          5418368.]],

        [[4444928., 4550656., 4688000., ..., 4856576., 4993024.,
          5070208.],
         [4521728., 4642816., 4764800., ..., 5040896., 5105664.,
          5147008.],
         [4567808., 4673536., 4810880., ..., 5430016., 5469184.,
          5351808.],
         ...,
         [4675328., 4740096., 4836480., ..., 5184256., 5346304.,
          5418368.],
         [4752128., 4852736., 4928640., ..., 5189376., 5351424.,
          5418368.],
         [4828928., 4960256., 5046400., ..., 5189376., 5351424.,
          5418368.]],

        ...,

        [[2365440., 2350080., 2365440., ..., 2790400., 2764800.,
          2728960.],
         [2442240., 2442240., 2442240., ..., 2974720., 2877440.,
          2805760.],
         [2488320., 2472960., 2488320., ..., 3363840., 3240960.,
          3010560.],
         ...,
         [2595840., 2539520., 2513920., ..., 3118080., 3118080.,
          3077120.],
         [2672640., 2652160., 2606080., ..., 3123200., 3123200.,
          3077120.],
         [2749440., 2759680., 2723840., ..., 3123200., 3123200.,
          3077120.]],

        [[2365440., 2350080., 2365440., ..., 2790400., 2764800.,
          2728960.],
         [2442240., 2442240., 2442240., ..., 2974720., 2877440.,
          2805760.],
         [2488320., 2472960., 2488320., ..., 3363840., 3240960.,
          3010560.],
         ...,
         [2595840., 2539520., 2513920., ..., 3118080., 3118080.,
          3077120.],
         [2672640., 2652160., 2606080., ..., 3123200., 3123200.,
          3077120.],
         [2749440., 2759680., 2723840., ..., 3123200., 3123200.,
          3077120.]],

        [[2365440., 2350080., 2365440., ..., 2790400., 2764800.,
          2728960.],
         [2442240., 2442240., 2442240., ..., 2974720., 2877440.,
          2805760.],
         [2488320., 2472960., 2488320., ..., 3363840., 3240960.,
          3010560.],
         ...,
         [2595840., 2539520., 2513920., ..., 3118080., 3118080.,
          3077120.],
         [2672640., 2652160., 2606080., ..., 3123200., 3123200.,
          3077120.],
         [2749440., 2759680., 2723840., ..., 3123200., 3123200.,
          3077120.]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [8, 8], 'to': [14]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.9967233 ,  0.6043782 ,  0.7149936 , ...,  0.46460292,
           0.30557021, -0.8629855 ],
         [ 0.7603365 ,  0.6672583 ,  0.16979784, ..., -0.10043775,
          -0.8554717 , -0.9953626 ],
         [ 0.9848867 ,  0.7858304 ,  0.8682517 , ..., -0.64960057,
          -0.8710465 , -0.94644856],
         ...,
         [-0.3784764 , -0.96720946, -0.94942236, ..., -0.19568302,
          -0.9667962 ,  0.31314293],
         [-0.8490265 , -0.47114742,  0.4887833 , ..., -0.837657  ,
          -0.49371445,  0.31314293],
         [-0.99759734,  0.9974352 , -0.03027367, ..., -0.837657  ,
          -0.49371445,  0.31314293]],

        [[ 0.9967233 ,  0.6043782 ,  0.7149936 , ...,  0.46460292,
           0.30557021, -0.8629855 ],
         [ 0.7603365 ,  0.6672583 ,  0.16979784, ..., -0.10043775,
          -0.8554717 , -0.9953626 ],
         [ 0.9848867 ,  0.7858304 ,  0.8682517 , ..., -0.64960057,
          -0.8710465 , -0.94644856],
         ...,
         [-0.3784764 , -0.96720946, -0.94942236, ..., -0.19568302,
          -0.9667962 ,  0.31314293],
         [-0.8490265 , -0.47114742,  0.4887833 , ..., -0.837657  ,
          -0.49371445,  0.31314293],
         [-0.99759734,  0.9974352 , -0.03027367, ..., -0.837657  ,
          -0.49371445,  0.31314293]],

        [[ 0.9967233 ,  0.6043782 ,  0.7149936 , ...,  0.46460292,
           0.30557021, -0.8629855 ],
         [ 0.7603365 ,  0.6672583 ,  0.16979784, ..., -0.10043775,
          -0.8554717 , -0.9953626 ],
         [ 0.9848867 ,  0.7858304 ,  0.8682517 , ..., -0.64960057,
          -0.8710465 , -0.94644856],
         ...,
         [-0.3784764 , -0.96720946, -0.94942236, ..., -0.19568302,
          -0.9667962 ,  0.31314293],
         [-0.8490265 , -0.47114742,  0.4887833 , ..., -0.837657  ,
          -0.49371445,  0.31314293],
         [-0.99759734,  0.9974352 , -0.03027367, ..., -0.837657  ,
          -0.49371445,  0.31314293]],

        ...,

        [[ 0.19609289, -0.813932  ,  0.19609289, ..., -0.2898119 ,
          -0.5179937 ,  0.16573575],
         [-0.41561466, -0.41561466, -0.41561466, ...,  0.6261527 ,
          -0.95211804, -0.44348776],
         [ 0.4371473 , -0.9341754 ,  0.4371473 , ..., -0.9962594 ,
          -0.9422288 , -0.034392  ],
         ...,
         [-0.9939777 ,  0.84794694, -0.9611002 , ..., -0.82723606,
          -0.82723606, -0.77653825],
         [-0.7412986 ,  0.7121067 , -0.0884328 , ..., -0.98018575,
          -0.98018575, -0.77653825],
         [-0.20749427, -0.97360545, -0.5887579 , ..., -0.98018575,
          -0.98018575, -0.77653825]],

        [[ 0.19609289, -0.813932  ,  0.19609289, ..., -0.2898119 ,
          -0.5179937 ,  0.16573575],
         [-0.41561466, -0.41561466, -0.41561466, ...,  0.6261527 ,
          -0.95211804, -0.44348776],
         [ 0.4371473 , -0.9341754 ,  0.4371473 , ..., -0.9962594 ,
          -0.9422288 , -0.034392  ],
         ...,
         [-0.9939777 ,  0.84794694, -0.9611002 , ..., -0.82723606,
          -0.82723606, -0.77653825],
         [-0.7412986 ,  0.7121067 , -0.0884328 , ..., -0.98018575,
          -0.98018575, -0.77653825],
         [-0.20749427, -0.97360545, -0.5887579 , ..., -0.98018575,
          -0.98018575, -0.77653825]],

        [[ 0.19609289, -0.813932  ,  0.19609289, ..., -0.2898119 ,
          -0.5179937 ,  0.16573575],
         [-0.41561466, -0.41561466, -0.41561466, ...,  0.6261527 ,
          -0.95211804, -0.44348776],
         [ 0.4371473 , -0.9341754 ,  0.4371473 , ..., -0.9962594 ,
          -0.9422288 , -0.034392  ],
         ...,
         [-0.9939777 ,  0.84794694, -0.9611002 , ..., -0.82723606,
          -0.82723606, -0.77653825],
         [-0.7412986 ,  0.7121067 , -0.0884328 , ..., -0.98018575,
          -0.98018575, -0.77653825],
         [-0.20749427, -0.97360545, -0.5887579 , ..., -0.98018575,
          -0.98018575, -0.77653825]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [9], 'to': [16]}
ms node:
{'name': 'sin', 'output': array([[[[ 9.9672329e-01,  6.0437828e-01,  7.1499354e-01, ...,
           4.6460292e-01,  3.0557019e-01, -8.6298549e-01],
         [ 7.6033646e-01,  6.6725832e-01,  1.6979784e-01, ...,
          -1.0043775e-01, -8.5547167e-01, -9.9536258e-01],
         [ 9.8488671e-01,  7.8583044e-01,  8.6825168e-01, ...,
          -6.4960057e-01, -8.7104648e-01, -9.4644856e-01],
         ...,
         [-3.7847641e-01, -9.6720946e-01, -9.4942236e-01, ...,
          -1.9568302e-01, -9.6679622e-01,  3.1314293e-01],
         [-8.4902650e-01, -4.7114742e-01,  4.8878330e-01, ...,
          -8.3765692e-01, -4.9371448e-01,  3.1314293e-01],
         [-9.9759734e-01,  9.9743521e-01, -3.0273670e-02, ...,
          -8.3765692e-01, -4.9371448e-01,  3.1314293e-01]],

        [[ 9.9672329e-01,  6.0437828e-01,  7.1499354e-01, ...,
           4.6460292e-01,  3.0557019e-01, -8.6298549e-01],
         [ 7.6033646e-01,  6.6725832e-01,  1.6979784e-01, ...,
          -1.0043775e-01, -8.5547167e-01, -9.9536258e-01],
         [ 9.8488671e-01,  7.8583044e-01,  8.6825168e-01, ...,
          -6.4960057e-01, -8.7104648e-01, -9.4644856e-01],
         ...,
         [-3.7847641e-01, -9.6720946e-01, -9.4942236e-01, ...,
          -1.9568302e-01, -9.6679622e-01,  3.1314293e-01],
         [-8.4902650e-01, -4.7114742e-01,  4.8878330e-01, ...,
          -8.3765692e-01, -4.9371448e-01,  3.1314293e-01],
         [-9.9759734e-01,  9.9743521e-01, -3.0273670e-02, ...,
          -8.3765692e-01, -4.9371448e-01,  3.1314293e-01]],

        [[ 9.9672329e-01,  6.0437828e-01,  7.1499354e-01, ...,
           4.6460292e-01,  3.0557019e-01, -8.6298549e-01],
         [ 7.6033646e-01,  6.6725832e-01,  1.6979784e-01, ...,
          -1.0043775e-01, -8.5547167e-01, -9.9536258e-01],
         [ 9.8488671e-01,  7.8583044e-01,  8.6825168e-01, ...,
          -6.4960057e-01, -8.7104648e-01, -9.4644856e-01],
         ...,
         [-3.7847641e-01, -9.6720946e-01, -9.4942236e-01, ...,
          -1.9568302e-01, -9.6679622e-01,  3.1314293e-01],
         [-8.4902650e-01, -4.7114742e-01,  4.8878330e-01, ...,
          -8.3765692e-01, -4.9371448e-01,  3.1314293e-01],
         [-9.9759734e-01,  9.9743521e-01, -3.0273670e-02, ...,
          -8.3765692e-01, -4.9371448e-01,  3.1314293e-01]],

        ...,

        [[ 1.1827200e+06,  1.1750400e+06,  1.1827200e+06, ...,
           1.3952000e+06,  1.3824000e+06,  1.3644800e+06],
         [ 1.2211200e+06,  1.2211200e+06,  1.2211200e+06, ...,
           1.4873600e+06,  1.4387200e+06,  1.4028800e+06],
         [ 1.2441600e+06,  1.2364800e+06,  1.2441600e+06, ...,
           1.6819200e+06,  1.6204800e+06,  1.5052800e+06],
         ...,
         [ 1.2979200e+06,  1.2697600e+06,  1.2569600e+06, ...,
           1.5590400e+06,  1.5590400e+06,  1.5385600e+06],
         [ 1.3363200e+06,  1.3260800e+06,  1.3030400e+06, ...,
           1.5616000e+06,  1.5616000e+06,  1.5385600e+06],
         [ 1.3747200e+06,  1.3798400e+06,  1.3619200e+06, ...,
           1.5616000e+06,  1.5616000e+06,  1.5385600e+06]],

        [[ 1.1827200e+06,  1.1750400e+06,  1.1827200e+06, ...,
           1.3952000e+06,  1.3824000e+06,  1.3644800e+06],
         [ 1.2211200e+06,  1.2211200e+06,  1.2211200e+06, ...,
           1.4873600e+06,  1.4387200e+06,  1.4028800e+06],
         [ 1.2441600e+06,  1.2364800e+06,  1.2441600e+06, ...,
           1.6819200e+06,  1.6204800e+06,  1.5052800e+06],
         ...,
         [ 1.2979200e+06,  1.2697600e+06,  1.2569600e+06, ...,
           1.5590400e+06,  1.5590400e+06,  1.5385600e+06],
         [ 1.3363200e+06,  1.3260800e+06,  1.3030400e+06, ...,
           1.5616000e+06,  1.5616000e+06,  1.5385600e+06],
         [ 1.3747200e+06,  1.3798400e+06,  1.3619200e+06, ...,
           1.5616000e+06,  1.5616000e+06,  1.5385600e+06]],

        [[ 1.1827200e+06,  1.1750400e+06,  1.1827200e+06, ...,
           1.3952000e+06,  1.3824000e+06,  1.3644800e+06],
         [ 1.2211200e+06,  1.2211200e+06,  1.2211200e+06, ...,
           1.4873600e+06,  1.4387200e+06,  1.4028800e+06],
         [ 1.2441600e+06,  1.2364800e+06,  1.2441600e+06, ...,
           1.6819200e+06,  1.6204800e+06,  1.5052800e+06],
         ...,
         [ 1.2979200e+06,  1.2697600e+06,  1.2569600e+06, ...,
           1.5590400e+06,  1.5590400e+06,  1.5385600e+06],
         [ 1.3363200e+06,  1.3260800e+06,  1.3030400e+06, ...,
           1.5616000e+06,  1.5616000e+06,  1.5385600e+06],
         [ 1.3747200e+06,  1.3798400e+06,  1.3619200e+06, ...,
           1.5616000e+06,  1.5616000e+06,  1.5385600e+06]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [9], 'to': [16]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.9967233 ,  0.6043783 ,  0.71499354, ...,  0.46460292,
           0.3055702 , -0.8629855 ],
         [ 0.76033646,  0.6672583 ,  0.16979784, ..., -0.10043775,
          -0.8554717 , -0.9953626 ],
         [ 0.9848867 ,  0.78583044,  0.8682517 , ..., -0.64960057,
          -0.8710465 , -0.94644856],
         ...,
         [-0.3784764 , -0.96720946, -0.94942236, ..., -0.19568302,
          -0.9667962 ,  0.31314293],
         [-0.8490265 , -0.47114742,  0.4887833 , ..., -0.8376569 ,
          -0.49371448,  0.31314293],
         [-0.99759734,  0.9974352 , -0.03027367, ..., -0.8376569 ,
          -0.49371448,  0.31314293]],

        [[ 0.9967233 ,  0.6043783 ,  0.71499354, ...,  0.46460292,
           0.3055702 , -0.8629855 ],
         [ 0.76033646,  0.6672583 ,  0.16979784, ..., -0.10043775,
          -0.8554717 , -0.9953626 ],
         [ 0.9848867 ,  0.78583044,  0.8682517 , ..., -0.64960057,
          -0.8710465 , -0.94644856],
         ...,
         [-0.3784764 , -0.96720946, -0.94942236, ..., -0.19568302,
          -0.9667962 ,  0.31314293],
         [-0.8490265 , -0.47114742,  0.4887833 , ..., -0.8376569 ,
          -0.49371448,  0.31314293],
         [-0.99759734,  0.9974352 , -0.03027367, ..., -0.8376569 ,
          -0.49371448,  0.31314293]],

        [[ 0.9967233 ,  0.6043783 ,  0.71499354, ...,  0.46460292,
           0.3055702 , -0.8629855 ],
         [ 0.76033646,  0.6672583 ,  0.16979784, ..., -0.10043775,
          -0.8554717 , -0.9953626 ],
         [ 0.9848867 ,  0.78583044,  0.8682517 , ..., -0.64960057,
          -0.8710465 , -0.94644856],
         ...,
         [-0.3784764 , -0.96720946, -0.94942236, ..., -0.19568302,
          -0.9667962 ,  0.31314293],
         [-0.8490265 , -0.47114742,  0.4887833 , ..., -0.8376569 ,
          -0.49371448,  0.31314293],
         [-0.99759734,  0.9974352 , -0.03027367, ..., -0.8376569 ,
          -0.49371448,  0.31314293]],

        ...,

        [[ 0.19609289, -0.813932  ,  0.19609289, ..., -0.2898119 ,
          -0.5179937 ,  0.16573577],
         [-0.41561466, -0.41561466, -0.41561466, ...,  0.6261527 ,
          -0.95211804, -0.44348773],
         [ 0.43714726, -0.9341754 ,  0.43714726, ..., -0.9962594 ,
          -0.94222873, -0.034392  ],
         ...,
         [-0.9939777 ,  0.84794694, -0.9611002 , ..., -0.827236  ,
          -0.827236  , -0.77653825],
         [-0.7412986 ,  0.7121067 , -0.0884328 , ..., -0.98018575,
          -0.98018575, -0.77653825],
         [-0.20749427, -0.97360545, -0.5887579 , ..., -0.98018575,
          -0.98018575, -0.77653825]],

        [[ 0.19609289, -0.813932  ,  0.19609289, ..., -0.2898119 ,
          -0.5179937 ,  0.16573577],
         [-0.41561466, -0.41561466, -0.41561466, ...,  0.6261527 ,
          -0.95211804, -0.44348773],
         [ 0.43714726, -0.9341754 ,  0.43714726, ..., -0.9962594 ,
          -0.94222873, -0.034392  ],
         ...,
         [-0.9939777 ,  0.84794694, -0.9611002 , ..., -0.827236  ,
          -0.827236  , -0.77653825],
         [-0.7412986 ,  0.7121067 , -0.0884328 , ..., -0.98018575,
          -0.98018575, -0.77653825],
         [-0.20749427, -0.97360545, -0.5887579 , ..., -0.98018575,
          -0.98018575, -0.77653825]],

        [[ 0.19609289, -0.813932  ,  0.19609289, ..., -0.2898119 ,
          -0.5179937 ,  0.16573577],
         [-0.41561466, -0.41561466, -0.41561466, ...,  0.6261527 ,
          -0.95211804, -0.44348773],
         [ 0.43714726, -0.9341754 ,  0.43714726, ..., -0.9962594 ,
          -0.94222873, -0.034392  ],
         ...,
         [-0.9939777 ,  0.84794694, -0.9611002 , ..., -0.827236  ,
          -0.827236  , -0.77653825],
         [-0.7412986 ,  0.7121067 , -0.0884328 , ..., -0.98018575,
          -0.98018575, -0.77653825],
         [-0.20749427, -0.97360545, -0.5887579 , ..., -0.98018575,
          -0.98018575, -0.77653825]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [9], 'to': [16]}

generate models:33

analyse output arrays in iter:57

pre layer res:
9:add
{'name': 'add', 'output': array([[[[ 88064.,  96256., 120832., ..., 112640., 117248., 105472.],
         [100352., 106496., 129536., ..., 112640., 117248., 104448.],
         [107008., 113664., 132096., ..., 104448., 107008.,  98816.],
         ...,
         [108544., 122880.,  82432., ...,  47104.,  33792.,  26112.],
         [107520.,  97792.,  49152., ..., 105984., 102912.,  87552.],
         [107520.,  86016.,  39936., ..., 193536., 186880., 180224.]],

        [[ 88064.,  96256., 120832., ..., 112640., 117248., 105472.],
         [100352., 106496., 129536., ..., 112640., 117248., 104448.],
         [107008., 113664., 132096., ..., 104448., 107008.,  98816.],
         ...,
         [108544., 122880.,  82432., ...,  47104.,  33792.,  26112.],
         [107520.,  97792.,  49152., ..., 105984., 102912.,  87552.],
         [107520.,  86016.,  39936., ..., 193536., 186880., 180224.]],

        [[ 88064.,  96256., 120832., ..., 112640., 117248., 105472.],
         [100352., 106496., 129536., ..., 112640., 117248., 104448.],
         [107008., 113664., 132096., ..., 104448., 107008.,  98816.],
         ...,
         [108544., 122880.,  82432., ...,  47104.,  33792.,  26112.],
         [107520.,  97792.,  49152., ..., 105984., 102912.,  87552.],
         [107520.,  86016.,  39936., ..., 193536., 186880., 180224.]],

        ...,

        [[ 88064.,  96256., 120832., ..., 112640., 117248., 105472.],
         [100352., 106496., 129536., ..., 112640., 117248., 104448.],
         [107008., 113664., 132096., ..., 104448., 107008.,  98816.],
         ...,
         [108544., 122880.,  82432., ...,  47104.,  33792.,  26112.],
         [107520.,  97792.,  49152., ..., 105984., 102912.,  87552.],
         [107520.,  86016.,  39936., ..., 193536., 186880., 180224.]],

        [[ 88064.,  96256., 120832., ..., 112640., 117248., 105472.],
         [100352., 106496., 129536., ..., 112640., 117248., 104448.],
         [107008., 113664., 132096., ..., 104448., 107008.,  98816.],
         ...,
         [108544., 122880.,  82432., ...,  47104.,  33792.,  26112.],
         [107520.,  97792.,  49152., ..., 105984., 102912.,  87552.],
         [107520.,  86016.,  39936., ..., 193536., 186880., 180224.]],

        [[ 88064.,  96256., 120832., ..., 112640., 117248., 105472.],
         [100352., 106496., 129536., ..., 112640., 117248., 104448.],
         [107008., 113664., 132096., ..., 104448., 107008.,  98816.],
         ...,
         [108544., 122880.,  82432., ...,  47104.,  33792.,  26112.],
         [107520.,  97792.,  49152., ..., 105984., 102912.,  87552.],
         [107520.,  86016.,  39936., ..., 193536., 186880., 180224.]]]],
      dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [7, 7], 'to': [16]}
tf node:
{'name': 'sin', 'output': array([[[[-0.902382  , -0.67626953,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.63665974],
         [-0.10566874,  0.7508606 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.8010017 ,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.8010017 ,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.865257  ],
         [ 0.84606993, -0.7221153 ,  0.07411954, ...,  0.9702275 ,
          -0.7036997 , -0.2515114 ]],

        [[-0.902382  , -0.67626953,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.63665974],
         [-0.10566874,  0.7508606 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.8010017 ,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.8010017 ,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.865257  ],
         [ 0.84606993, -0.7221153 ,  0.07411954, ...,  0.9702275 ,
          -0.7036997 , -0.2515114 ]],

        [[-0.902382  , -0.67626953,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.63665974],
         [-0.10566874,  0.7508606 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.8010017 ,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.8010017 ,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.865257  ],
         [ 0.84606993, -0.7221153 ,  0.07411954, ...,  0.9702275 ,
          -0.7036997 , -0.2515114 ]],

        ...,

        [[-0.902382  , -0.67626953,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.63665974],
         [-0.10566874,  0.7508606 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.8010017 ,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.8010017 ,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.865257  ],
         [ 0.84606993, -0.7221153 ,  0.07411954, ...,  0.9702275 ,
          -0.7036997 , -0.2515114 ]],

        [[-0.902382  , -0.67626953,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.63665974],
         [-0.10566874,  0.7508606 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.8010017 ,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.8010017 ,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.865257  ],
         [ 0.84606993, -0.7221153 ,  0.07411954, ...,  0.9702275 ,
          -0.7036997 , -0.2515114 ]],

        [[-0.902382  , -0.67626953,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.63665974],
         [-0.10566874,  0.7508606 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.8010017 ,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.8010017 ,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.865257  ],
         [ 0.84606993, -0.7221153 ,  0.07411954, ...,  0.9702275 ,
          -0.7036997 , -0.2515114 ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [9], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[-9.0238202e-01, -6.7626947e-01,  6.3315250e-02, ...,
           9.7279346e-01, -5.8150333e-01,  6.3665980e-01],
         [-1.0566874e-01,  7.5086051e-01,  9.6080333e-01, ...,
           9.7279346e-01, -5.8150333e-01,  5.0635612e-01],
         [-8.0100167e-01,  9.2376310e-01, -9.9315143e-01, ...,
           5.0635612e-01, -8.0100167e-01,  3.3788985e-01],
         ...,
         [ 9.1987991e-01, -2.5229621e-01,  2.4705276e-01, ...,
          -8.6252970e-01,  8.5699922e-01, -7.9447138e-01],
         [ 8.4606993e-01,  4.8282611e-01, -9.7758293e-01, ...,
          -6.9596398e-01, -2.8800824e-01,  8.6525708e-01],
         [ 8.4606993e-01, -7.2211534e-01,  7.4119531e-02, ...,
           9.7022748e-01, -7.0369977e-01, -2.5151137e-01]],

        [[-9.0238202e-01, -6.7626947e-01,  6.3315250e-02, ...,
           9.7279346e-01, -5.8150333e-01,  6.3665980e-01],
         [-1.0566874e-01,  7.5086051e-01,  9.6080333e-01, ...,
           9.7279346e-01, -5.8150333e-01,  5.0635612e-01],
         [-8.0100167e-01,  9.2376310e-01, -9.9315143e-01, ...,
           5.0635612e-01, -8.0100167e-01,  3.3788985e-01],
         ...,
         [ 9.1987991e-01, -2.5229621e-01,  2.4705276e-01, ...,
          -8.6252970e-01,  8.5699922e-01, -7.9447138e-01],
         [ 8.4606993e-01,  4.8282611e-01, -9.7758293e-01, ...,
          -6.9596398e-01, -2.8800824e-01,  8.6525708e-01],
         [ 8.4606993e-01, -7.2211534e-01,  7.4119531e-02, ...,
           9.7022748e-01, -7.0369977e-01, -2.5151137e-01]],

        [[-9.0238202e-01, -6.7626947e-01,  6.3315250e-02, ...,
           9.7279346e-01, -5.8150333e-01,  6.3665980e-01],
         [-1.0566874e-01,  7.5086051e-01,  9.6080333e-01, ...,
           9.7279346e-01, -5.8150333e-01,  5.0635612e-01],
         [-8.0100167e-01,  9.2376310e-01, -9.9315143e-01, ...,
           5.0635612e-01, -8.0100167e-01,  3.3788985e-01],
         ...,
         [ 9.1987991e-01, -2.5229621e-01,  2.4705276e-01, ...,
          -8.6252970e-01,  8.5699922e-01, -7.9447138e-01],
         [ 8.4606993e-01,  4.8282611e-01, -9.7758293e-01, ...,
          -6.9596398e-01, -2.8800824e-01,  8.6525708e-01],
         [ 8.4606993e-01, -7.2211534e-01,  7.4119531e-02, ...,
           9.7022748e-01, -7.0369977e-01, -2.5151137e-01]],

        ...,

        [[ 4.4032000e+04,  4.8128000e+04,  6.0416000e+04, ...,
           5.6320000e+04,  5.8624000e+04,  5.2736000e+04],
         [ 5.0176000e+04,  5.3248000e+04,  6.4768000e+04, ...,
           5.6320000e+04,  5.8624000e+04,  5.2224000e+04],
         [ 5.3504000e+04,  5.6832000e+04,  6.6048000e+04, ...,
           5.2224000e+04,  5.3504000e+04,  4.9408000e+04],
         ...,
         [ 5.4272000e+04,  6.1440000e+04,  4.1216000e+04, ...,
           2.3552000e+04,  1.6896000e+04,  1.3056000e+04],
         [ 5.3760000e+04,  4.8896000e+04,  2.4576000e+04, ...,
           5.2992000e+04,  5.1456000e+04,  4.3776000e+04],
         [ 5.3760000e+04,  4.3008000e+04,  1.9968000e+04, ...,
           9.6768000e+04,  9.3440000e+04,  9.0112000e+04]],

        [[ 4.4032000e+04,  4.8128000e+04,  6.0416000e+04, ...,
           5.6320000e+04,  5.8624000e+04,  5.2736000e+04],
         [ 5.0176000e+04,  5.3248000e+04,  6.4768000e+04, ...,
           5.6320000e+04,  5.8624000e+04,  5.2224000e+04],
         [ 5.3504000e+04,  5.6832000e+04,  6.6048000e+04, ...,
           5.2224000e+04,  5.3504000e+04,  4.9408000e+04],
         ...,
         [ 5.4272000e+04,  6.1440000e+04,  4.1216000e+04, ...,
           2.3552000e+04,  1.6896000e+04,  1.3056000e+04],
         [ 5.3760000e+04,  4.8896000e+04,  2.4576000e+04, ...,
           5.2992000e+04,  5.1456000e+04,  4.3776000e+04],
         [ 5.3760000e+04,  4.3008000e+04,  1.9968000e+04, ...,
           9.6768000e+04,  9.3440000e+04,  9.0112000e+04]],

        [[ 4.4032000e+04,  4.8128000e+04,  6.0416000e+04, ...,
           5.6320000e+04,  5.8624000e+04,  5.2736000e+04],
         [ 5.0176000e+04,  5.3248000e+04,  6.4768000e+04, ...,
           5.6320000e+04,  5.8624000e+04,  5.2224000e+04],
         [ 5.3504000e+04,  5.6832000e+04,  6.6048000e+04, ...,
           5.2224000e+04,  5.3504000e+04,  4.9408000e+04],
         ...,
         [ 5.4272000e+04,  6.1440000e+04,  4.1216000e+04, ...,
           2.3552000e+04,  1.6896000e+04,  1.3056000e+04],
         [ 5.3760000e+04,  4.8896000e+04,  2.4576000e+04, ...,
           5.2992000e+04,  5.1456000e+04,  4.3776000e+04],
         [ 5.3760000e+04,  4.3008000e+04,  1.9968000e+04, ...,
           9.6768000e+04,  9.3440000e+04,  9.0112000e+04]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [9], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[-0.902382  , -0.6762695 ,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.6366598 ],
         [-0.10566874,  0.7508605 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.80100167,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.80100167,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.8652571 ],
         [ 0.84606993, -0.72211534,  0.07411953, ...,  0.9702275 ,
          -0.70369977, -0.25151137]],

        [[-0.902382  , -0.6762695 ,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.6366598 ],
         [-0.10566874,  0.7508605 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.80100167,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.80100167,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.8652571 ],
         [ 0.84606993, -0.72211534,  0.07411953, ...,  0.9702275 ,
          -0.70369977, -0.25151137]],

        [[-0.902382  , -0.6762695 ,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.6366598 ],
         [-0.10566874,  0.7508605 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.80100167,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.80100167,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.8652571 ],
         [ 0.84606993, -0.72211534,  0.07411953, ...,  0.9702275 ,
          -0.70369977, -0.25151137]],

        ...,

        [[-0.902382  , -0.6762695 ,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.6366598 ],
         [-0.10566874,  0.7508605 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.80100167,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.80100167,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.8652571 ],
         [ 0.84606993, -0.72211534,  0.07411953, ...,  0.9702275 ,
          -0.70369977, -0.25151137]],

        [[-0.902382  , -0.6762695 ,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.6366598 ],
         [-0.10566874,  0.7508605 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.80100167,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.80100167,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.8652571 ],
         [ 0.84606993, -0.72211534,  0.07411953, ...,  0.9702275 ,
          -0.70369977, -0.25151137]],

        [[-0.902382  , -0.6762695 ,  0.06331525, ...,  0.97279346,
          -0.58150333,  0.6366598 ],
         [-0.10566874,  0.7508605 ,  0.96080333, ...,  0.97279346,
          -0.58150333,  0.5063561 ],
         [-0.80100167,  0.9237631 , -0.9931514 , ...,  0.5063561 ,
          -0.80100167,  0.33788985],
         ...,
         [ 0.9198799 , -0.2522962 ,  0.24705276, ..., -0.8625297 ,
           0.8569992 , -0.7944714 ],
         [ 0.84606993,  0.4828261 , -0.97758293, ..., -0.695964  ,
          -0.28800824,  0.8652571 ],
         [ 0.84606993, -0.72211534,  0.07411953, ...,  0.9702275 ,
          -0.70369977, -0.25151137]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [9], 'to': []}

generate models:37

analyse the exceptions in iter:60
tensorflow exception:
{'id': 16, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          ...,
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan]],

         [[nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          ...,
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan]],

         [[nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          ...,
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          ...,
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan]],

         [[nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          ...,
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan]],

         [[nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          ...,
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan],
          [nan, nan, nan, ..., nan, nan, nan]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:38

analyse the exceptions in iter:62
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[-44.651855, -45.047142, -48.541996, ..., -63.19002 ,
           -71.765205, -65.75065 ],
          [-58.3101  , -59.694817, -60.88096 , ..., -67.287445,
           -78.10707 , -77.08362 ],
          [-77.72079 , -78.66527 , -72.83147 , ..., -79.94904 ,
           -83.48051 , -75.612526],
          ...,
          [-37.21852 , -38.999744, -40.426003, ..., -33.882774,
           -34.076115, -36.68751 ],
          [-34.16605 , -27.877546, -23.349411, ..., -45.83876 ,
           -47.668076, -49.54464 ],
          [-28.358383, -26.971302, -29.08576 , ..., -32.84062 ,
           -36.890297, -35.38134 ]],

         [[-44.651855, -45.047142, -48.541996, ..., -63.19002 ,
           -71.765205, -65.75065 ],
          [-58.3101  , -59.694817, -60.88096 , ..., -67.287445,
           -78.10707 , -77.08362 ],
          [-77.72079 , -78.66527 , -72.83147 , ..., -79.94904 ,
           -83.48051 , -75.612526],
          ...,
          [-37.21852 , -38.999744, -40.426003, ..., -33.882774,
           -34.076115, -36.68751 ],
          [-34.16605 , -27.877546, -23.349411, ..., -45.83876 ,
           -47.668076, -49.54464 ],
          [-28.358383, -26.971302, -29.08576 , ..., -32.84062 ,
           -36.890297, -35.38134 ]],

         [[-44.651855, -45.047142, -48.541996, ..., -63.19002 ,
           -71.765205, -65.75065 ],
          [-58.3101  , -59.694817, -60.88096 , ..., -67.287445,
           -78.10707 , -77.08362 ],
          [-77.72079 , -78.66527 , -72.83147 , ..., -79.94904 ,
           -83.48051 , -75.612526],
          ...,
          [-37.21852 , -38.999744, -40.426003, ..., -33.882774,
           -34.076115, -36.68751 ],
          [-34.16605 , -27.877546, -23.349411, ..., -45.83876 ,
           -47.668076, -49.54464 ],
          [-28.358383, -26.971302, -29.08576 , ..., -32.84062 ,
           -36.890297, -35.38134 ]],

         ...,

         [[-56.42961 , -56.791378, -60.240646, ..., -75.122314,
           -83.66649 , -77.65193 ],
          [-70.12627 , -71.44468 , -72.57384 , ..., -79.23506 ,
           -90.02908 , -89.021034],
          [-89.49854 , -90.36392 , -84.50108 , ..., -91.86072 ,
           -95.366104, -87.51901 ],
          ...,
          [-46.673298, -48.24969 , -49.61624 , ..., -44.1661  ,
           -44.394226, -46.899403],
          [-42.514824, -35.81813 , -30.87181 , ..., -55.146683,
           -56.95686 , -58.890297],
          [-39.779236, -38.262196, -40.282604, ..., -44.51024 ,
           -48.55406 , -47.102913]],

         [[-56.42961 , -56.791378, -60.240646, ..., -75.122314,
           -83.66649 , -77.65193 ],
          [-70.12627 , -71.44468 , -72.57384 , ..., -79.23506 ,
           -90.02908 , -89.021034],
          [-89.49854 , -90.36392 , -84.50108 , ..., -91.86072 ,
           -95.366104, -87.51901 ],
          ...,
          [-46.673298, -48.24969 , -49.61624 , ..., -44.1661  ,
           -44.394226, -46.899403],
          [-42.514824, -35.81813 , -30.87181 , ..., -55.146683,
           -56.95686 , -58.890297],
          [-39.779236, -38.262196, -40.282604, ..., -44.51024 ,
           -48.55406 , -47.102913]],

         [[-56.42961 , -56.791378, -60.240646, ..., -75.122314,
           -83.66649 , -77.65193 ],
          [-70.12627 , -71.44468 , -72.57384 , ..., -79.23506 ,
           -90.02908 , -89.021034],
          [-89.49854 , -90.36392 , -84.50108 , ..., -91.86072 ,
           -95.366104, -87.51901 ],
          ...,
          [-46.673298, -48.24969 , -49.61624 , ..., -44.1661  ,
           -44.394226, -46.899403],
          [-42.514824, -35.81813 , -30.87181 , ..., -55.146683,
           -56.95686 , -58.890297],
          [-39.779236, -38.262196, -40.282604, ..., -44.51024 ,
           -48.55406 , -47.102913]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:40

analyse the exceptions in iter:67
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[4.0600007e+03, 3.9617246e+03, 4.0336487e+03, ...,
           4.0012324e+03, 3.9643613e+03, 3.9643613e+03],
          [3.7696077e+03, 3.7075701e+03, 4.1147197e+03, ...,
           4.0753469e+03, 4.0383433e+03, 4.0420657e+03],
          [3.6105642e+03, 3.7372983e+03, 4.1479102e+03, ...,
           4.0862385e+03, 4.0600007e+03, 4.0687839e+03],
          ...,
          [2.7919922e+03, 2.5098879e+03, 2.4669121e+03, ...,
           2.1940000e+03, 2.2203086e+03, 2.3080952e+03],
          [2.4493730e+03, 2.3260007e+03, 2.3080952e+03, ...,
           2.3227837e+03, 2.3440654e+03, 2.3440654e+03],
          [2.1537090e+03, 2.0800845e+03, 2.0956875e+03, ...,
           2.2819299e+03, 2.2552002e+03, 2.2276685e+03]],

         [[4.0600007e+03, 3.9617246e+03, 4.0336487e+03, ...,
           4.0012324e+03, 3.9643613e+03, 3.9643613e+03],
          [3.7696077e+03, 3.7075701e+03, 4.1147197e+03, ...,
           4.0753469e+03, 4.0383433e+03, 4.0420657e+03],
          [3.6105642e+03, 3.7372983e+03, 4.1479102e+03, ...,
           4.0862385e+03, 4.0600007e+03, 4.0687839e+03],
          ...,
          [2.7919922e+03, 2.5098879e+03, 2.4669121e+03, ...,
           2.1940000e+03, 2.2203086e+03, 2.3080952e+03],
          [2.4493730e+03, 2.3260007e+03, 2.3080952e+03, ...,
           2.3227837e+03, 2.3440654e+03, 2.3440654e+03],
          [2.1537090e+03, 2.0800845e+03, 2.0956875e+03, ...,
           2.2819299e+03, 2.2552002e+03, 2.2276685e+03]],

         [[4.0600007e+03, 3.9617246e+03, 4.0336487e+03, ...,
           4.0012324e+03, 3.9643613e+03, 3.9643613e+03],
          [3.7696077e+03, 3.7075701e+03, 4.1147197e+03, ...,
           4.0753469e+03, 4.0383433e+03, 4.0420657e+03],
          [3.6105642e+03, 3.7372983e+03, 4.1479102e+03, ...,
           4.0862385e+03, 4.0600007e+03, 4.0687839e+03],
          ...,
          [2.7919922e+03, 2.5098879e+03, 2.4669121e+03, ...,
           2.1940000e+03, 2.2203086e+03, 2.3080952e+03],
          [2.4493730e+03, 2.3260007e+03, 2.3080952e+03, ...,
           2.3227837e+03, 2.3440654e+03, 2.3440654e+03],
          [2.1537090e+03, 2.0800845e+03, 2.0956875e+03, ...,
           2.2819299e+03, 2.2552002e+03, 2.2276685e+03]],

         ...,

         [[2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          ...,
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00]],

         [[2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          ...,
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00]],

         [[2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          ...,
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00],
          [2.0000000e+00, 2.0000000e+00, 2.0000000e+00, ...,
           2.0000000e+00, 2.0000000e+00, 2.0000000e+00]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:44

analyse the exceptions in iter:73
tensorflow exception:
{'id': 16, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[ 46849.57,  56449.57,  66817.57, ...,  66433.57,  48001.57,
            48769.57],
          [ 61441.57,  66049.57,  58369.57, ...,  50689.57,  39937.57,
            41473.57],
          [ 75265.57,  79489.57,  65281.57, ...,  60289.57,  48769.57,
            45697.57],
          ...,
          [153601.58, 160129.58, 159361.58, ..., 128257.57, 132481.58,
           125953.57],
          [159745.58, 159361.58, 153985.58, ..., 175873.58, 175489.58,
           168193.58],
          [100993.57, 100993.57,  98305.57, ..., 120194.57, 119425.57,
           112513.57]],

         [[ 46849.57,  56449.57,  66817.57, ...,  66433.57,  48001.57,
            48769.57],
          [ 61441.57,  66049.57,  58369.57, ...,  50689.57,  39937.57,
            41473.57],
          [ 75265.57,  79489.57,  65281.57, ...,  60289.57,  48769.57,
            45697.57],
          ...,
          [153601.58, 160129.58, 159361.58, ..., 128257.57, 132481.58,
           125953.57],
          [159745.58, 159361.58, 153985.58, ..., 175873.58, 175489.58,
           168193.58],
          [100993.57, 100993.57,  98305.57, ..., 120194.57, 119425.57,
           112513.57]],

         [[ 46849.57,  56449.57,  66817.57, ...,  66433.57,  48001.57,
            48769.57],
          [ 61441.57,  66049.57,  58369.57, ...,  50689.57,  39937.57,
            41473.57],
          [ 75265.57,  79489.57,  65281.57, ...,  60289.57,  48769.57,
            45697.57],
          ...,
          [153601.58, 160129.58, 159361.58, ..., 128257.57, 132481.58,
           125953.57],
          [159745.58, 159361.58, 153985.58, ..., 175873.58, 175489.58,
           168193.58],
          [100993.57, 100993.57,  98305.57, ..., 120194.57, 119425.57,
           112513.57]],

         ...,

         [[ 46849.57,  56449.57,  66817.57, ...,  66433.57,  48001.57,
            48769.57],
          [ 61441.57,  66049.57,  58369.57, ...,  50689.57,  39937.57,
            41473.57],
          [ 75265.57,  79489.57,  65281.57, ...,  60289.57,  48769.57,
            45697.57],
          ...,
          [153601.58, 160129.58, 159361.58, ..., 128257.57, 132481.58,
           125953.57],
          [159745.58, 159361.58, 153985.58, ..., 175873.58, 175489.58,
           168193.58],
          [100993.57, 100993.57,  98305.57, ..., 120194.57, 119425.57,
           112513.57]],

         [[ 46849.57,  56449.57,  66817.57, ...,  66433.57,  48001.57,
            48769.57],
          [ 61441.57,  66049.57,  58369.57, ...,  50689.57,  39937.57,
            41473.57],
          [ 75265.57,  79489.57,  65281.57, ...,  60289.57,  48769.57,
            45697.57],
          ...,
          [153601.58, 160129.58, 159361.58, ..., 128257.57, 132481.58,
           125953.57],
          [159745.58, 159361.58, 153985.58, ..., 175873.58, 175489.58,
           168193.58],
          [100993.57, 100993.57,  98305.57, ..., 120194.57, 119425.57,
           112513.57]],

         [[ 46849.57,  56449.57,  66817.57, ...,  66433.57,  48001.57,
            48769.57],
          [ 61441.57,  66049.57,  58369.57, ...,  50689.57,  39937.57,
            41473.57],
          [ 75265.57,  79489.57,  65281.57, ...,  60289.57,  48769.57,
            45697.57],
          ...,
          [153601.58, 160129.58, 159361.58, ..., 128257.57, 132481.58,
           125953.57],
          [159745.58, 159361.58, 153985.58, ..., 175873.58, 175489.58,
           168193.58],
          [100993.57, 100993.57,  98305.57, ..., 120194.57, 119425.57,
           112513.57]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:47

analyse output arrays in iter:74

pre layer res:
7:add
{'name': 'add', 'output': array([[[[24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         ...,
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014]],

        [[24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         ...,
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014]],

        [[24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         ...,
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014]],

        ...,

        [[24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         ...,
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014]],

        [[24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         ...,
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014]],

        [[24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         ...,
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014],
         [24.371014, 24.371014, 24.371014, ..., 24.371014, 24.371014,
          24.371014]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [6, 6], 'to': [4, 15]}
tf node:
{'name': 'sin', 'output': array([[[[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        ...,

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [7], 'to': [9]}
ms node:
{'name': 'sin', 'output': array([[[[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        [[-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         ...,
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726],
         [-0.6901726, -0.6901726, -0.6901726, ..., -0.6901726,
          -0.6901726, -0.6901726]],

        ...,

        [[12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         ...,
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ]],

        [[12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         ...,
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ]],

        [[12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         ...,
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ],
         [12.185507 , 12.185507 , 12.185507 , ..., 12.185507 ,
          12.185507 , 12.185507 ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [7], 'to': [9]}
torch node:
{'name': 'sin', 'output': array([[[[-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         ...,
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124]],

        [[-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         ...,
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124]],

        [[-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         ...,
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124]],

        ...,

        [[-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         ...,
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124]],

        [[-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         ...,
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124]],

        [[-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         ...,
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124],
         [-0.69017124, -0.69017124, -0.69017124, ..., -0.69017124,
          -0.69017124, -0.69017124]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [7], 'to': [9]}

generate models:48

analyse the exceptions in iter:78
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[169472., 139776., 154624., ..., 294912., 271872., 208896.],
          [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
          [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
          ...,
          [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
          [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
          [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

         [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
          [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
          [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
          ...,
          [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
          [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
          [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

         [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
          [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
          [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
          ...,
          [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
          [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
          [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

         ...,

         [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
          [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
          [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
          ...,
          [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
          [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
          [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

         [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
          [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
          [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
          ...,
          [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
          [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
          [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

         [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
          [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
          [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
          ...,
          [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
          [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
          [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]]]]],
      dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:51

analyse the exceptions in iter:79
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[380416.,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          ...,
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf]],

         [[   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          ...,
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf]],

         [[   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          ...,
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf]],

         ...,

         [[   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          ...,
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf]],

         [[   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          ...,
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf]],

         [[   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          ...,
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf],
          [   -inf,    -inf,    -inf, ...,    -inf,    -inf,    -inf]]]]],
      dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:52

analyse output arrays in iter:86

pre layer res:
2:sigmoid
{'name': 'sigmoid', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32, 32]), 'from': [0], 'to': [17]}
tf node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': TensorShape([1, 128, 32, 32]), 'from': [2], 'to': [1]}
ms node:
{'name': 'sin', 'output': array([[[[  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         ...,
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096]],

        [[  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         ...,
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096]],

        [[  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         ...,
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096]],

        ...,

        [[296.        , 185.        ,  82.        , ..., 265.        ,
          197.        , 199.        ],
         [299.        , 175.        ,  88.        , ..., 272.        ,
          229.        , 257.        ],
         [294.        , 187.        , 129.        , ..., 250.        ,
          241.        , 263.        ],
         ...,
         [439.        , 459.        , 468.        , ..., 420.        ,
          423.        , 421.        ],
         [433.        , 440.        , 444.        , ..., 446.        ,
          432.        , 428.        ],
         [418.        , 414.        , 403.        , ..., 438.        ,
          438.        , 437.        ]],

        [[296.        , 185.        ,  82.        , ..., 265.        ,
          197.        , 199.        ],
         [299.        , 175.        ,  88.        , ..., 272.        ,
          229.        , 257.        ],
         [294.        , 187.        , 129.        , ..., 250.        ,
          241.        , 263.        ],
         ...,
         [439.        , 459.        , 468.        , ..., 420.        ,
          423.        , 421.        ],
         [433.        , 440.        , 444.        , ..., 446.        ,
          432.        , 428.        ],
         [418.        , 414.        , 403.        , ..., 438.        ,
          438.        , 437.        ]],

        [[296.        , 185.        ,  82.        , ..., 265.        ,
          197.        , 199.        ],
         [299.        , 175.        ,  88.        , ..., 272.        ,
          229.        , 257.        ],
         [294.        , 187.        , 129.        , ..., 250.        ,
          241.        , 263.        ],
         ...,
         [439.        , 459.        , 468.        , ..., 420.        ,
          423.        , 421.        ],
         [433.        , 440.        , 444.        , ..., 446.        ,
          432.        , 428.        ],
         [418.        , 414.        , 403.        , ..., 438.        ,
          438.        , 437.        ]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [2], 'to': [1]}
torch node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [2], 'to': [1]}

generate models:54

analyse the exceptions in iter:87
tensorflow exception:
{'id': 16, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[2.7723733e+11, 3.4140332e+07, 3.4734380e+07, ...,
           3.6411688e+07, 4.1653284e+07, 4.2736548e+07],
          [3.8019112e+07, 3.4629548e+07, 3.7005736e+07, ...,
           3.6865960e+07, 4.5112736e+07, 4.5042848e+07],
          [3.8473384e+07, 3.6236968e+07, 3.8089000e+07, ...,
           3.4699436e+07, 4.7104544e+07, 4.6265888e+07],
          ...,
          [3.8543268e+07, 4.0220580e+07, 4.7244320e+07, ...,
           4.0185636e+07, 4.3505312e+07, 4.8642076e+07],
          [3.9871140e+07, 4.1513508e+07, 4.6440608e+07, ...,
           4.3505312e+07, 4.8013088e+07, 5.1472540e+07],
          [4.2142496e+07, 4.4274080e+07, 4.4448800e+07, ...,
           4.7244320e+07, 5.3289628e+07, 5.4337948e+07]],

         [[3.5083816e+07, 3.4140332e+07, 3.4734380e+07, ...,
           3.6411688e+07, 4.1653284e+07, 4.2736548e+07],
          [3.8019112e+07, 3.4629548e+07, 3.7005736e+07, ...,
           3.6865960e+07, 4.5112736e+07, 4.5042848e+07],
          [3.8473384e+07, 3.6236968e+07, 3.8089000e+07, ...,
           3.4699436e+07, 4.7104544e+07, 4.6265888e+07],
          ...,
          [3.8543268e+07, 4.0220580e+07, 4.7244320e+07, ...,
           4.0185636e+07, 4.3505312e+07, 4.8642076e+07],
          [3.9871140e+07, 4.1513508e+07, 4.6440608e+07, ...,
           4.3505312e+07, 4.8013088e+07, 5.1472540e+07],
          [4.2142496e+07, 4.4274080e+07, 4.4448800e+07, ...,
           4.7244320e+07, 5.3289628e+07, 5.4337948e+07]],

         [[3.5083816e+07, 3.4140332e+07, 3.4734380e+07, ...,
           3.6411688e+07, 4.1653284e+07, 4.2736548e+07],
          [3.8019112e+07, 3.4629548e+07, 3.7005736e+07, ...,
           3.6865960e+07, 4.5112736e+07, 4.5042848e+07],
          [3.8473384e+07, 3.6236968e+07, 3.8089000e+07, ...,
           3.4699436e+07, 4.7104544e+07, 4.6265888e+07],
          ...,
          [3.8543268e+07, 4.0220580e+07, 4.7244320e+07, ...,
           4.0185636e+07, 4.3505312e+07, 4.8642076e+07],
          [3.9871140e+07, 4.1513508e+07, 4.6440608e+07, ...,
           4.3505312e+07, 4.8013088e+07, 5.1472540e+07],
          [4.2142496e+07, 4.4274080e+07, 4.4448800e+07, ...,
           4.7244320e+07, 5.3289628e+07, 5.4337948e+07]],

         ...,

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:55

analyse output arrays in iter:89

pre layer res:
6:add
{'name': 'add', 'output': array([[[[117175.914, 110467.67 , 111757.72 , ..., 106339.52 ,
           91890.94 ,  86214.69 ],
         [137558.55 , 135494.5  , 132914.42 , ..., 131108.36 ,
          120014.01 , 124400.15 ],
         [140912.66 , 137300.55 , 140396.64 , ..., 144266.75 ,
          144782.77 , 147620.83 ],
         ...,
         [ 77184.24 ,  74862.12 ,  72281.98 , ...,  74088.08 ,
           71507.94 ,  71507.94 ],
         [ 79506.36 ,  73572.05 ,  73572.05 , ...,  74862.12 ,
           72798.01 ,  73314.03 ],
         [ 79248.34 ,  73830.06 ,  73572.05 , ...,  75636.16 ,
           73056.02 ,  74604.1  ]],

        [[117175.914, 110467.67 , 111757.72 , ..., 106339.52 ,
           91890.94 ,  86214.69 ],
         [137558.55 , 135494.5  , 132914.42 , ..., 131108.36 ,
          120014.01 , 124400.15 ],
         [140912.66 , 137300.55 , 140396.64 , ..., 144266.75 ,
          144782.77 , 147620.83 ],
         ...,
         [ 77184.24 ,  74862.12 ,  72281.98 , ...,  74088.08 ,
           71507.94 ,  71507.94 ],
         [ 79506.36 ,  73572.05 ,  73572.05 , ...,  74862.12 ,
           72798.01 ,  73314.03 ],
         [ 79248.34 ,  73830.06 ,  73572.05 , ...,  75636.16 ,
           73056.02 ,  74604.1  ]],

        [[117175.914, 110467.67 , 111757.72 , ..., 106339.52 ,
           91890.94 ,  86214.69 ],
         [137558.55 , 135494.5  , 132914.42 , ..., 131108.36 ,
          120014.01 , 124400.15 ],
         [140912.66 , 137300.55 , 140396.64 , ..., 144266.75 ,
          144782.77 , 147620.83 ],
         ...,
         [ 77184.24 ,  74862.12 ,  72281.98 , ...,  74088.08 ,
           71507.94 ,  71507.94 ],
         [ 79506.36 ,  73572.05 ,  73572.05 , ...,  74862.12 ,
           72798.01 ,  73314.03 ],
         [ 79248.34 ,  73830.06 ,  73572.05 , ...,  75636.16 ,
           73056.02 ,  74604.1  ]],

        ...,

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [3, 3], 'to': [8, 15]}
15:square
{'name': 'square', 'output': array([[[[1.3730194e+10, 1.2203106e+10, 1.2489787e+10, ...,
          1.1308094e+10, 8.4439444e+09, 7.4329723e+09],
         [1.8922355e+10, 1.8358759e+10, 1.7666243e+10, ...,
          1.7189403e+10, 1.4403362e+10, 1.5475397e+10],
         [1.9856376e+10, 1.8851441e+10, 1.9711218e+10, ...,
          2.0812894e+10, 2.0962050e+10, 2.1791910e+10],
         ...,
         [5.9574072e+09, 5.6043366e+09, 5.2246840e+09, ...,
          5.4890435e+09, 5.1133850e+09, 5.1133850e+09],
         [6.3212611e+09, 5.4128461e+09, 5.4128461e+09, ...,
          5.6043366e+09, 5.2995497e+09, 5.3749473e+09],
         [6.2803000e+09, 5.4508780e+09, 5.4128461e+09, ...,
          5.7208279e+09, 5.3371827e+09, 5.5657718e+09]],

        [[1.3730194e+10, 1.2203106e+10, 1.2489787e+10, ...,
          1.1308094e+10, 8.4439444e+09, 7.4329723e+09],
         [1.8922355e+10, 1.8358759e+10, 1.7666243e+10, ...,
          1.7189403e+10, 1.4403362e+10, 1.5475397e+10],
         [1.9856376e+10, 1.8851441e+10, 1.9711218e+10, ...,
          2.0812894e+10, 2.0962050e+10, 2.1791910e+10],
         ...,
         [5.9574072e+09, 5.6043366e+09, 5.2246840e+09, ...,
          5.4890435e+09, 5.1133850e+09, 5.1133850e+09],
         [6.3212611e+09, 5.4128461e+09, 5.4128461e+09, ...,
          5.6043366e+09, 5.2995497e+09, 5.3749473e+09],
         [6.2803000e+09, 5.4508780e+09, 5.4128461e+09, ...,
          5.7208279e+09, 5.3371827e+09, 5.5657718e+09]],

        [[1.3730194e+10, 1.2203106e+10, 1.2489787e+10, ...,
          1.1308094e+10, 8.4439444e+09, 7.4329723e+09],
         [1.8922355e+10, 1.8358759e+10, 1.7666243e+10, ...,
          1.7189403e+10, 1.4403362e+10, 1.5475397e+10],
         [1.9856376e+10, 1.8851441e+10, 1.9711218e+10, ...,
          2.0812894e+10, 2.0962050e+10, 2.1791910e+10],
         ...,
         [5.9574072e+09, 5.6043366e+09, 5.2246840e+09, ...,
          5.4890435e+09, 5.1133850e+09, 5.1133850e+09],
         [6.3212611e+09, 5.4128461e+09, 5.4128461e+09, ...,
          5.6043366e+09, 5.2995497e+09, 5.3749473e+09],
         [6.2803000e+09, 5.4508780e+09, 5.4128461e+09, ...,
          5.7208279e+09, 5.3371827e+09, 5.5657718e+09]],

        ...,

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [6], 'to': [8]}
tf node:
{'name': 'add', 'output': array([[[[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        [[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        [[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        ...,

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]],

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]],

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [6, 15], 'to': [9, 9]}
ms node:
{'name': 'add', 'output': array([[[[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        [[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        [[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        ...,

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]],

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]],

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [6, 15], 'to': [9, 9]}
torch node:
{'name': 'add', 'output': array([[[[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        [[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        [[1.3730311e+10, 1.2203217e+10, 1.2489899e+10, ...,
          1.1308201e+10, 8.4440361e+09, 7.4330583e+09],
         [1.8922492e+10, 1.8358895e+10, 1.7666376e+10, ...,
          1.7189534e+10, 1.4403482e+10, 1.5475521e+10],
         [1.9856517e+10, 1.8851578e+10, 1.9711359e+10, ...,
          2.0813038e+10, 2.0962195e+10, 2.1792057e+10],
         ...,
         [5.9574845e+09, 5.6044114e+09, 5.2247562e+09, ...,
          5.4891177e+09, 5.1134566e+09, 5.1134566e+09],
         [6.3213404e+09, 5.4129198e+09, 5.4129198e+09, ...,
          5.6044114e+09, 5.2996224e+09, 5.3750205e+09],
         [6.2803794e+09, 5.4509517e+09, 5.4129198e+09, ...,
          5.7209037e+09, 5.3372559e+09, 5.5658465e+09]],

        ...,

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]],

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]],

        [[          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         ...,
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan],
         [          nan,           nan,           nan, ...,
                    nan,           nan,           nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [6, 15], 'to': [9, 9]}

generate models:56

final statics:
total operators:28
tensorflow --> nums:14,distinct_bugs:6
mindspore --> nums:8,distinct_bugs:5
torch --> nums:3,distinct_bugs:3
tensorflow --> 
sin:1
cos:1
avgpool2d:7
log:1
maxpool2d:3
add:1
mindspore --> 
cos:1
empty_merge_operator:1
log:1
sin:4
add:1
torch --> 
cos:1
log:1
add:1

generate models:64

analyse output arrays in iter:110

pre layer res:
9:add
{'name': 'add', 'output': array([[[[341104., 343448., 320896., ..., 293888., 293272., 294184.],
         [346992., 347544., 324992., ..., 295168., 298136., 296744.],
         [326256., 324760., 300928., ..., 282880., 286616., 284456.],
         ...,
         [284016., 285592., 261760., ..., 231168., 232088., 229416.],
         [285552., 287896., 266368., ..., 232704., 233624., 230952.],
         [283248., 287896., 265600., ..., 228864., 231576., 228904.]],

        [[341104., 343448., 320896., ..., 293888., 293272., 294184.],
         [346992., 347544., 324992., ..., 295168., 298136., 296744.],
         [326256., 324760., 300928., ..., 282880., 286616., 284456.],
         ...,
         [284016., 285592., 261760., ..., 231168., 232088., 229416.],
         [285552., 287896., 266368., ..., 232704., 233624., 230952.],
         [283248., 287896., 265600., ..., 228864., 231576., 228904.]],

        [[341104., 343448., 320896., ..., 293888., 293272., 294184.],
         [346992., 347544., 324992., ..., 295168., 298136., 296744.],
         [326256., 324760., 300928., ..., 282880., 286616., 284456.],
         ...,
         [284016., 285592., 261760., ..., 231168., 232088., 229416.],
         [285552., 287896., 266368., ..., 232704., 233624., 230952.],
         [283248., 287896., 265600., ..., 228864., 231576., 228904.]],

        ...,

        [[167680., 166912., 168960., ..., 178432., 176128., 179200.],
         [173568., 171008., 173056., ..., 179712., 180992., 181760.],
         [152832., 148224., 148992., ..., 167424., 169472., 169472.],
         ...,
         [110592., 109056., 109824., ..., 115712., 114944., 114432.],
         [112128., 111360., 114432., ..., 117248., 116480., 115968.],
         [109824., 111360., 113664., ..., 113408., 114432., 113920.]],

        [[167680., 166912., 168960., ..., 178432., 176128., 179200.],
         [173568., 171008., 173056., ..., 179712., 180992., 181760.],
         [152832., 148224., 148992., ..., 167424., 169472., 169472.],
         ...,
         [110592., 109056., 109824., ..., 115712., 114944., 114432.],
         [112128., 111360., 114432., ..., 117248., 116480., 115968.],
         [109824., 111360., 113664., ..., 113408., 114432., 113920.]],

        [[167680., 166912., 168960., ..., 178432., 176128., 179200.],
         [173568., 171008., 173056., ..., 179712., 180992., 181760.],
         [152832., 148224., 148992., ..., 167424., 169472., 169472.],
         ...,
         [110592., 109056., 109824., ..., 115712., 114944., 114432.],
         [112128., 111360., 114432., ..., 117248., 116480., 115968.],
         [109824., 111360., 113664., ..., 113408., 114432., 113920.]]]],
      dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [8, 15], 'to': [16]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.64845175,  0.3275113 ,  0.9167998 , ..., -0.99038804,
          -0.92619574, -0.8517244 ],
         [ 0.05016059,  0.8251619 ,  0.49962986, ...,  0.33138207,
          -0.9098098 ,  0.9882395 ],
         [ 0.99948394,  0.8420259 ,  0.90135926, ..., -0.9999982 ,
           0.7971529 , -0.47342995],
         ...,
         [-0.31091177,  0.6913529 ,  0.5983897 , ..., -0.18666944,
          -0.2944468 , -0.9307548 ],
         [ 0.07726752,  0.43426758, -0.9774257 , ..., -0.05101455,
           0.5121483 ,  0.81784964],
         [ 0.9066356 ,  0.43426758, -0.3262063 , ..., -0.8546176 ,
           0.21752112,  0.9568829 ]],

        [[ 0.64845175,  0.3275113 ,  0.9167998 , ..., -0.99038804,
          -0.92619574, -0.8517244 ],
         [ 0.05016059,  0.8251619 ,  0.49962986, ...,  0.33138207,
          -0.9098098 ,  0.9882395 ],
         [ 0.99948394,  0.8420259 ,  0.90135926, ..., -0.9999982 ,
           0.7971529 , -0.47342995],
         ...,
         [-0.31091177,  0.6913529 ,  0.5983897 , ..., -0.18666944,
          -0.2944468 , -0.9307548 ],
         [ 0.07726752,  0.43426758, -0.9774257 , ..., -0.05101455,
           0.5121483 ,  0.81784964],
         [ 0.9066356 ,  0.43426758, -0.3262063 , ..., -0.8546176 ,
           0.21752112,  0.9568829 ]],

        [[ 0.64845175,  0.3275113 ,  0.9167998 , ..., -0.99038804,
          -0.92619574, -0.8517244 ],
         [ 0.05016059,  0.8251619 ,  0.49962986, ...,  0.33138207,
          -0.9098098 ,  0.9882395 ],
         [ 0.99948394,  0.8420259 ,  0.90135926, ..., -0.9999982 ,
           0.7971529 , -0.47342995],
         ...,
         [-0.31091177,  0.6913529 ,  0.5983897 , ..., -0.18666944,
          -0.2944468 , -0.9307548 ],
         [ 0.07726752,  0.43426758, -0.9774257 , ..., -0.05101455,
           0.5121483 ,  0.81784964],
         [ 0.9066356 ,  0.43426758, -0.3262063 , ..., -0.8546176 ,
           0.21752112,  0.9568829 ]],

        ...,

        [[ 0.59213626, -0.72956467, -0.906996  , ...,  0.8613626 ,
          -0.77773964, -0.40176788],
         [ 0.96057814, -0.99324584, -0.97964334, ...,  0.32767725,
          -0.99092317,  0.0154333 ],
         [-0.19809286, -0.494284  , -0.92199016, ...,  0.781638  ,
           0.9376123 ,  0.9376123 ],
         ...,
         [ 0.9964225 , -0.9481542 ,  0.20260347, ...,  0.75743985,
          -0.5580297 ,  0.49027652],
         [-0.9881354 ,  0.03478478,  0.49027652, ..., -0.58150333,
           0.7384826 , -0.68252695],
         [ 0.20260347,  0.03478478,  0.9237631 , ...,  0.34590384,
           0.49027652, -0.41941833]],

        [[ 0.59213626, -0.72956467, -0.906996  , ...,  0.8613626 ,
          -0.77773964, -0.40176788],
         [ 0.96057814, -0.99324584, -0.97964334, ...,  0.32767725,
          -0.99092317,  0.0154333 ],
         [-0.19809286, -0.494284  , -0.92199016, ...,  0.781638  ,
           0.9376123 ,  0.9376123 ],
         ...,
         [ 0.9964225 , -0.9481542 ,  0.20260347, ...,  0.75743985,
          -0.5580297 ,  0.49027652],
         [-0.9881354 ,  0.03478478,  0.49027652, ..., -0.58150333,
           0.7384826 , -0.68252695],
         [ 0.20260347,  0.03478478,  0.9237631 , ...,  0.34590384,
           0.49027652, -0.41941833]],

        [[ 0.59213626, -0.72956467, -0.906996  , ...,  0.8613626 ,
          -0.77773964, -0.40176788],
         [ 0.96057814, -0.99324584, -0.97964334, ...,  0.32767725,
          -0.99092317,  0.0154333 ],
         [-0.19809286, -0.494284  , -0.92199016, ...,  0.781638  ,
           0.9376123 ,  0.9376123 ],
         ...,
         [ 0.9964225 , -0.9481542 ,  0.20260347, ...,  0.75743985,
          -0.5580297 ,  0.49027652],
         [-0.9881354 ,  0.03478478,  0.49027652, ..., -0.58150333,
           0.7384826 , -0.68252695],
         [ 0.20260347,  0.03478478,  0.9237631 , ...,  0.34590384,
           0.49027652, -0.41941833]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [9], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[ 6.4845175e-01,  3.2751131e-01,  9.1679978e-01, ...,
          -9.9038804e-01, -9.2619574e-01, -8.5172439e-01],
         [ 5.0160587e-02,  8.2516187e-01,  4.9962988e-01, ...,
           3.3138207e-01, -9.0980983e-01,  9.8823953e-01],
         [ 9.9948394e-01,  8.4202588e-01,  9.0135926e-01, ...,
          -9.9999821e-01,  7.9715288e-01, -4.7342995e-01],
         ...,
         [-3.1091177e-01,  6.9135290e-01,  5.9838969e-01, ...,
          -1.8666944e-01, -2.9444680e-01, -9.3075472e-01],
         [ 7.7267520e-02,  4.3426758e-01, -9.7742569e-01, ...,
          -5.1014550e-02,  5.1214832e-01,  8.1784958e-01],
         [ 9.0663558e-01,  4.3426758e-01, -3.2620630e-01, ...,
          -8.5461766e-01,  2.1752113e-01,  9.5688289e-01]],

        [[ 6.4845175e-01,  3.2751131e-01,  9.1679978e-01, ...,
          -9.9038804e-01, -9.2619574e-01, -8.5172439e-01],
         [ 5.0160587e-02,  8.2516187e-01,  4.9962988e-01, ...,
           3.3138207e-01, -9.0980983e-01,  9.8823953e-01],
         [ 9.9948394e-01,  8.4202588e-01,  9.0135926e-01, ...,
          -9.9999821e-01,  7.9715288e-01, -4.7342995e-01],
         ...,
         [-3.1091177e-01,  6.9135290e-01,  5.9838969e-01, ...,
          -1.8666944e-01, -2.9444680e-01, -9.3075472e-01],
         [ 7.7267520e-02,  4.3426758e-01, -9.7742569e-01, ...,
          -5.1014550e-02,  5.1214832e-01,  8.1784958e-01],
         [ 9.0663558e-01,  4.3426758e-01, -3.2620630e-01, ...,
          -8.5461766e-01,  2.1752113e-01,  9.5688289e-01]],

        [[ 6.4845175e-01,  3.2751131e-01,  9.1679978e-01, ...,
          -9.9038804e-01, -9.2619574e-01, -8.5172439e-01],
         [ 5.0160587e-02,  8.2516187e-01,  4.9962988e-01, ...,
           3.3138207e-01, -9.0980983e-01,  9.8823953e-01],
         [ 9.9948394e-01,  8.4202588e-01,  9.0135926e-01, ...,
          -9.9999821e-01,  7.9715288e-01, -4.7342995e-01],
         ...,
         [-3.1091177e-01,  6.9135290e-01,  5.9838969e-01, ...,
          -1.8666944e-01, -2.9444680e-01, -9.3075472e-01],
         [ 7.7267520e-02,  4.3426758e-01, -9.7742569e-01, ...,
          -5.1014550e-02,  5.1214832e-01,  8.1784958e-01],
         [ 9.0663558e-01,  4.3426758e-01, -3.2620630e-01, ...,
          -8.5461766e-01,  2.1752113e-01,  9.5688289e-01]],

        ...,

        [[ 1.6768000e+05,  1.6691200e+05,  1.6896000e+05, ...,
           1.7843200e+05,  1.7612800e+05,  1.7920000e+05],
         [ 1.7356800e+05,  1.7100800e+05,  1.7305600e+05, ...,
           1.7971200e+05,  1.8099200e+05,  1.8176000e+05],
         [ 1.5283200e+05,  1.4822400e+05,  1.4899200e+05, ...,
           1.6742400e+05,  1.6947200e+05,  1.6947200e+05],
         ...,
         [ 1.1059200e+05,  1.0905600e+05,  1.0982400e+05, ...,
           1.1571200e+05,  1.1494400e+05,  1.1443200e+05],
         [ 1.1212800e+05,  1.1136000e+05,  1.1443200e+05, ...,
           1.1724800e+05,  1.1648000e+05,  1.1596800e+05],
         [ 1.0982400e+05,  1.1136000e+05,  1.1366400e+05, ...,
           1.1340800e+05,  1.1443200e+05,  1.1392000e+05]],

        [[ 1.6768000e+05,  1.6691200e+05,  1.6896000e+05, ...,
           1.7843200e+05,  1.7612800e+05,  1.7920000e+05],
         [ 1.7356800e+05,  1.7100800e+05,  1.7305600e+05, ...,
           1.7971200e+05,  1.8099200e+05,  1.8176000e+05],
         [ 1.5283200e+05,  1.4822400e+05,  1.4899200e+05, ...,
           1.6742400e+05,  1.6947200e+05,  1.6947200e+05],
         ...,
         [ 1.1059200e+05,  1.0905600e+05,  1.0982400e+05, ...,
           1.1571200e+05,  1.1494400e+05,  1.1443200e+05],
         [ 1.1212800e+05,  1.1136000e+05,  1.1443200e+05, ...,
           1.1724800e+05,  1.1648000e+05,  1.1596800e+05],
         [ 1.0982400e+05,  1.1136000e+05,  1.1366400e+05, ...,
           1.1340800e+05,  1.1443200e+05,  1.1392000e+05]],

        [[ 1.6768000e+05,  1.6691200e+05,  1.6896000e+05, ...,
           1.7843200e+05,  1.7612800e+05,  1.7920000e+05],
         [ 1.7356800e+05,  1.7100800e+05,  1.7305600e+05, ...,
           1.7971200e+05,  1.8099200e+05,  1.8176000e+05],
         [ 1.5283200e+05,  1.4822400e+05,  1.4899200e+05, ...,
           1.6742400e+05,  1.6947200e+05,  1.6947200e+05],
         ...,
         [ 1.1059200e+05,  1.0905600e+05,  1.0982400e+05, ...,
           1.1571200e+05,  1.1494400e+05,  1.1443200e+05],
         [ 1.1212800e+05,  1.1136000e+05,  1.1443200e+05, ...,
           1.1724800e+05,  1.1648000e+05,  1.1596800e+05],
         [ 1.0982400e+05,  1.1136000e+05,  1.1366400e+05, ...,
           1.1340800e+05,  1.1443200e+05,  1.1392000e+05]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [9], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[ 0.64845175,  0.3275113 ,  0.9167998 , ..., -0.99038804,
          -0.92619574, -0.8517244 ],
         [ 0.05016059,  0.8251619 ,  0.49962988, ...,  0.33138207,
          -0.9098098 ,  0.9882395 ],
         [ 0.99948394,  0.8420259 ,  0.90135926, ..., -0.9999982 ,
           0.7971529 , -0.47342995],
         ...,
         [-0.31091177,  0.6913529 ,  0.5983897 , ..., -0.18666944,
          -0.2944468 , -0.9307547 ],
         [ 0.07726752,  0.43426758, -0.9774257 , ..., -0.05101455,
           0.5121483 ,  0.8178496 ],
         [ 0.9066356 ,  0.43426758, -0.3262063 , ..., -0.85461766,
           0.21752113,  0.9568829 ]],

        [[ 0.64845175,  0.3275113 ,  0.9167998 , ..., -0.99038804,
          -0.92619574, -0.8517244 ],
         [ 0.05016059,  0.8251619 ,  0.49962988, ...,  0.33138207,
          -0.9098098 ,  0.9882395 ],
         [ 0.99948394,  0.8420259 ,  0.90135926, ..., -0.9999982 ,
           0.7971529 , -0.47342995],
         ...,
         [-0.31091177,  0.6913529 ,  0.5983897 , ..., -0.18666944,
          -0.2944468 , -0.9307547 ],
         [ 0.07726752,  0.43426758, -0.9774257 , ..., -0.05101455,
           0.5121483 ,  0.8178496 ],
         [ 0.9066356 ,  0.43426758, -0.3262063 , ..., -0.85461766,
           0.21752113,  0.9568829 ]],

        [[ 0.64845175,  0.3275113 ,  0.9167998 , ..., -0.99038804,
          -0.92619574, -0.8517244 ],
         [ 0.05016059,  0.8251619 ,  0.49962988, ...,  0.33138207,
          -0.9098098 ,  0.9882395 ],
         [ 0.99948394,  0.8420259 ,  0.90135926, ..., -0.9999982 ,
           0.7971529 , -0.47342995],
         ...,
         [-0.31091177,  0.6913529 ,  0.5983897 , ..., -0.18666944,
          -0.2944468 , -0.9307547 ],
         [ 0.07726752,  0.43426758, -0.9774257 , ..., -0.05101455,
           0.5121483 ,  0.8178496 ],
         [ 0.9066356 ,  0.43426758, -0.3262063 , ..., -0.85461766,
           0.21752113,  0.9568829 ]],

        ...,

        [[ 0.5921363 , -0.72956467, -0.906996  , ...,  0.8613626 ,
          -0.77773964, -0.40176788],
         [ 0.96057814, -0.99324584, -0.97964334, ...,  0.32767725,
          -0.99092317,  0.0154333 ],
         [-0.19809286, -0.494284  , -0.92199016, ...,  0.7816381 ,
           0.9376123 ,  0.9376123 ],
         ...,
         [ 0.9964225 , -0.94815415,  0.20260347, ...,  0.75743985,
          -0.5580297 ,  0.49027655],
         [-0.9881354 ,  0.03478478,  0.49027655, ..., -0.58150333,
           0.7384826 , -0.682527  ],
         [ 0.20260347,  0.03478478,  0.9237631 , ...,  0.34590384,
           0.49027655, -0.41941833]],

        [[ 0.5921363 , -0.72956467, -0.906996  , ...,  0.8613626 ,
          -0.77773964, -0.40176788],
         [ 0.96057814, -0.99324584, -0.97964334, ...,  0.32767725,
          -0.99092317,  0.0154333 ],
         [-0.19809286, -0.494284  , -0.92199016, ...,  0.7816381 ,
           0.9376123 ,  0.9376123 ],
         ...,
         [ 0.9964225 , -0.94815415,  0.20260347, ...,  0.75743985,
          -0.5580297 ,  0.49027655],
         [-0.9881354 ,  0.03478478,  0.49027655, ..., -0.58150333,
           0.7384826 , -0.682527  ],
         [ 0.20260347,  0.03478478,  0.9237631 , ...,  0.34590384,
           0.49027655, -0.41941833]],

        [[ 0.5921363 , -0.72956467, -0.906996  , ...,  0.8613626 ,
          -0.77773964, -0.40176788],
         [ 0.96057814, -0.99324584, -0.97964334, ...,  0.32767725,
          -0.99092317,  0.0154333 ],
         [-0.19809286, -0.494284  , -0.92199016, ...,  0.7816381 ,
           0.9376123 ,  0.9376123 ],
         ...,
         [ 0.9964225 , -0.94815415,  0.20260347, ...,  0.75743985,
          -0.5580297 ,  0.49027655],
         [-0.9881354 ,  0.03478478,  0.49027655, ..., -0.58150333,
           0.7384826 , -0.682527  ],
         [ 0.20260347,  0.03478478,  0.9237631 , ...,  0.34590384,
           0.49027655, -0.41941833]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [9], 'to': []}

generate models:69

analyse the exceptions in iter:111
tensorflow exception:
{'id': 16, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[546053.5, 541445.5, 539141.5, ..., 514949.5, 505733.5,
           562181.5],
          [516101.5, 510341.5, 510341.5, ..., 482693.5, 488453.5,
           437765.5],
          [523013.5, 520709.5, 519557.5, ..., 490757.5, 493061.5,
           422789.5],
          ...,
          [328325.5, 306437.5, 313349.5, ..., 322565.5, 291461.5,
           326021.5],
          [344453.5, 285701.5, 296069.5, ..., 294917.5, 285701.5,
           290309.5],
          [548357.5, 476933.5, 484997.5, ..., 490757.5, 483845.5,
           481541.5]],

         [[546053.5, 541445.5, 539141.5, ..., 514949.5, 505733.5,
           562181.5],
          [516101.5, 510341.5, 510341.5, ..., 482693.5, 488453.5,
           437765.5],
          [523013.5, 520709.5, 519557.5, ..., 490757.5, 493061.5,
           422789.5],
          ...,
          [328325.5, 306437.5, 313349.5, ..., 322565.5, 291461.5,
           326021.5],
          [344453.5, 285701.5, 296069.5, ..., 294917.5, 285701.5,
           290309.5],
          [548357.5, 476933.5, 484997.5, ..., 490757.5, 483845.5,
           481541.5]],

         [[546053.5, 541445.5, 539141.5, ..., 514949.5, 505733.5,
           562181.5],
          [516101.5, 510341.5, 510341.5, ..., 482693.5, 488453.5,
           437765.5],
          [523013.5, 520709.5, 519557.5, ..., 490757.5, 493061.5,
           422789.5],
          ...,
          [328325.5, 306437.5, 313349.5, ..., 322565.5, 291461.5,
           326021.5],
          [344453.5, 285701.5, 296069.5, ..., 294917.5, 285701.5,
           290309.5],
          [548357.5, 476933.5, 484997.5, ..., 490757.5, 483845.5,
           481541.5]],

         ...,

         [[546048. , 541440. , 539136. , ..., 514944. , 505728. ,
           562176. ],
          [516096. , 510336. , 510336. , ..., 482688. , 488448. ,
           437760. ],
          [523008. , 520704. , 519552. , ..., 490752. , 493056. ,
           422784. ],
          ...,
          [328320. , 306432. , 313344. , ..., 322560. , 291456. ,
           326016. ],
          [344448. , 285696. , 296064. , ..., 294912. , 285696. ,
           290304. ],
          [548352. , 476928. , 484992. , ..., 490752. , 483840. ,
           481536. ]],

         [[546048. , 541440. , 539136. , ..., 514944. , 505728. ,
           562176. ],
          [516096. , 510336. , 510336. , ..., 482688. , 488448. ,
           437760. ],
          [523008. , 520704. , 519552. , ..., 490752. , 493056. ,
           422784. ],
          ...,
          [328320. , 306432. , 313344. , ..., 322560. , 291456. ,
           326016. ],
          [344448. , 285696. , 296064. , ..., 294912. , 285696. ,
           290304. ],
          [548352. , 476928. , 484992. , ..., 490752. , 483840. ,
           481536. ]],

         [[546048. , 541440. , 539136. , ..., 514944. , 505728. ,
           562176. ],
          [516096. , 510336. , 510336. , ..., 482688. , 488448. ,
           437760. ],
          [523008. , 520704. , 519552. , ..., 490752. , 493056. ,
           422784. ],
          ...,
          [328320. , 306432. , 313344. , ..., 322560. , 291456. ,
           326016. ],
          [344448. , 285696. , 296064. , ..., 294912. , 285696. ,
           290304. ],
          [548352. , 476928. , 484992. , ..., 490752. , 483840. ,
           481536. ]]]]], dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:70

analyse output arrays in iter:113

pre layer res:
4:empty_seq_operator
{'name': 'empty_seq_operator', 'output': array([[[[91648., 92416., 92288., ..., 93056., 92288., 92672.],
         [90880., 92928., 92672., ..., 72320., 89856., 91264.],
         [89344., 81024., 81408., ..., 31360., 75136., 96128.],
         ...,
         [55424., 55040., 53504., ..., 56832., 58240., 55424.],
         [51200., 51968., 49792., ..., 58240., 57984., 58112.],
         [28672., 29568., 29184., ..., 59264., 52608., 45184.]],

        [[91648., 92416., 92288., ..., 93056., 92288., 92672.],
         [90880., 92928., 92672., ..., 72320., 89856., 91264.],
         [89344., 81024., 81408., ..., 31360., 75136., 96128.],
         ...,
         [55424., 55040., 53504., ..., 56832., 58240., 55424.],
         [51200., 51968., 49792., ..., 58240., 57984., 58112.],
         [28672., 29568., 29184., ..., 59264., 52608., 45184.]],

        [[91648., 92416., 92288., ..., 93056., 92288., 92672.],
         [90880., 92928., 92672., ..., 72320., 89856., 91264.],
         [89344., 81024., 81408., ..., 31360., 75136., 96128.],
         ...,
         [55424., 55040., 53504., ..., 56832., 58240., 55424.],
         [51200., 51968., 49792., ..., 58240., 57984., 58112.],
         [28672., 29568., 29184., ..., 59264., 52608., 45184.]],

        ...,

        [[91648., 92416., 92288., ..., 93056., 92288., 92672.],
         [90880., 92928., 92672., ..., 72320., 89856., 91264.],
         [89344., 81024., 81408., ..., 31360., 75136., 96128.],
         ...,
         [55424., 55040., 53504., ..., 56832., 58240., 55424.],
         [51200., 51968., 49792., ..., 58240., 57984., 58112.],
         [28672., 29568., 29184., ..., 59264., 52608., 45184.]],

        [[91648., 92416., 92288., ..., 93056., 92288., 92672.],
         [90880., 92928., 92672., ..., 72320., 89856., 91264.],
         [89344., 81024., 81408., ..., 31360., 75136., 96128.],
         ...,
         [55424., 55040., 53504., ..., 56832., 58240., 55424.],
         [51200., 51968., 49792., ..., 58240., 57984., 58112.],
         [28672., 29568., 29184., ..., 59264., 52608., 45184.]],

        [[91648., 92416., 92288., ..., 93056., 92288., 92672.],
         [90880., 92928., 92672., ..., 72320., 89856., 91264.],
         [89344., 81024., 81408., ..., 31360., 75136., 96128.],
         ...,
         [55424., 55040., 53504., ..., 56832., 58240., 55424.],
         [51200., 51968., 49792., ..., 58240., 57984., 58112.],
         [28672., 29568., 29184., ..., 59264., 52608., 45184.]]]],
      dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [1], 'to': [5, 11]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.3057187 ,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.66940916],
         [-0.24403507,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.0224035 , -0.6467312 ,  0.44796088, ...,  0.5554438 ,
           0.9149515 ,  0.0224035 ],
         [-0.9943585 , -0.22376497, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.3057187 ,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.66940916],
         [-0.24403507,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.0224035 , -0.6467312 ,  0.44796088, ...,  0.5554438 ,
           0.9149515 ,  0.0224035 ],
         [-0.9943585 , -0.22376497, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.3057187 ,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.66940916],
         [-0.24403507,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.0224035 , -0.6467312 ,  0.44796088, ...,  0.5554438 ,
           0.9149515 ,  0.0224035 ],
         [-0.9943585 , -0.22376497, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        ...,

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.3057187 ,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.66940916],
         [-0.24403507,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.0224035 , -0.6467312 ,  0.44796088, ...,  0.5554438 ,
           0.9149515 ,  0.0224035 ],
         [-0.9943585 , -0.22376497, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.3057187 ,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.66940916],
         [-0.24403507,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.0224035 , -0.6467312 ,  0.44796088, ...,  0.5554438 ,
           0.9149515 ,  0.0224035 ],
         [-0.9943585 , -0.22376497, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.3057187 ,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.66940916],
         [-0.24403507,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.0224035 , -0.6467312 ,  0.44796088, ...,  0.5554438 ,
           0.9149515 ,  0.0224035 ],
         [-0.9943585 , -0.22376497, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [4], 'to': [3]}
ms node:
{'name': 'sin', 'output': array([[[[ 9.9376953e-01,  2.2903931e-01,  5.4317009e-01, ...,
           8.9834702e-01,  5.4317009e-01,  9.6353263e-01],
         [ 7.7168779e-03, -3.0571872e-01,  9.6353263e-01, ...,
           5.1165885e-01,  1.6614795e-01,  6.6940922e-01],
         [-2.4403508e-01,  7.2849929e-01,  9.0309262e-02, ...,
           5.8276892e-01,  9.9507374e-01,  9.9973983e-01],
         ...,
         [ 2.2403494e-02, -6.4673120e-01,  4.4796088e-01, ...,
           5.5544376e-01,  9.1495150e-01,  2.2403494e-02],
         [-9.9435848e-01, -2.2376496e-01, -7.8210282e-01, ...,
           9.1495150e-01,  3.6683756e-01, -9.2495078e-01],
         [ 9.6775228e-01, -6.2102956e-01, -9.8471880e-01, ...,
           8.3940238e-01, -8.9595509e-01,  9.9904704e-01]],

        [[ 9.9376953e-01,  2.2903931e-01,  5.4317009e-01, ...,
           8.9834702e-01,  5.4317009e-01,  9.6353263e-01],
         [ 7.7168779e-03, -3.0571872e-01,  9.6353263e-01, ...,
           5.1165885e-01,  1.6614795e-01,  6.6940922e-01],
         [-2.4403508e-01,  7.2849929e-01,  9.0309262e-02, ...,
           5.8276892e-01,  9.9507374e-01,  9.9973983e-01],
         ...,
         [ 2.2403494e-02, -6.4673120e-01,  4.4796088e-01, ...,
           5.5544376e-01,  9.1495150e-01,  2.2403494e-02],
         [-9.9435848e-01, -2.2376496e-01, -7.8210282e-01, ...,
           9.1495150e-01,  3.6683756e-01, -9.2495078e-01],
         [ 9.6775228e-01, -6.2102956e-01, -9.8471880e-01, ...,
           8.3940238e-01, -8.9595509e-01,  9.9904704e-01]],

        [[ 9.9376953e-01,  2.2903931e-01,  5.4317009e-01, ...,
           8.9834702e-01,  5.4317009e-01,  9.6353263e-01],
         [ 7.7168779e-03, -3.0571872e-01,  9.6353263e-01, ...,
           5.1165885e-01,  1.6614795e-01,  6.6940922e-01],
         [-2.4403508e-01,  7.2849929e-01,  9.0309262e-02, ...,
           5.8276892e-01,  9.9507374e-01,  9.9973983e-01],
         ...,
         [ 2.2403494e-02, -6.4673120e-01,  4.4796088e-01, ...,
           5.5544376e-01,  9.1495150e-01,  2.2403494e-02],
         [-9.9435848e-01, -2.2376496e-01, -7.8210282e-01, ...,
           9.1495150e-01,  3.6683756e-01, -9.2495078e-01],
         [ 9.6775228e-01, -6.2102956e-01, -9.8471880e-01, ...,
           8.3940238e-01, -8.9595509e-01,  9.9904704e-01]],

        ...,

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           1.7920000e+03,  1.2800000e+03,  7.6800000e+02],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           1.0240000e+03,  1.0240000e+03,  1.0240000e+03],
         [ 7.6800000e+02,  7.6800000e+02,  0.0000000e+00, ...,
           5.1200000e+02,  1.2800000e+03,  1.2800000e+03],
         ...,
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           5.6320000e+04,  6.3744000e+04,  2.6624000e+04],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           5.2992000e+04,  3.7376000e+04,  5.1200000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           4.5312000e+04,  2.8160000e+04,  1.7920000e+03]],

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           1.7920000e+03,  1.2800000e+03,  7.6800000e+02],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           1.0240000e+03,  1.0240000e+03,  1.0240000e+03],
         [ 7.6800000e+02,  7.6800000e+02,  0.0000000e+00, ...,
           5.1200000e+02,  1.2800000e+03,  1.2800000e+03],
         ...,
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           5.6320000e+04,  6.3744000e+04,  2.6624000e+04],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           5.2992000e+04,  3.7376000e+04,  5.1200000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           4.5312000e+04,  2.8160000e+04,  1.7920000e+03]],

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           1.7920000e+03,  1.2800000e+03,  7.6800000e+02],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           1.0240000e+03,  1.0240000e+03,  1.0240000e+03],
         [ 7.6800000e+02,  7.6800000e+02,  0.0000000e+00, ...,
           5.1200000e+02,  1.2800000e+03,  1.2800000e+03],
         ...,
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           5.6320000e+04,  6.3744000e+04,  2.6624000e+04],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           5.2992000e+04,  3.7376000e+04,  5.1200000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           4.5312000e+04,  2.8160000e+04,  1.7920000e+03]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [4], 'to': [3]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.30571872,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.6694092 ],
         [-0.24403508,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.02240349, -0.6467312 ,  0.44796088, ...,  0.55544376,
           0.9149515 ,  0.02240349],
         [-0.9943585 , -0.22376496, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.30571872,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.6694092 ],
         [-0.24403508,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.02240349, -0.6467312 ,  0.44796088, ...,  0.55544376,
           0.9149515 ,  0.02240349],
         [-0.9943585 , -0.22376496, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.30571872,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.6694092 ],
         [-0.24403508,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.02240349, -0.6467312 ,  0.44796088, ...,  0.55544376,
           0.9149515 ,  0.02240349],
         [-0.9943585 , -0.22376496, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        ...,

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.30571872,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.6694092 ],
         [-0.24403508,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.02240349, -0.6467312 ,  0.44796088, ...,  0.55544376,
           0.9149515 ,  0.02240349],
         [-0.9943585 , -0.22376496, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.30571872,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.6694092 ],
         [-0.24403508,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.02240349, -0.6467312 ,  0.44796088, ...,  0.55544376,
           0.9149515 ,  0.02240349],
         [-0.9943585 , -0.22376496, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]],

        [[ 0.9937695 ,  0.22903931,  0.5431701 , ...,  0.898347  ,
           0.5431701 ,  0.9635326 ],
         [ 0.00771688, -0.30571872,  0.9635326 , ...,  0.51165885,
           0.16614795,  0.6694092 ],
         [-0.24403508,  0.7284993 ,  0.09030926, ...,  0.5827689 ,
           0.99507374,  0.9997398 ],
         ...,
         [ 0.02240349, -0.6467312 ,  0.44796088, ...,  0.55544376,
           0.9149515 ,  0.02240349],
         [-0.9943585 , -0.22376496, -0.7821028 , ...,  0.9149515 ,
           0.36683756, -0.9249508 ],
         [ 0.9677523 , -0.62102956, -0.9847188 , ...,  0.8394024 ,
          -0.8959551 ,  0.99904704]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [4], 'to': [3]}

generate models:72

analyse the exceptions in iter:117
tensorflow exception:
{'id': 16, 'name': 'maxpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          ...,
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625]],

         [[4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          ...,
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625]],

         [[4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          ...,
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625]],

         ...,

         [[4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          ...,
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625]],

         [[4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          ...,
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625]],

         [[4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          ...,
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625],
          [4.0625, 4.0625, 4.0625, ..., 4.0625, 4.0625, 4.0625]]]]],
      dtype=float32)>}
Default MaxPoolingOp only supports NHWC on device type CPU [Op:MaxPool]

generate models:73

analyse output arrays in iter:125

pre layer res:
10:cos
{'name': 'cos', 'output': array([[[[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        ...,

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [5], 'to': [16]}
tf node:
{'name': 'sin', 'output': array([[[[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        ...,

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [10], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        ...,

        [[1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         ...,
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707952e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707953e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00]],

        [[1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         ...,
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707952e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707953e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00]],

        [[1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00],
         ...,
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707952e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707953e+00, 1.5707954e+00, 1.5707954e+00],
         [1.5707954e+00, 1.5707954e+00, 1.5707954e+00, ...,
          1.5707954e+00, 1.5707954e+00, 1.5707954e+00]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [10], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        ...,

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]],

        [[9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07],
         ...,
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.1483816e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          1.0291723e-06, 9.0996292e-07, 9.0996292e-07],
         [9.0996292e-07, 9.0996292e-07, 9.0996292e-07, ...,
          9.0996292e-07, 9.0996292e-07, 9.0996292e-07]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [10], 'to': []}

pre layer res:
3:add
{'name': 'add', 'output': array([[[[195840., 192512., 192768., ..., 193536., 192768., 195840.],
         [195840., 194048., 195840., ..., 195840., 195072., 195840.],
         [195840., 192256., 177152., ..., 195072., 195072., 195840.],
         ...,
         [195840., 195072., 195072., ..., 139776., 179200., 192000.],
         [195840., 195072., 195840., ..., 163584., 183296., 193024.],
         [195840., 192768., 193536., ..., 183040., 190208., 195072.]],

        [[195840., 192512., 192768., ..., 193536., 192768., 195840.],
         [195840., 194048., 195840., ..., 195840., 195072., 195840.],
         [195840., 192256., 177152., ..., 195072., 195072., 195840.],
         ...,
         [195840., 195072., 195072., ..., 139776., 179200., 192000.],
         [195840., 195072., 195840., ..., 163584., 183296., 193024.],
         [195840., 192768., 193536., ..., 183040., 190208., 195072.]],

        [[195840., 192512., 192768., ..., 193536., 192768., 195840.],
         [195840., 194048., 195840., ..., 195840., 195072., 195840.],
         [195840., 192256., 177152., ..., 195072., 195072., 195840.],
         ...,
         [195840., 195072., 195072., ..., 139776., 179200., 192000.],
         [195840., 195072., 195840., ..., 163584., 183296., 193024.],
         [195840., 192768., 193536., ..., 183040., 190208., 195072.]],

        ...,

        [[195840., 192512., 192768., ..., 193536., 192768., 195840.],
         [195840., 194048., 195840., ..., 195840., 195072., 195840.],
         [195840., 192256., 177152., ..., 195072., 195072., 195840.],
         ...,
         [195840., 195072., 195072., ..., 139776., 179200., 192000.],
         [195840., 195072., 195840., ..., 163584., 183296., 193024.],
         [195840., 192768., 193536., ..., 183040., 190208., 195072.]],

        [[195840., 192512., 192768., ..., 193536., 192768., 195840.],
         [195840., 194048., 195840., ..., 195840., 195072., 195840.],
         [195840., 192256., 177152., ..., 195072., 195072., 195840.],
         ...,
         [195840., 195072., 195072., ..., 139776., 179200., 192000.],
         [195840., 195072., 195840., ..., 163584., 183296., 193024.],
         [195840., 192768., 193536., ..., 183040., 190208., 195072.]],

        [[195840., 192512., 192768., ..., 193536., 192768., 195840.],
         [195840., 194048., 195840., ..., 195840., 195072., 195840.],
         [195840., 192256., 177152., ..., 195072., 195072., 195840.],
         ...,
         [195840., 195072., 195072., ..., 139776., 179200., 192000.],
         [195840., 195072., 195840., ..., 163584., 183296., 193024.],
         [195840., 192768., 193536., ..., 183040., 190208., 195072.]]]],
      dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [1, 1], 'to': [6, 2]}
tf node:
{'name': 'sin', 'output': array([[[[-0.5669837 ,  0.9963537 , -0.12489724, ...,  0.9702275 ,
          -0.12489724, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489724,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489724, ...,  0.9702275 ,
          -0.12489724, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489724,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489724, ...,  0.9702275 ,
          -0.12489724, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489724,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        ...,

        [[-0.5669837 ,  0.9963537 , -0.12489724, ...,  0.9702275 ,
          -0.12489724, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489724,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489724, ...,  0.9702275 ,
          -0.12489724, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489724,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489724, ...,  0.9702275 ,
          -0.12489724, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489724,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [3], 'to': [11, 12]}
ms node:
{'name': 'sin', 'output': array([[[[-5.6698370e-01,  9.9635369e-01, -1.2489725e-01, ...,
           9.7022748e-01, -1.2489725e-01, -5.6698370e-01],
         [-5.6698370e-01, -9.4789612e-01, -5.6698370e-01, ...,
          -5.6698370e-01, -8.8540316e-01, -5.6698370e-01],
         [-5.6698370e-01,  4.5605909e-02, -6.6825205e-01, ...,
          -8.8540316e-01, -8.8540316e-01, -5.6698370e-01],
         ...,
         [-5.6698370e-01, -8.8540316e-01, -8.8540316e-01, ...,
           2.5674856e-01, -4.0176788e-01, -9.9998307e-01],
         [-5.6698370e-01, -8.8540316e-01, -5.6698370e-01, ...,
           9.5525706e-01,  2.2152075e-01, -9.8641413e-01],
         [-5.6698370e-01, -1.2489725e-01,  9.7022748e-01, ...,
          -9.8319787e-01, -2.6941779e-01, -8.8540316e-01]],

        [[-5.6698370e-01,  9.9635369e-01, -1.2489725e-01, ...,
           9.7022748e-01, -1.2489725e-01, -5.6698370e-01],
         [-5.6698370e-01, -9.4789612e-01, -5.6698370e-01, ...,
          -5.6698370e-01, -8.8540316e-01, -5.6698370e-01],
         [-5.6698370e-01,  4.5605909e-02, -6.6825205e-01, ...,
          -8.8540316e-01, -8.8540316e-01, -5.6698370e-01],
         ...,
         [-5.6698370e-01, -8.8540316e-01, -8.8540316e-01, ...,
           2.5674856e-01, -4.0176788e-01, -9.9998307e-01],
         [-5.6698370e-01, -8.8540316e-01, -5.6698370e-01, ...,
           9.5525706e-01,  2.2152075e-01, -9.8641413e-01],
         [-5.6698370e-01, -1.2489725e-01,  9.7022748e-01, ...,
          -9.8319787e-01, -2.6941779e-01, -8.8540316e-01]],

        [[-5.6698370e-01,  9.9635369e-01, -1.2489725e-01, ...,
           9.7022748e-01, -1.2489725e-01, -5.6698370e-01],
         [-5.6698370e-01, -9.4789612e-01, -5.6698370e-01, ...,
          -5.6698370e-01, -8.8540316e-01, -5.6698370e-01],
         [-5.6698370e-01,  4.5605909e-02, -6.6825205e-01, ...,
          -8.8540316e-01, -8.8540316e-01, -5.6698370e-01],
         ...,
         [-5.6698370e-01, -8.8540316e-01, -8.8540316e-01, ...,
           2.5674856e-01, -4.0176788e-01, -9.9998307e-01],
         [-5.6698370e-01, -8.8540316e-01, -5.6698370e-01, ...,
           9.5525706e-01,  2.2152075e-01, -9.8641413e-01],
         [-5.6698370e-01, -1.2489725e-01,  9.7022748e-01, ...,
          -9.8319787e-01, -2.6941779e-01, -8.8540316e-01]],

        ...,

        [[ 9.7920000e+04,  9.6256000e+04,  9.6384000e+04, ...,
           9.6768000e+04,  9.6384000e+04,  9.7920000e+04],
         [ 9.7920000e+04,  9.7024000e+04,  9.7920000e+04, ...,
           9.7920000e+04,  9.7536000e+04,  9.7920000e+04],
         [ 9.7920000e+04,  9.6128000e+04,  8.8576000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7920000e+04],
         ...,
         [ 9.7920000e+04,  9.7536000e+04,  9.7536000e+04, ...,
           6.9888000e+04,  8.9600000e+04,  9.6000000e+04],
         [ 9.7920000e+04,  9.7536000e+04,  9.7920000e+04, ...,
           8.1792000e+04,  9.1648000e+04,  9.6512000e+04],
         [ 9.7920000e+04,  9.6384000e+04,  9.6768000e+04, ...,
           9.1520000e+04,  9.5104000e+04,  9.7536000e+04]],

        [[ 9.7920000e+04,  9.6256000e+04,  9.6384000e+04, ...,
           9.6768000e+04,  9.6384000e+04,  9.7920000e+04],
         [ 9.7920000e+04,  9.7024000e+04,  9.7920000e+04, ...,
           9.7920000e+04,  9.7536000e+04,  9.7920000e+04],
         [ 9.7920000e+04,  9.6128000e+04,  8.8576000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7920000e+04],
         ...,
         [ 9.7920000e+04,  9.7536000e+04,  9.7536000e+04, ...,
           6.9888000e+04,  8.9600000e+04,  9.6000000e+04],
         [ 9.7920000e+04,  9.7536000e+04,  9.7920000e+04, ...,
           8.1792000e+04,  9.1648000e+04,  9.6512000e+04],
         [ 9.7920000e+04,  9.6384000e+04,  9.6768000e+04, ...,
           9.1520000e+04,  9.5104000e+04,  9.7536000e+04]],

        [[ 9.7920000e+04,  9.6256000e+04,  9.6384000e+04, ...,
           9.6768000e+04,  9.6384000e+04,  9.7920000e+04],
         [ 9.7920000e+04,  9.7024000e+04,  9.7920000e+04, ...,
           9.7920000e+04,  9.7536000e+04,  9.7920000e+04],
         [ 9.7920000e+04,  9.6128000e+04,  8.8576000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7920000e+04],
         ...,
         [ 9.7920000e+04,  9.7536000e+04,  9.7536000e+04, ...,
           6.9888000e+04,  8.9600000e+04,  9.6000000e+04],
         [ 9.7920000e+04,  9.7536000e+04,  9.7920000e+04, ...,
           8.1792000e+04,  9.1648000e+04,  9.6512000e+04],
         [ 9.7920000e+04,  9.6384000e+04,  9.6768000e+04, ...,
           9.1520000e+04,  9.5104000e+04,  9.7536000e+04]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [3], 'to': [11, 12]}
torch node:
{'name': 'sin', 'output': array([[[[-0.5669837 ,  0.9963537 , -0.12489725, ...,  0.9702275 ,
          -0.12489725, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489725,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489725, ...,  0.9702275 ,
          -0.12489725, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489725,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489725, ...,  0.9702275 ,
          -0.12489725, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489725,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        ...,

        [[-0.5669837 ,  0.9963537 , -0.12489725, ...,  0.9702275 ,
          -0.12489725, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489725,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489725, ...,  0.9702275 ,
          -0.12489725, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489725,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]],

        [[-0.5669837 ,  0.9963537 , -0.12489725, ...,  0.9702275 ,
          -0.12489725, -0.5669837 ],
         [-0.5669837 , -0.9478961 , -0.5669837 , ..., -0.5669837 ,
          -0.88540316, -0.5669837 ],
         [-0.5669837 ,  0.04560591, -0.66825205, ..., -0.88540316,
          -0.88540316, -0.5669837 ],
         ...,
         [-0.5669837 , -0.88540316, -0.88540316, ...,  0.25674856,
          -0.40176788, -0.9999831 ],
         [-0.5669837 , -0.88540316, -0.5669837 , ...,  0.95525706,
           0.22152075, -0.98641413],
         [-0.5669837 , -0.12489725,  0.9702275 , ..., -0.98319787,
          -0.2694178 , -0.88540316]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [3], 'to': [11, 12]}

generate models:78

analyse the exceptions in iter:126
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[1090562., 1069442., 1067522., ...,  662402.,  658562.,
            639362.],
          [1092482., 1069442., 1069442., ...,  635522.,  637442.,
            627842.],
          [1107842., 1086722., 1082882., ...,  625922.,  625922.,
            614402.],
          ...,
          [1296002., 1315202., 1338242., ...,  677762.,  687362.,
            673922.],
          [1288322., 1307522., 1336322., ...,  760322.,  771842.,
            712322.],
          [1278722., 1299842., 1330562., ...,  760322.,  729602.,
            685442.]],

         [[1090562., 1069442., 1067522., ...,  662402.,  658562.,
            639362.],
          [1092482., 1069442., 1069442., ...,  635522.,  637442.,
            627842.],
          [1107842., 1086722., 1082882., ...,  625922.,  625922.,
            614402.],
          ...,
          [1296002., 1315202., 1338242., ...,  677762.,  687362.,
            673922.],
          [1288322., 1307522., 1336322., ...,  760322.,  771842.,
            712322.],
          [1278722., 1299842., 1330562., ...,  760322.,  729602.,
            685442.]],

         [[1090562., 1069442., 1067522., ...,  662402.,  658562.,
            639362.],
          [1092482., 1069442., 1069442., ...,  635522.,  637442.,
            627842.],
          [1107842., 1086722., 1082882., ...,  625922.,  625922.,
            614402.],
          ...,
          [1296002., 1315202., 1338242., ...,  677762.,  687362.,
            673922.],
          [1288322., 1307522., 1336322., ...,  760322.,  771842.,
            712322.],
          [1278722., 1299842., 1330562., ...,  760322.,  729602.,
            685442.]],

         ...,

         [[1090562., 1069442., 1067522., ...,  662402.,  658562.,
            639362.],
          [1092482., 1069442., 1069442., ...,  635522.,  637442.,
            627842.],
          [1107842., 1086722., 1082882., ...,  625922.,  625922.,
            614402.],
          ...,
          [1296002., 1315202., 1338242., ...,  677762.,  687362.,
            673922.],
          [1288322., 1307522., 1336322., ...,  760322.,  771842.,
            712322.],
          [1278722., 1299842., 1330562., ...,  760322.,  729602.,
            685442.]],

         [[1090562., 1069442., 1067522., ...,  662402.,  658562.,
            639362.],
          [1092482., 1069442., 1069442., ...,  635522.,  637442.,
            627842.],
          [1107842., 1086722., 1082882., ...,  625922.,  625922.,
            614402.],
          ...,
          [1296002., 1315202., 1338242., ...,  677762.,  687362.,
            673922.],
          [1288322., 1307522., 1336322., ...,  760322.,  771842.,
            712322.],
          [1278722., 1299842., 1330562., ...,  760322.,  729602.,
            685442.]],

         [[1090562., 1069442., 1067522., ...,  662402.,  658562.,
            639362.],
          [1092482., 1069442., 1069442., ...,  635522.,  637442.,
            627842.],
          [1107842., 1086722., 1082882., ...,  625922.,  625922.,
            614402.],
          ...,
          [1296002., 1315202., 1338242., ...,  677762.,  687362.,
            673922.],
          [1288322., 1307522., 1336322., ...,  760322.,  771842.,
            712322.],
          [1278722., 1299842., 1330562., ...,  760322.,  729602.,
            685442.]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:79

analyse the exceptions in iter:127
tensorflow exception:
{'id': 16, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 32, 32), dtype=float32, numpy=
array([[[[[      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          ...,
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan]],

         [[      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          ...,
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan]],

         [[      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          ...,
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan],
          [      nan,       nan,       nan, ...,       nan,       nan,
                 nan]],

         ...,

         [[469.56747, 469.54715, 469.54715, ..., 469.5654 , 469.5654 ,
           469.5654 ],
          [469.56747, 469.49197, 469.5341 , ..., 469.56747, 469.56747,
           469.56747],
          [469.5438 , 469.4454 , 469.5226 , ..., 469.56747, 469.56747,
           469.56747],
          ...,
          [468.93073, 468.10574, 468.22293, ..., 467.63174, 468.12997,
           468.38754],
          [469.02713, 468.86722, 468.79715, ..., 468.2665 , 468.4794 ,
           468.70786],
          [468.9216 , 468.78522, 468.6376 , ..., 468.4794 , 468.6376 ,
           468.79715]],

         [[469.56747, 469.54715, 469.54715, ..., 469.5654 , 469.5654 ,
           469.5654 ],
          [469.56747, 469.49197, 469.5341 , ..., 469.56747, 469.56747,
           469.56747],
          [469.5438 , 469.4454 , 469.5226 , ..., 469.56747, 469.56747,
           469.56747],
          ...,
          [468.93073, 468.10574, 468.22293, ..., 467.63174, 468.12997,
           468.38754],
          [469.02713, 468.86722, 468.79715, ..., 468.2665 , 468.4794 ,
           468.70786],
          [468.9216 , 468.78522, 468.6376 , ..., 468.4794 , 468.6376 ,
           468.79715]],

         [[469.56747, 469.54715, 469.54715, ..., 469.5654 , 469.5654 ,
           469.5654 ],
          [469.56747, 469.49197, 469.5341 , ..., 469.56747, 469.56747,
           469.56747],
          [469.5438 , 469.4454 , 469.5226 , ..., 469.56747, 469.56747,
           469.56747],
          ...,
          [468.93073, 468.10574, 468.22293, ..., 467.63174, 468.12997,
           468.38754],
          [469.02713, 468.86722, 468.79715, ..., 468.2665 , 468.4794 ,
           468.70786],
          [468.9216 , 468.78522, 468.6376 , ..., 468.4794 , 468.6376 ,
           468.79715]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:80

analyse output arrays in iter:146

pre layer res:
12:transpose
{'name': 'transpose', 'output': array([[[[   0.     ,    0.     ,    0.     , ..., 1523.9668 ,
             0.     ,    0.     ],
         [1335.4225 , 2182.3003 ,    0.     , ...,    0.     ,
          1683.385  , 2474.293  ],
         [   0.     ,    0.     , 2569.5947 , ...,    0.     ,
           714.3448 , 1034.0331 ],
         ...,
         [   0.     ,    0.     ,    0.     , ..., 2411.3232 ,
             0.     ,  692.45667],
         [2563.5889 , 2553.082  ,    0.     , ...,    0.     ,
             0.     ,    0.     ],
         [   0.     ,    0.     , 1136.7671 , ..., 1767.2919 ,
             0.     ,    0.     ]],

        [[   0.     ,    0.     ,    0.     , ..., 1523.9668 ,
             0.     ,    0.     ],
         [1335.4225 , 2182.3003 ,    0.     , ...,    0.     ,
          1683.385  , 2474.293  ],
         [   0.     ,    0.     , 2569.5947 , ...,    0.     ,
           714.3448 , 1034.0331 ],
         ...,
         [   0.     ,    0.     ,    0.     , ..., 2411.3232 ,
             0.     ,  692.45667],
         [2563.5889 , 2553.082  ,    0.     , ...,    0.     ,
             0.     ,    0.     ],
         [   0.     ,    0.     , 1136.7671 , ..., 1767.2919 ,
             0.     ,    0.     ]],

        [[   0.     ,    0.     ,    0.     , ..., 1523.9668 ,
             0.     ,    0.     ],
         [1335.4225 , 2182.3003 ,    0.     , ...,    0.     ,
          1683.385  , 2474.293  ],
         [   0.     ,    0.     , 2569.5947 , ...,    0.     ,
           714.3448 , 1034.0331 ],
         ...,
         [   0.     ,    0.     ,    0.     , ..., 2411.3232 ,
             0.     ,  692.45667],
         [2563.5889 , 2553.082  ,    0.     , ...,    0.     ,
             0.     ,    0.     ],
         [   0.     ,    0.     , 1136.7671 , ..., 1767.2919 ,
             0.     ,    0.     ]],

        ...,

        [[   0.     ,    0.     ,    0.     , ..., 1523.9668 ,
             0.     ,    0.     ],
         [1335.4225 , 2182.3003 ,    0.     , ...,    0.     ,
          1683.385  , 2474.293  ],
         [   0.     ,    0.     , 2569.5947 , ...,    0.     ,
           714.3448 , 1034.0331 ],
         ...,
         [   0.     ,    0.     ,    0.     , ..., 2411.3232 ,
             0.     ,  692.45667],
         [2563.5889 , 2553.082  ,    0.     , ...,    0.     ,
             0.     ,    0.     ],
         [   0.     ,    0.     , 1136.7671 , ..., 1767.2919 ,
             0.     ,    0.     ]],

        [[   0.     ,    0.     ,    0.     , ..., 1523.9668 ,
             0.     ,    0.     ],
         [1335.4225 , 2182.3003 ,    0.     , ...,    0.     ,
          1683.385  , 2474.293  ],
         [   0.     ,    0.     , 2569.5947 , ...,    0.     ,
           714.3448 , 1034.0331 ],
         ...,
         [   0.     ,    0.     ,    0.     , ..., 2411.3232 ,
             0.     ,  692.45667],
         [2563.5889 , 2553.082  ,    0.     , ...,    0.     ,
             0.     ,    0.     ],
         [   0.     ,    0.     , 1136.7671 , ..., 1767.2919 ,
             0.     ,    0.     ]],

        [[   0.     ,    0.     ,    0.     , ..., 1523.9668 ,
             0.     ,    0.     ],
         [1335.4225 , 2182.3003 ,    0.     , ...,    0.     ,
          1683.385  , 2474.293  ],
         [   0.     ,    0.     , 2569.5947 , ...,    0.     ,
           714.3448 , 1034.0331 ],
         ...,
         [   0.     ,    0.     ,    0.     , ..., 2411.3232 ,
             0.     ,  692.45667],
         [2563.5889 , 2553.082  ,    0.     , ...,    0.     ,
             0.     ,    0.     ],
         [   0.     ,    0.     , 1136.7671 , ..., 1767.2919 ,
             0.     ,    0.     ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [10], 'to': [16]}
tf node:
{'name': 'cos', 'output': array([[[[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28475806],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.3593218 , -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.51241976,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.88259125, ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28475806],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.3593218 , -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.51241976,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.88259125, ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28475806],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.3593218 , -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.51241976,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.88259125, ..., -0.14548431,
           1.        ,  1.        ]],

        ...,

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28475806],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.3593218 , -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.51241976,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.88259125, ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28475806],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.3593218 , -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.51241976,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.88259125, ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28475806],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.3593218 , -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.51241976,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.88259125, ..., -0.14548431,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': TensorShape([1, 1024, 32, 32]), 'from': [12], 'to': []}
ms node:
{'name': 'cos', 'output': array([[[[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709754],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709754],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709754],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        ...,

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709754],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709754],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709754],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [12], 'to': []}
torch node:
{'name': 'cos', 'output': array([[[[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709757],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709757],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709757],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        ...,

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709757],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709757],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ..., -0.95698804,
           1.        ,  1.        ],
         [-0.9699898 , -0.44770318,  1.        , ...,  1.        ,
           0.8734015 ,  0.28709757],
         [ 1.        ,  1.        ,  0.9741059 , ...,  1.        ,
          -0.35932183, -0.9008391 ],
         ...,
         [ 1.        ,  1.        ,  1.        , ...,  0.15030874,
           1.        ,  0.26144123],
         [ 0.99878687, -0.5124197 ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  1.        ,  0.8825912 , ..., -0.14548431,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [12], 'to': []}

generate models:89

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:10

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:18
tensorflow exception:
{'id': 12, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 262144), dtype=float32, numpy=
array([[[292864., 299008., 302080., ..., 157184., 153088., 154624.]]],
      dtype=float32)>}
Input to reshape is a tensor with 262144 values, but the requested shape has 295936 [Op:Reshape]

generate models:18

analyse the exceptions in iter:20

generate models:19

analyse the exceptions in iter:24

generate models:22

analyse the exceptions in iter:36

generate models:28

analyse the exceptions in iter:41

generate models:32

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:1
mindspore --> 
torch --> 

generate models:37

analyse the exceptions in iter:62

generate models:46

analyse the exceptions in iter:64

generate models:47

analyse the exceptions in iter:66

generate models:48

analyse the exceptions in iter:91
tensorflow exception:
{'id': 2, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 32768), dtype=float32, numpy=
array([[[1.9063964e+10, 1.9466590e+10, 1.7989927e+10, ...,
         1.5507048e+10, 1.4366226e+10, 1.1010677e+10]]], dtype=float32)>}
Input to reshape is a tensor with 32768 values, but the requested shape has 41472 [Op:Reshape]

generate models:59

analyse output arrays in iter:96

pre layer res:
0:add
{'name': 'add', 'output': array([[inf, inf, inf, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': TensorShape([1, 1048576]), 'from': [94, 94], 'to': [1]}
tf node:
{'name': 'softmax', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': TensorShape([1, 1048576]), 'from': [0], 'to': [2]}
ms node:
{'name': 'softmax', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': (1, 1048576), 'from': [0], 'to': [2]}
torch node:
{'name': 'softmax', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [0], 'to': [2]}

generate models:60

analyse the exceptions in iter:1
tensorflow exception:
{'id': 4, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 9216), dtype=float32, numpy=array([[[6091., 7564., 6630., ...,    0.,    0.,    0.]]], dtype=float32)>}
Input to reshape is a tensor with 9216 values, but the requested shape has 9248 [Op:Reshape]

generate models:2

analyse output arrays in iter:3

analyse the exceptions in iter:9
tensorflow exception:
{'id': 8, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 262144), dtype=float32, numpy=
array([[[0.5403023, 0.5403023, 0.5403023, ..., 0.5403023, 0.5403023,
         0.5403023]]], dtype=float32)>}
Input to reshape is a tensor with 262144 values, but the requested shape has 295936 [Op:Reshape]

generate models:10

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:1
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:13

generate models:13

analyse the exceptions in iter:15

generate models:15

analyse the exceptions in iter:18
tensorflow exception:
{'id': 9, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 294912), dtype=float32, numpy=
array([[[78168., 79080., 56656., ...,     0.,     0.,     0.]]],
      dtype=float32)>}
Input to reshape is a tensor with 294912 values, but the requested shape has 295936 [Op:Reshape]

generate models:18

analyse the exceptions in iter:20

generate models:19

analyse the exceptions in iter:21

generate models:20

analyse the exceptions in iter:22

generate models:21

analyse the exceptions in iter:23
tensorflow exception:
{'id': 12, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 294912), dtype=float32, numpy=
array([[[641280., 679168., 692224., ...,      0.,      0.,      0.]]],
      dtype=float32)>}
Input to reshape is a tensor with 294912 values, but the requested shape has 295936 [Op:Reshape]

generate models:22

analyse the exceptions in iter:25
tensorflow exception:
{'id': 8, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 294912), dtype=float32, numpy=
array([[[-12.119267 ,   6.6992464, -13.713625 , ...,   0.       ,
           0.       ,   0.       ]]], dtype=float32)>}
Input to reshape is a tensor with 294912 values, but the requested shape has 295936 [Op:Reshape]

generate models:23

analyse the exceptions in iter:26
tensorflow exception:
{'id': 9, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 294912), dtype=float32, numpy=array([[[2048., 2048., 2048., ...,    0.,    0.,    0.]]], dtype=float32)>}
Input to reshape is a tensor with 294912 values, but the requested shape has 295936 [Op:Reshape]

generate models:24

analyse the exceptions in iter:28

generate models:26

analyse the exceptions in iter:30
torch exception:
{'id': 8, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([2.5454e+10], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:27

analyse output arrays in iter:32

pre layer res:
15:conv2d
{'name': 'conv2d', 'output': array([[[[4.3961549e+08, 4.4879053e+08, 4.9387930e+08, ...,
          3.8771098e+08, 3.6149658e+08, 1.5754854e+08],
         [4.0081818e+08, 4.0842035e+08, 4.1838182e+08, ...,
          3.7670195e+08, 3.4419610e+08, 1.3867418e+08],
         [2.6240614e+08, 2.7420262e+08, 3.0198989e+08, ...,
          3.7355622e+08, 3.3554534e+08, 1.2320768e+08],
         ...,
         [7.6152909e+08, 8.7529965e+08, 1.0189537e+09, ...,
          1.1799101e+09, 1.1770266e+09, 1.1888230e+09],
         [1.1075592e+09, 1.1675901e+09, 1.1990467e+09, ...,
          1.1778130e+09, 1.1867259e+09, 1.1990467e+09],
         [1.2307668e+09, 1.2137275e+09, 1.2066488e+09, ...,
          1.1922309e+09, 1.2008817e+09, 1.2006195e+09]],

        [[4.3961549e+08, 4.4879053e+08, 4.9387930e+08, ...,
          3.8771098e+08, 3.6149658e+08, 1.5754854e+08],
         [4.0081818e+08, 4.0842035e+08, 4.1838182e+08, ...,
          3.7670195e+08, 3.4419610e+08, 1.3867418e+08],
         [2.6240614e+08, 2.7420262e+08, 3.0198989e+08, ...,
          3.7355622e+08, 3.3554534e+08, 1.2320768e+08],
         ...,
         [7.6152909e+08, 8.7529965e+08, 1.0189537e+09, ...,
          1.1799101e+09, 1.1770266e+09, 1.1888230e+09],
         [1.1075592e+09, 1.1675901e+09, 1.1990467e+09, ...,
          1.1778130e+09, 1.1867259e+09, 1.1990467e+09],
         [1.2307668e+09, 1.2137275e+09, 1.2066488e+09, ...,
          1.1922309e+09, 1.2008817e+09, 1.2006195e+09]],

        [[4.3961549e+08, 4.4879053e+08, 4.9387930e+08, ...,
          3.8771098e+08, 3.6149658e+08, 1.5754854e+08],
         [4.0081818e+08, 4.0842035e+08, 4.1838182e+08, ...,
          3.7670195e+08, 3.4419610e+08, 1.3867418e+08],
         [2.6240614e+08, 2.7420262e+08, 3.0198989e+08, ...,
          3.7355622e+08, 3.3554534e+08, 1.2320768e+08],
         ...,
         [7.6152909e+08, 8.7529965e+08, 1.0189537e+09, ...,
          1.1799101e+09, 1.1770266e+09, 1.1888230e+09],
         [1.1075592e+09, 1.1675901e+09, 1.1990467e+09, ...,
          1.1778130e+09, 1.1867259e+09, 1.1990467e+09],
         [1.2307668e+09, 1.2137275e+09, 1.2066488e+09, ...,
          1.1922309e+09, 1.2008817e+09, 1.2006195e+09]],

        ...,

        [[4.3961549e+08, 4.4879053e+08, 4.9387930e+08, ...,
          3.8771098e+08, 3.6149658e+08, 1.5754854e+08],
         [4.0081818e+08, 4.0842035e+08, 4.1838182e+08, ...,
          3.7670195e+08, 3.4419610e+08, 1.3867418e+08],
         [2.6240614e+08, 2.7420262e+08, 3.0198989e+08, ...,
          3.7355622e+08, 3.3554534e+08, 1.2320768e+08],
         ...,
         [7.6152909e+08, 8.7529965e+08, 1.0189537e+09, ...,
          1.1799101e+09, 1.1770266e+09, 1.1888230e+09],
         [1.1075592e+09, 1.1675901e+09, 1.1990467e+09, ...,
          1.1778130e+09, 1.1867259e+09, 1.1990467e+09],
         [1.2307668e+09, 1.2137275e+09, 1.2066488e+09, ...,
          1.1922309e+09, 1.2008817e+09, 1.2006195e+09]],

        [[4.3961549e+08, 4.4879053e+08, 4.9387930e+08, ...,
          3.8771098e+08, 3.6149658e+08, 1.5754854e+08],
         [4.0081818e+08, 4.0842035e+08, 4.1838182e+08, ...,
          3.7670195e+08, 3.4419610e+08, 1.3867418e+08],
         [2.6240614e+08, 2.7420262e+08, 3.0198989e+08, ...,
          3.7355622e+08, 3.3554534e+08, 1.2320768e+08],
         ...,
         [7.6152909e+08, 8.7529965e+08, 1.0189537e+09, ...,
          1.1799101e+09, 1.1770266e+09, 1.1888230e+09],
         [1.1075592e+09, 1.1675901e+09, 1.1990467e+09, ...,
          1.1778130e+09, 1.1867259e+09, 1.1990467e+09],
         [1.2307668e+09, 1.2137275e+09, 1.2066488e+09, ...,
          1.1922309e+09, 1.2008817e+09, 1.2006195e+09]],

        [[4.3961549e+08, 4.4879053e+08, 4.9387930e+08, ...,
          3.8771098e+08, 3.6149658e+08, 1.5754854e+08],
         [4.0081818e+08, 4.0842035e+08, 4.1838182e+08, ...,
          3.7670195e+08, 3.4419610e+08, 1.3867418e+08],
         [2.6240614e+08, 2.7420262e+08, 3.0198989e+08, ...,
          3.7355622e+08, 3.3554534e+08, 1.2320768e+08],
         ...,
         [7.6152909e+08, 8.7529965e+08, 1.0189537e+09, ...,
          1.1799101e+09, 1.1770266e+09, 1.1888230e+09],
         [1.1075592e+09, 1.1675901e+09, 1.1990467e+09, ...,
          1.1778130e+09, 1.1867259e+09, 1.1990467e+09],
         [1.2307668e+09, 1.2137275e+09, 1.2066488e+09, ...,
          1.1922309e+09, 1.2008817e+09, 1.2006195e+09]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 30, 30]), 'from': [37], 'to': [0, 9]}
tf node:
{'name': 'softmax', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 30, 30]), 'from': [15], 'to': [39]}
ms node:
{'name': 'softmax', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': (1, 64, 30, 30), 'from': [15], 'to': [39]}
torch node:
{'name': 'softmax', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [1., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 30, 30]), 'from': [15], 'to': [39]}

generate models:28

analyse output arrays in iter:48

pre layer res:
2:conv2d
{'name': 'conv2d', 'output': array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.2833331e-01, 4.3955721e-11, 2.7714582e-26],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          2.5645239e+00, 3.4725311e-01, 9.6866064e-11],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          7.1443192e-06, 2.1296894e-02, 4.3896203e-11],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2399322e-10, 3.8963550e-04, 4.2728055e-01],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2617292e-10, 4.8408328e-08, 1.3158754e-07],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6735165e+01, 2.1136785e-03, 2.3786312e-10]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.2833331e-01, 4.3955721e-11, 2.7714582e-26],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          2.5645239e+00, 3.4725311e-01, 9.6866064e-11],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          7.1443192e-06, 2.1296894e-02, 4.3896203e-11],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2399322e-10, 3.8963550e-04, 4.2728055e-01],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2617292e-10, 4.8408328e-08, 1.3158754e-07],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6735165e+01, 2.1136785e-03, 2.3786312e-10]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.2833331e-01, 4.3955721e-11, 2.7714582e-26],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          2.5645239e+00, 3.4725311e-01, 9.6866064e-11],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          7.1443192e-06, 2.1296894e-02, 4.3896203e-11],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2399322e-10, 3.8963550e-04, 4.2728055e-01],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2617292e-10, 4.8408328e-08, 1.3158754e-07],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6735165e+01, 2.1136785e-03, 2.3786312e-10]],

        ...,

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.2833331e-01, 4.3955721e-11, 2.7714582e-26],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          2.5645239e+00, 3.4725311e-01, 9.6866064e-11],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          7.1443192e-06, 2.1296894e-02, 4.3896203e-11],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2399322e-10, 3.8963550e-04, 4.2728055e-01],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2617292e-10, 4.8408328e-08, 1.3158754e-07],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6735165e+01, 2.1136785e-03, 2.3786312e-10]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.2833331e-01, 4.3955721e-11, 2.7714582e-26],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          2.5645239e+00, 3.4725311e-01, 9.6866064e-11],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          7.1443192e-06, 2.1296894e-02, 4.3896203e-11],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2399322e-10, 3.8963550e-04, 4.2728055e-01],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2617292e-10, 4.8408328e-08, 1.3158754e-07],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6735165e+01, 2.1136785e-03, 2.3786312e-10]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          4.2833331e-01, 4.3955721e-11, 2.7714582e-26],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          2.5645239e+00, 3.4725311e-01, 9.6866064e-11],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          7.1443192e-06, 2.1296894e-02, 4.3896203e-11],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2399322e-10, 3.8963550e-04, 4.2728055e-01],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          3.2617292e-10, 4.8408328e-08, 1.3158754e-07],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6735165e+01, 2.1136785e-03, 2.3786312e-10]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [3], 'to': [8]}
tf node:
{'name': 'log', 'output': array([[[[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577013, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849194 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577013, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849194 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577013, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849194 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        ...,

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577013, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849194 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577013, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849194 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577013, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849194 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]]]], dtype=float32), 'output_shape': TensorShape([1, 256, 32, 32]), 'from': [2], 'to': [5]}
ms node:
{'name': 'log', 'output': array([[[[       -inf,        -inf,        -inf, ...,  -0.8478569,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417757,
           -1.0576985, -23.057695 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.8491957, -23.849195 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850296 ,
           -7.8503013,  -0.8503178],
         [       -inf,        -inf,        -inf, ..., -21.843592 ,
          -16.843597 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175156,
           -6.1593285, -22.159328 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478569,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417757,
           -1.0576985, -23.057695 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.8491957, -23.849195 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850296 ,
           -7.8503013,  -0.8503178],
         [       -inf,        -inf,        -inf, ..., -21.843592 ,
          -16.843597 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175156,
           -6.1593285, -22.159328 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478569,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417757,
           -1.0576985, -23.057695 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.8491957, -23.849195 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850296 ,
           -7.8503013,  -0.8503178],
         [       -inf,        -inf,        -inf, ..., -21.843592 ,
          -16.843597 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175156,
           -6.1593285, -22.159328 ]],

        ...,

        [[       -inf,        -inf,        -inf, ...,  -0.8478569,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417757,
           -1.0576985, -23.057695 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.8491957, -23.849195 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850296 ,
           -7.8503013,  -0.8503178],
         [       -inf,        -inf,        -inf, ..., -21.843592 ,
          -16.843597 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175156,
           -6.1593285, -22.159328 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478569,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417757,
           -1.0576985, -23.057695 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.8491957, -23.849195 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850296 ,
           -7.8503013,  -0.8503178],
         [       -inf,        -inf,        -inf, ..., -21.843592 ,
          -16.843597 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175156,
           -6.1593285, -22.159328 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478569,
          -23.84784  , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417757,
           -1.0576985, -23.057695 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.8491957, -23.849195 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850296 ,
           -7.8503013,  -0.8503178],
         [       -inf,        -inf,        -inf, ..., -21.843592 ,
          -16.843597 , -15.843593 ],
         [       -inf,        -inf,        -inf, ...,   2.8175156,
           -6.1593285, -22.159328 ]]]], dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [2], 'to': [5]}
torch node:
{'name': 'log', 'output': array([[[[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.847837 , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577012, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843594 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.847837 , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577012, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843594 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.847837 , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577012, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843594 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        ...,

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.847837 , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577012, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843594 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.847837 , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577012, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843594 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]],

        [[       -inf,        -inf,        -inf, ...,  -0.8478536,
          -23.847837 , -58.84784  ],
         [       -inf,        -inf,        -inf, ...,   0.9417729,
           -1.0577012, -23.057692 ],
         [       -inf,        -inf,        -inf, ..., -11.849193 ,
           -3.849194 , -23.849194 ],
         ...,
         [       -inf,        -inf,        -inf, ..., -21.850298 ,
           -7.850299 ,  -0.8503145],
         [       -inf,        -inf,        -inf, ..., -21.843594 ,
          -16.843594 , -15.843594 ],
         [       -inf,        -inf,        -inf, ...,   2.8175123,
           -6.1593256, -22.159327 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [2], 'to': [5]}

generate models:37

final statics:
total operators:28
tensorflow --> nums:7,distinct_bugs:3
mindspore --> nums:1,distinct_bugs:1
torch --> nums:2,distinct_bugs:2
tensorflow --> 
reshape:5
softmax:1
log:1
mindspore --> 
log:1
torch --> 
flatten:1
log:1

generate models:38

analyse the exceptions in iter:58
tensorflow exception:
{'id': 99, 'name': 'avgpool2d', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 64, 30, 30), dtype=float32, numpy=
array([[[[[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)>}
Default AvgPoolingOp only supports NHWC on device type CPU [Op:AvgPool]

generate models:43

analyse output arrays in iter:59

pre layer res:
39:add
{'name': 'add', 'output': array([[[[ 1650.0377  ,   536.2356  , -1246.6204  , ..., -1824.291   ,
           -998.58765 ,   534.1346  ],
         [ 1810.7195  ,   121.547035, -2314.4622  , ...,  1404.5239  ,
           2592.9382  ,  1541.0209  ],
         [ 1864.3434  ,   532.4835  , -3154.1025  , ..., -1031.4199  ,
            374.2434  ,   361.0784  ],
         ...,
         [  447.34235 ,  4178.705   ,   -65.20819 , ...,  -419.33652 ,
          -3755.671   , -2393.01    ],
         [-1601.863   ,  2112.252   ,  -605.06134 , ...,  -699.74316 ,
          -2865.8525  , -1742.2573  ],
         [ 1552.5667  ,  1983.7349  , -1478.8782  , ...,  -811.9021  ,
           -444.33984 , -1454.2979  ]],

        [[ 1650.0377  ,   536.2356  , -1246.6204  , ..., -1824.291   ,
           -998.58765 ,   534.1346  ],
         [ 1810.7195  ,   121.547035, -2314.4622  , ...,  1404.5239  ,
           2592.9382  ,  1541.0209  ],
         [ 1864.3434  ,   532.4835  , -3154.1025  , ..., -1031.4199  ,
            374.2434  ,   361.0784  ],
         ...,
         [  447.34235 ,  4178.705   ,   -65.20819 , ...,  -419.33652 ,
          -3755.671   , -2393.01    ],
         [-1601.863   ,  2112.252   ,  -605.06134 , ...,  -699.74316 ,
          -2865.8525  , -1742.2573  ],
         [ 1552.5667  ,  1983.7349  , -1478.8782  , ...,  -811.9021  ,
           -444.33984 , -1454.2979  ]],

        [[ 1650.0377  ,   536.2356  , -1246.6204  , ..., -1824.291   ,
           -998.58765 ,   534.1346  ],
         [ 1810.7195  ,   121.547035, -2314.4622  , ...,  1404.5239  ,
           2592.9382  ,  1541.0209  ],
         [ 1864.3434  ,   532.4835  , -3154.1025  , ..., -1031.4199  ,
            374.2434  ,   361.0784  ],
         ...,
         [  447.009   ,  4178.305   ,   -65.34152 , ...,  -419.4032  ,
          -3755.671   , -2393.21    ],
         [-1602.1964  ,  2111.852   ,  -605.1947  , ...,  -699.8098  ,
          -2865.8525  , -1742.4573  ],
         [ 1552.2333  ,  1983.3348  , -1479.0115  , ...,  -811.96875 ,
           -444.33984 , -1454.4978  ]],

        ...,

        [[ 1649.7043  ,   535.8356  , -1246.7537  , ..., -1824.3577  ,
           -998.58765 ,   533.9346  ],
         [ 1810.3861  ,   121.14703 , -2314.5955  , ...,  1404.4573  ,
           2592.9382  ,  1540.8209  ],
         [ 1864.01    ,   532.0835  , -3154.2358  , ..., -1031.4866  ,
            374.2434  ,   360.8784  ],
         ...,
         [  447.009   ,  4178.305   ,   -65.34152 , ...,  -419.4032  ,
          -3755.671   , -2393.21    ],
         [-1602.1964  ,  2111.852   ,  -605.1947  , ...,  -699.8098  ,
          -2865.8525  , -1742.4573  ],
         [ 1552.2333  ,  1983.3348  , -1479.0115  , ...,  -811.96875 ,
           -444.33984 , -1454.4978  ]],

        [[ 1649.7043  ,   535.8356  , -1246.7537  , ..., -1824.3577  ,
           -998.58765 ,   533.9346  ],
         [ 1810.3861  ,   121.14703 , -2314.5955  , ...,  1404.4573  ,
           2592.9382  ,  1540.8209  ],
         [ 1864.01    ,   532.0835  , -3154.2358  , ..., -1031.4866  ,
            374.2434  ,   360.8784  ],
         ...,
         [  447.009   ,  4178.305   ,   -65.34152 , ...,  -419.4032  ,
          -3755.671   , -2393.21    ],
         [-1602.1964  ,  2111.852   ,  -605.1947  , ...,  -699.8098  ,
          -2865.8525  , -1742.4573  ],
         [ 1552.2333  ,  1983.3348  , -1479.0115  , ...,  -811.96875 ,
           -444.33984 , -1454.4978  ]],

        [[ 1649.7043  ,   535.8356  , -1246.7537  , ..., -1824.3577  ,
           -998.58765 ,   533.9346  ],
         [ 1810.3861  ,   121.14703 , -2314.5955  , ...,  1404.4573  ,
           2592.9382  ,  1540.8209  ],
         [ 1864.01    ,   532.0835  , -3154.2358  , ..., -1031.4866  ,
            374.2434  ,   360.8784  ],
         ...,
         [  447.009   ,  4178.305   ,   -65.34152 , ...,  -419.4032  ,
          -3755.671   , -2393.21    ],
         [-1602.1964  ,  2111.852   ,  -605.1947  , ...,  -699.8098  ,
          -2865.8525  , -1742.4573  ],
         [ 1552.2333  ,  1983.3348  , -1479.0115  , ...,  -811.96875 ,
           -444.33984 , -1454.4978  ]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 30, 30]), 'from': [15, 12], 'to': [4]}
7:reshape
{'name': 'reshape', 'output': array([[[[192512., 195840., 161280., ..., 193280., 194560., 195072.],
         [194560., 193792., 190976., ..., 178688., 192512., 192000.],
         [192768., 192512., 193536., ..., 111360., 113408., 156416.],
         ...,
         [ 55808.,  37888.,  26112., ...,  34560.,  41984.,  35072.],
         [ 50432.,  62976.,  42240., ...,  65536.,  44032.,  49664.],
         [ 54528.,  40448.,  42496., ...,  67328.,  81920.,  28416.]],

        [[  6912.,  18944.,  33024., ..., 113408.,  83712.,  65024.],
         [ 69376.,  28160.,  15360., ...,  46848.,  62976., 114432.],
         [102400.,  60672.,  60416., ...,  52736.,  54016.,  60416.],
         ...,
         [ 26880.,  25600.,  31232., ...,  69632.,  57344.,  55808.],
         [ 48640.,  40704.,  35072., ...,  71680.,  73216.,  79360.],
         [ 62464.,  55296.,  45824., ...,   9728.,  40960.,  76800.]],

        [[ 83456.,  79872.,  59136., ...,  64000.,  39424.,  18944.],
         [ 46080.,  54528.,  68096., ...,  61440.,  52992.,  66560.],
         [ 51712.,  34560.,  41984., ..., 113664.,  85248.,  65024.],
         ...,
         [ 54784., 129024., 125184., ...,  15872.,  12032.,   9216.],
         [  5632.,   4096.,  18944., ...,  28416.,  20992.,  16896.],
         [ 20736.,  22272.,  14848., ...,  65280.,  49920.,  29440.]],

        ...,

        [[  2304.,      0.,      0., ...,  20992.,  16128.,  13056.],
         [ 10752.,   7680.,   3840., ...,  25600.,  26880.,  25600.],
         [ 31232.,  35584.,  26624., ...,  55808.,  48640.,  40704.],
         ...,
         [ 65280., 113152.,  82432., ..., 125696., 132608., 137984.],
         [163072., 134656.,  66048., ..., 122624., 118528., 125696.],
         [132096., 134144., 150272., ..., 124416., 122880., 123392.]],

        [[119552., 124928., 130560., ..., 125696., 132608., 123904.],
         [116992., 120832., 122624., ...,    768.,  54784., 129024.],
         [125184., 109824.,  98304., ...,   9216.,   5632.,   4096.],
         ...,
         [103936., 107264.,  77056., ..., 124416.,  67072., 113408.],
         [ 83968.,  68864.,  96768., ..., 135680., 146432., 123904.],
         [ 66304., 112896.,  83456., ..., 128256., 135168., 139520.]],

        [[153344., 123392.,  65280., ..., 121344., 118272., 126208.],
         [134400., 139520., 163328., ..., 123136., 112384., 120832.],
         [118272., 125696., 132608., ...,  83456., 130304., 121856.],
         ...,
         [ 66048.,  68608.,  67072., ...,  66560.,  90624.,  96512.],
         [106240., 108032.,  64768., ..., 120832.,  84224.,  70400.],
         [102912., 113152., 122368., ..., 118784.,  65280., 113152.]]]],
      dtype=float32), 'output_shape': TensorShape([1, 64, 30, 30]), 'from': [6], 'to': [4]}
tf node:
{'name': 'add', 'output': array([[[[194162.03  , 196376.23  , 160033.38  , ..., 191455.7   ,
          193561.4   , 195606.14  ],
         [196370.72  , 193913.55  , 188661.53  , ..., 180092.53  ,
          195104.94  , 193541.02  ],
         [194632.34  , 193044.48  , 190381.89  , ..., 110328.58  ,
          113782.24  , 156777.08  ],
         ...,
         [ 56255.344 ,  42066.703 ,  26046.791 , ...,  34140.664 ,
           38228.33  ,  32678.99  ],
         [ 48830.137 ,  65088.25  ,  41634.938 , ...,  64836.258 ,
           41166.15  ,  47921.742 ],
         [ 56080.566 ,  42431.734 ,  41017.12  , ...,  66516.1   ,
           81475.66  ,  26961.703 ]],

        [[  8562.038 ,  19480.236 ,  31777.379 , ..., 111583.71  ,
           82713.414 ,  65558.13  ],
         [ 71186.72  ,  28281.547 ,  13045.538 , ...,  48252.523 ,
           65568.94  , 115973.02  ],
         [104264.34  ,  61204.484 ,  57261.9   , ...,  51704.58  ,
           54390.242 ,  60777.08  ],
         ...,
         [ 27327.342 ,  29778.705 ,  31166.791 , ...,  69212.664 ,
           53588.33  ,  53414.99  ],
         [ 47038.137 ,  42816.25  ,  34466.938 , ...,  70980.26  ,
           70350.15  ,  77617.74  ],
         [ 64016.566 ,  57279.734 ,  44345.12  , ...,   8916.098 ,
           40515.66  ,  75345.7   ]],

        [[ 85106.04  ,  80408.234 ,  57889.38  , ...,  62175.71  ,
           38425.414 ,  19478.135 ],
         [ 47890.72  ,  54649.547 ,  65781.54  , ...,  62844.523 ,
           55584.938 ,  68101.02  ],
         [ 53576.344 ,  35092.484 ,  38829.9   , ..., 112632.58  ,
           85622.24  ,  65385.08  ],
         ...,
         [ 55231.008 , 133202.31  , 125118.66  , ...,  15452.597 ,
            8276.329 ,   6822.79  ],
         [  4029.8037,   6207.852 ,  18338.805 , ...,  27716.19  ,
           18126.148 ,  15153.543 ],
         [ 22288.232 ,  24255.334 ,  13368.988 , ...,  64468.03  ,
           49475.66  ,  27985.502 ]],

        ...,

        [[  3953.7043,    535.8356,  -1246.7537, ...,  19167.643 ,
           15129.412 ,  13589.935 ],
         [ 12562.386 ,   7801.147 ,   1525.4045, ...,  27004.457 ,
           29472.938 ,  27140.82  ],
         [ 33096.01  ,  36116.082 ,  23469.764 , ...,  54776.51  ,
           49014.242 ,  41064.88  ],
         ...,
         [ 65727.01  , 117330.305 ,  82366.66  , ..., 125276.59  ,
          128852.33  , 135590.8   ],
         [161469.8   , 136767.86  ,  65442.805 , ..., 121924.19  ,
          115662.15  , 123953.54  ],
         [133648.23  , 136127.33  , 148792.98  , ..., 123604.03  ,
          122435.66  , 121937.5   ]],

        [[121201.7   , 125463.836 , 129313.25  , ..., 123871.64  ,
          131609.4   , 124437.94  ],
         [118802.38  , 120953.15  , 120309.41  , ...,   2172.4573,
           57376.938 , 130564.82  ],
         [127048.01  , 110356.086 ,  95149.766 , ...,   8184.5137,
            6006.243 ,   4456.8784],
         ...,
         [104383.01  , 111442.305 ,  76990.66  , ..., 123996.59  ,
           63316.33  , 111014.79  ],
         [ 82365.805 ,  70975.85  ,  96162.805 , ..., 134980.19  ,
          143566.14  , 122161.54  ],
         [ 67856.234 , 114879.336 ,  81976.99  , ..., 127444.03  ,
          134723.66  , 138065.5   ]],

        [[154993.7   , 123927.836 ,  64033.246 , ..., 119519.64  ,
          117273.414 , 126741.94  ],
         [136210.39  , 139641.14  , 161013.4   , ..., 124540.46  ,
          114976.94  , 122372.82  ],
         [120136.01  , 126228.086 , 129453.766 , ...,  82424.516 ,
          130678.24  , 122216.875 ],
         ...,
         [ 66495.01  ,  72786.305 ,  67006.66  , ...,  66140.59  ,
           86868.33  ,  94118.79  ],
         [104637.805 , 110143.85  ,  64162.805 , ..., 120132.19  ,
           81358.15  ,  68657.54  ],
         [104464.234 , 115135.336 , 120888.99  , ..., 117972.03  ,
           64835.66  , 111697.5   ]]]], dtype=float32), 'output_shape': TensorShape([1, 64, 30, 30]), 'from': [39, 7], 'to': [0]}
ms node:
{'name': 'add', 'output': array([[[[194162.05   , 196376.23   , 160033.38   , ..., 191455.7    ,
          193561.4    , 195606.12   ],
         [196370.72   , 193913.55   , 188661.53   , ..., 180092.52   ,
          195104.94   , 193541.02   ],
         [194632.34   , 193044.48   , 190381.89   , ..., 110328.58   ,
          113782.234  , 156777.08   ],
         ...,
         [ 56255.344  ,  42066.707  ,  26046.797  , ...,  34140.66   ,
           38228.33   ,  32678.988  ],
         [ 48830.137  ,  65088.254  ,  41634.945  , ...,  64836.254  ,
           41166.14   ,  47921.74   ],
         [ 56080.566  ,  42431.74   ,  41017.13   , ...,  66516.09   ,
           81475.66   ,  26961.701  ]],

        [[  8562.039  ,  19480.234  ,  31777.379  , ..., 111583.7    ,
           82713.41   ,  65558.13   ],
         [ 71186.72   ,  28281.547  ,  13045.533  , ...,  48252.523  ,
           65568.94   , 115973.016  ],
         [104264.34   ,  61204.48   ,  57261.89   , ...,  51704.58   ,
           54390.24   ,  60777.074  ],
         ...,
         [ 27327.342  ,  29778.707  ,  31166.797  , ...,  69212.664  ,
           53588.33   ,  53414.99   ],
         [ 47038.137  ,  42816.254  ,  34466.945  , ...,  70980.26   ,
           70350.14   ,  77617.74   ],
         [ 64016.566  ,  57279.74   ,  44345.13   , ...,   8916.097  ,
           40515.66   ,  75345.7    ]],

        [[ 85106.04   ,  80408.234  ,  57889.38   , ...,  62175.707  ,
           38425.41   ,  19478.129  ],
         [ 47890.723  ,  54649.547  ,  65781.53   , ...,  62844.523  ,
           55584.938  ,  68101.016  ],
         [ 53576.344  ,  35092.48   ,  38829.89   , ..., 112632.58   ,
           85622.234  ,  65385.074  ],
         ...,
         [ 55231.008  , 133202.31   , 125118.664  , ...,  15452.594  ,
            8276.326  ,   6822.788  ],
         [  4029.8037 ,   6207.854  ,  18338.812  , ...,  27716.188  ,
           18126.14   ,  15153.539  ],
         [ 22288.232  ,  24255.336  ,  13368.996  , ...,  64468.03   ,
           49475.66   ,  27985.5    ]],

        ...,

        [[  3953.706  ,    535.83514,  -1246.755  , ...,  19167.64   ,
           15129.409  ,  13589.93   ],
         [ 12562.388  ,   7801.146  ,   1525.4001 , ...,  27004.457  ,
           29472.936  ,  27140.816  ],
         [ 33096.008  ,  36116.082  ,  23469.76   , ...,  54776.508  ,
           49014.24   ,  41064.875  ],
         ...,
         [ 65727.01   , 117330.305  ,  82366.664  , ..., 125276.59   ,
          128852.33   , 135590.78   ],
         [161469.8    , 136767.86   ,  65442.812  , ..., 121924.19   ,
          115662.14   , 123953.54   ],
         [133648.23   , 136127.34   , 148793.     , ..., 123604.03   ,
          122435.66   , 121937.5    ]],

        [[121201.7    , 125463.836  , 129313.24   , ..., 123871.64   ,
          131609.4    , 124437.93   ],
         [118802.39   , 120953.15   , 120309.4    , ...,   2172.4565 ,
           57376.938  , 130564.81   ],
         [127048.01   , 110356.08   ,  95149.76   , ...,   8184.51   ,
            6006.2383 ,   4456.873  ],
         ...,
         [104383.01   , 111442.305  ,  76990.664  , ..., 123996.59   ,
           63316.33   , 111014.79   ],
         [ 82365.805  ,  70975.85   ,  96162.81   , ..., 134980.19   ,
          143566.14   , 122161.54   ],
         [ 67856.234  , 114879.336  ,  81976.99   , ..., 127444.03   ,
          134723.66   , 138065.5    ]],

        [[154993.7    , 123927.836  ,  64033.246  , ..., 119519.64   ,
          117273.41   , 126741.93   ],
         [136210.39   , 139641.14   , 161013.4    , ..., 124540.45   ,
          114976.94   , 122372.81   ],
         [120136.01   , 126228.08   , 129453.76   , ...,  82424.51   ,
          130678.234  , 122216.875  ],
         ...,
         [ 66495.01   ,  72786.305  ,  67006.664  , ...,  66140.59   ,
           86868.33   ,  94118.79   ],
         [104637.805  , 110143.85   ,  64162.812  , ..., 120132.19   ,
           81358.14   ,  68657.54   ],
         [104464.234  , 115135.336  , 120888.99   , ..., 117972.03   ,
           64835.66   , 111697.5    ]]]], dtype=float32), 'output_shape': (1, 64, 30, 30), 'from': [39, 7], 'to': [0]}
torch node:
{'name': 'add', 'output': array([[[[194162.02   , 196376.22   , 160033.34   , ..., 191455.7    ,
          193561.4    , 195606.12   ],
         [196370.73   , 193913.55   , 188661.64   , ..., 180092.52   ,
          195104.97   , 193540.98   ],
         [194632.4    , 193044.47   , 190382.1    , ..., 110328.55   ,
          113782.24   , 156777.08   ],
         ...,
         [ 56255.332  ,  42066.684  ,  26046.799  , ...,  34140.63   ,
           38228.3    ,  32678.994  ],
         [ 48830.184  ,  65088.234  ,  41634.957  , ...,  64836.234  ,
           41166.164  ,  47921.715  ],
         [ 56080.637  ,  42431.734  ,  41017.133  , ...,  66516.055  ,
           81475.664  ,  26961.723  ]],

        [[  8562.0205 ,  19480.22   ,  31777.352  , ..., 111583.7    ,
           82713.4    ,  65558.125  ],
         [ 71186.74   ,  28281.545  ,  13045.635  , ...,  48252.52   ,
           65568.97   , 115972.99   ],
         [104264.41   ,  61204.46   ,  57262.098  , ...,  51704.547  ,
           54390.242  ,  60777.082  ],
         ...,
         [ 27327.332  ,  29778.684  ,  31166.799  , ...,  69212.63   ,
           53588.3    ,  53414.996  ],
         [ 47038.184  ,  42816.234  ,  34466.957  , ...,  70980.234  ,
           70350.164  ,  77617.72   ],
         [ 64016.637  ,  57279.734  ,  44345.133  , ...,   8916.056  ,
           40515.664  ,  75345.73   ]],

        [[ 85106.02   ,  80408.22   ,  57889.35   , ...,  62175.703  ,
           38425.4    ,  19478.121  ],
         [ 47890.742  ,  54649.543  ,  65781.63   , ...,  62844.52   ,
           55584.965  ,  68100.99   ],
         [ 53576.406  ,  35092.46   ,  38830.098  , ..., 112632.55   ,
           85622.24   ,  65385.082  ],
         ...,
         [ 55231.     , 133202.28   , 125118.664  , ...,  15452.5625 ,
            8276.301  ,   6822.795  ],
         [  4029.8518 ,   6207.833  ,  18338.822  , ...,  27716.17   ,
           18126.164  ,  15153.516  ],
         [ 22288.303  ,  24255.332  ,  13369.001  , ...,  64467.99   ,
           49475.664  ,  27985.523  ]],

        ...,

        [[  3953.687  ,    535.82074,  -1246.7826 , ...,  19167.637  ,
           15129.399  ,  13589.921  ],
         [ 12562.408  ,   7801.144  ,   1525.5017 , ...,  27004.453  ,
           29472.967  ,  27140.791  ],
         [ 33096.07   ,  36116.062  ,  23469.965  , ...,  54776.48   ,
           49014.242  ,  41064.88   ],
         ...,
         [ 65727.     , 117330.28   ,  82366.664  , ..., 125276.56   ,
          128852.305  , 135590.8    ],
         [161469.86   , 136767.83   ,  65442.824  , ..., 121924.17   ,
          115662.164  , 123953.516  ],
         [133648.3    , 136127.33   , 148793.     , ..., 123603.99   ,
          122435.664  , 121937.52   ]],

        [[121201.69   , 125463.82   , 129313.22   , ..., 123871.64   ,
          131609.4    , 124437.92   ],
         [118802.41   , 120953.14   , 120309.5    , ...,   2172.4524 ,
           57376.965  , 130564.79   ],
         [127048.07   , 110356.06   ,  95149.97   , ...,   8184.479  ,
            6006.242  ,   4456.8804 ],
         ...,
         [104383.     , 111442.28   ,  76990.664  , ..., 123996.56   ,
           63316.3    , 111014.8    ],
         [ 82365.85   ,  70975.836  ,  96162.82   , ..., 134980.17   ,
          143566.17   , 122161.516  ],
         [ 67856.305  , 114879.336  ,  81977.     , ..., 127443.99   ,
          134723.67   , 138065.52   ]],

        [[154993.69   , 123927.82   ,  64033.22   , ..., 119519.64   ,
          117273.4    , 126741.92   ],
         [136210.4    , 139641.14   , 161013.5    , ..., 124540.45   ,
          114976.97   , 122372.79   ],
         [120136.07   , 126228.06   , 129453.97   , ...,  82424.48   ,
          130678.24   , 122216.88   ],
         ...,
         [ 66495.     ,  72786.28   ,  67006.664  , ...,  66140.56   ,
           86868.305  ,  94118.8    ],
         [104637.85   , 110143.836  ,  64162.824  , ..., 120132.17   ,
           81358.164  ,  68657.516  ],
         [104464.305  , 115135.336  , 120889.     , ..., 117971.99   ,
           64835.664  , 111697.52   ]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 30, 30]), 'from': [39, 7], 'to': [0]}

generate models:44

analyse the exceptions in iter:8
tensorflow exception:
{'id': 5, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1024, 16, 16), dtype=float32, numpy=
array([[[[[556032., 551936., 542720., ..., 563200., 562176., 674816.],
          [540672., 545792., 537600., ..., 454656., 515072., 593920.],
          [556032., 531456., 535552., ..., 263168., 297984., 579584.],
          ...,
          [542720., 552960., 547840., ..., 228352., 182272., 269312.],
          [543744., 544768., 544768., ..., 258048., 235520., 247808.],
          [542720., 541696., 544768., ..., 282624., 263168., 271360.]],

         [[556032., 551936., 542720., ..., 563200., 562176., 674816.],
          [540672., 545792., 537600., ..., 454656., 515072., 593920.],
          [556032., 531456., 535552., ..., 263168., 297984., 579584.],
          ...,
          [542720., 552960., 547840., ..., 228352., 182272., 269312.],
          [543744., 544768., 544768., ..., 258048., 235520., 247808.],
          [542720., 541696., 544768., ..., 282624., 263168., 271360.]],

         [[556032., 551936., 542720., ..., 563200., 562176., 674816.],
          [540672., 545792., 537600., ..., 454656., 515072., 593920.],
          [556032., 531456., 535552., ..., 263168., 297984., 579584.],
          ...,
          [542720., 552960., 547840., ..., 228352., 182272., 269312.],
          [543744., 544768., 544768., ..., 258048., 235520., 247808.],
          [542720., 541696., 544768., ..., 282624., 263168., 271360.]],

         ...,

         [[556032., 551936., 542720., ..., 563200., 562176., 674816.],
          [540672., 545792., 537600., ..., 454656., 515072., 593920.],
          [556032., 531456., 535552., ..., 263168., 297984., 579584.],
          ...,
          [542720., 552960., 547840., ..., 228352., 182272., 269312.],
          [543744., 544768., 544768., ..., 258048., 235520., 247808.],
          [542720., 541696., 544768., ..., 282624., 263168., 271360.]],

         [[556032., 551936., 542720., ..., 563200., 562176., 674816.],
          [540672., 545792., 537600., ..., 454656., 515072., 593920.],
          [556032., 531456., 535552., ..., 263168., 297984., 579584.],
          ...,
          [542720., 552960., 547840., ..., 228352., 182272., 269312.],
          [543744., 544768., 544768., ..., 258048., 235520., 247808.],
          [542720., 541696., 544768., ..., 282624., 263168., 271360.]],

         [[556032., 551936., 542720., ..., 563200., 562176., 674816.],
          [540672., 545792., 537600., ..., 454656., 515072., 593920.],
          [556032., 531456., 535552., ..., 263168., 297984., 579584.],
          ...,
          [542720., 552960., 547840., ..., 228352., 182272., 269312.],
          [543744., 544768., 544768., ..., 258048., 235520., 247808.],
          [542720., 541696., 544768., ..., 282624., 263168., 271360.]]]]],
      dtype=float32)>}
Input to reshape is a tensor with 262144 values, but the requested shape has 295936 [Op:Reshape]

generate models:7

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:1
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:13

generate models:12

analyse output arrays in iter:15

analyse the exceptions in iter:9

generate models:8

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:8

analyse the exceptions in iter:10
tensorflow exception:
{'id': 11, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 18464), dtype=float32, numpy=
array([[[413824., 412992., 415424., ...,      0.,      0.,      0.]]],
      dtype=float32)>}
Input to reshape is a tensor with 18464 values, but the requested shape has 18496 [Op:Reshape]

generate models:9

analyse the exceptions in iter:11
tensorflow exception:
{'id': 14, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 198592), dtype=float32, numpy=
array([[[2.7182817, 2.7182817, 2.7182817, ..., 0.       , 0.       ,
         0.       ]]], dtype=float32)>}
Input to reshape is a tensor with 198592 values, but the requested shape has 200704 [Op:Reshape]

generate models:10

analyse the exceptions in iter:12

generate models:11

analyse the exceptions in iter:13
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 16384), dtype=float32, numpy=array([[[1408., 1408., 1280., ..., 5312., 4928., 4544.]]], dtype=float32)>}
Input to reshape is a tensor with 16384 values, but the requested shape has 18496 [Op:Reshape]

generate models:12

analyse the exceptions in iter:23
tensorflow exception:
{'id': 14, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 295424), dtype=float32, numpy=
array([[[4.8266991e+12, 5.0501654e+12, 4.7193763e+12, ...,
         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)>}
Input to reshape is a tensor with 295424 values, but the requested shape has 295936 [Op:Reshape]

generate models:16

analyse the exceptions in iter:24

generate models:17

analyse the exceptions in iter:26
tensorflow exception:
{'id': 5, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 256, 32, 32), dtype=float32, numpy=
array([[[[[8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          ...,
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358]],

         [[8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          ...,
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358]],

         [[8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          ...,
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358]],

         ...,

         [[8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          ...,
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358]],

         [[8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          ...,
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358]],

         [[8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          ...,
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358],
          [8.989358, 8.989358, 8.989358, ..., 8.989358, 8.989358,
           8.989358]]]]], dtype=float32)>}
Input to reshape is a tensor with 262144 values, but the requested shape has 295936 [Op:Reshape]

generate models:18

analyse the exceptions in iter:27
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 256, 32, 32), dtype=float32, numpy=
array([[[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           1.2134870e-24, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           2.6075940e-20, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 1.6835675e-35],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           1.2134870e-24, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           2.6075940e-20, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 1.6835675e-35],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           1.2134870e-24, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           2.6075940e-20, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 1.6835675e-35],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         ...,

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           1.2134870e-24, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           2.6075940e-20, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 1.6835675e-35],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           1.2134870e-24, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           2.6075940e-20, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 1.6835675e-35],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

         [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           1.2134870e-24, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           2.6075940e-20, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          ...,
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 1.6835675e-35],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]]], dtype=float32)>}
Input to reshape is a tensor with 262144 values, but the requested shape has 295936 [Op:Reshape]

generate models:19

analyse output arrays in iter:45

pre layer res:
12:add
{'name': 'add', 'output': array([[[[13184., 15744., 10880., ..., 54144., 48384., 42752.],
         [14336., 16256., 10496., ..., 54016., 52352., 49024.],
         [14720., 14848.,  8960., ..., 55040., 53888., 57600.],
         ...,
         [35584., 51840., 55040., ..., 49536., 43904., 42240.],
         [34432., 55040., 53504., ..., 47744., 44032., 40832.],
         [35712., 54400., 51840., ..., 45184., 43264., 39040.]],

        [[13184., 15744., 10880., ..., 54144., 48384., 42752.],
         [14336., 16256., 10496., ..., 54016., 52352., 49024.],
         [14720., 14848.,  8960., ..., 55040., 53888., 57600.],
         ...,
         [35584., 51840., 55040., ..., 49536., 43904., 42240.],
         [34432., 55040., 53504., ..., 47744., 44032., 40832.],
         [35712., 54400., 51840., ..., 45184., 43264., 39040.]],

        [[13184., 15744., 10880., ..., 54144., 48384., 42752.],
         [14336., 16256., 10496., ..., 54016., 52352., 49024.],
         [14720., 14848.,  8960., ..., 55040., 53888., 57600.],
         ...,
         [35584., 51840., 55040., ..., 49536., 43904., 42240.],
         [34432., 55040., 53504., ..., 47744., 44032., 40832.],
         [35712., 54400., 51840., ..., 45184., 43264., 39040.]],

        ...,

        [[13184., 15744., 10880., ..., 54144., 48384., 42752.],
         [14336., 16256., 10496., ..., 54016., 52352., 49024.],
         [14720., 14848.,  8960., ..., 55040., 53888., 57600.],
         ...,
         [35584., 51840., 55040., ..., 49536., 43904., 42240.],
         [34432., 55040., 53504., ..., 47744., 44032., 40832.],
         [35712., 54400., 51840., ..., 45184., 43264., 39040.]],

        [[13184., 15744., 10880., ..., 54144., 48384., 42752.],
         [14336., 16256., 10496., ..., 54016., 52352., 49024.],
         [14720., 14848.,  8960., ..., 55040., 53888., 57600.],
         ...,
         [35584., 51840., 55040., ..., 49536., 43904., 42240.],
         [34432., 55040., 53504., ..., 47744., 44032., 40832.],
         [35712., 54400., 51840., ..., 45184., 43264., 39040.]],

        [[13184., 15744., 10880., ..., 54144., 48384., 42752.],
         [14336., 16256., 10496., ..., 54016., 52352., 49024.],
         [14720., 14848.,  8960., ..., 55040., 53888., 57600.],
         ...,
         [35584., 51840., 55040., ..., 49536., 43904., 42240.],
         [34432., 55040., 53504., ..., 47744., 44032., 40832.],
         [35712., 54400., 51840., ..., 45184., 43264., 39040.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [0, 5], 'to': [3]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        ...,

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [12], 'to': [87]}
ms node:
{'name': 'sin', 'output': array([[[[ 9.5341682e-01, -9.9580914e-01, -6.1677629e-01, ...,
           9.7558838e-01, -3.2550150e-01,  9.3461317e-01],
         [-7.9117125e-01,  9.8538345e-01,  6.1017718e-02, ...,
          -5.1763612e-01,  4.7944361e-01,  5.2554816e-01],
         [-9.9771452e-01,  7.4003279e-01,  1.7681740e-01, ...,
          -6.4673120e-01, -2.5825256e-01,  8.9179790e-01],
         ...,
         [ 7.3113710e-01, -5.4770863e-01, -6.4673120e-01, ...,
          -5.9153539e-01, -2.4029145e-01, -9.5993567e-01],
         [ 1.4401414e-01, -6.4673120e-01,  4.4796088e-01, ...,
          -9.3787122e-01, -5.3341496e-01, -6.5959615e-01],
         [-9.9851578e-01,  1.8061376e-01, -5.4770863e-01, ...,
           9.9904704e-01, -9.0337163e-01,  5.4123586e-01]],

        [[ 9.5341682e-01, -9.9580914e-01, -6.1677629e-01, ...,
           9.7558838e-01, -3.2550150e-01,  9.3461317e-01],
         [-7.9117125e-01,  9.8538345e-01,  6.1017718e-02, ...,
          -5.1763612e-01,  4.7944361e-01,  5.2554816e-01],
         [-9.9771452e-01,  7.4003279e-01,  1.7681740e-01, ...,
          -6.4673120e-01, -2.5825256e-01,  8.9179790e-01],
         ...,
         [ 7.3113710e-01, -5.4770863e-01, -6.4673120e-01, ...,
          -5.9153539e-01, -2.4029145e-01, -9.5993567e-01],
         [ 1.4401414e-01, -6.4673120e-01,  4.4796088e-01, ...,
          -9.3787122e-01, -5.3341496e-01, -6.5959615e-01],
         [-9.9851578e-01,  1.8061376e-01, -5.4770863e-01, ...,
           9.9904704e-01, -9.0337163e-01,  5.4123586e-01]],

        [[ 9.5341682e-01, -9.9580914e-01, -6.1677629e-01, ...,
           9.7558838e-01, -3.2550150e-01,  9.3461317e-01],
         [-7.9117125e-01,  9.8538345e-01,  6.1017718e-02, ...,
          -5.1763612e-01,  4.7944361e-01,  5.2554816e-01],
         [-9.9771452e-01,  7.4003279e-01,  1.7681740e-01, ...,
          -6.4673120e-01, -2.5825256e-01,  8.9179790e-01],
         ...,
         [ 7.3113710e-01, -5.4770863e-01, -6.4673120e-01, ...,
          -5.9153539e-01, -2.4029145e-01, -9.5993567e-01],
         [ 1.4401414e-01, -6.4673120e-01,  4.4796088e-01, ...,
          -9.3787122e-01, -5.3341496e-01, -6.5959615e-01],
         [-9.9851578e-01,  1.8061376e-01, -5.4770863e-01, ...,
           9.9904704e-01, -9.0337163e-01,  5.4123586e-01]],

        ...,

        [[ 6.5920000e+03,  7.8720000e+03,  5.4400000e+03, ...,
           2.7072000e+04,  2.4192000e+04,  2.1376000e+04],
         [ 7.1680000e+03,  8.1280000e+03,  5.2480000e+03, ...,
           2.7008000e+04,  2.6176000e+04,  2.4512000e+04],
         [ 7.3600000e+03,  7.4240000e+03,  4.4800000e+03, ...,
           2.7520000e+04,  2.6944000e+04,  2.8800000e+04],
         ...,
         [ 1.7792000e+04,  2.5920000e+04,  2.7520000e+04, ...,
           2.4768000e+04,  2.1952000e+04,  2.1120000e+04],
         [ 1.7216000e+04,  2.7520000e+04,  2.6752000e+04, ...,
           2.3872000e+04,  2.2016000e+04,  2.0416000e+04],
         [ 1.7856000e+04,  2.7200000e+04,  2.5920000e+04, ...,
           2.2592000e+04,  2.1632000e+04,  1.9520000e+04]],

        [[ 6.5920000e+03,  7.8720000e+03,  5.4400000e+03, ...,
           2.7072000e+04,  2.4192000e+04,  2.1376000e+04],
         [ 7.1680000e+03,  8.1280000e+03,  5.2480000e+03, ...,
           2.7008000e+04,  2.6176000e+04,  2.4512000e+04],
         [ 7.3600000e+03,  7.4240000e+03,  4.4800000e+03, ...,
           2.7520000e+04,  2.6944000e+04,  2.8800000e+04],
         ...,
         [ 1.7792000e+04,  2.5920000e+04,  2.7520000e+04, ...,
           2.4768000e+04,  2.1952000e+04,  2.1120000e+04],
         [ 1.7216000e+04,  2.7520000e+04,  2.6752000e+04, ...,
           2.3872000e+04,  2.2016000e+04,  2.0416000e+04],
         [ 1.7856000e+04,  2.7200000e+04,  2.5920000e+04, ...,
           2.2592000e+04,  2.1632000e+04,  1.9520000e+04]],

        [[ 6.5920000e+03,  7.8720000e+03,  5.4400000e+03, ...,
           2.7072000e+04,  2.4192000e+04,  2.1376000e+04],
         [ 7.1680000e+03,  8.1280000e+03,  5.2480000e+03, ...,
           2.7008000e+04,  2.6176000e+04,  2.4512000e+04],
         [ 7.3600000e+03,  7.4240000e+03,  4.4800000e+03, ...,
           2.7520000e+04,  2.6944000e+04,  2.8800000e+04],
         ...,
         [ 1.7792000e+04,  2.5920000e+04,  2.7520000e+04, ...,
           2.4768000e+04,  2.1952000e+04,  2.1120000e+04],
         [ 1.7216000e+04,  2.7520000e+04,  2.6752000e+04, ...,
           2.3872000e+04,  2.2016000e+04,  2.0416000e+04],
         [ 1.7856000e+04,  2.7200000e+04,  2.5920000e+04, ...,
           2.2592000e+04,  2.1632000e+04,  1.9520000e+04]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [12], 'to': [87]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        ...,

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]],

        [[ 0.9534168 , -0.99580914, -0.6167763 , ...,  0.9755884 ,
          -0.3255015 ,  0.93461317],
         [-0.79117125,  0.98538345,  0.06101772, ..., -0.5176361 ,
           0.4794436 ,  0.52554816],
         [-0.9977145 ,  0.7400328 ,  0.1768174 , ..., -0.6467312 ,
          -0.25825256,  0.8917979 ],
         ...,
         [ 0.7311371 , -0.54770863, -0.6467312 , ..., -0.5915354 ,
          -0.24029145, -0.95993567],
         [ 0.14401414, -0.6467312 ,  0.44796088, ..., -0.9378712 ,
          -0.53341496, -0.65959615],
         [-0.9985158 ,  0.18061376, -0.54770863, ...,  0.99904704,
          -0.90337163,  0.54123586]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [12], 'to': [87]}

generate models:27

final statics:
total operators:28
tensorflow --> nums:6,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:6
mindspore --> 
sin:1
torch --> 

generate models:31

analyse the exceptions in iter:65
tensorflow exception:
{'id': 4, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 400416), dtype=float32, numpy=array([[[-inf, -inf, -inf, ..., -inf, -inf, -inf]]], dtype=float32)>}
Input to reshape is a tensor with 400416 values, but the requested shape has 401408 [Op:Reshape]

generate models:38

analyse the exceptions in iter:66
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 15392), dtype=float32, numpy=array([[[nan, nan, nan, ...,  0.,  0.,  0.]]], dtype=float32)>}
Input to reshape is a tensor with 15392 values, but the requested shape has 16384 [Op:Reshape]

generate models:39

final statics:
total operators:28
tensorflow --> nums:8,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:8
mindspore --> 
sin:1
torch --> 

generate models:47

analyse the exceptions in iter:1
tensorflow exception:
{'id': 3, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 590848), dtype=float32, numpy=
array([[[11997., 14010., 15073., ...,     0.,     0.,     0.]]],
      dtype=float32)>}
Input to reshape is a tensor with 590848 values, but the requested shape has 591872 [Op:Reshape]

generate models:2

analyse the exceptions in iter:3

generate models:4

analyse the exceptions in iter:4
tensorflow exception:
{'id': 11, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 82688), dtype=float32, numpy=array([[[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>}
Input to reshape is a tensor with 82688 values, but the requested shape has 82944 [Op:Reshape]

generate models:5

analyse output arrays in iter:7

pre layer res:
7:flatten
{'name': 'flatten', 'output': array([[137338.52, 134900.47, 134921.1 , ...,      0.  ,      0.  ,
             0.  ]], dtype=float32), 'output_shape': torch.Size([1, 32768]), 'from': [17], 'to': [18]}
tf node:
{'name': 'cos', 'output': array([[ 0.79536873,  0.8869003 , -0.6325589 , ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': torch.Size([1, 32768]), 'from': [7], 'to': [8]}
ms node:
{'name': 'cos', 'output': array([[ 0.74563724,  0.87203336, -0.58294827, ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': (1, 32768), 'from': [7], 'to': [8]}
torch node:
{'name': 'cos', 'output': array([[ 0.79536873,  0.8869003 , -0.6325589 , ...,  1.        ,
         1.        ,  1.        ]], dtype=float32), 'output_shape': torch.Size([1, 32768]), 'from': [7], 'to': [8]}

generate models:7

analyse the exceptions in iter:9
tensorflow exception:
{'id': 8, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1116160), dtype=float32, numpy=array([[[366., 430., 548., ...,   0.,   0.,   0.]]], dtype=float32)>}
Input to reshape is a tensor with 1116160 values, but the requested shape has 1183744 [Op:Reshape]

generate models:9

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:3
mindspore --> 
cos:1
torch --> 

generate models:9

analyse the exceptions in iter:10
tensorflow exception:
{'id': 4, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 590848), dtype=float32, numpy=
array([[[12632., 12800., 12988., ...,     0.,     0.,     0.]]],
      dtype=float32)>}
Input to reshape is a tensor with 590848 values, but the requested shape has 591872 [Op:Reshape]

generate models:10

analyse the exceptions in iter:11
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1116160), dtype=float32, numpy=
array([[[12.1871395, 12.701772 , 12.935397 , ...,  0.       ,
          0.       ,  0.       ]]], dtype=float32)>}
Input to reshape is a tensor with 1116160 values, but the requested shape has 1183744 [Op:Reshape]

generate models:11

analyse the exceptions in iter:12

generate models:12

analyse output arrays in iter:19

pre layer res:
13:reshape
{'name': 'reshape', 'output': array([[[inf, inf, inf, ..., inf, inf, inf],
        [inf, inf, inf, ..., inf, inf, inf],
        [inf, inf, inf, ..., inf, inf, inf],
        ...,
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32]), 'from': [12], 'to': [14]}
tf node:
{'name': 'sin', 'output': array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32]), 'from': [13], 'to': [1]}
ms node:
{'name': 'sin', 'output': array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), 'output_shape': (1, 512, 32), 'from': [13], 'to': [1]}
torch node:
{'name': 'sin', 'output': array([[[nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        [nan, nan, nan, ..., nan, nan, nan],
        ...,
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32]), 'from': [13], 'to': [1]}

generate models:18

analyse output arrays in iter:20

pre layer res:
13:exp
{'name': 'exp', 'output': array([[inf, inf, inf, ...,  1.,  1.,  1.]], dtype=float32), 'output_shape': torch.Size([1, 921600]), 'from': [1], 'to': [5]}
tf node:
{'name': 'softmax', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 921600]), 'from': [13], 'to': [2]}
ms node:
{'name': 'softmax', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': (1, 921600), 'from': [13], 'to': [2]}
torch node:
{'name': 'softmax', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 921600]), 'from': [13], 'to': [2]}

generate models:19

analyse output arrays in iter:23

pre layer res:
2:flatten
{'name': 'flatten', 'output': array([[inf, inf, inf, ..., inf, inf, inf]], dtype=float32), 'output_shape': torch.Size([1, 18496]), 'from': [5], 'to': [11]}
tf node:
{'name': 'sin', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 18496]), 'from': [2], 'to': [3]}
ms node:
{'name': 'sin', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': (1, 18496), 'from': [2], 'to': [3]}
torch node:
{'name': 'sin', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 18496]), 'from': [2], 'to': [3]}

generate models:22

analyse output arrays in iter:28

pre layer res:
68:flatten
{'name': 'flatten', 'output': array([[inf, inf, inf, ..., inf, inf, inf]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [8], 'to': [0]}
tf node:
{'name': 'sin', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [68], 'to': [69]}
ms node:
{'name': 'sin', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': (1, 262144), 'from': [68], 'to': [69]}
torch node:
{'name': 'sin', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [68], 'to': [69]}

generate models:26

analyse the exceptions in iter:40

generate models:29

analyse the exceptions in iter:41

generate models:30

analyse the exceptions in iter:42
tensorflow exception:
{'id': 4, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 147712), dtype=float32, numpy=array([[[0.5, 0.5, 0.5, ..., 0. , 0. , 0. ]]], dtype=float32)>}
Input to reshape is a tensor with 147712 values, but the requested shape has 147968 [Op:Reshape]

generate models:31

analyse the exceptions in iter:43

generate models:32

analyse the exceptions in iter:45
tensorflow exception:
{'id': 2, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 131072), dtype=float32, numpy=
array([[[1.7280532e+09, 1.8790482e+09, 1.9293798e+09, ...,
         5.5364813e+09, 5.3519319e+09, 5.1170509e+09]]], dtype=float32)>}
Input to reshape is a tensor with 131072 values, but the requested shape has 147968 [Op:Reshape]

generate models:33

analyse the exceptions in iter:46

generate models:34

analyse the exceptions in iter:47

generate models:35

analyse the exceptions in iter:48

generate models:36

final statics:
total operators:28
tensorflow --> nums:11,distinct_bugs:3
mindspore --> nums:5,distinct_bugs:3
torch --> nums:4,distinct_bugs:2
tensorflow --> 
reshape:7
sin:3
softmax:1
mindspore --> 
cos:1
sin:3
softmax:1
torch --> 
sin:3
softmax:1

generate models:36

analyse output arrays in iter:51

pre layer res:
0:conv2d
{'name': 'conv2d', 'output': array([[[[   23138.426,  -951512.06 ,  -926814.4  , ...,   189226.02 ,
          -1033783.94 , -1011831.94 ],
         [ -962864.06 ,   699359.9  ,  1044471.94 , ...,   115718.   ,
            170939.39 ,   542947.8  ],
         [ -170845.98 ,   324063.97 ,   859104.06 , ...,  -966536.5  ,
            453199.97 ,   115780.99 ],
         ...,
         [  510852.25 ,   986750.44 , -1020936.06 , ...,   899455.94 ,
           -814392.6  , -1047919.94 ],
         [  367837.2  ,  1023015.94 ,  -752861.94 , ...,  -597400.06 ,
           -904191.94 ,  -904191.94 ],
         [ -627530.7  ,    69527.97 ,  -752861.94 , ..., -1043608.06 ,
             97314.26 ,   526983.94 ]],

        [[   23138.426,  -951512.06 ,  -926814.4  , ...,   189226.02 ,
          -1033783.94 , -1011831.94 ],
         [ -962864.06 ,   699359.9  ,  1044471.94 , ...,   115718.   ,
            170939.39 ,   542947.8  ],
         [ -170845.98 ,   324063.97 ,   859104.06 , ...,  -966536.5  ,
            453199.97 ,   115780.99 ],
         ...,
         [  510852.25 ,   986750.44 , -1020936.06 , ...,   899455.94 ,
           -814392.6  , -1047919.94 ],
         [  367837.2  ,  1023015.94 ,  -752861.94 , ...,  -597400.06 ,
           -904191.94 ,  -904191.94 ],
         [ -627530.7  ,    69527.97 ,  -752861.94 , ..., -1043608.06 ,
             97314.26 ,   526983.94 ]],

        [[   23138.426,  -951512.06 ,  -926814.4  , ...,   189226.02 ,
          -1033783.94 , -1011831.94 ],
         [ -962864.06 ,   699359.9  ,  1044471.94 , ...,   115718.   ,
            170939.39 ,   542947.8  ],
         [ -170845.98 ,   324063.97 ,   859104.06 , ...,  -966536.5  ,
            453199.97 ,   115780.99 ],
         ...,
         [  510852.25 ,   986750.44 , -1020936.06 , ...,   899455.94 ,
           -814392.6  , -1047919.94 ],
         [  367837.2  ,  1023015.94 ,  -752861.94 , ...,  -597400.06 ,
           -904191.94 ,  -904191.94 ],
         [ -627530.7  ,    69527.97 ,  -752861.94 , ..., -1043608.06 ,
             97314.26 ,   526983.94 ]],

        ...,

        [[   23138.426,  -951512.06 ,  -926814.4  , ...,   189226.02 ,
          -1033783.94 , -1011831.94 ],
         [ -962864.06 ,   699359.9  ,  1044471.94 , ...,   115718.   ,
            170939.39 ,   542947.8  ],
         [ -170845.98 ,   324063.97 ,   859104.06 , ...,  -966536.5  ,
            453199.97 ,   115780.99 ],
         ...,
         [  510852.25 ,   986750.44 , -1020936.06 , ...,   899455.94 ,
           -814392.6  , -1047919.94 ],
         [  367837.2  ,  1023015.94 ,  -752861.94 , ...,  -597400.06 ,
           -904191.94 ,  -904191.94 ],
         [ -627530.7  ,    69527.97 ,  -752861.94 , ..., -1043608.06 ,
             97314.26 ,   526983.94 ]],

        [[   23138.426,  -951512.06 ,  -926814.4  , ...,   189226.02 ,
          -1033783.94 , -1011831.94 ],
         [ -962864.06 ,   699359.9  ,  1044471.94 , ...,   115718.   ,
            170939.39 ,   542947.8  ],
         [ -170845.98 ,   324063.97 ,   859104.06 , ...,  -966536.5  ,
            453199.97 ,   115780.99 ],
         ...,
         [  510852.25 ,   986750.44 , -1020936.06 , ...,   899455.94 ,
           -814392.6  , -1047919.94 ],
         [  367837.2  ,  1023015.94 ,  -752861.94 , ...,  -597400.06 ,
           -904191.94 ,  -904191.94 ],
         [ -627530.7  ,    69527.97 ,  -752861.94 , ..., -1043608.06 ,
             97314.26 ,   526983.94 ]],

        [[   23138.426,  -951512.06 ,  -926814.4  , ...,   189226.02 ,
          -1033783.94 , -1011831.94 ],
         [ -962864.06 ,   699359.9  ,  1044471.94 , ...,   115718.   ,
            170939.39 ,   542947.8  ],
         [ -170845.98 ,   324063.97 ,   859104.06 , ...,  -966536.5  ,
            453199.97 ,   115780.99 ],
         ...,
         [  510852.25 ,   986750.44 , -1020936.06 , ...,   899455.94 ,
           -814392.6  , -1047919.94 ],
         [  367837.2  ,  1023015.94 ,  -752861.94 , ...,  -597400.06 ,
           -904191.94 ,  -904191.94 ],
         [ -627530.7  ,    69527.97 ,  -752861.94 , ..., -1043608.06 ,
             97314.26 ,   526983.94 ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [21], 'to': [3, 4]}
tf node:
{'name': 'log', 'output': array([[[[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        ...,

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [0], 'to': [22]}
ms node:
{'name': 'log', 'output': array([[[[10.049255 ,        nan,        nan, ..., 12.150701 ,
                 nan,        nan],
         [       nan, 13.457919 , 13.859015 , ..., 11.658911 ,
          12.04907  , 13.204768 ],
         [       nan, 12.688698 , 13.663643 , ...,        nan,
          13.024088 , 11.659451 ],
         ...,
         [13.143839 , 13.802174 ,        nan, ..., 13.709541 ,
                 nan,        nan],
         [12.8154   , 13.83826  ,        nan, ...,        nan,
                 nan,        nan],
         [       nan, 11.1494875,        nan, ...,        nan,
          11.485698 , 13.174924 ]],

        [[10.049255 ,        nan,        nan, ..., 12.150701 ,
                 nan,        nan],
         [       nan, 13.457919 , 13.859015 , ..., 11.658911 ,
          12.04907  , 13.204768 ],
         [       nan, 12.688698 , 13.663643 , ...,        nan,
          13.024088 , 11.659451 ],
         ...,
         [13.143839 , 13.802174 ,        nan, ..., 13.709541 ,
                 nan,        nan],
         [12.8154   , 13.83826  ,        nan, ...,        nan,
                 nan,        nan],
         [       nan, 11.1494875,        nan, ...,        nan,
          11.485698 , 13.174924 ]],

        [[10.049255 ,        nan,        nan, ..., 12.150701 ,
                 nan,        nan],
         [       nan, 13.457919 , 13.859015 , ..., 11.658911 ,
          12.04907  , 13.204768 ],
         [       nan, 12.688698 , 13.663643 , ...,        nan,
          13.024088 , 11.659451 ],
         ...,
         [13.143839 , 13.802174 ,        nan, ..., 13.709541 ,
                 nan,        nan],
         [12.8154   , 13.83826  ,        nan, ...,        nan,
                 nan,        nan],
         [       nan, 11.1494875,        nan, ...,        nan,
          11.485698 , 13.174924 ]],

        ...,

        [[10.049255 ,        nan,        nan, ..., 12.150701 ,
                 nan,        nan],
         [       nan, 13.457919 , 13.859015 , ..., 11.658911 ,
          12.04907  , 13.204768 ],
         [       nan, 12.688698 , 13.663643 , ...,        nan,
          13.024088 , 11.659451 ],
         ...,
         [13.143839 , 13.802174 ,        nan, ..., 13.709541 ,
                 nan,        nan],
         [12.8154   , 13.83826  ,        nan, ...,        nan,
                 nan,        nan],
         [       nan, 11.1494875,        nan, ...,        nan,
          11.485698 , 13.174924 ]],

        [[10.049253 ,        nan,        nan, ..., 12.150698 ,
                 nan,        nan],
         [       nan, 13.457919 , 13.859018 , ..., 11.658911 ,
          12.049069 , 13.204771 ],
         [       nan, 12.688698 , 13.663643 , ...,        nan,
          13.024088 , 11.659454 ],
         ...,
         [13.143836 , 13.802173 ,        nan, ..., 13.709541 ,
                 nan,        nan],
         [12.815399 , 13.838263 ,        nan, ...,        nan,
                 nan,        nan],
         [       nan, 11.1494875,        nan, ...,        nan,
          11.485699 , 13.174924 ]],

        [[10.049253 ,        nan,        nan, ..., 12.150698 ,
                 nan,        nan],
         [       nan, 13.457919 , 13.859018 , ..., 11.658911 ,
          12.049069 , 13.204771 ],
         [       nan, 12.688698 , 13.663643 , ...,        nan,
          13.024088 , 11.659454 ],
         ...,
         [13.143836 , 13.802173 ,        nan, ..., 13.709541 ,
                 nan,        nan],
         [12.815399 , 13.838263 ,        nan, ...,        nan,
                 nan,        nan],
         [       nan, 11.1494875,        nan, ...,        nan,
          11.485699 , 13.174924 ]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [0], 'to': [22]}
torch node:
{'name': 'log', 'output': array([[[[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        ...,

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]],

        [[10.04925 ,       nan,       nan, ..., 12.150698,       nan,
                nan],
         [      nan, 13.457921, 13.859022, ..., 11.658912, 12.049065,
          13.204768],
         [      nan, 12.688696, 13.663646, ...,       nan, 13.024089,
          11.659455],
         ...,
         [13.143836, 13.802173,       nan, ..., 13.709545,       nan,
                nan],
         [12.815395, 13.838265,       nan, ...,       nan,       nan,
                nan],
         [      nan, 11.149485,       nan, ...,       nan, 11.485701,
          13.174926]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [0], 'to': [22]}

generate models:37

analyse the exceptions in iter:63

generate models:45

analyse the exceptions in iter:4
tensorflow exception:
{'id': 5, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 1181696), dtype=float32, numpy=
array([[[37136., 36164., 31326., ...,     0.,     0.,     0.]]],
      dtype=float32)>}
Input to reshape is a tensor with 1181696 values, but the requested shape has 1183744 [Op:Reshape]

generate models:5

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:1
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:10

generate models:10

analyse the exceptions in iter:21
tensorflow exception:
{'id': 2, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 65536), dtype=float32, numpy=
array([[[ 1.5701987,  1.5703057,  1.5696796, ...,  1.5574554,
         -1.5694801, -1.5694549]]], dtype=float32)>}
Input to reshape is a tensor with 65536 values, but the requested shape has 73984 [Op:Reshape]

generate models:20

analyse the exceptions in iter:23

generate models:21

analyse the exceptions in iter:24

generate models:22

analyse the exceptions in iter:25
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 287488), dtype=float32, numpy=
array([[[9.563013e+08, 9.625928e+08, 9.877586e+08, ..., 0.000000e+00,
         0.000000e+00, 0.000000e+00]]], dtype=float32)>}
Input to reshape is a tensor with 287488 values, but the requested shape has 295936 [Op:Reshape]

generate models:23

analyse the exceptions in iter:26

generate models:24

analyse the exceptions in iter:29

generate models:27

analyse the exceptions in iter:30

generate models:28

analyse the exceptions in iter:31

generate models:29

analyse the exceptions in iter:36
torch exception:
{'id': 12, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([9.5367e-07], grad_fn=<MeanBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:33

analyse the exceptions in iter:42

generate models:37

analyse the exceptions in iter:43
tensorflow exception:
{'id': 1, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 64, 16, 16), dtype=float32, numpy=
array([[[[[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]],

         [[0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          ...,
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.],
          [0., 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)>}
Input to reshape is a tensor with 16384 values, but the requested shape has 18496 [Op:Reshape]

generate models:38

analyse the exceptions in iter:46
tensorflow exception:
{'id': 6, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 16384), dtype=float32, numpy=
array([[[505856., 333824., 311296., ..., 534528., 321536., 280576.]]],
      dtype=float32)>}
Input to reshape is a tensor with 16384 values, but the requested shape has 18496 [Op:Reshape]

generate models:39

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
reshape:5
mindspore --> 
torch --> 
flatten:1

generate models:39

analyse the exceptions in iter:56
tensorflow exception:
{'id': 19, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 287488), dtype=float32, numpy=
array([[[49112064., 41783296., 37356544., ...,        0.,        0.,
                0.]]], dtype=float32)>}
Input to reshape is a tensor with 287488 values, but the requested shape has 295936 [Op:Reshape]

generate models:42

analyse output arrays in iter:64

pre layer res:
0:sum
{'name': 'sum', 'output': array([[[ 8684.,  9628., 11789., ...,  5631.,  5595.,  6047.],
        [ 8684.,  9628., 11789., ...,  5631.,  5595.,  6047.],
        [ 8684.,  9628., 11789., ...,  5631.,  5595.,  6047.],
        ...,
        [ 8684.,  9628., 11789., ...,  5631.,  5595.,  6047.],
        [ 8684.,  9628., 11789., ...,  5631.,  5595.,  6047.],
        [ 8684.,  9628., 11789., ...,  5631.,  5595.,  6047.]]],
      dtype=float32), 'output_shape': torch.Size([1, 1024, 32]), 'from': [6], 'to': [12]}
tf node:
{'name': 'sin', 'output': array([[[0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        ...,
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32]), 'from': [0], 'to': [17]}
ms node:
{'name': 'sin', 'output': array([[[5.9551412e-01, 8.3132267e-01, 9.8497498e-01, ...,
         9.5389754e-01, 1.7560083e-01, 5.3614038e-01],
        [5.9551412e-01, 8.3132267e-01, 9.8497498e-01, ...,
         9.5389754e-01, 1.7560083e-01, 5.3614038e-01],
        [5.9551412e-01, 8.3132267e-01, 9.8497498e-01, ...,
         9.5389754e-01, 1.7560083e-01, 5.3614038e-01],
        ...,
        [2.4800000e+02, 2.5500000e+02, 2.7200000e+02, ...,
         2.6700000e+02, 2.9000000e+02, 3.0000000e+02],
        [2.5400000e+02, 2.6700000e+02, 2.8000000e+02, ...,
         2.1200000e+02, 2.3500000e+02, 2.6800000e+02],
        [2.7100000e+02, 2.9000000e+02, 3.0000000e+02, ...,
         1.9800000e+02, 2.2200000e+02, 2.4500000e+02]]], dtype=float32), 'output_shape': (1, 1024, 32), 'from': [0], 'to': [17]}
torch node:
{'name': 'sin', 'output': array([[[0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        ...,
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044],
        [0.5955141 , 0.83132267, 0.984975  , ..., 0.95389754,
         0.17560083, 0.53614044]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32]), 'from': [0], 'to': [17]}

generate models:45

analyse the exceptions in iter:71

generate models:49

analyse the exceptions in iter:79

generate models:53

analyse the exceptions in iter:5
tensorflow exception:
{'id': 2, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 101344), dtype=float32, numpy=array([[[1., 1., 1., ..., 0., 0., 0.]]], dtype=float32)>}
Input to reshape is a tensor with 101344 values, but the requested shape has 102400 [Op:Reshape]

generate models:6

analyse the exceptions in iter:7
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 19680), dtype=float32, numpy=array([[[1., 1., 1., ..., 0., 0., 0.]]], dtype=float32)>}
Input to reshape is a tensor with 19680 values, but the requested shape has 20736 [Op:Reshape]

generate models:8

analyse the exceptions in iter:9
tensorflow exception:
{'id': 8, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 101344), dtype=float32, numpy=array([[[366., 275., 301., ...,   0.,   0.,   0.]]], dtype=float32)>}
Input to reshape is a tensor with 101344 values, but the requested shape has 102400 [Op:Reshape]

generate models:9

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:3
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:10
tensorflow exception:
{'id': 9, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 9216), dtype=float32, numpy=
array([[[0.0625, 0.0625, 0.0625, ..., 0.    , 0.    , 0.    ]]],
      dtype=float32)>}
Input to reshape is a tensor with 9216 values, but the requested shape has 9248 [Op:Reshape]

generate models:10

analyse the exceptions in iter:11
torch exception:
{'id': 13, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([0.0800, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
       grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:11

analyse the exceptions in iter:12
tensorflow exception:
{'id': 4, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 261088), dtype=float32, numpy=
array([[[1552516., 1507984., 1517824., ...,       0.,       0.,
               0.]]], dtype=float32)>}
Input to reshape is a tensor with 261088 values, but the requested shape has 262144 [Op:Reshape]

generate models:12

analyse the exceptions in iter:14

generate models:13

analyse the exceptions in iter:17

generate models:16

analyse the exceptions in iter:21

generate models:18

analyse the exceptions in iter:22

generate models:19

analyse the exceptions in iter:23
tensorflow exception:
{'id': 6, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 16384), dtype=float32, numpy=
array([[[38016., 34560., 38144., ..., 63616., 60416., 69248.]]],
      dtype=float32)>}
Input to reshape is a tensor with 16384 values, but the requested shape has 18496 [Op:Reshape]

generate models:20

analyse output arrays in iter:24

pre layer res:
0:log
{'name': 'log', 'output': array([[[[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 8.754003 , 9.0148115, ..., 9.624831 , 9.773834 ,
          9.71764  ],
         [     -inf, 9.093357 , 9.086137 , ..., 9.237177 , 9.80433  ,
          9.80079  ],
         ...,
         [     -inf, 8.962904 , 9.40063  , ..., 9.791885 , 9.594786 ,
          7.931644 ],
         [     -inf, 8.983189 , 9.30928  , ..., 8.184235 , 8.995165 ,
          9.306377 ],
         [     -inf, 9.0340805, 9.142489 , ..., 9.162829 , 9.132163 ,
          8.378391 ]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 8.754003 , 9.0148115, ..., 9.624831 , 9.773834 ,
          9.71764  ],
         [     -inf, 9.093357 , 9.086137 , ..., 9.237177 , 9.80433  ,
          9.80079  ],
         ...,
         [     -inf, 8.962904 , 9.40063  , ..., 9.791885 , 9.594786 ,
          7.931644 ],
         [     -inf, 8.983189 , 9.30928  , ..., 8.184235 , 8.995165 ,
          9.306377 ],
         [     -inf, 9.0340805, 9.142489 , ..., 9.162829 , 9.132163 ,
          8.378391 ]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 8.754003 , 9.0148115, ..., 9.624831 , 9.773834 ,
          9.71764  ],
         [     -inf, 9.093357 , 9.086137 , ..., 9.237177 , 9.80433  ,
          9.80079  ],
         ...,
         [     -inf, 8.962904 , 9.40063  , ..., 9.791885 , 9.594786 ,
          7.931644 ],
         [     -inf, 8.983189 , 9.30928  , ..., 8.184235 , 8.995165 ,
          9.306377 ],
         [     -inf, 9.0340805, 9.142489 , ..., 9.162829 , 9.132163 ,
          8.378391 ]],

        ...,

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 8.754003 , 9.0148115, ..., 9.624831 , 9.773834 ,
          9.71764  ],
         [     -inf, 9.093357 , 9.086137 , ..., 9.237177 , 9.80433  ,
          9.80079  ],
         ...,
         [     -inf, 8.962904 , 9.40063  , ..., 9.791885 , 9.594786 ,
          7.931644 ],
         [     -inf, 8.983189 , 9.30928  , ..., 8.184235 , 8.995165 ,
          9.306377 ],
         [     -inf, 9.0340805, 9.142489 , ..., 9.162829 , 9.132163 ,
          8.378391 ]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 8.754003 , 9.0148115, ..., 9.624831 , 9.773834 ,
          9.71764  ],
         [     -inf, 9.093357 , 9.086137 , ..., 9.237177 , 9.80433  ,
          9.80079  ],
         ...,
         [     -inf, 8.962904 , 9.40063  , ..., 9.791885 , 9.594786 ,
          7.931644 ],
         [     -inf, 8.983189 , 9.30928  , ..., 8.184235 , 8.995165 ,
          9.306377 ],
         [     -inf, 9.0340805, 9.142489 , ..., 9.162829 , 9.132163 ,
          8.378391 ]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 8.754003 , 9.0148115, ..., 9.624831 , 9.773834 ,
          9.71764  ],
         [     -inf, 9.093357 , 9.086137 , ..., 9.237177 , 9.80433  ,
          9.80079  ],
         ...,
         [     -inf, 8.962904 , 9.40063  , ..., 9.791885 , 9.594786 ,
          7.931644 ],
         [     -inf, 8.983189 , 9.30928  , ..., 8.184235 , 8.995165 ,
          9.306377 ],
         [     -inf, 9.0340805, 9.142489 , ..., 9.162829 , 9.132163 ,
          8.378391 ]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 17, 17]), 'from': [1], 'to': [2, 3]}
tf node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 17, 17]), 'from': [0], 'to': [2]}
ms node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215951 ,  0.39857942, ..., -0.19872244,
          -0.34200934, -0.2886926 ],
         [        nan,  0.32538962,  0.33220842, ...,  0.18649977,
          -0.37050518, -0.36721477],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589144 ,
          -0.16918996,  0.996986  ],
         [        nan,  0.42737773,  0.11524285, ...,  0.94596064,
           0.41651994,  0.118126  ],
         [        nan,  0.38083518,  0.27855706, ...,  0.258965  ,
           0.2884606 ,  0.8656216 ]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215951 ,  0.39857942, ..., -0.19872244,
          -0.34200934, -0.2886926 ],
         [        nan,  0.32538962,  0.33220842, ...,  0.18649977,
          -0.37050518, -0.36721477],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589144 ,
          -0.16918996,  0.996986  ],
         [        nan,  0.42737773,  0.11524285, ...,  0.94596064,
           0.41651994,  0.118126  ],
         [        nan,  0.38083518,  0.27855706, ...,  0.258965  ,
           0.2884606 ,  0.8656216 ]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215951 ,  0.39857942, ..., -0.19872244,
          -0.34200934, -0.2886926 ],
         [        nan,  0.32538962,  0.33220842, ...,  0.18649977,
          -0.37050518, -0.36721477],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589144 ,
          -0.16918996,  0.996986  ],
         [        nan,  0.42737773,  0.11524285, ...,  0.94596064,
           0.41651994,  0.118126  ],
         [        nan,  0.38083518,  0.27855706, ...,  0.258965  ,
           0.2884606 ,  0.8656216 ]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215951 ,  0.39857942, ..., -0.19872244,
          -0.34200934, -0.2886926 ],
         [        nan,  0.32538962,  0.33220842, ...,  0.18649977,
          -0.37050518, -0.36721477],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589144 ,
          -0.16918996,  0.996986  ],
         [        nan,  0.42737773,  0.11524285, ...,  0.94596064,
           0.41651994,  0.118126  ],
         [        nan,  0.38083518,  0.27855706, ...,  0.258965  ,
           0.2884606 ,  0.8656216 ]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215951 ,  0.39857942, ..., -0.19872244,
          -0.34200934, -0.2886926 ],
         [        nan,  0.32538962,  0.33220842, ...,  0.18649977,
          -0.37050518, -0.36721477],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589144 ,
          -0.16918996,  0.996986  ],
         [        nan,  0.42737773,  0.11524285, ...,  0.94596064,
           0.41651994,  0.118126  ],
         [        nan,  0.38083518,  0.27855706, ...,  0.258965  ,
           0.2884606 ,  0.8656216 ]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215951 ,  0.39857942, ..., -0.19872244,
          -0.34200934, -0.2886926 ],
         [        nan,  0.32538962,  0.33220842, ...,  0.18649977,
          -0.37050518, -0.36721477],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589144 ,
          -0.16918996,  0.996986  ],
         [        nan,  0.42737773,  0.11524285, ...,  0.94596064,
           0.41651994,  0.118126  ],
         [        nan,  0.38083518,  0.27855706, ...,  0.258965  ,
           0.2884606 ,  0.8656216 ]]]], dtype=float32), 'output_shape': (1, 64, 17, 17), 'from': [0], 'to': [2]}
torch node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,  0.6215936 ,  0.39857855, ..., -0.19872151,
          -0.34201115, -0.28869352],
         [        nan,  0.3253869 ,  0.3322057 , ...,  0.18650259,
          -0.37050432, -0.3672139 ],
         ...,
         [        nan,  0.44562653,  0.02414562, ..., -0.3589171 ,
          -0.16918997,  0.9969858 ],
         [        nan,  0.42737687,  0.11524095, ...,  0.94596034,
           0.41651908,  0.11812411],
         [        nan,  0.38083342,  0.27855432, ...,  0.25896314,
           0.28845698,  0.86561966]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 17, 17]), 'from': [0], 'to': [2]}

generate models:21

analyse the exceptions in iter:25

generate models:22

analyse the exceptions in iter:33

generate models:29

analyse the exceptions in iter:34

generate models:30

analyse the exceptions in iter:35

generate models:31

final statics:
total operators:28
tensorflow --> nums:7,distinct_bugs:2
mindspore --> nums:1,distinct_bugs:1
torch --> nums:2,distinct_bugs:2
tensorflow --> 
reshape:6
sin:1
mindspore --> 
sin:1
torch --> 
flatten:1
sin:1

generate models:38

final statics:
total operators:28
tensorflow --> nums:7,distinct_bugs:2
mindspore --> nums:1,distinct_bugs:1
torch --> nums:2,distinct_bugs:2
tensorflow --> 
reshape:6
sin:1
mindspore --> 
sin:1
torch --> 
flatten:1
sin:1

generate models:53

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:8
tensorflow exception:
{'id': 10, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 2576), dtype=float32, numpy=
array([[[951.8918, 951.8918, 951.8918, ...,   0.    ,   0.    ,
           0.    ]]], dtype=float32)>}
Input to reshape is a tensor with 2576 values, but the requested shape has 2592 [Op:Reshape]

generate models:9

analyse the exceptions in iter:9
tensorflow exception:
{'id': 4, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 8, 16, 16), dtype=float32, numpy=
array([[[[[187392., 140800., 154112., ..., 320512., 321024., 315904.],
          [280576., 240640., 297984., ..., 102400., 146944., 203776.],
          [234496., 240128., 242176., ...,  61952.,  60416.,  55296.],
          ...,
          [142336.,  53248.,  40960., ...,  53760.,  41472.,  39936.],
          [118272.,  73728.,  64512., ..., 120320., 128512., 134144.],
          [115200., 122880., 137216., ..., 160768., 166400., 168960.]],

         [[187392., 140800., 154112., ..., 320512., 321024., 315904.],
          [280576., 240640., 297984., ..., 102400., 146944., 203776.],
          [234496., 240128., 242176., ...,  61952.,  60416.,  55296.],
          ...,
          [142336.,  53248.,  40960., ...,  53760.,  41472.,  39936.],
          [118272.,  73728.,  64512., ..., 120320., 128512., 134144.],
          [115200., 122880., 137216., ..., 160768., 166400., 168960.]],

         [[187392., 140800., 154112., ..., 320512., 321024., 315904.],
          [280576., 240640., 297984., ..., 102400., 146944., 203776.],
          [234496., 240128., 242176., ...,  61952.,  60416.,  55296.],
          ...,
          [142336.,  53248.,  40960., ...,  53760.,  41472.,  39936.],
          [118272.,  73728.,  64512., ..., 120320., 128512., 134144.],
          [115200., 122880., 137216., ..., 160768., 166400., 168960.]],

         ...,

         [[187392., 140800., 154112., ..., 320512., 321024., 315904.],
          [280576., 240640., 297984., ..., 102400., 146944., 203776.],
          [234496., 240128., 242176., ...,  61952.,  60416.,  55296.],
          ...,
          [142336.,  53248.,  40960., ...,  53760.,  41472.,  39936.],
          [118272.,  73728.,  64512., ..., 120320., 128512., 134144.],
          [115200., 122880., 137216., ..., 160768., 166400., 168960.]],

         [[187392., 140800., 154112., ..., 320512., 321024., 315904.],
          [280576., 240640., 297984., ..., 102400., 146944., 203776.],
          [234496., 240128., 242176., ...,  61952.,  60416.,  55296.],
          ...,
          [142336.,  53248.,  40960., ...,  53760.,  41472.,  39936.],
          [118272.,  73728.,  64512., ..., 120320., 128512., 134144.],
          [115200., 122880., 137216., ..., 160768., 166400., 168960.]],

         [[187392., 140800., 154112., ..., 320512., 321024., 315904.],
          [280576., 240640., 297984., ..., 102400., 146944., 203776.],
          [234496., 240128., 242176., ...,  61952.,  60416.,  55296.],
          ...,
          [142336.,  53248.,  40960., ...,  53760.,  41472.,  39936.],
          [118272.,  73728.,  64512., ..., 120320., 128512., 134144.],
          [115200., 122880., 137216., ..., 160768., 166400., 168960.]]]]],
      dtype=float32)>}
Input to reshape is a tensor with 2048 values, but the requested shape has 2592 [Op:Reshape]

generate models:10

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:2
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:10

generate models:11

analyse the exceptions in iter:13
tensorflow exception:
{'id': 10, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 64992), dtype=float32, numpy=
array([[[1.8354747e+12, 2.4840453e+11, 7.4048377e+14, ...,
         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)>}
Input to reshape is a tensor with 64992 values, but the requested shape has 65536 [Op:Reshape]

generate models:13

analyse the exceptions in iter:20
tensorflow exception:
{'id': 7, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 64, 16, 16), dtype=float32, numpy=
array([[[[[1904640., 1761280., 2596864., ..., 2560000., 2093056.,
           2179072.],
          [2015232., 1798144., 2551808., ..., 2424832., 1986560.,
           2142208.],
          [1884160., 1769472., 2490368., ..., 2424832., 2207744.,
           2019328.],
          ...,
          [1212416., 1175552., 2281472., ..., 1921024., 2019328.,
           2560000.],
          [1458176.,  958464., 2220032., ..., 2252800., 2445312.,
           2584576.],
          [1728512., 1548288., 2306048., ..., 2469888., 2310144.,
           2576384.]],

         [[1904640., 1761280., 2596864., ..., 2560000., 2093056.,
           2179072.],
          [2015232., 1798144., 2551808., ..., 2424832., 1986560.,
           2142208.],
          [1884160., 1769472., 2490368., ..., 2424832., 2207744.,
           2019328.],
          ...,
          [1212416., 1175552., 2281472., ..., 1921024., 2019328.,
           2560000.],
          [1458176.,  958464., 2220032., ..., 2252800., 2445312.,
           2584576.],
          [1728512., 1548288., 2306048., ..., 2469888., 2310144.,
           2576384.]],

         [[1904640., 1761280., 2596864., ..., 2560000., 2093056.,
           2179072.],
          [2015232., 1798144., 2551808., ..., 2424832., 1986560.,
           2142208.],
          [1884160., 1769472., 2490368., ..., 2424832., 2207744.,
           2019328.],
          ...,
          [1212416., 1175552., 2281472., ..., 1921024., 2019328.,
           2560000.],
          [1458176.,  958464., 2220032., ..., 2252800., 2445312.,
           2584576.],
          [1728512., 1548288., 2306048., ..., 2469888., 2310144.,
           2576384.]],

         ...,

         [[1904640., 1761280., 2596864., ..., 2560000., 2093056.,
           2179072.],
          [2015232., 1798144., 2551808., ..., 2424832., 1986560.,
           2142208.],
          [1884160., 1769472., 2490368., ..., 2424832., 2207744.,
           2019328.],
          ...,
          [1212416., 1175552., 2281472., ..., 1921024., 2019328.,
           2560000.],
          [1458176.,  958464., 2220032., ..., 2252800., 2445312.,
           2584576.],
          [1728512., 1548288., 2306048., ..., 2469888., 2310144.,
           2576384.]],

         [[1904640., 1761280., 2596864., ..., 2560000., 2093056.,
           2179072.],
          [2015232., 1798144., 2551808., ..., 2424832., 1986560.,
           2142208.],
          [1884160., 1769472., 2490368., ..., 2424832., 2207744.,
           2019328.],
          ...,
          [1212416., 1175552., 2281472., ..., 1921024., 2019328.,
           2560000.],
          [1458176.,  958464., 2220032., ..., 2252800., 2445312.,
           2584576.],
          [1728512., 1548288., 2306048., ..., 2469888., 2310144.,
           2576384.]],

         [[1904640., 1761280., 2596864., ..., 2560000., 2093056.,
           2179072.],
          [2015232., 1798144., 2551808., ..., 2424832., 1986560.,
           2142208.],
          [1884160., 1769472., 2490368., ..., 2424832., 2207744.,
           2019328.],
          ...,
          [1212416., 1175552., 2281472., ..., 1921024., 2019328.,
           2560000.],
          [1458176.,  958464., 2220032., ..., 2252800., 2445312.,
           2584576.],
          [1728512., 1548288., 2306048., ..., 2469888., 2310144.,
           2576384.]]]]], dtype=float32)>}
Input to reshape is a tensor with 16384 values, but the requested shape has 18496 [Op:Reshape]

generate models:16

analyse the exceptions in iter:26

generate models:20

analyse the exceptions in iter:27

generate models:21

analyse the exceptions in iter:31
tensorflow exception:
{'id': 1, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 16384), dtype=float32, numpy=
array([[[32.      , 32.      , 31.999989, ..., 32.      , 32.      ,
         32.      ]]], dtype=float32)>}
Input to reshape is a tensor with 16384 values, but the requested shape has 18496 [Op:Reshape]

generate models:23

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
reshape:5
mindspore --> 
torch --> 

generate models:30

analyse output arrays in iter:80

pre layer res:
10:slice
{'name': 'slice', 'output': array([[inf, inf, inf, ..., inf, inf, inf]], dtype=float32), 'output_shape': torch.Size([1, 57600]), 'from': [8], 'to': [18]}
tf node:
{'name': 'cos', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 57600]), 'from': [10], 'to': [11]}
ms node:
{'name': 'cos', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': (1, 57600), 'from': [10], 'to': [11]}
torch node:
{'name': 'cos', 'output': array([[nan, nan, nan, ..., nan, nan, nan]], dtype=float32), 'output_shape': torch.Size([1, 57600]), 'from': [10], 'to': [11]}

generate models:40

analyse the exceptions in iter:85
tensorflow exception:
{'id': 5, 'name': 'reshape', 'framework': 'tensorflow', 'input_datas': <tf.Tensor: shape=(1, 1, 256, 32, 32), dtype=float32, numpy=
array([[[[[524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          ...,
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.]],

         [[524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          ...,
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.]],

         [[524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          ...,
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.]],

         ...,

         [[524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          ...,
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.]],

         [[524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          ...,
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.]],

         [[524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          ...,
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.],
          [524288., 524288., 524288., ..., 524288., 524288., 524288.]]]]],
      dtype=float32)>}
Input to reshape is a tensor with 262144 values, but the requested shape has 295936 [Op:Reshape]

generate models:42

analyse output arrays in iter:86

pre layer res:
3:reshape
{'name': 'reshape', 'output': array([[[[606208., 378880., 167936., ..., 542720., 403456., 407552.],
         [612352., 358400., 180224., ..., 557056., 468992., 526336.],
         [602112., 382976., 264192., ..., 512000., 493568., 538624.],
         ...,
         [899072., 940032., 958464., ..., 860160., 866304., 862208.],
         [886784., 901120., 909312., ..., 913408., 884736., 876544.],
         [856064., 847872., 825344., ..., 897024., 897024., 894976.]],

        [[606208., 378880., 167936., ..., 542720., 403456., 407552.],
         [612352., 358400., 180224., ..., 557056., 468992., 526336.],
         [602112., 382976., 264192., ..., 512000., 493568., 538624.],
         ...,
         [899072., 940032., 958464., ..., 860160., 866304., 862208.],
         [886784., 901120., 909312., ..., 913408., 884736., 876544.],
         [856064., 847872., 825344., ..., 897024., 897024., 894976.]],

        [[606208., 378880., 167936., ..., 542720., 403456., 407552.],
         [612352., 358400., 180224., ..., 557056., 468992., 526336.],
         [602112., 382976., 264192., ..., 512000., 493568., 538624.],
         ...,
         [899072., 940032., 958464., ..., 860160., 866304., 862208.],
         [886784., 901120., 909312., ..., 913408., 884736., 876544.],
         [856064., 847872., 825344., ..., 897024., 897024., 894976.]],

        ...,

        [[606208., 378880., 167936., ..., 542720., 403456., 407552.],
         [612352., 358400., 180224., ..., 557056., 468992., 526336.],
         [602112., 382976., 264192., ..., 512000., 493568., 538624.],
         ...,
         [899072., 940032., 958464., ..., 860160., 866304., 862208.],
         [886784., 901120., 909312., ..., 913408., 884736., 876544.],
         [856064., 847872., 825344., ..., 897024., 897024., 894976.]],

        [[606208., 378880., 167936., ..., 542720., 403456., 407552.],
         [612352., 358400., 180224., ..., 557056., 468992., 526336.],
         [602112., 382976., 264192., ..., 512000., 493568., 538624.],
         ...,
         [899072., 940032., 958464., ..., 860160., 866304., 862208.],
         [886784., 901120., 909312., ..., 913408., 884736., 876544.],
         [856064., 847872., 825344., ..., 897024., 897024., 894976.]],

        [[606208., 378880., 167936., ..., 542720., 403456., 407552.],
         [612352., 358400., 180224., ..., 557056., 468992., 526336.],
         [602112., 382976., 264192., ..., 512000., 493568., 538624.],
         ...,
         [899072., 940032., 958464., ..., 860160., 866304., 862208.],
         [886784., 901120., 909312., ..., 913408., 884736., 876544.],
         [856064., 847872., 825344., ..., 897024., 897024., 894976.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [2], 'to': [0]}
tf node:
{'name': 'sin', 'output': array([[[[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        ...,

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [3], 'to': [13]}
ms node:
{'name': 'sin', 'output': array([[[[-1.6219930e-03, -7.0638961e-01, -8.2876116e-01, ...,
          -4.2983896e-01,  1.0486225e-01, -5.0705534e-01],
         [-8.1738234e-01,  7.3583108e-01, -2.5151137e-01, ...,
           9.7724015e-01,  6.1255670e-01, -1.4943530e-01],
         [ 5.9333712e-01, -1.4702918e-01,  2.3206843e-01, ...,
           8.7368143e-01, -9.7316796e-01, -8.8249207e-01],
         ...,
         [-9.9982285e-01, -9.9780983e-01,  9.7809231e-01, ...,
          -9.7706777e-01, -3.9033428e-01, -8.6129606e-01],
         [ 3.5085678e-01, -9.5545793e-01,  2.4329880e-03, ...,
           5.9659630e-01,  6.2637645e-01,  9.2876095e-01],
         [-9.1216958e-01,  1.2476727e-01, -4.6710354e-01, ...,
          -9.4367433e-01, -9.4367433e-01, -7.9265690e-01]],

        [[-1.6219930e-03, -7.0638961e-01, -8.2876116e-01, ...,
          -4.2983896e-01,  1.0486225e-01, -5.0705534e-01],
         [-8.1738234e-01,  7.3583108e-01, -2.5151137e-01, ...,
           9.7724015e-01,  6.1255670e-01, -1.4943530e-01],
         [ 5.9333712e-01, -1.4702918e-01,  2.3206843e-01, ...,
           8.7368143e-01, -9.7316796e-01, -8.8249207e-01],
         ...,
         [-9.9982285e-01, -9.9780983e-01,  9.7809231e-01, ...,
          -9.7706777e-01, -3.9033428e-01, -8.6129606e-01],
         [ 3.5085678e-01, -9.5545793e-01,  2.4329880e-03, ...,
           5.9659630e-01,  6.2637645e-01,  9.2876095e-01],
         [-9.1216958e-01,  1.2476727e-01, -4.6710354e-01, ...,
          -9.4367433e-01, -9.4367433e-01, -7.9265690e-01]],

        [[-1.6219930e-03, -7.0638961e-01, -8.2876116e-01, ...,
          -4.2983896e-01,  1.0486225e-01, -5.0705534e-01],
         [-8.1738234e-01,  7.3583108e-01, -2.5151137e-01, ...,
           9.7724015e-01,  6.1255670e-01, -1.4943530e-01],
         [ 5.9333712e-01, -1.4702918e-01,  2.3206843e-01, ...,
           8.7368143e-01, -9.7316796e-01, -8.8249207e-01],
         ...,
         [-9.9982285e-01, -9.9780983e-01,  9.7809231e-01, ...,
          -9.7706777e-01, -3.9033428e-01, -8.6129606e-01],
         [ 3.5085678e-01, -9.5545793e-01,  2.4329880e-03, ...,
           5.9659630e-01,  6.2637645e-01,  9.2876095e-01],
         [-9.1216958e-01,  1.2476727e-01, -4.6710354e-01, ...,
          -9.4367433e-01, -9.4367433e-01, -7.9265690e-01]],

        ...,

        [[ 6.0620800e+05,  3.7888000e+05,  1.6793600e+05, ...,
           5.4272000e+05,  4.0345600e+05,  4.0755200e+05],
         [ 6.1235200e+05,  3.5840000e+05,  1.8022400e+05, ...,
           5.5705600e+05,  4.6899200e+05,  5.2633600e+05],
         [ 6.0211200e+05,  3.8297600e+05,  2.6419200e+05, ...,
           5.1200000e+05,  4.9356800e+05,  5.3862400e+05],
         ...,
         [ 8.9907200e+05,  9.4003200e+05,  9.5846400e+05, ...,
           8.6016000e+05,  8.6630400e+05,  8.6220800e+05],
         [ 8.8678400e+05,  9.0112000e+05,  9.0931200e+05, ...,
           9.1340800e+05,  8.8473600e+05,  8.7654400e+05],
         [ 8.5606400e+05,  8.4787200e+05,  8.2534400e+05, ...,
           8.9702400e+05,  8.9702400e+05,  8.9497600e+05]],

        [[ 6.0620800e+05,  3.7888000e+05,  1.6793600e+05, ...,
           5.4272000e+05,  4.0345600e+05,  4.0755200e+05],
         [ 6.1235200e+05,  3.5840000e+05,  1.8022400e+05, ...,
           5.5705600e+05,  4.6899200e+05,  5.2633600e+05],
         [ 6.0211200e+05,  3.8297600e+05,  2.6419200e+05, ...,
           5.1200000e+05,  4.9356800e+05,  5.3862400e+05],
         ...,
         [ 8.9907200e+05,  9.4003200e+05,  9.5846400e+05, ...,
           8.6016000e+05,  8.6630400e+05,  8.6220800e+05],
         [ 8.8678400e+05,  9.0112000e+05,  9.0931200e+05, ...,
           9.1340800e+05,  8.8473600e+05,  8.7654400e+05],
         [ 8.5606400e+05,  8.4787200e+05,  8.2534400e+05, ...,
           8.9702400e+05,  8.9702400e+05,  8.9497600e+05]],

        [[ 6.0620800e+05,  3.7888000e+05,  1.6793600e+05, ...,
           5.4272000e+05,  4.0345600e+05,  4.0755200e+05],
         [ 6.1235200e+05,  3.5840000e+05,  1.8022400e+05, ...,
           5.5705600e+05,  4.6899200e+05,  5.2633600e+05],
         [ 6.0211200e+05,  3.8297600e+05,  2.6419200e+05, ...,
           5.1200000e+05,  4.9356800e+05,  5.3862400e+05],
         ...,
         [ 8.9907200e+05,  9.4003200e+05,  9.5846400e+05, ...,
           8.6016000e+05,  8.6630400e+05,  8.6220800e+05],
         [ 8.8678400e+05,  9.0112000e+05,  9.0931200e+05, ...,
           9.1340800e+05,  8.8473600e+05,  8.7654400e+05],
         [ 8.5606400e+05,  8.4787200e+05,  8.2534400e+05, ...,
           8.9702400e+05,  8.9702400e+05,  8.9497600e+05]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [3], 'to': [13]}
torch node:
{'name': 'sin', 'output': array([[[[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        ...,

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]],

        [[-0.00162199, -0.7063896 , -0.82876116, ..., -0.42983896,
           0.10486225, -0.50705534],
         [-0.81738234,  0.7358311 , -0.25151137, ...,  0.97724015,
           0.6125567 , -0.1494353 ],
         [ 0.5933371 , -0.14702918,  0.23206843, ...,  0.8736814 ,
          -0.97316796, -0.88249207],
         ...,
         [-0.99982285, -0.9978098 ,  0.9780923 , ..., -0.97706777,
          -0.39033428, -0.86129606],
         [ 0.35085678, -0.9554579 ,  0.00243299, ...,  0.5965963 ,
           0.62637645,  0.92876095],
         [-0.9121696 ,  0.12476727, -0.46710354, ..., -0.9436743 ,
          -0.9436743 , -0.7926569 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [3], 'to': [13]}

generate models:43

analyse the exceptions in iter:88

generate models:44

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse the exceptions in iter:31
tensorflow exception:
{'id': 22, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([2.5393e+10], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 22, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([2.5393e+10], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:25

analyse the exceptions in iter:33
tensorflow exception:
{'id': 11, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([92405.2500], grad_fn=<MeanBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 11, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([92405.2500], grad_fn=<MeanBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:27

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:2,distinct_bugs:1
tensorflow --> 
flatten:2
mindspore --> 
torch --> 
flatten:2

generate models:36

analyse output arrays in iter:55

pre layer res:
3:softmax
{'name': 'softmax', 'output': array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.0000000e+00, 2.8625186e-20, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6699318e-05, 1.8045938e-35, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          5.2422390e-22, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 1.1446674e-24, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [3.9924520e-30, 1.1136820e-39, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [2.8625186e-20, 1.2664166e-14, 1.6038109e-28, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.0000000e+00, 2.8625186e-20, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6699318e-05, 1.8045938e-35, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          5.2422390e-22, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 1.1446674e-24, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [3.9924520e-30, 1.1136820e-39, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [2.8625186e-20, 1.2664166e-14, 1.6038109e-28, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.0000000e+00, 2.8625186e-20, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6699318e-05, 1.8045938e-35, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          5.2422390e-22, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 1.1446674e-24, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [3.9924520e-30, 1.1136820e-39, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [2.8625186e-20, 1.2664166e-14, 1.6038109e-28, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        ...,

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.0000000e+00, 2.8625186e-20, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6699318e-05, 1.8045938e-35, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          5.2422390e-22, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 1.1446674e-24, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [3.9924520e-30, 1.1136820e-39, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [2.8625186e-20, 1.2664166e-14, 1.6038109e-28, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.0000000e+00, 2.8625186e-20, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6699318e-05, 1.8045938e-35, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          5.2422390e-22, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 1.1446674e-24, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [3.9924520e-30, 1.1136820e-39, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [2.8625186e-20, 1.2664166e-14, 1.6038109e-28, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.0000000e+00, 2.8625186e-20, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          1.6699318e-05, 1.8045938e-35, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          5.2422390e-22, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 1.1446674e-24, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [3.9924520e-30, 1.1136820e-39, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [2.8625186e-20, 1.2664166e-14, 1.6038109e-28, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [40], 'to': [2]}
tf node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [3], 'to': [4]}
ms node:
{'name': 'log', 'output': array([[[[          -inf,           -inf,           -inf, ...,
          -1.4305115e-06, -4.4999996e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.1000143e+01, -8.0000145e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -4.9000122e+01,           -inf,           -inf],
         ...,
         [          -inf,           -inf, -5.5126923e+01, ...,
                    -inf,           -inf,           -inf],
         [-6.7693146e+01,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [-4.4999996e+01, -3.2000004e+01, -6.3999996e+01, ...,
                    -inf,           -inf,           -inf]],

        [[          -inf,           -inf,           -inf, ...,
          -1.4305115e-06, -4.4999996e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.1000143e+01, -8.0000145e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -4.9000122e+01,           -inf,           -inf],
         ...,
         [          -inf,           -inf, -5.5126923e+01, ...,
                    -inf,           -inf,           -inf],
         [-6.7693146e+01,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [-4.4999996e+01, -3.2000004e+01, -6.3999996e+01, ...,
                    -inf,           -inf,           -inf]],

        [[          -inf,           -inf,           -inf, ...,
          -1.4305115e-06, -4.4999996e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.1000143e+01, -8.0000145e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -4.9000122e+01,           -inf,           -inf],
         ...,
         [          -inf,           -inf, -5.5126923e+01, ...,
                    -inf,           -inf,           -inf],
         [-6.7693146e+01,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [-4.4999996e+01, -3.2000004e+01, -6.3999996e+01, ...,
                    -inf,           -inf,           -inf]],

        ...,

        [[          -inf,           -inf,           -inf, ...,
          -1.4305115e-06, -4.4999996e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.1000143e+01, -8.0000145e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -4.9000122e+01,           -inf,           -inf],
         ...,
         [          -inf,           -inf, -5.5126923e+01, ...,
                    -inf,           -inf,           -inf],
         [-6.7693146e+01,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [-4.4999996e+01, -3.2000004e+01, -6.3999996e+01, ...,
                    -inf,           -inf,           -inf]],

        [[          -inf,           -inf,           -inf, ...,
          -1.4305115e-06, -4.4999996e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.1000143e+01, -8.0000145e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -4.9000122e+01,           -inf,           -inf],
         ...,
         [          -inf,           -inf, -5.5126923e+01, ...,
                    -inf,           -inf,           -inf],
         [-6.7693146e+01,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [-4.4999996e+01, -3.2000004e+01, -6.3999996e+01, ...,
                    -inf,           -inf,           -inf]],

        [[          -inf,           -inf,           -inf, ...,
          -1.4305115e-06, -4.4999996e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.1000143e+01, -8.0000145e+01,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -4.9000122e+01,           -inf,           -inf],
         ...,
         [          -inf,           -inf, -5.5126923e+01, ...,
                    -inf,           -inf,           -inf],
         [-6.7693146e+01,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [-4.4999996e+01, -3.2000004e+01, -6.3999996e+01, ...,
                    -inf,           -inf,           -inf]]]],
      dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [3], 'to': [4]}
torch node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,   0.      ,
          -45.      ,       -inf],
         [      -inf,       -inf,       -inf, ..., -11.000143,
          -80.000145,       -inf],
         [      -inf,       -inf,       -inf, ..., -49.000122,
                -inf,       -inf],
         ...,
         [      -inf,       -inf, -55.126926, ...,       -inf,
                -inf,       -inf],
         [-67.693146, -89.693146,       -inf, ...,       -inf,
                -inf,       -inf],
         [-45.      , -32.      , -64.      , ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [3], 'to': [4]}

generate models:39

analyse the exceptions in iter:74
tensorflow exception:
{'id': 14, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 14, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:52

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:3,distinct_bugs:1
tensorflow --> 
flatten:3
mindspore --> 
log:1
torch --> 
flatten:3

generate models:59

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:42

analyse output arrays in iter:55

pre layer res:
6:softmax
{'name': 'softmax', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [2], 'to': [5]}
tf node:
{'name': 'sin', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [6], 'to': [9]}
ms node:
{'name': 'sin', 'output': array([[[[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         ...,
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         ...,
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         ...,
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        ...,

        [[245248., 271872., 292352., ..., 281088., 351744., 360448.],
         [259072., 296960., 308224., ..., 320000., 340480., 367104.],
         [262656., 275968., 291328., ..., 356352., 305152., 350720.],
         ...,
         [366592., 359936., 345600., ..., 313856., 259072., 190976.],
         [343552., 324608., 303104., ..., 325120., 268288., 207360.],
         [308736., 280576., 286720., ..., 300544., 260096., 212992.]],

        [[245248., 271872., 292352., ..., 281088., 351744., 360448.],
         [259072., 296960., 308224., ..., 320000., 340480., 367104.],
         [262656., 275968., 291328., ..., 356352., 305152., 350720.],
         ...,
         [366592., 359936., 345600., ..., 313856., 259072., 190976.],
         [343552., 324608., 303104., ..., 325120., 268288., 207360.],
         [308736., 280576., 286720., ..., 300544., 260096., 212992.]],

        [[245248., 271872., 292352., ..., 281088., 351744., 360448.],
         [259072., 296960., 308224., ..., 320000., 340480., 367104.],
         [262656., 275968., 291328., ..., 356352., 305152., 350720.],
         ...,
         [366592., 359936., 345600., ..., 313856., 259072., 190976.],
         [343552., 324608., 303104., ..., 325120., 268288., 207360.],
         [308736., 280576., 286720., ..., 300544., 260096., 212992.]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [6], 'to': [9]}
torch node:
{'name': 'sin', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [6], 'to': [9]}

generate models:48

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:1
torch --> 

generate models:60

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:8

analyse output arrays in iter:28

pre layer res:
10:flatten
{'name': 'flatten', 'output': array([[374.81934,   0.     ,   0.     , ...,   0.     ,   0.     ,
          0.     ]], dtype=float32), 'output_shape': torch.Size([1, 16384]), 'from': [7], 'to': [9, 16]}
tf node:
{'name': 'sin', 'output': array([[-0.8247784,  0.       ,  0.       , ...,  0.       ,  0.       ,
         0.       ]], dtype=float32), 'output_shape': torch.Size([1, 16384]), 'from': [10], 'to': [8]}
ms node:
{'name': 'sin', 'output': array([[-0.83153456,  0.        ,  0.        , ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': (1, 16384), 'from': [10], 'to': [8]}
torch node:
{'name': 'sin', 'output': array([[-0.8247784,  0.       ,  0.       , ...,  0.       ,  0.       ,
         0.       ]], dtype=float32), 'output_shape': torch.Size([1, 16384]), 'from': [10], 'to': [8]}

generate models:24

analyse output arrays in iter:33

pre layer res:
75:flatten
{'name': 'flatten', 'output': array([[   1.8258905,    1.8258905,    1.3005757, ...,  -19.235254 ,
        -125.76015  ,   54.19869  ]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [2], 'to': [1]}
tf node:
{'name': 'sin', 'output': array([[ 0.9676395 ,  0.9676395 ,  0.96371204, ..., -0.37620628,
        -0.09629153, -0.71148795]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [75], 'to': [6]}
ms node:
{'name': 'sin', 'output': array([[ 0.9676395 ,  0.9676395 ,  0.96371204, ..., -0.37620628,
        -0.09629152, -0.71148795]], dtype=float32), 'output_shape': (1, 9248), 'from': [75], 'to': [6]}
torch node:
{'name': 'sin', 'output': array([[ 0.9676395 ,  0.9676395 ,  0.96371204, ..., -0.37620628,
        -0.09629153, -0.71148795]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [75], 'to': [6]}

pre layer res:
6:sigmoid
{'name': 'sigmoid', 'output': array([[0.7246488 , 0.7246488 , 0.7238644 , ..., 0.40704224, 0.4759457 ,
        0.32927015]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [1], 'to': [8]}
11:reshape
{'name': 'reshape', 'output': array([[ 0.40808207,  0.40808207, -0.7596879 , ...,  0.5025704 ,
         0.57697755, -0.88387746]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [10], 'to': [8]}
tf node:
{'name': 'add', 'output': array([[ 1.1327308 ,  1.1327308 , -0.03582352, ...,  0.90961266,
         1.0529232 , -0.5546073 ]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [6, 11], 'to': [76]}
ms node:
{'name': 'add', 'output': array([[ 1.1327307 ,  1.1327307 , -0.03582346, ...,  0.90961266,
         1.0529232 , -0.5546073 ]], dtype=float32), 'output_shape': (1, 9248), 'from': [6, 11], 'to': [76]}
torch node:
{'name': 'add', 'output': array([[ 1.1327308 ,  1.1327308 , -0.03582352, ...,  0.90961266,
         1.0529232 , -0.5546073 ]], dtype=float32), 'output_shape': torch.Size([1, 9248]), 'from': [6, 11], 'to': [76]}

generate models:29

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:3,distinct_bugs:2
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
add:1
torch --> 

generate models:38

analyse output arrays in iter:96

pre layer res:
1:add
{'name': 'add', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 30, 30]), 'from': [41, 41], 'to': [108]}
tf node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 30, 30]), 'from': [1], 'to': []}
ms node:
{'name': 'log', 'output': array([[[[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        ...,

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]]]], dtype=float32), 'output_shape': (1, 512, 30, 30), 'from': [1], 'to': []}
torch node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 30, 30]), 'from': [1], 'to': []}

generate models:52

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:4,distinct_bugs:3
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
add:1
log:1
torch --> 

generate models:53

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:43
tensorflow exception:
{'id': 18, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([463.,   0.,   0.,  ...,   0.,   0.,   0.],
       grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 18, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([463.,   0.,   0.,  ...,   0.,   0.,   0.],
       grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:38

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
flatten:1
mindspore --> 
torch --> 
flatten:1

generate models:44

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
flatten:1
mindspore --> 
torch --> 
flatten:1

generate models:63

analyse output arrays in iter:6

pre layer res:
10:log
{'name': 'log', 'output': array([[10.274223, 10.227526, 10.182028, ...,      -inf,      -inf,
             -inf]], dtype=float32), 'output_shape': torch.Size([1, 131072]), 'from': [0], 'to': [11]}
tf node:
{'name': 'cos', 'output': array([[-0.66039973, -0.69473296, -0.7267279 , ...,         nan,
                nan,         nan]], dtype=float32), 'output_shape': torch.Size([1, 131072]), 'from': [10], 'to': [1]}
ms node:
{'name': 'cos', 'output': array([[-0.66040045, -0.69473505, -0.7267292 , ...,         nan,
                nan,         nan]], dtype=float32), 'output_shape': (1, 131072), 'from': [10], 'to': [1]}
torch node:
{'name': 'cos', 'output': array([[-0.66039973, -0.69473296, -0.7267279 , ...,         nan,
                nan,         nan]], dtype=float32), 'output_shape': torch.Size([1, 131072]), 'from': [10], 'to': [1]}

generate models:7

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:1,distinct_bugs:1
tensorflow --> 
cos:1
mindspore --> 
cos:1
torch --> 
cos:1

generate models:10

analyse output arrays in iter:20

pre layer res:
4:cos
{'name': 'cos', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [0], 'to': [13]}
tf node:
{'name': 'log', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [4], 'to': [1]}
ms node:
{'name': 'log', 'output': array([[[[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        ...,

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [4], 'to': [1]}
torch node:
{'name': 'log', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [4], 'to': [1]}

generate models:19

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:2,distinct_bugs:2
torch --> nums:1,distinct_bugs:1
tensorflow --> 
cos:1
mindspore --> 
cos:1
log:1
torch --> 
cos:1

generate models:33

analyse the exceptions in iter:71
tensorflow exception:
{'id': 16, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([0.])]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 16, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([0.])]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:43

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:2,distinct_bugs:2
torch --> nums:2,distinct_bugs:2
tensorflow --> 
cos:1
flatten:1
mindspore --> 
cos:1
log:1
torch --> 
cos:1
flatten:1

generate models:46

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse output arrays in iter:22

pre layer res:
9:exp
{'name': 'exp', 'output': array([[[[2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         ...,
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817]],

        [[2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         ...,
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817],
         [2.7182817, 2.7182817, 2.7182817, ..., 2.7182817, 2.7182817,
          2.7182817]],

        [[1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         ...,
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ]],

        ...,

        [[1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         ...,
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ]],

        [[1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         ...,
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ]],

        [[1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         ...,
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ],
         [1.       , 1.       , 1.       , ..., 1.       , 1.       ,
          1.       ]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [8], 'to': [5]}
tf node:
{'name': 'log', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [9], 'to': [10]}
ms node:
{'name': 'log', 'output': array([[[[ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         ...,
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01]],

        [[ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         ...,
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01],
         [ 9.9999815e-01,  9.9999815e-01,  9.9999815e-01, ...,
           9.9999815e-01,  9.9999815e-01,  9.9999815e-01]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        ...,

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]]]],
      dtype=float32), 'output_shape': (1, 64, 32, 32), 'from': [9], 'to': [10]}
torch node:
{'name': 'log', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [9], 'to': [10]}

generate models:18

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
log:1
torch --> 

generate models:35

analyse output arrays in iter:74

pre layer res:
8:reshape
{'name': 'reshape', 'output': array([[inf, inf, inf, ...,  1.,  1.,  1.]], dtype=float32), 'output_shape': torch.Size([1, 230400]), 'from': [16], 'to': [17]}
tf node:
{'name': 'sin', 'output': array([[       nan,        nan,        nan, ..., 0.84147096, 0.84147096,
        0.84147096]], dtype=float32), 'output_shape': torch.Size([1, 230400]), 'from': [8], 'to': [5]}
ms node:
{'name': 'sin', 'output': array([[       nan,        nan,        nan, ..., 0.84147096, 0.84147096,
        0.84147096]], dtype=float32), 'output_shape': (1, 230400), 'from': [8], 'to': [5]}
torch node:
{'name': 'sin', 'output': array([[       nan,        nan,        nan, ..., 0.84147096, 0.84147096,
        0.84147096]], dtype=float32), 'output_shape': torch.Size([1, 230400]), 'from': [8], 'to': [5]}

generate models:51

analyse output arrays in iter:77

pre layer res:
5:add
{'name': 'add', 'output': array([[[[    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf, 9.317766, 9.317766, ..., 9.317766, 9.317766,
          9.317766],
         [    -inf, 9.317766, 9.317766, ..., 9.317766, 9.317766,
          9.317766],
         ...,
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf]],

        [[    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         ...,
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf]],

        [[    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         ...,
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf]],

        ...,

        [[    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         ...,
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf]],

        [[    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         ...,
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf]],

        [[    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         [    -inf, 8.317766, 8.317766, ..., 8.317766, 8.317766,
          8.317766],
         ...,
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf],
         [    -inf,     -inf,     -inf, ...,     -inf,     -inf,
              -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 17, 17]), 'from': [4, 8], 'to': [9]}
tf node:
{'name': 'cos', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.9942797 , -0.9942797 , ..., -0.9942797 ,
          -0.9942797 , -0.9942797 ],
         [        nan, -0.9942797 , -0.9942797 , ..., -0.9942797 ,
          -0.9942797 , -0.9942797 ],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 17, 17]), 'from': [5], 'to': [1]}
ms node:
{'name': 'cos', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.9942795 , -0.9942795 , ..., -0.9942795 ,
          -0.9942795 , -0.9942795 ],
         [        nan, -0.9942795 , -0.9942795 , ..., -0.9942795 ,
          -0.9942795 , -0.9942795 ],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         [        nan, -0.44733438, -0.44733438, ..., -0.44733438,
          -0.44733438, -0.44733438],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': (1, 512, 17, 17), 'from': [5], 'to': [1]}
torch node:
{'name': 'cos', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.9942797 , -0.9942797 , ..., -0.9942797 ,
          -0.9942797 , -0.9942797 ],
         [        nan, -0.9942797 , -0.9942797 , ..., -0.9942797 ,
          -0.9942797 , -0.9942797 ],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         [        nan, -0.44733608, -0.44733608, ..., -0.44733608,
          -0.44733608, -0.44733608],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 17, 17]), 'from': [5], 'to': [1]}

generate models:52

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:3,distinct_bugs:3
torch --> nums:2,distinct_bugs:2
tensorflow --> 
sin:1
cos:1
mindspore --> 
log:1
sin:1
cos:1
torch --> 
sin:1
cos:1

generate models:60

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse output arrays in iter:33

pre layer res:
15:reshape
{'name': 'reshape', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [14], 'to': [17]}
tf node:
{'name': 'sin', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [15], 'to': [12]}
ms node:
{'name': 'sin', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': (1, 512, 16, 16), 'from': [15], 'to': [12]}
torch node:
{'name': 'sin', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [15], 'to': [12]}

generate models:26

analyse output arrays in iter:36

pre layer res:
14:reshape
{'name': 'reshape', 'output': array([[inf,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 10368]), 'from': [13], 'to': [15]}
tf node:
{'name': 'log', 'output': array([[ inf, -inf, -inf, ..., -inf, -inf, -inf]], dtype=float32), 'output_shape': torch.Size([1, 10368]), 'from': [14], 'to': [102]}
ms node:
{'name': 'log', 'output': array([[88.72284,     -inf,     -inf, ...,     -inf,     -inf,     -inf]],
      dtype=float32), 'output_shape': (1, 10368), 'from': [14], 'to': [102]}
torch node:
{'name': 'log', 'output': array([[ inf, -inf, -inf, ..., -inf, -inf, -inf]], dtype=float32), 'output_shape': torch.Size([1, 10368]), 'from': [14], 'to': [102]}

generate models:28

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:2,distinct_bugs:2
torch --> nums:1,distinct_bugs:1
tensorflow --> 
sin:1
mindspore --> 
sin:1
log:1
torch --> 
sin:1

generate models:34

analyse output arrays in iter:51

pre layer res:
34:add
{'name': 'add', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [15, 1], 'to': [35, 7]}
tf node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [34], 'to': [35]}
ms node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [34], 'to': [35]}
torch node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [34], 'to': [35]}

generate models:36

analyse output arrays in iter:84

pre layer res:
10:flatten
{'name': 'flatten', 'output': array([[7680., 7168., 7168., ..., 7680., 7680., 8192.]], dtype=float32), 'output_shape': torch.Size([1, 1605632]), 'from': [6], 'to': [13]}
tf node:
{'name': 'sum', 'output': array([1.1651842e+10], dtype=float32), 'output_shape': torch.Size([1]), 'from': [10], 'to': [14]}
ms node:
{'name': 'sum', 'output': array([1.1681104e+10], dtype=float32), 'output_shape': (1,), 'from': [10], 'to': [14]}
torch node:
{'name': 'sum', 'output': array([1.1651842e+10], dtype=float32), 'output_shape': torch.Size([1]), 'from': [10], 'to': [14]}

generate models:48

analyse output arrays in iter:87

pre layer res:
15:conv2d
{'name': 'conv2d', 'output': array([[[[ 29184.,  31488.,  33536., ...,  18176.,  18432.,  22272.],
         [ 28160.,  32768.,  35840., ...,  22272.,  24064.,  22784.],
         [ 26624.,  29952.,  35328., ...,  26880.,  27904.,  29440.],
         ...,
         [113920., 109312., 114432., ..., 115456., 107008., 115200.],
         [111104., 103936., 111872., ..., 119552., 117248., 118784.],
         [111872., 114688., 116480., ..., 124672., 124672., 121856.]],

        [[ 29184.,  31488.,  33536., ...,  18176.,  18432.,  22272.],
         [ 28160.,  32768.,  35840., ...,  22272.,  24064.,  22784.],
         [ 26624.,  29952.,  35328., ...,  26880.,  27904.,  29440.],
         ...,
         [113920., 109312., 114432., ..., 115456., 107008., 115200.],
         [111104., 103936., 111872., ..., 119552., 117248., 118784.],
         [111872., 114688., 116480., ..., 124672., 124672., 121856.]],

        [[ 29184.,  31488.,  33536., ...,  18176.,  18432.,  22272.],
         [ 28160.,  32768.,  35840., ...,  22272.,  24064.,  22784.],
         [ 26624.,  29952.,  35328., ...,  26880.,  27904.,  29440.],
         ...,
         [113920., 109312., 114432., ..., 115456., 107008., 115200.],
         [111104., 103936., 111872., ..., 119552., 117248., 118784.],
         [111872., 114688., 116480., ..., 124672., 124672., 121856.]],

        ...,

        [[ 29184.,  31488.,  33536., ...,  18176.,  18432.,  22272.],
         [ 28160.,  32768.,  35840., ...,  22272.,  24064.,  22784.],
         [ 26624.,  29952.,  35328., ...,  26880.,  27904.,  29440.],
         ...,
         [113920., 109312., 114432., ..., 115456., 107008., 115200.],
         [111104., 103936., 111872., ..., 119552., 117248., 118784.],
         [111872., 114688., 116480., ..., 124672., 124672., 121856.]],

        [[ 29184.,  31488.,  33536., ...,  18176.,  18432.,  22272.],
         [ 28160.,  32768.,  35840., ...,  22272.,  24064.,  22784.],
         [ 26624.,  29952.,  35328., ...,  26880.,  27904.,  29440.],
         ...,
         [113920., 109312., 114432., ..., 115456., 107008., 115200.],
         [111104., 103936., 111872., ..., 119552., 117248., 118784.],
         [111872., 114688., 116480., ..., 124672., 124672., 121856.]],

        [[ 29184.,  31488.,  33536., ...,  18176.,  18432.,  22272.],
         [ 28160.,  32768.,  35840., ...,  22272.,  24064.,  22784.],
         [ 26624.,  29952.,  35328., ...,  26880.,  27904.,  29440.],
         ...,
         [113920., 109312., 114432., ..., 115456., 107008., 115200.],
         [111104., 103936., 111872., ..., 119552., 117248., 118784.],
         [111872., 114688., 116480., ..., 124672., 124672., 121856.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [39], 'to': [0]}
tf node:
{'name': 'sin', 'output': array([[[[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        ...,

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [15], 'to': [9]}
ms node:
{'name': 'sin', 'output': array([[[[-9.8471880e-01,  1.8214443e-01,  4.8080894e-01, ...,
          -9.5057845e-01, -2.7241436e-01, -9.4888324e-01],
         [-9.4465679e-01,  9.2785633e-01,  6.5259773e-01, ...,
          -9.4888324e-01, -5.6441671e-01,  9.2078030e-01],
         [ 8.4024733e-01,  5.5611968e-02, -7.1078277e-01, ...,
           5.0833988e-01,  3.6538914e-01, -1.3483131e-01],
         ...,
         [-4.1941833e-01, -2.7983126e-01,  4.9027655e-01, ...,
           6.2224877e-01, -8.0100167e-01, -8.0695933e-01],
         [-9.9998742e-01, -4.3618196e-01, -1.1414500e-01, ...,
           9.6577954e-01, -5.8150333e-01,  3.7256154e-01],
         [-1.1414500e-01,  8.5136819e-01,  7.3848259e-01, ...,
           8.6095035e-01,  8.6095035e-01, -9.5700756e-02]],

        [[-9.8471880e-01,  1.8214443e-01,  4.8080894e-01, ...,
          -9.5057845e-01, -2.7241436e-01, -9.4888324e-01],
         [-9.4465679e-01,  9.2785633e-01,  6.5259773e-01, ...,
          -9.4888324e-01, -5.6441671e-01,  9.2078030e-01],
         [ 8.4024733e-01,  5.5611968e-02, -7.1078277e-01, ...,
           5.0833988e-01,  3.6538914e-01, -1.3483131e-01],
         ...,
         [-4.1941833e-01, -2.7983126e-01,  4.9027655e-01, ...,
           6.2224877e-01, -8.0100167e-01, -8.0695933e-01],
         [-9.9998742e-01, -4.3618196e-01, -1.1414500e-01, ...,
           9.6577954e-01, -5.8150333e-01,  3.7256154e-01],
         [-1.1414500e-01,  8.5136819e-01,  7.3848259e-01, ...,
           8.6095035e-01,  8.6095035e-01, -9.5700756e-02]],

        [[-9.8471880e-01,  1.8214443e-01,  4.8080894e-01, ...,
          -9.5057845e-01, -2.7241436e-01, -9.4888324e-01],
         [-9.4465679e-01,  9.2785633e-01,  6.5259773e-01, ...,
          -9.4888324e-01, -5.6441671e-01,  9.2078030e-01],
         [ 8.4024733e-01,  5.5611968e-02, -7.1078277e-01, ...,
           5.0833988e-01,  3.6538914e-01, -1.3483131e-01],
         ...,
         [-4.1941833e-01, -2.7983126e-01,  4.9027655e-01, ...,
           6.2224877e-01, -8.0100167e-01, -8.0695933e-01],
         [-9.9998742e-01, -4.3618196e-01, -1.1414500e-01, ...,
           9.6577954e-01, -5.8150333e-01,  3.7256154e-01],
         [-1.1414500e-01,  8.5136819e-01,  7.3848259e-01, ...,
           8.6095035e-01,  8.6095035e-01, -9.5700756e-02]],

        ...,

        [[ 3.5162723e+02,  5.6314545e+02,  6.7004993e+02, ...,
           3.5494843e+02,  4.5095367e+02,  3.5511633e+02],
         [ 3.5553601e+02,  9.0344525e+02,  7.4765417e+02, ...,
           3.5511633e+02,  4.0158527e+02,  8.9888049e+02],
         [ 8.4913550e+02,  5.2664026e+02,  3.8176227e+02, ...,
           6.8160712e+02,  6.2491492e+02,  4.7970932e+02],
         ...,
         [ 4.2430212e+02,  4.4951337e+02,  6.7398883e+02, ...,
           7.3295618e+02,  3.7091290e+02,  3.7023047e+02],
         [ 3.5017834e+02,  4.2150391e+02,  4.8438516e+02, ...,
           9.2846893e+02,  3.9911890e+02,  6.2757043e+02],
         [ 4.8438516e+02,  8.5577081e+02,  7.9174500e+02, ...,
           8.6154492e+02,  8.6154492e+02,  4.8863660e+02]],

        [[ 3.5162723e+02,  5.6314545e+02,  6.7004993e+02, ...,
           3.5494843e+02,  4.5095367e+02,  3.5511633e+02],
         [ 3.5553601e+02,  9.0344525e+02,  7.4765417e+02, ...,
           3.5511633e+02,  4.0158527e+02,  8.9888049e+02],
         [ 8.4913550e+02,  5.2664026e+02,  3.8176227e+02, ...,
           6.8160712e+02,  6.2491492e+02,  4.7970932e+02],
         ...,
         [ 4.2430212e+02,  4.4951337e+02,  6.7398883e+02, ...,
           7.3295618e+02,  3.7091290e+02,  3.7023047e+02],
         [ 3.5017834e+02,  4.2150391e+02,  4.8438516e+02, ...,
           9.2846893e+02,  3.9911890e+02,  6.2757043e+02],
         [ 4.8438516e+02,  8.5577081e+02,  7.9174500e+02, ...,
           8.6154492e+02,  8.6154492e+02,  4.8863660e+02]],

        [[ 3.5162723e+02,  5.6314545e+02,  6.7004993e+02, ...,
           3.5494843e+02,  4.5095367e+02,  3.5511633e+02],
         [ 3.5553601e+02,  9.0344525e+02,  7.4765417e+02, ...,
           3.5511633e+02,  4.0158527e+02,  8.9888049e+02],
         [ 8.4913550e+02,  5.2664026e+02,  3.8176227e+02, ...,
           6.8160712e+02,  6.2491492e+02,  4.7970932e+02],
         ...,
         [ 4.2430212e+02,  4.4951337e+02,  6.7398883e+02, ...,
           7.3295618e+02,  3.7091290e+02,  3.7023047e+02],
         [ 3.5017834e+02,  4.2150391e+02,  4.8438516e+02, ...,
           9.2846893e+02,  3.9911890e+02,  6.2757043e+02],
         [ 4.8438516e+02,  8.5577081e+02,  7.9174500e+02, ...,
           8.6154492e+02,  8.6154492e+02,  4.8863660e+02]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [15], 'to': [9]}
torch node:
{'name': 'sin', 'output': array([[[[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        ...,

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]],

        [[-0.9847188 ,  0.18214443,  0.48080894, ..., -0.95057845,
          -0.27241436, -0.94888324],
         [-0.9446568 ,  0.9278563 ,  0.6525977 , ..., -0.94888324,
          -0.5644167 ,  0.9207803 ],
         [ 0.84024733,  0.05561197, -0.71078277, ...,  0.5083399 ,
           0.36538914, -0.13483131],
         ...,
         [-0.41941833, -0.27983126,  0.49027655, ...,  0.62224877,
          -0.80100167, -0.80695933],
         [-0.9999874 , -0.43618196, -0.114145  , ...,  0.96577954,
          -0.58150333,  0.37256154],
         [-0.114145  ,  0.8513682 ,  0.7384826 , ...,  0.86095035,
           0.86095035, -0.09570076]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [15], 'to': [9]}

generate models:50

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:5,distinct_bugs:4
torch --> nums:2,distinct_bugs:2
tensorflow --> 
sin:1
softmax:1
mindspore --> 
sin:2
log:1
softmax:1
sum:1
torch --> 
sin:1
softmax:1

generate models:51

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse output arrays in iter:38

pre layer res:
5:slice
{'name': 'slice', 'output': array([[inf,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [15], 'to': [11]}
tf node:
{'name': 'sin', 'output': array([[nan,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [5], 'to': [6]}
ms node:
{'name': 'sin', 'output': array([[nan,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': (1, 1048576), 'from': [5], 'to': [6]}
torch node:
{'name': 'sin', 'output': array([[nan,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [5], 'to': [6]}

pre layer res:
4:flatten
{'name': 'flatten', 'output': array([[5.2323942e+08, 8.3309363e+08, 1.0218373e+09, ..., 4.1261466e+08,
        3.2610714e+08, 2.3697818e+08]], dtype=float32), 'output_shape': torch.Size([1, 3211264]), 'from': [16], 'to': [12]}
tf node:
{'name': 'mean', 'output': array([8.279062e+08], dtype=float32), 'output_shape': torch.Size([1]), 'from': [4], 'to': [13]}
ms node:
{'name': 'mean', 'output': array([8.2964006e+08], dtype=float32), 'output_shape': (1,), 'from': [4], 'to': [13]}
torch node:
{'name': 'mean', 'output': array([8.279062e+08], dtype=float32), 'output_shape': torch.Size([1]), 'from': [4], 'to': [13]}

generate models:37

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:2,distinct_bugs:2
torch --> nums:1,distinct_bugs:1
tensorflow --> 
sin:1
mindspore --> 
sin:1
mean:1
torch --> 
sin:1

generate models:41

analyse output arrays in iter:51

pre layer res:
2:add
{'name': 'add', 'output': array([[3071.9998,    0.    ,    0.    , ...,    0.    ,    0.    ,
           0.    ]], dtype=float32), 'output_shape': torch.Size([1, 524288]), 'from': [0, 5], 'to': [8]}
tf node:
{'name': 'cos', 'output': array([[0.8879814, 1.       , 1.       , ..., 1.       , 1.       ,
        1.       ]], dtype=float32), 'output_shape': torch.Size([1, 524288]), 'from': [2], 'to': [93]}
ms node:
{'name': 'cos', 'output': array([[0.8879814, 1.       , 1.       , ..., 1.       , 1.       ,
        1.       ]], dtype=float32), 'output_shape': (1, 524288), 'from': [2], 'to': [93]}
torch node:
{'name': 'cos', 'output': array([[0.8879814, 1.       , 1.       , ..., 1.       , 1.       ,
        1.       ]], dtype=float32), 'output_shape': torch.Size([1, 524288]), 'from': [2], 'to': [93]}

generate models:43

analyse output arrays in iter:56

pre layer res:
39:add
{'name': 'add', 'output': array([[[[5.0290979e+10, 4.2786300e+10, 3.8253298e+10, ...,
          3.5395895e+11, 3.5640004e+11, 3.6007739e+11],
         [5.4988607e+10, 5.1678249e+10, 4.8020808e+10, ...,
          3.5031305e+11, 3.4789294e+11, 3.5031305e+11],
         [5.9395785e+10, 5.1678249e+10, 4.8922583e+10, ...,
          3.5031305e+11, 3.4910195e+11, 3.4910195e+11],
         ...,
         [9.3118046e+10, 9.8184774e+10, 1.1007564e+11, ...,
          2.6005155e+11, 1.9208279e+11, 2.1233710e+11],
         [9.5634637e+10, 8.2208645e+10, 1.0404527e+11, ...,
          3.7122274e+11, 2.9232674e+11, 1.9208279e+11],
         [1.0404527e+11, 1.0939721e+11, 1.5061890e+11, ...,
          3.8127229e+11, 3.7623074e+11, 2.6847373e+11]],

        [[5.0290979e+10, 4.2786300e+10, 3.8253298e+10, ...,
          3.5395895e+11, 3.5640004e+11, 3.6007739e+11],
         [5.4988607e+10, 5.1678249e+10, 4.8020808e+10, ...,
          3.5031305e+11, 3.4789294e+11, 3.5031305e+11],
         [5.9395785e+10, 5.1678249e+10, 4.8922583e+10, ...,
          3.5031305e+11, 3.4910195e+11, 3.4910195e+11],
         ...,
         [9.3118046e+10, 9.8184774e+10, 1.1007564e+11, ...,
          2.6005155e+11, 1.9208279e+11, 2.1233710e+11],
         [9.5634637e+10, 8.2208645e+10, 1.0404527e+11, ...,
          3.7122274e+11, 2.9232674e+11, 1.9208279e+11],
         [1.0404527e+11, 1.0939721e+11, 1.5061890e+11, ...,
          3.8127229e+11, 3.7623074e+11, 2.6847373e+11]],

        [[5.0290979e+10, 4.2786300e+10, 3.8253298e+10, ...,
          3.5395895e+11, 3.5640004e+11, 3.6007739e+11],
         [5.4988607e+10, 5.1678249e+10, 4.8020808e+10, ...,
          3.5031305e+11, 3.4789294e+11, 3.5031305e+11],
         [5.9395785e+10, 5.1678249e+10, 4.8922583e+10, ...,
          3.5031305e+11, 3.4910195e+11, 3.4910195e+11],
         ...,
         [9.3118046e+10, 9.8184774e+10, 1.1007564e+11, ...,
          2.6005155e+11, 1.9208279e+11, 2.1233710e+11],
         [9.5634637e+10, 8.2208645e+10, 1.0404527e+11, ...,
          3.7122274e+11, 2.9232674e+11, 1.9208279e+11],
         [1.0404527e+11, 1.0939721e+11, 1.5061890e+11, ...,
          3.8127229e+11, 3.7623074e+11, 2.6847373e+11]],

        ...,

        [[5.0290979e+10, 4.2786300e+10, 3.8253298e+10, ...,
          3.5395895e+11, 3.5640004e+11, 3.6007739e+11],
         [5.4988607e+10, 5.1678249e+10, 4.8020808e+10, ...,
          3.5031305e+11, 3.4789294e+11, 3.5031305e+11],
         [5.9395785e+10, 5.1678249e+10, 4.8922583e+10, ...,
          3.5031305e+11, 3.4910195e+11, 3.4910195e+11],
         ...,
         [9.3118046e+10, 9.8184774e+10, 1.1007564e+11, ...,
          2.6005155e+11, 1.9208279e+11, 2.1233710e+11],
         [9.5634637e+10, 8.2208645e+10, 1.0404527e+11, ...,
          3.7122274e+11, 2.9232674e+11, 1.9208279e+11],
         [1.0404527e+11, 1.0939721e+11, 1.5061890e+11, ...,
          3.8127229e+11, 3.7623074e+11, 2.6847373e+11]],

        [[5.0290979e+10, 4.2786300e+10, 3.8253298e+10, ...,
          3.5395895e+11, 3.5640004e+11, 3.6007739e+11],
         [5.4988607e+10, 5.1678249e+10, 4.8020808e+10, ...,
          3.5031305e+11, 3.4789294e+11, 3.5031305e+11],
         [5.9395785e+10, 5.1678249e+10, 4.8922583e+10, ...,
          3.5031305e+11, 3.4910195e+11, 3.4910195e+11],
         ...,
         [9.3118046e+10, 9.8184774e+10, 1.1007564e+11, ...,
          2.6005155e+11, 1.9208279e+11, 2.1233710e+11],
         [9.5634637e+10, 8.2208645e+10, 1.0404527e+11, ...,
          3.7122274e+11, 2.9232674e+11, 1.9208279e+11],
         [1.0404527e+11, 1.0939721e+11, 1.5061890e+11, ...,
          3.8127229e+11, 3.7623074e+11, 2.6847373e+11]],

        [[5.0290979e+10, 4.2786300e+10, 3.8253298e+10, ...,
          3.5395895e+11, 3.5640004e+11, 3.6007739e+11],
         [5.4988607e+10, 5.1678249e+10, 4.8020808e+10, ...,
          3.5031305e+11, 3.4789294e+11, 3.5031305e+11],
         [5.9395785e+10, 5.1678249e+10, 4.8922583e+10, ...,
          3.5031305e+11, 3.4910195e+11, 3.4910195e+11],
         ...,
         [9.3118046e+10, 9.8184774e+10, 1.1007564e+11, ...,
          2.6005155e+11, 1.9208279e+11, 2.1233710e+11],
         [9.5634637e+10, 8.2208645e+10, 1.0404527e+11, ...,
          3.7122274e+11, 2.9232674e+11, 1.9208279e+11],
         [1.0404527e+11, 1.0939721e+11, 1.5061890e+11, ...,
          3.8127229e+11, 3.7623074e+11, 2.6847373e+11]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [19, 6], 'to': [2, 7]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        ...,

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [39], 'to': [8]}
ms node:
{'name': 'sin', 'output': array([[[[ 2.39123255e-02,  8.64281178e-01, -9.66595590e-01, ...,
           9.76810455e-01,  8.77356157e-02,  9.77331102e-02],
         [ 2.77725399e-01,  9.11146283e-01, -2.31920645e-01, ...,
          -8.98618639e-01,  5.67853570e-01, -8.98618639e-01],
         [ 2.26796106e-01,  9.11146283e-01, -7.69406378e-01, ...,
          -8.98618639e-01, -5.59003472e-01, -5.59003472e-01],
         ...,
         [ 3.83961678e-01, -6.29715562e-01,  6.10261023e-01, ...,
           9.21694219e-01,  5.62791288e-01,  8.84411991e-01],
         [-1.13352440e-01, -9.95806396e-01,  9.48402584e-01, ...,
          -5.26601076e-03, -3.22854102e-01,  5.62791288e-01],
         [ 9.48402584e-01, -9.70826983e-01, -5.60393892e-02, ...,
          -9.88930345e-01,  1.79425865e-01,  1.02555074e-01]],

        [[ 2.39123255e-02,  8.64281178e-01, -9.66595590e-01, ...,
           9.76810455e-01,  8.77356157e-02,  9.77331102e-02],
         [ 2.77725399e-01,  9.11146283e-01, -2.31920645e-01, ...,
          -8.98618639e-01,  5.67853570e-01, -8.98618639e-01],
         [ 2.26796106e-01,  9.11146283e-01, -7.69406378e-01, ...,
          -8.98618639e-01, -5.59003472e-01, -5.59003472e-01],
         ...,
         [ 3.83961678e-01, -6.29715562e-01,  6.10261023e-01, ...,
           9.21694219e-01,  5.62791288e-01,  8.84411991e-01],
         [-1.13352440e-01, -9.95806396e-01,  9.48402584e-01, ...,
          -5.26601076e-03, -3.22854102e-01,  5.62791288e-01],
         [ 9.48402584e-01, -9.70826983e-01, -5.60393892e-02, ...,
          -9.88930345e-01,  1.79425865e-01,  1.02555074e-01]],

        [[ 2.39123255e-02,  8.64281178e-01, -9.66595590e-01, ...,
           9.76810455e-01,  8.77356157e-02,  9.77331102e-02],
         [ 2.77725399e-01,  9.11146283e-01, -2.31920645e-01, ...,
          -8.98618639e-01,  5.67853570e-01, -8.98618639e-01],
         [ 2.26796106e-01,  9.11146283e-01, -7.69406378e-01, ...,
          -8.98618639e-01, -5.59003472e-01, -5.59003472e-01],
         ...,
         [ 3.83961678e-01, -6.29715562e-01,  6.10261023e-01, ...,
           9.21694219e-01,  5.62791288e-01,  8.84411991e-01],
         [-1.13352440e-01, -9.95806396e-01,  9.48402584e-01, ...,
          -5.26601076e-03, -3.22854102e-01,  5.62791288e-01],
         [ 9.48402584e-01, -9.70826983e-01, -5.60393892e-02, ...,
          -9.88930345e-01,  1.79425865e-01,  1.02555074e-01]],

        ...,

        [[ 5.02907535e+10,  4.27860951e+10,  3.82531011e+10, ...,
           3.53958363e+11,  3.56399448e+11,  3.60076804e+11],
         [ 5.49883740e+10,  5.16780196e+10,  4.80205865e+10, ...,
           3.50312464e+11,  3.47892351e+11,  3.50312464e+11],
         [ 5.93955389e+10,  5.16780196e+10,  4.89223619e+10, ...,
           3.50312464e+11,  3.49101359e+11,  3.49101359e+11],
         ...,
         [ 9.31177431e+10,  9.81844623e+10,  1.10075314e+11, ...,
           2.60051042e+11,  1.92082346e+11,  2.12336640e+11],
         [ 9.56343255e+10,  8.22083584e+10,  1.04044954e+11, ...,
           3.71222118e+11,  2.92326212e+11,  1.92082346e+11],
         [ 1.04044954e+11,  1.09396886e+11,  1.50618505e+11, ...,
           3.81271671e+11,  3.76230117e+11,  2.68473205e+11]],

        [[ 5.02907535e+10,  4.27860951e+10,  3.82531011e+10, ...,
           3.53958363e+11,  3.56399448e+11,  3.60076804e+11],
         [ 5.49883740e+10,  5.16780196e+10,  4.80205865e+10, ...,
           3.50312464e+11,  3.47892351e+11,  3.50312464e+11],
         [ 5.93955389e+10,  5.16780196e+10,  4.89223619e+10, ...,
           3.50312464e+11,  3.49101359e+11,  3.49101359e+11],
         ...,
         [ 9.31177431e+10,  9.81844623e+10,  1.10075314e+11, ...,
           2.60051042e+11,  1.92082346e+11,  2.12336640e+11],
         [ 9.56343255e+10,  8.22083584e+10,  1.04044954e+11, ...,
           3.71222118e+11,  2.92326212e+11,  1.92082346e+11],
         [ 1.04044954e+11,  1.09396886e+11,  1.50618505e+11, ...,
           3.81271671e+11,  3.76230117e+11,  2.68473205e+11]],

        [[ 5.02907535e+10,  4.27860951e+10,  3.82531011e+10, ...,
           3.53958363e+11,  3.56399448e+11,  3.60076804e+11],
         [ 5.49883740e+10,  5.16780196e+10,  4.80205865e+10, ...,
           3.50312464e+11,  3.47892351e+11,  3.50312464e+11],
         [ 5.93955389e+10,  5.16780196e+10,  4.89223619e+10, ...,
           3.50312464e+11,  3.49101359e+11,  3.49101359e+11],
         ...,
         [ 9.31177431e+10,  9.81844623e+10,  1.10075314e+11, ...,
           2.60051042e+11,  1.92082346e+11,  2.12336640e+11],
         [ 9.56343255e+10,  8.22083584e+10,  1.04044954e+11, ...,
           3.71222118e+11,  2.92326212e+11,  1.92082346e+11],
         [ 1.04044954e+11,  1.09396886e+11,  1.50618505e+11, ...,
           3.81271671e+11,  3.76230117e+11,  2.68473205e+11]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [39], 'to': [8]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        ...,

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]],

        [[ 0.02391233,  0.8642812 , -0.9665956 , ...,  0.97681046,
           0.08773562,  0.09773311],
         [ 0.2777254 ,  0.9111463 , -0.23192064, ..., -0.89861864,
           0.56785357, -0.89861864],
         [ 0.2267961 ,  0.9111463 , -0.7694064 , ..., -0.89861864,
          -0.5590035 , -0.5590035 ],
         ...,
         [ 0.38396168, -0.62971556,  0.610261  , ...,  0.9216942 ,
           0.5627913 ,  0.884412  ],
         [-0.11335244, -0.9958064 ,  0.9484026 , ..., -0.00526601,
          -0.3228541 ,  0.5627913 ],
         [ 0.9484026 , -0.970827  , -0.05603939, ..., -0.98893034,
           0.17942587,  0.10255507]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [39], 'to': [8]}

generate models:46

analyse output arrays in iter:62

pre layer res:
1:add
{'name': 'add', 'output': array([[[[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        ...,

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [1.6948892e+28, 1.0413759e+23, 4.7278395e+18, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [1.6948892e+28, 1.0413759e+23, 4.7278395e+18, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [1.6948892e+28, 1.0413759e+23, 4.7278395e+18, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [4, 9], 'to': [5]}
tf node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.75333923,  0.99240243, -0.7045878 , ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.75333923,  0.99240243, -0.7045878 , ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.75333923,  0.99240243, -0.7045878 , ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [12]}
ms node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.88871336,  0.99240243,  0.54809016, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.88871336,  0.99240243,  0.54809016, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.88871336,  0.99240243,  0.54809016, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [1], 'to': [12]}
torch node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.75333923,  0.99240243, -0.7045878 , ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.75333923,  0.99240243, -0.7045878 , ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         ...,
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [-0.75333923,  0.99240243, -0.7045878 , ...,         nan,
                  nan,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [12]}

generate models:51

analyse output arrays in iter:65

pre layer res:
102:pad
{'name': 'pad', 'output': array([[inf, inf, inf, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 623616]), 'from': [3], 'to': [2]}
tf node:
{'name': 'log', 'output': array([[ inf,  inf,  inf, ..., -inf, -inf, -inf]], dtype=float32), 'output_shape': torch.Size([1, 623616]), 'from': [102], 'to': [4]}
ms node:
{'name': 'log', 'output': array([[88.72284, 88.72284, 88.72284, ...,     -inf,     -inf,     -inf]],
      dtype=float32), 'output_shape': (1, 623616), 'from': [102], 'to': [4]}
torch node:
{'name': 'log', 'output': array([[ inf,  inf,  inf, ..., -inf, -inf, -inf]], dtype=float32), 'output_shape': torch.Size([1, 623616]), 'from': [102], 'to': [4]}

generate models:52

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:6,distinct_bugs:4
torch --> nums:2,distinct_bugs:1
tensorflow --> 
sin:2
mindspore --> 
sin:3
mean:1
cos:1
log:1
torch --> 
sin:2

generate models:62

analyse output arrays in iter:110

pre layer res:
3:exp
{'name': 'exp', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [41], 'to': [2]}
tf node:
{'name': 'sin', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [3], 'to': [5]}
ms node:
{'name': 'sin', 'output': array([[[[ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         ...,
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],

        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         ...,
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],

        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         ...,
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan],
         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],

        ...,

        [[655., 652., 660., ..., 697., 688., 700.],
         [678., 668., 676., ..., 702., 707., 710.],
         [597., 579., 582., ..., 654., 662., 662.],
         ...,
         [432., 426., 429., ..., 452., 449., 447.],
         [438., 435., 447., ..., 458., 455., 453.],
         [429., 435., 444., ..., 443., 447., 445.]],

        [[655., 652., 660., ..., 697., 688., 700.],
         [678., 668., 676., ..., 702., 707., 710.],
         [597., 579., 582., ..., 654., 662., 662.],
         ...,
         [432., 426., 429., ..., 452., 449., 447.],
         [438., 435., 447., ..., 458., 455., 453.],
         [429., 435., 444., ..., 443., 447., 445.]],

        [[655., 652., 660., ..., 697., 688., 700.],
         [678., 668., 676., ..., 702., 707., 710.],
         [597., 579., 582., ..., 654., 662., 662.],
         ...,
         [432., 426., 429., ..., 452., 449., 447.],
         [438., 435., 447., ..., 458., 455., 453.],
         [429., 435., 444., ..., 443., 447., 445.]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [3], 'to': [5]}
torch node:
{'name': 'sin', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [3], 'to': [5]}

generate models:63

analyse output arrays in iter:131

pre layer res:
44:flatten
{'name': 'flatten', 'output': array([[-21.345419, -29.915348, -29.915348, ...,   9.307605, -24.855   ,
        -31.33813 ]], dtype=float32), 'output_shape': torch.Size([1, 8192]), 'from': [7], 'to': [9]}
tf node:
{'name': 'log', 'output': array([[      nan,       nan,       nan, ..., 2.2308319,       nan,
              nan]], dtype=float32), 'output_shape': torch.Size([1, 8192]), 'from': [44], 'to': [0]}
ms node:
{'name': 'log', 'output': array([[      nan,       nan,       nan, ..., 2.2308302,       nan,
              nan]], dtype=float32), 'output_shape': (1, 8192), 'from': [44], 'to': [0]}
torch node:
{'name': 'log', 'output': array([[      nan,       nan,       nan, ..., 2.2308319,       nan,
              nan]], dtype=float32), 'output_shape': torch.Size([1, 8192]), 'from': [44], 'to': [0]}

generate models:65

analyse output arrays in iter:233

pre layer res:
10:conv2d
{'name': 'conv2d', 'output': array([[[[3.77041864e-08, 3.05520749e-04, 6.72953892e+00, ...,
          2.78598606e-07, 2.78598606e-07, 3.77041864e-08],
         [4.64189134e-06, 3.76136862e-02, 2.77929515e-01, ...,
          3.42992171e-05, 3.42992171e-05, 3.42992171e-05],
         [5.47397576e-05, 8.12409911e-03, 2.20835246e-02, ...,
          4.04474267e-04, 5.47397576e-05, 7.40820587e-06],
         ...,
         [1.25095566e-20, 2.51261152e-19, 1.64978170e-11, ...,
          3.40045581e-20, 9.24339309e-20, 2.51261152e-19],
         [1.02395306e+03, 3.13229772e-04, 4.23910060e-05, ...,
          2.11052270e-06, 2.11052270e-06, 3.86556245e-08],
         [7.81365527e-17, 3.54739596e-21, 5.26481228e-19, ...,
          2.32921755e-13, 1.43112441e-18, 1.19001896e-24]],

        [[3.77041864e-08, 3.05520749e-04, 6.72953892e+00, ...,
          2.78598606e-07, 2.78598606e-07, 3.77041864e-08],
         [4.64189134e-06, 3.76136862e-02, 2.77929515e-01, ...,
          3.42992171e-05, 3.42992171e-05, 3.42992171e-05],
         [5.47397576e-05, 8.12409911e-03, 2.20835246e-02, ...,
          4.04474267e-04, 5.47397576e-05, 7.40820587e-06],
         ...,
         [1.25095566e-20, 2.51261152e-19, 1.64978170e-11, ...,
          3.40045581e-20, 9.24339309e-20, 2.51261152e-19],
         [1.02395306e+03, 3.13229772e-04, 4.23910060e-05, ...,
          2.11052270e-06, 2.11052270e-06, 3.86556245e-08],
         [7.81365527e-17, 3.54739596e-21, 5.26481228e-19, ...,
          2.32921755e-13, 1.43112441e-18, 1.19001896e-24]],

        [[3.77041864e-08, 3.05520749e-04, 6.72953892e+00, ...,
          2.78598606e-07, 2.78598606e-07, 3.77041864e-08],
         [4.64189134e-06, 3.76136862e-02, 2.77929515e-01, ...,
          3.42992171e-05, 3.42992171e-05, 3.42992171e-05],
         [5.47397576e-05, 8.12409911e-03, 2.20835246e-02, ...,
          4.04474267e-04, 5.47397576e-05, 7.40820587e-06],
         ...,
         [1.25095566e-20, 2.51261152e-19, 1.64978170e-11, ...,
          3.40045581e-20, 9.24339309e-20, 2.51261152e-19],
         [1.02395306e+03, 3.13229772e-04, 4.23910060e-05, ...,
          2.11052270e-06, 2.11052270e-06, 3.86556245e-08],
         [7.81365527e-17, 3.54739596e-21, 5.26481228e-19, ...,
          2.32921755e-13, 1.43112441e-18, 1.19001896e-24]],

        ...,

        [[3.77041864e-08, 3.05520749e-04, 6.72953892e+00, ...,
          2.78598606e-07, 2.78598606e-07, 3.77041864e-08],
         [4.64189134e-06, 3.76136862e-02, 2.77929515e-01, ...,
          3.42992171e-05, 3.42992171e-05, 3.42992171e-05],
         [5.47397576e-05, 8.12409911e-03, 2.20835246e-02, ...,
          4.04474267e-04, 5.47397576e-05, 7.40820587e-06],
         ...,
         [1.25095566e-20, 2.51261152e-19, 1.64978170e-11, ...,
          3.40045581e-20, 9.24339309e-20, 2.51261152e-19],
         [1.02395306e+03, 3.13229772e-04, 4.23910060e-05, ...,
          2.11052270e-06, 2.11052270e-06, 3.86556245e-08],
         [7.81365527e-17, 3.54739596e-21, 5.26481228e-19, ...,
          2.32921755e-13, 1.43112441e-18, 1.19001896e-24]],

        [[3.77041864e-08, 3.05520749e-04, 6.72953892e+00, ...,
          2.78598606e-07, 2.78598606e-07, 3.77041864e-08],
         [4.64189134e-06, 3.76136862e-02, 2.77929515e-01, ...,
          3.42992171e-05, 3.42992171e-05, 3.42992171e-05],
         [5.47397576e-05, 8.12409911e-03, 2.20835246e-02, ...,
          4.04474267e-04, 5.47397576e-05, 7.40820587e-06],
         ...,
         [1.25095566e-20, 2.51261152e-19, 1.64978170e-11, ...,
          3.40045581e-20, 9.24339309e-20, 2.51261152e-19],
         [1.02395306e+03, 3.13229772e-04, 4.23910060e-05, ...,
          2.11052270e-06, 2.11052270e-06, 3.86556245e-08],
         [7.81365527e-17, 3.54739596e-21, 5.26481228e-19, ...,
          2.32921755e-13, 1.43112441e-18, 1.19001896e-24]],

        [[3.77041864e-08, 3.05520749e-04, 6.72953892e+00, ...,
          2.78598606e-07, 2.78598606e-07, 3.77041864e-08],
         [4.64189134e-06, 3.76136862e-02, 2.77929515e-01, ...,
          3.42992171e-05, 3.42992171e-05, 3.42992171e-05],
         [5.47397576e-05, 8.12409911e-03, 2.20835246e-02, ...,
          4.04474267e-04, 5.47397576e-05, 7.40820587e-06],
         ...,
         [1.25095566e-20, 2.51261152e-19, 1.64978170e-11, ...,
          3.40045581e-20, 9.24339309e-20, 2.51261152e-19],
         [1.02395306e+03, 3.13229772e-04, 4.23910060e-05, ...,
          2.11052270e-06, 2.11052270e-06, 3.86556245e-08],
         [7.81365527e-17, 3.54739596e-21, 5.26481228e-19, ...,
          2.32921755e-13, 1.43112441e-18, 1.19001896e-24]]]],
      dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [5], 'to': [1]}
tf node:
{'name': 'cos', 'output': array([[[[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        ...,

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [10], 'to': [8]}
ms node:
{'name': 'cos', 'output': array([[[[1.        , 0.99999994, 0.9020346 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.96162534, ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020346 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.96162534, ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020346 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.96162534, ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        ...,

        [[1.        , 0.99999994, 0.9020346 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.96162534, ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.90202695, ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.97881556, 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.90202695, ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.97881556, 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]]]], dtype=float32), 'output_shape': (1, 32, 32, 32), 'from': [10], 'to': [8]}
torch node:
{'name': 'cos', 'output': array([[[[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        ...,

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 0.99999994, 0.9020272 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.9992927 , 0.9616256 , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 0.999967  , 0.99975616, ..., 0.99999994,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [0.9788281 , 0.99999994, 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [10], 'to': [8]}

generate models:72

analyse the exceptions in iter:272
tensorflow exception:
{'id': 12, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([1.7427e+09], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 12, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([1.7427e+09], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:75

analyse output arrays in iter:415

pre layer res:
3:reshape
{'name': 'reshape', 'output': array([[[[8.7581248e+08, 1.1714232e+09, 1.1294638e+09, ...,
          9.7992704e+08, 9.2975923e+08, 8.8327782e+08],
         [8.6769664e+08, 8.7385702e+08, 8.9276416e+08, ...,
          1.1438817e+09, 1.1556291e+09, 7.7594624e+08],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         ...,
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09]],

        [[1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         ...,
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09]],

        [[1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         ...,
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09]],

        ...,

        [[1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         ...,
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09]],

        [[1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         ...,
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09]],

        [[1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [1.1860623e+09, 1.7571348e+09, 1.6941957e+09, ...,
          1.4698906e+09, 1.3946388e+09, 1.3249167e+09],
         ...,
         [1.3015450e+09, 1.3107855e+09, 1.3391462e+09, ...,
          1.7158226e+09, 1.7334436e+09, 1.1639194e+09],
         [7.9070822e+08, 1.1714232e+09, 1.1294638e+09, ...,
          9.7992704e+08, 9.2975923e+08, 8.8327782e+08],
         [8.6769664e+08, 8.7385702e+08, 8.9276416e+08, ...,
          1.1438817e+09, 1.1556291e+09, 7.7594624e+08]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [9], 'to': [13]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.5167452 , -0.8896215 ,  0.5176439 , ...,  0.97535235,
          -0.8379546 , -0.92254394],
         [ 0.7695961 , -0.45302162,  0.4778051 , ...,  0.8946881 ,
          -0.7824719 , -0.8750024 ],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        ...,

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [ 0.6227208 , -0.8896215 ,  0.5176439 , ...,  0.97535235,
          -0.8379546 , -0.92254394],
         [ 0.7695961 , -0.45302162,  0.4778051 , ...,  0.8946881 ,
          -0.7824719 , -0.8750024 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [3], 'to': [89]}
ms node:
{'name': 'sin', 'output': array([[[[ 0.9115982 , -0.8896215 ,  0.5176439 , ...,  0.97535235,
          -0.8379546 , -0.92254394],
         [ 0.7695961 , -0.45302162,  0.4778051 , ...,  0.8946881 ,
          -0.7824719 , -0.8750024 ],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        ...,

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [ 0.6227208 , -0.8896215 ,  0.5176439 , ...,  0.97535235,
          -0.8379546 , -0.92254394],
         [ 0.7695961 , -0.45302162,  0.4778051 , ...,  0.8946881 ,
          -0.7824719 , -0.8750024 ]]]], dtype=float32), 'output_shape': (1, 512, 16, 16), 'from': [3], 'to': [89]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.5167452 , -0.8896215 ,  0.5176439 , ...,  0.97535235,
          -0.8379546 , -0.92254394],
         [ 0.7695961 , -0.45302162,  0.4778051 , ...,  0.8946881 ,
          -0.7824719 , -0.8750024 ],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        ...,

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137]],

        [[-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [-0.5332803 , -0.9972649 ,  0.72850865, ...,  0.43647048,
           0.08042284, -0.981789  ],
         ...,
         [ 0.2507779 ,  0.64820725, -0.6796106 , ..., -0.09067767,
          -0.22101757, -0.02736137],
         [ 0.6227208 , -0.8896215 ,  0.5176439 , ...,  0.97535235,
          -0.8379546 , -0.92254394],
         [ 0.7695961 , -0.45302162,  0.4778051 , ...,  0.8946881 ,
          -0.7824719 , -0.8750024 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [3], 'to': [89]}

generate models:83

final statics:
total operators:28
tensorflow --> nums:5,distinct_bugs:3
mindspore --> nums:10,distinct_bugs:4
torch --> nums:5,distinct_bugs:3
tensorflow --> 
sin:3
log:1
flatten:1
mindspore --> 
sin:5
mean:1
cos:2
log:2
torch --> 
sin:3
log:1
flatten:1

generate models:89

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:10

analyse output arrays in iter:11

pre layer res:
2:add
{'name': 'add', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 8, 8]), 'from': [9, 12], 'to': [0]}
tf node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 8, 8]), 'from': [2], 'to': [48]}
ms node:
{'name': 'log', 'output': array([[[[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        ...,

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]]]], dtype=float32), 'output_shape': (1, 1024, 8, 8), 'from': [2], 'to': [48]}
torch node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 8, 8]), 'from': [2], 'to': [48]}

generate models:11

analyse the exceptions in iter:31
tensorflow exception:
{'id': 4, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([nan], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 4, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([nan], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:26

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:1,distinct_bugs:1
tensorflow --> 
flatten:1
mindspore --> 
log:1
torch --> 
flatten:1

generate models:35

analyse the exceptions in iter:53
tensorflow exception:
{'id': 13, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([1.4601e+08], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 13, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([1.4601e+08], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:38

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:2,distinct_bugs:1
tensorflow --> 
flatten:2
mindspore --> 
log:1
torch --> 
flatten:2

generate models:51

analyse output arrays in iter:105

pre layer res:
73:slice
{'name': 'slice', 'output': array([[1. , 1. , 1. , ..., 0.5, 0.5, 0.5]], dtype=float32), 'output_shape': torch.Size([1, 82944]), 'from': [9], 'to': [1]}
tf node:
{'name': 'log', 'output': array([[ 0.       ,  0.       ,  0.       , ..., -0.6931472, -0.6931472,
        -0.6931472]], dtype=float32), 'output_shape': torch.Size([1, 82944]), 'from': [73], 'to': [74]}
ms node:
{'name': 'log', 'output': array([[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
        -6.9314861e-01, -6.9314861e-01, -6.9314861e-01]], dtype=float32), 'output_shape': (1, 82944), 'from': [73], 'to': [74]}
torch node:
{'name': 'log', 'output': array([[ 0.       ,  0.       ,  0.       , ..., -0.6931472, -0.6931472,
        -0.6931472]], dtype=float32), 'output_shape': torch.Size([1, 82944]), 'from': [73], 'to': [74]}

generate models:52

analyse the exceptions in iter:180

generate models:59

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse output arrays in iter:38

pre layer res:
1:add
{'name': 'add', 'output': array([[[[32.861977, 40.078663, 41.402332, ...,  6.783829,       inf,
                inf],
         [31.976982, 39.514153, 42.008186, ..., 32.723476, 29.993053,
          19.13882 ],
         [29.772099, 38.913258, 41.931637, ..., 41.86408 , 39.423813,
          29.643759],
         ...,
         [27.952742, 29.089985, 30.092995, ..., 11.37775 , 10.703561,
           8.537369],
         [29.807076, 28.92152 , 27.824081, ..., 24.82428 , 23.631485,
          21.690536],
         [30.963886, 26.82687 , 29.381086, ..., 10.51104 , 10.994801,
           9.887358]],

        [[32.861977, 40.078663, 41.402332, ...,  6.783829,       inf,
                inf],
         [31.976982, 39.514153, 42.008186, ..., 32.723476, 29.993053,
          19.13882 ],
         [29.772099, 38.913258, 41.931637, ..., 41.86408 , 39.423813,
          29.643759],
         ...,
         [27.952742, 29.089985, 30.092995, ..., 11.37775 , 10.703561,
           8.537369],
         [29.807076, 28.92152 , 27.824081, ..., 24.82428 , 23.631485,
          21.690536],
         [30.963886, 26.82687 , 29.381086, ..., 10.51104 , 10.994801,
           9.887358]],

        [[32.861977, 40.078663, 41.402332, ...,  6.783829,       inf,
                inf],
         [31.976982, 39.514153, 42.008186, ..., 32.723476, 29.993053,
          19.13882 ],
         [29.772099, 38.913258, 41.931637, ..., 41.86408 , 39.423813,
          29.643759],
         ...,
         [27.952742, 29.089985, 30.092995, ..., 11.37775 , 10.703561,
           8.537369],
         [29.807076, 28.92152 , 27.824081, ..., 24.82428 , 23.631485,
          21.690536],
         [30.963886, 26.82687 , 29.381086, ..., 10.51104 , 10.994801,
           9.887358]],

        ...,

        [[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         ...,
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ]],

        [[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         ...,
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ]],

        [[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         ...,
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ],
         [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,
           0.      ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [5, 8], 'to': [0]}
tf node:
{'name': 'cos', 'output': array([[[[ 1.24422945e-01, -7.23427951e-01, -8.46389294e-01, ...,
           8.77273679e-01,             nan,             nan],
         [ 8.46693933e-01, -2.41823182e-01, -3.92469049e-01, ...,
           2.60216534e-01,  1.47384360e-01,  9.58453894e-01],
         [-7.29667619e-02,  3.49137545e-01, -4.61658567e-01, ...,
          -5.20487964e-01, -1.53297842e-01, -2.00013235e-01],
         ...,
         [-9.48733330e-01, -6.85394466e-01,  2.45334268e-01, ...,
           3.72940481e-01, -2.87881017e-01, -6.31423175e-01],
         [-3.80455256e-02, -7.97783434e-01, -9.00337279e-01, ...,
           9.52801824e-01,  6.94840476e-02, -9.55155432e-01],
         [ 8.99557769e-01, -1.23019978e-01, -4.47567970e-01, ...,
          -4.65796530e-01, -7.73719861e-04, -8.94904256e-01]],

        [[ 1.24422945e-01, -7.23427951e-01, -8.46389294e-01, ...,
           8.77273679e-01,             nan,             nan],
         [ 8.46693933e-01, -2.41823182e-01, -3.92469049e-01, ...,
           2.60216534e-01,  1.47384360e-01,  9.58453894e-01],
         [-7.29667619e-02,  3.49137545e-01, -4.61658567e-01, ...,
          -5.20487964e-01, -1.53297842e-01, -2.00013235e-01],
         ...,
         [-9.48733330e-01, -6.85394466e-01,  2.45334268e-01, ...,
           3.72940481e-01, -2.87881017e-01, -6.31423175e-01],
         [-3.80455256e-02, -7.97783434e-01, -9.00337279e-01, ...,
           9.52801824e-01,  6.94840476e-02, -9.55155432e-01],
         [ 8.99557769e-01, -1.23019978e-01, -4.47567970e-01, ...,
          -4.65796530e-01, -7.73719861e-04, -8.94904256e-01]],

        [[ 1.24422945e-01, -7.23427951e-01, -8.46389294e-01, ...,
           8.77273679e-01,             nan,             nan],
         [ 8.46693933e-01, -2.41823182e-01, -3.92469049e-01, ...,
           2.60216534e-01,  1.47384360e-01,  9.58453894e-01],
         [-7.29667619e-02,  3.49137545e-01, -4.61658567e-01, ...,
          -5.20487964e-01, -1.53297842e-01, -2.00013235e-01],
         ...,
         [-9.48733330e-01, -6.85394466e-01,  2.45334268e-01, ...,
           3.72940481e-01, -2.87881017e-01, -6.31423175e-01],
         [-3.80455256e-02, -7.97783434e-01, -9.00337279e-01, ...,
           9.52801824e-01,  6.94840476e-02, -9.55155432e-01],
         [ 8.99557769e-01, -1.23019978e-01, -4.47567970e-01, ...,
          -4.65796530e-01, -7.73719861e-04, -8.94904256e-01]],

        ...,

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]]]],
      dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [1], 'to': [48]}
ms node:
{'name': 'cos', 'output': array([[[[ 1.24419160e-01, -7.23414838e-01, -8.46369028e-01, ...,
           8.77278924e-01,             nan,             nan],
         [ 8.46703053e-01, -2.41782457e-01, -3.92433941e-01, ...,
           2.60205477e-01,  1.47373036e-01,  9.58458245e-01],
         [-7.29819834e-02,  3.49173278e-01, -4.61678863e-01, ...,
          -5.20455360e-01, -1.53256372e-01, -2.00030059e-01],
         ...,
         [-9.48724926e-01, -6.85402811e-01,  2.45323166e-01, ...,
           3.72926295e-01, -2.87895650e-01, -6.31416500e-01],
         [-3.80550548e-02, -7.97799528e-01, -9.00322318e-01, ...,
           9.52811658e-01,  6.94878548e-02, -9.55150366e-01],
         [ 8.99551094e-01, -1.23001054e-01, -4.47590142e-01, ...,
          -4.65810031e-01, -7.88978650e-04, -8.94896567e-01]],

        [[ 1.24419160e-01, -7.23414838e-01, -8.46369028e-01, ...,
           8.77278924e-01,             nan,             nan],
         [ 8.46703053e-01, -2.41782457e-01, -3.92433941e-01, ...,
           2.60205477e-01,  1.47373036e-01,  9.58458245e-01],
         [-7.29819834e-02,  3.49173278e-01, -4.61678863e-01, ...,
          -5.20455360e-01, -1.53256372e-01, -2.00030059e-01],
         ...,
         [-9.48724926e-01, -6.85402811e-01,  2.45323166e-01, ...,
           3.72926295e-01, -2.87895650e-01, -6.31416500e-01],
         [-3.80550548e-02, -7.97799528e-01, -9.00322318e-01, ...,
           9.52811658e-01,  6.94878548e-02, -9.55150366e-01],
         [ 8.99551094e-01, -1.23001054e-01, -4.47590142e-01, ...,
          -4.65810031e-01, -7.88978650e-04, -8.94896567e-01]],

        [[ 1.24419160e-01, -7.23414838e-01, -8.46369028e-01, ...,
           8.77278924e-01,             nan,             nan],
         [ 8.46703053e-01, -2.41782457e-01, -3.92433941e-01, ...,
           2.60205477e-01,  1.47373036e-01,  9.58458245e-01],
         [-7.29819834e-02,  3.49173278e-01, -4.61678863e-01, ...,
          -5.20455360e-01, -1.53256372e-01, -2.00030059e-01],
         ...,
         [-9.48724926e-01, -6.85402811e-01,  2.45323166e-01, ...,
           3.72926295e-01, -2.87895650e-01, -6.31416500e-01],
         [-3.80550548e-02, -7.97799528e-01, -9.00322318e-01, ...,
           9.52811658e-01,  6.94878548e-02, -9.55150366e-01],
         [ 8.99551094e-01, -1.23001054e-01, -4.47590142e-01, ...,
          -4.65810031e-01, -7.88978650e-04, -8.94896567e-01]],

        ...,

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]]]],
      dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [1], 'to': [48]}
torch node:
{'name': 'cos', 'output': array([[[[ 1.24422945e-01, -7.23427951e-01, -8.46389294e-01, ...,
           8.77273679e-01,             nan,             nan],
         [ 8.46693933e-01, -2.41823182e-01, -3.92469049e-01, ...,
           2.60216534e-01,  1.47384360e-01,  9.58453894e-01],
         [-7.29667619e-02,  3.49137545e-01, -4.61658567e-01, ...,
          -5.20487964e-01, -1.53297842e-01, -2.00013235e-01],
         ...,
         [-9.48733330e-01, -6.85394466e-01,  2.45334268e-01, ...,
           3.72940481e-01, -2.87881017e-01, -6.31423175e-01],
         [-3.80455256e-02, -7.97783434e-01, -9.00337279e-01, ...,
           9.52801824e-01,  6.94840476e-02, -9.55155432e-01],
         [ 8.99557769e-01, -1.23019978e-01, -4.47567970e-01, ...,
          -4.65796530e-01, -7.73719861e-04, -8.94904256e-01]],

        [[ 1.24422945e-01, -7.23427951e-01, -8.46389294e-01, ...,
           8.77273679e-01,             nan,             nan],
         [ 8.46693933e-01, -2.41823182e-01, -3.92469049e-01, ...,
           2.60216534e-01,  1.47384360e-01,  9.58453894e-01],
         [-7.29667619e-02,  3.49137545e-01, -4.61658567e-01, ...,
          -5.20487964e-01, -1.53297842e-01, -2.00013235e-01],
         ...,
         [-9.48733330e-01, -6.85394466e-01,  2.45334268e-01, ...,
           3.72940481e-01, -2.87881017e-01, -6.31423175e-01],
         [-3.80455256e-02, -7.97783434e-01, -9.00337279e-01, ...,
           9.52801824e-01,  6.94840476e-02, -9.55155432e-01],
         [ 8.99557769e-01, -1.23019978e-01, -4.47567970e-01, ...,
          -4.65796530e-01, -7.73719861e-04, -8.94904256e-01]],

        [[ 1.24422945e-01, -7.23427951e-01, -8.46389294e-01, ...,
           8.77273679e-01,             nan,             nan],
         [ 8.46693933e-01, -2.41823182e-01, -3.92469049e-01, ...,
           2.60216534e-01,  1.47384360e-01,  9.58453894e-01],
         [-7.29667619e-02,  3.49137545e-01, -4.61658567e-01, ...,
          -5.20487964e-01, -1.53297842e-01, -2.00013235e-01],
         ...,
         [-9.48733330e-01, -6.85394466e-01,  2.45334268e-01, ...,
           3.72940481e-01, -2.87881017e-01, -6.31423175e-01],
         [-3.80455256e-02, -7.97783434e-01, -9.00337279e-01, ...,
           9.52801824e-01,  6.94840476e-02, -9.55155432e-01],
         [ 8.99557769e-01, -1.23019978e-01, -4.47567970e-01, ...,
          -4.65796530e-01, -7.73719861e-04, -8.94904256e-01]],

        ...,

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]],

        [[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         ...,
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00],
         [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,
           1.00000000e+00,  1.00000000e+00,  1.00000000e+00]]]],
      dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [1], 'to': [48]}

generate models:30

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:1,distinct_bugs:1
tensorflow --> 
cos:1
mindspore --> 
cos:1
torch --> 
cos:1

generate models:37

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:1,distinct_bugs:1
tensorflow --> 
cos:1
mindspore --> 
cos:1
torch --> 
cos:1

generate models:56

analyse output arrays in iter:134

pre layer res:
5:conv2d
{'name': 'conv2d', 'output': array([[[[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         ...,
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        [[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         ...,
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        [[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         ...,
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        ...,

        [[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         ...,
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        [[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         ...,
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        [[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         ...,
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0., 2064384., 2064384., ..., 1327104., 1327104.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [24], 'to': [1, 6]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [5], 'to': [13]}
ms node:
{'name': 'sin', 'output': array([[[[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         ...,
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         ...,
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         ...,
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00, -4.9250960e-01, -4.9250960e-01, ...,
           8.4966207e-01,  8.4966207e-01,  0.0000000e+00],
         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],

        ...,

        [[ 6.8864000e+04,  5.4528000e+04,  3.3536000e+04, ...,
           7.4240000e+04,  7.0400000e+04,  7.5008000e+04],
         [ 3.5584000e+04,  1.7152000e+04,  3.4560000e+04, ...,
           8.1152000e+04,  2.2784000e+04,  5.3760000e+03],
         [ 6.4000000e+03,  6.4000000e+03,  6.9120000e+03, ...,
           1.2032000e+04,  1.6384000e+04,  2.2016000e+04],
         ...,
         [ 3.6096000e+04,  7.4240000e+04,  7.0400000e+04, ...,
           6.4000000e+03,  2.1760000e+04,  8.3968000e+04],
         [ 9.9072000e+04,  8.1152000e+04,  2.2784000e+04, ...,
           5.4016000e+04,  9.2928000e+04,  5.0944000e+04],
         [ 1.1776000e+04,  1.2032000e+04,  1.6384000e+04, ...,
           6.7072000e+04,  6.6816000e+04,  6.9632000e+04]],

        [[ 7.1424000e+04,  7.1424000e+04,  7.5776000e+04, ...,
           8.0640000e+04,  7.7312000e+04,  7.2960000e+04],
         [ 7.1936000e+04,  7.0144000e+04,  6.9120000e+04, ...,
           4.3776000e+04,  4.2240000e+04,  4.0704000e+04],
         [ 3.8656000e+04,  3.7120000e+04,  3.5584000e+04, ...,
           8.4480000e+03,  7.9360000e+03,  6.9120000e+03],
         ...,
         [ 4.1856000e+04,  4.0320000e+04,  3.8656000e+04, ...,
           2.5984000e+04,  2.4960000e+04,  2.3808000e+04],
         [ 2.2784000e+04,  2.1888000e+04,  2.1120000e+04, ...,
           6.2720000e+03,  5.5040000e+03,  5.5040000e+03],
         [ 4.7360000e+03,  4.2240000e+03,  3.9680000e+03, ...,
           1.1520000e+03,  1.0240000e+03,  1.0240000e+03]],

        [[ 1.1520000e+03,  1.1520000e+03,  1.1520000e+03, ...,
           1.1520000e+03,  1.1520000e+03,  1.1520000e+03],
         [ 1.1520000e+03,  1.1520000e+03,  1.7920000e+03, ...,
           1.1520000e+03,  1.1520000e+03,  1.1520000e+03],
         [ 1.7920000e+03,  1.7920000e+03,  1.9200000e+03, ...,
           1.1520000e+03,  1.7920000e+03,  1.7920000e+03],
         ...,
         [ 1.2800000e+03,  1.1520000e+03,  1.1520000e+03, ...,
           1.1520000e+03,  1.1520000e+03,  1.1520000e+03],
         [ 1.1520000e+03,  1.1520000e+03,  1.1520000e+03, ...,
           1.1520000e+03,  1.1520000e+03,  1.1520000e+03],
         [ 1.1520000e+03,  1.1520000e+03,  1.7920000e+03, ...,
           1.1520000e+03,  1.1520000e+03,  1.1520000e+03]]]],
      dtype=float32), 'output_shape': (1, 256, 34, 34), 'from': [5], 'to': [13]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         ...,
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        , -0.4925096 , -0.4925096 , ...,  0.84966207,
           0.84966207,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [5], 'to': [13]}

generate models:65

analyse output arrays in iter:173

pre layer res:
23:add
{'name': 'add', 'output': array([[[[27649.168 , 20610.232 ,  7744.5713, ..., 13248.575 ,
           4098.3745,  2689.9297],
         [27328.814 , 19776.623 , 10112.864 , ..., 20417.219 ,
          17985.617 , 12993.514 ],
         [27522.51  , 18817.031 , 12993.514 , ..., 21953.691 ,
          22338.32  , 22145.105 ],
         ...,
         [ 8513.426 ,  8128.8057,  7938.5146, ..., 11457.389 ,
          11010.561 , 16000.579 ],
         [11650.089 , 11969.673 , 12034.525 , ..., 14146.423 ,
          11650.089 , 11904.695 ],
         [14146.423 , 14529.861 , 14146.423 , ..., 15745.479 ,
          14721.638 , 12608.865 ]],

        [[27649.168 , 20610.232 ,  7744.5713, ..., 13248.575 ,
           4098.3745,  2689.9297],
         [27328.814 , 19776.623 , 10112.864 , ..., 20417.219 ,
          17985.617 , 12993.514 ],
         [27522.51  , 18817.031 , 12993.514 , ..., 21953.691 ,
          22338.32  , 22145.105 ],
         ...,
         [ 8513.426 ,  8128.8057,  7938.5146, ..., 11457.389 ,
          11010.561 , 16000.579 ],
         [11650.089 , 11969.673 , 12034.525 , ..., 14146.423 ,
          11650.089 , 11904.695 ],
         [14146.423 , 14529.861 , 14146.423 , ..., 15745.479 ,
          14721.638 , 12608.865 ]],

        [[27649.168 , 20610.232 ,  7744.5713, ..., 13248.575 ,
           4098.3745,  2689.9297],
         [27328.814 , 19776.623 , 10112.864 , ..., 20417.219 ,
          17985.617 , 12993.514 ],
         [27522.51  , 18817.031 , 12993.514 , ..., 21953.691 ,
          22338.32  , 22145.105 ],
         ...,
         [ 8513.426 ,  8128.8057,  7938.5146, ..., 11457.389 ,
          11010.561 , 16000.579 ],
         [11650.089 , 11969.673 , 12034.525 , ..., 14146.423 ,
          11650.089 , 11904.695 ],
         [14146.423 , 14529.861 , 14146.423 , ..., 15745.479 ,
          14721.638 , 12608.865 ]],

        ...,

        [[27649.168 , 20610.232 ,  7744.5713, ..., 13248.575 ,
           4098.3745,  2689.9297],
         [27328.814 , 19776.623 , 10112.864 , ..., 20417.219 ,
          17985.617 , 12993.514 ],
         [27522.51  , 18817.031 , 12993.514 , ..., 21953.691 ,
          22338.32  , 22145.105 ],
         ...,
         [ 8513.426 ,  8128.8057,  7938.5146, ..., 11457.389 ,
          11010.561 , 16000.579 ],
         [11650.089 , 11969.673 , 12034.525 , ..., 14146.423 ,
          11650.089 , 11904.695 ],
         [14146.423 , 14529.861 , 14146.423 , ..., 15745.479 ,
          14721.638 , 12608.865 ]],

        [[27649.168 , 20610.232 ,  7744.5713, ..., 13248.575 ,
           4098.3745,  2689.9297],
         [27328.814 , 19776.623 , 10112.864 , ..., 20417.219 ,
          17985.617 , 12993.514 ],
         [27522.51  , 18817.031 , 12993.514 , ..., 21953.691 ,
          22338.32  , 22145.105 ],
         ...,
         [ 8513.426 ,  8128.8057,  7938.5146, ..., 11457.389 ,
          11010.561 , 16000.579 ],
         [11650.089 , 11969.673 , 12034.525 , ..., 14146.423 ,
          11650.089 , 11904.695 ],
         [14146.423 , 14529.861 , 14146.423 , ..., 15745.479 ,
          14721.638 , 12608.865 ]],

        [[27649.168 , 20610.232 ,  7744.5713, ..., 13248.575 ,
           4098.3745,  2689.9297],
         [27328.814 , 19776.623 , 10112.864 , ..., 20417.219 ,
          17985.617 , 12993.514 ],
         [27522.51  , 18817.031 , 12993.514 , ..., 21953.691 ,
          22338.32  , 22145.105 ],
         ...,
         [ 8513.426 ,  8128.8057,  7938.5146, ..., 11457.389 ,
          11010.561 , 16000.579 ],
         [11650.089 , 11969.673 , 12034.525 , ..., 14146.423 ,
          11650.089 , 11904.695 ],
         [14146.423 , 14529.861 , 14146.423 , ..., 15745.479 ,
          14721.638 , 12608.865 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [22, 13], 'to': [1, 3]}
tf node:
{'name': 'sin', 'output': array([[[[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        ...,

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]]]],
      dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [23], 'to': [24]}
ms node:
{'name': 'sin', 'output': array([[[[-1.1024283e-02,  9.8271811e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271811e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271811e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        ...,

        [[ 1.5707601e+00,  1.5707479e+00,  1.5706671e+00, ...,
           1.5707208e+00,  1.5705522e+00,  1.5704243e+00],
         [ 1.5707598e+00,  1.5707457e+00,  1.5706974e+00, ...,
           1.5707474e+00,  1.5707407e+00,  1.5707194e+00],
         [ 1.5707600e+00,  1.5707432e+00,  1.5707194e+00, ...,
           1.5707508e+00,  1.5707515e+00,  1.5707512e+00],
         ...,
         [ 1.5706788e+00,  1.5706732e+00,  1.5706704e+00, ...,
           1.5707090e+00,  1.5707055e+00,  1.5707338e+00],
         [ 1.5707104e+00,  1.5707128e+00,  1.5707132e+00, ...,
           1.5707257e+00,  1.5707104e+00,  1.5707123e+00],
         [ 1.5707257e+00,  1.5707275e+00,  1.5707257e+00, ...,
           1.5707328e+00,  1.5707284e+00,  1.5707170e+00]],

        [[ 1.5707601e+00,  1.5707479e+00,  1.5706671e+00, ...,
           1.5707208e+00,  1.5705522e+00,  1.5704243e+00],
         [ 1.5707598e+00,  1.5707457e+00,  1.5706974e+00, ...,
           1.5707474e+00,  1.5707407e+00,  1.5707194e+00],
         [ 1.5707600e+00,  1.5707432e+00,  1.5707194e+00, ...,
           1.5707508e+00,  1.5707515e+00,  1.5707512e+00],
         ...,
         [ 1.5706788e+00,  1.5706732e+00,  1.5706704e+00, ...,
           1.5707090e+00,  1.5707055e+00,  1.5707338e+00],
         [ 1.5707104e+00,  1.5707128e+00,  1.5707132e+00, ...,
           1.5707257e+00,  1.5707104e+00,  1.5707123e+00],
         [ 1.5707257e+00,  1.5707275e+00,  1.5707257e+00, ...,
           1.5707328e+00,  1.5707284e+00,  1.5707170e+00]],

        [[ 1.5707601e+00,  1.5707479e+00,  1.5706671e+00, ...,
           1.5707208e+00,  1.5705522e+00,  1.5704243e+00],
         [ 1.5707598e+00,  1.5707457e+00,  1.5706974e+00, ...,
           1.5707474e+00,  1.5707407e+00,  1.5707194e+00],
         [ 1.5707600e+00,  1.5707432e+00,  1.5707194e+00, ...,
           1.5707508e+00,  1.5707515e+00,  1.5707512e+00],
         ...,
         [ 1.5706788e+00,  1.5706732e+00,  1.5706704e+00, ...,
           1.5707090e+00,  1.5707055e+00,  1.5707338e+00],
         [ 1.5707104e+00,  1.5707128e+00,  1.5707132e+00, ...,
           1.5707257e+00,  1.5707104e+00,  1.5707123e+00],
         [ 1.5707257e+00,  1.5707275e+00,  1.5707257e+00, ...,
           1.5707328e+00,  1.5707284e+00,  1.5707170e+00]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [23], 'to': [24]}
torch node:
{'name': 'sin', 'output': array([[[[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        ...,

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]],

        [[-1.1024283e-02,  9.8271817e-01, -5.1875836e-01, ...,
          -4.6086988e-01,  9.8610532e-01,  6.6416478e-01],
         [-9.9793166e-02, -2.9293257e-01, -7.7428333e-02, ...,
          -8.0942316e-03,  7.5430149e-04, -1.1329956e-01],
         [ 8.3242661e-01, -8.9513993e-01, -1.1329956e-01, ...,
           2.3958945e-01,  9.9966854e-01, -1.8852478e-02],
         ...,
         [-2.8624925e-01, -9.9786693e-01,  2.8593993e-01, ...,
          -2.6423301e-04,  6.6066474e-01, -4.3290854e-01],
         [ 8.7396777e-01,  2.0341186e-01,  7.9321176e-01, ...,
           1.6806611e-01,  8.7396777e-01, -9.3230987e-01],
         [ 1.6806611e-01,  4.6947105e-03,  1.6806611e-01, ...,
          -1.8282996e-01,  1.3411525e-01, -9.9654758e-01]]]],
      dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [23], 'to': [24]}

generate models:71

analyse output arrays in iter:237

pre layer res:
1:exp
{'name': 'exp', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [22], 'to': [17]}
tf node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [23]}
ms node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [1], 'to': [23]}
torch node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [23]}

generate models:79

analyse output arrays in iter:340

pre layer res:
9:add
{'name': 'add', 'output': array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.4905328e+08, 4.5141184e+08, ...,
          4.3411050e+08, 4.3411050e+08, 0.0000000e+00],
         [0.0000000e+00, 4.4433405e+08, 4.4905328e+08, ...,
          4.1208970e+08, 4.1051744e+08, 0.0000000e+00],
         ...,
         [0.0000000e+00, 4.5691757e+08, 4.6242259e+08, ...,
          4.2939251e+08, 4.2781917e+08, 0.0000000e+00],
         [0.0000000e+00, 4.6163571e+08, 4.6635357e+08, ...,
          4.4590630e+08, 4.4354813e+08, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.4905328e+08, 4.5141184e+08, ...,
          4.3411050e+08, 4.3411050e+08, 0.0000000e+00],
         [0.0000000e+00, 4.4433405e+08, 4.4905328e+08, ...,
          4.1208970e+08, 4.1051744e+08, 0.0000000e+00],
         ...,
         [0.0000000e+00, 4.5691757e+08, 4.6242259e+08, ...,
          4.2939251e+08, 4.2781917e+08, 0.0000000e+00],
         [0.0000000e+00, 4.6163571e+08, 4.6635357e+08, ...,
          4.4590630e+08, 4.4354813e+08, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.4905328e+08, 4.5141184e+08, ...,
          4.3411050e+08, 4.3411050e+08, 0.0000000e+00],
         [0.0000000e+00, 4.4433405e+08, 4.4905328e+08, ...,
          4.1208970e+08, 4.1051744e+08, 0.0000000e+00],
         ...,
         [0.0000000e+00, 4.5691757e+08, 4.6242259e+08, ...,
          4.2939251e+08, 4.2781917e+08, 0.0000000e+00],
         [0.0000000e+00, 4.6163571e+08, 4.6635357e+08, ...,
          4.4590630e+08, 4.4354813e+08, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        ...,

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.4905328e+08, 4.5141184e+08, ...,
          4.3411050e+08, 4.3411050e+08, 0.0000000e+00],
         [0.0000000e+00, 4.4433405e+08, 4.4905328e+08, ...,
          4.1208970e+08, 4.1051744e+08, 0.0000000e+00],
         ...,
         [0.0000000e+00, 4.5691757e+08, 4.6242259e+08, ...,
          4.2939251e+08, 4.2781917e+08, 0.0000000e+00],
         [0.0000000e+00, 4.6163571e+08, 4.6635357e+08, ...,
          4.4590630e+08, 4.4354813e+08, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.4905328e+08, 4.5141184e+08, ...,
          4.3411050e+08, 4.3411050e+08, 0.0000000e+00],
         [0.0000000e+00, 4.4433405e+08, 4.4905328e+08, ...,
          4.1208970e+08, 4.1051744e+08, 0.0000000e+00],
         ...,
         [0.0000000e+00, 4.5691757e+08, 4.6242259e+08, ...,
          4.2939251e+08, 4.2781917e+08, 0.0000000e+00],
         [0.0000000e+00, 4.6163571e+08, 4.6635357e+08, ...,
          4.4590630e+08, 4.4354813e+08, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.4905328e+08, 4.5141184e+08, ...,
          4.3411050e+08, 4.3411050e+08, 0.0000000e+00],
         [0.0000000e+00, 4.4433405e+08, 4.4905328e+08, ...,
          4.1208970e+08, 4.1051744e+08, 0.0000000e+00],
         ...,
         [0.0000000e+00, 4.5691757e+08, 4.6242259e+08, ...,
          4.2939251e+08, 4.2781917e+08, 0.0000000e+00],
         [0.0000000e+00, 4.6163571e+08, 4.6635357e+08, ...,
          4.4590630e+08, 4.4354813e+08, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [21, 12], 'to': [13]}
tf node:
{'name': 'cos', 'output': array([[[[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        ...,

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [9], 'to': [0]}
ms node:
{'name': 'cos', 'output': array([[[[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        ...,

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': (1, 256, 34, 34), 'from': [9], 'to': [0]}
torch node:
{'name': 'cos', 'output': array([[[[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        ...,

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]],

        [[ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ],
         [ 1.        ,  0.16493711, -0.27169585, ..., -0.22717492,
          -0.22717492,  1.        ],
         [ 1.        ,  0.7149202 ,  0.16493711, ...,  0.74746054,
           0.31755292,  1.        ],
         ...,
         [ 1.        , -0.9789323 , -0.3923375 , ...,  0.37655663,
          -0.518002  ,  1.        ],
         [ 1.        , -0.98515964, -0.8888793 , ..., -0.9237289 ,
           0.9038705 ,  1.        ],
         [ 1.        ,  1.        ,  1.        , ...,  1.        ,
           1.        ,  1.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [9], 'to': [0]}

generate models:84

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:5,distinct_bugs:2
torch --> nums:2,distinct_bugs:1
tensorflow --> 
cos:2
mindspore --> 
cos:3
sin:2
torch --> 
cos:2

generate models:93

analyse output arrays in iter:6

pre layer res:
6:exp
{'name': 'exp', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [7], 'to': [3]}
tf node:
{'name': 'log', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [6], 'to': [11]}
ms node:
{'name': 'log', 'output': array([[[[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        ...,

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]]]],
      dtype=float32), 'output_shape': (1, 256, 34, 34), 'from': [6], 'to': [11]}
torch node:
{'name': 'log', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 34, 34]), 'from': [6], 'to': [11]}

generate models:7

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
log:1
torch --> 

generate models:10

analyse output arrays in iter:10

pre layer res:
6:arctan
{'name': 'arctan', 'output': array([[[[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 1.5697963, 1.5698164, ..., 0.       , 1.5666704,
          0.       ],
         [0.       , 0.       , 1.5663458, ..., 1.5688382, 1.5697634,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 1.5569887, 1.5696836,
          0.       ],
         [0.       , 0.       , 1.5615827, ..., 1.5693934, 1.5698   ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 1.5697963, 1.5698164, ..., 0.       , 1.5666704,
          0.       ],
         [0.       , 0.       , 1.5663458, ..., 1.5688382, 1.5697634,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 1.5569887, 1.5696836,
          0.       ],
         [0.       , 0.       , 1.5615827, ..., 1.5693934, 1.5698   ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 1.5697963, 1.5698164, ..., 0.       , 1.5666704,
          0.       ],
         [0.       , 0.       , 1.5663458, ..., 1.5688382, 1.5697634,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 1.5569887, 1.5696836,
          0.       ],
         [0.       , 0.       , 1.5615827, ..., 1.5693934, 1.5698   ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        ...,

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 1.5697963, 1.5698164, ..., 0.       , 1.5666704,
          0.       ],
         [0.       , 0.       , 1.5663458, ..., 1.5688382, 1.5697634,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 1.5569887, 1.5696836,
          0.       ],
         [0.       , 0.       , 1.5615827, ..., 1.5693934, 1.5698   ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 1.5697963, 1.5698164, ..., 0.       , 1.5666704,
          0.       ],
         [0.       , 0.       , 1.5663458, ..., 1.5688382, 1.5697634,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 1.5569887, 1.5696836,
          0.       ],
         [0.       , 0.       , 1.5615827, ..., 1.5693934, 1.5698   ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]],

        [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ],
         [0.       , 1.5697963, 1.5698164, ..., 0.       , 1.5666704,
          0.       ],
         [0.       , 0.       , 1.5663458, ..., 1.5688382, 1.5697634,
          0.       ],
         ...,
         [0.       , 0.       , 0.       , ..., 1.5569887, 1.5696836,
          0.       ],
         [0.       , 0.       , 1.5615827, ..., 1.5693934, 1.5698   ,
          0.       ],
         [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
          0.       ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [9], 'to': [8]}
tf node:
{'name': 'sin', 'output': array([[[[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        ...,

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [6], 'to': [10]}
ms node:
{'name': 'sin', 'output': array([[[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 9.99999523e-01, 9.99999523e-01, ...,
          0.00000000e+00, 9.99991477e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 9.99990106e-01, ...,
          9.99998093e-01, 9.99999464e-01, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          9.99904692e-01, 9.99999404e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 9.99957561e-01, ...,
          9.99998987e-01, 9.99999523e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 9.99999523e-01, 9.99999523e-01, ...,
          0.00000000e+00, 9.99991477e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 9.99990106e-01, ...,
          9.99998093e-01, 9.99999464e-01, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          9.99904692e-01, 9.99999404e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 9.99957561e-01, ...,
          9.99998987e-01, 9.99999523e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 9.99999523e-01, 9.99999523e-01, ...,
          0.00000000e+00, 9.99991477e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 9.99990106e-01, ...,
          9.99998093e-01, 9.99999464e-01, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          9.99904692e-01, 9.99999404e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 9.99957561e-01, ...,
          9.99998987e-01, 9.99999523e-01, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        ...,

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 1.00003046e+03, 1.02038696e+03, ...,
          0.00000000e+00, 2.42371109e+02, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 2.24691422e+02, ...,
          5.10710449e+02, 9.68137451e+02, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          7.24197159e+01, 8.98652893e+02, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 1.08531242e+02, ...,
          7.12785522e+02, 1.00376556e+03, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 1.00002972e+03, 1.02038330e+03, ...,
          0.00000000e+00, 2.42371124e+02, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 2.24691422e+02, ...,
          5.10709961e+02, 9.68134766e+02, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          7.24195099e+01, 8.98650635e+02, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 1.08531242e+02, ...,
          7.12786438e+02, 1.00376556e+03, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],

        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
         [0.00000000e+00, 1.00002972e+03, 1.02038330e+03, ...,
          0.00000000e+00, 2.42371124e+02, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 2.24691422e+02, ...,
          5.10709961e+02, 9.68134766e+02, 0.00000000e+00],
         ...,
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          7.24195099e+01, 8.98650635e+02, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 1.08531242e+02, ...,
          7.12786438e+02, 1.00376556e+03, 0.00000000e+00],
         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]],
      dtype=float32), 'output_shape': (1, 128, 34, 34), 'from': [6], 'to': [10]}
torch node:
{'name': 'sin', 'output': array([[[[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        ...,

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.9999995 , 0.9999995 , ..., 0.        ,
          0.9999915 , 0.        ],
         [0.        , 0.        , 0.9999901 , ..., 0.9999981 ,
          0.99999946, 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.9999047 ,
          0.9999994 , 0.        ],
         [0.        , 0.        , 0.99995756, ..., 0.99999905,
          0.9999995 , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [6], 'to': [10]}

generate models:11

analyse output arrays in iter:15

pre layer res:
1:conv2d
{'name': 'conv2d', 'output': array([[[[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 510976., 508928., ..., 498688., 502784.,      0.],
         [     0., 515072., 510976., ..., 501760., 505856.,      0.],
         ...,
         [     0., 516096., 553984., ..., 355328., 360448.,      0.],
         [     0., 523264., 522240., ..., 483328., 562176.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 510976., 508928., ..., 498688., 502784.,      0.],
         [     0., 515072., 510976., ..., 501760., 505856.,      0.],
         ...,
         [     0., 516096., 553984., ..., 355328., 360448.,      0.],
         [     0., 523264., 522240., ..., 483328., 562176.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 510976., 508928., ..., 498688., 502784.,      0.],
         [     0., 515072., 510976., ..., 501760., 505856.,      0.],
         ...,
         [     0., 516096., 553984., ..., 355328., 360448.,      0.],
         [     0., 523264., 522240., ..., 483328., 562176.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        ...,

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 510976., 508928., ..., 498688., 502784.,      0.],
         [     0., 515072., 510976., ..., 501760., 505856.,      0.],
         ...,
         [     0., 516096., 553984., ..., 355328., 360448.,      0.],
         [     0., 523264., 522240., ..., 483328., 562176.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 510976., 508928., ..., 498688., 502784.,      0.],
         [     0., 515072., 510976., ..., 501760., 505856.,      0.],
         ...,
         [     0., 516096., 553984., ..., 355328., 360448.,      0.],
         [     0., 523264., 522240., ..., 483328., 562176.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 510976., 508928., ..., 498688., 502784.,      0.],
         [     0., 515072., 510976., ..., 501760., 505856.,      0.],
         ...,
         [     0., 516096., 553984., ..., 355328., 360448.,      0.],
         [     0., 523264., 522240., ..., 483328., 562176.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [0], 'to': [11]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [1], 'to': [3]}
ms node:
{'name': 'sin', 'output': array([[[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
         [ 0.00000000e+00,  7.85506248e-01,  5.52285731e-01, ...,
          -8.45204175e-01, -3.61733675e-01,  0.00000000e+00],
         [ 0.00000000e+00,  9.99536037e-01,  7.85506248e-01, ...,
          -5.04956782e-01,  1.07281514e-01,  0.00000000e+00],
         ...,
         [ 0.00000000e+00,  9.91724074e-01,  9.65391755e-01, ...,
           9.64754403e-01,  4.86852765e-01,  0.00000000e+00],
         [ 0.00000000e+00,  3.21788728e-01,  4.67820495e-01, ...,
           2.50726372e-01,  5.32042265e-01,  0.00000000e+00],
         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],

        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
         [ 0.00000000e+00,  7.85506248e-01,  5.52285731e-01, ...,
          -8.45204175e-01, -3.61733675e-01,  0.00000000e+00],
         [ 0.00000000e+00,  9.99536037e-01,  7.85506248e-01, ...,
          -5.04956782e-01,  1.07281514e-01,  0.00000000e+00],
         ...,
         [ 0.00000000e+00,  9.91724074e-01,  9.65391755e-01, ...,
           9.64754403e-01,  4.86852765e-01,  0.00000000e+00],
         [ 0.00000000e+00,  3.21788728e-01,  4.67820495e-01, ...,
           2.50726372e-01,  5.32042265e-01,  0.00000000e+00],
         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],

        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],
         [ 0.00000000e+00,  7.85506248e-01,  5.52285731e-01, ...,
          -8.45204175e-01, -3.61733675e-01,  0.00000000e+00],
         [ 0.00000000e+00,  9.99536037e-01,  7.85506248e-01, ...,
          -5.04956782e-01,  1.07281514e-01,  0.00000000e+00],
         ...,
         [ 0.00000000e+00,  9.91724074e-01,  9.65391755e-01, ...,
           9.64754403e-01,  4.86852765e-01,  0.00000000e+00],
         [ 0.00000000e+00,  3.21788728e-01,  4.67820495e-01, ...,
           2.50726372e-01,  5.32042265e-01,  0.00000000e+00],
         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,
           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],

        ...,

        [[ 5.02724152e+01,  1.14242676e+02,  1.04678833e+02, ...,
           2.68765793e+01,  8.40648346e+01,  2.05944805e+01],
         [ 8.56186752e+01,  1.99861389e+02,  2.36440994e+02, ...,
           1.45043137e+02,  1.75790390e+02,  5.05349960e+01],
         [ 1.28976334e+02,  2.86576477e+02,  3.69299866e+02, ...,
           1.91696091e+02,  1.68007248e+02,  1.06450577e+02],
         ...,
         [-1.00394936e+02, -1.29154480e+02,  4.40416641e+01, ...,
           2.79360870e+02,  1.37475708e+02, -8.79545593e+00],
         [-7.72440109e+01, -1.02695213e+02,  1.45854187e+01, ...,
           2.21251953e+02,  1.43000122e+02,  5.00971909e+01],
         [-2.31509476e+01, -1.62849274e+01,  4.50800934e+01, ...,
           1.12302444e+02,  6.52092896e+01,  3.40507126e+01]],

        [[ 5.02724152e+01,  1.14242676e+02,  1.04678833e+02, ...,
           2.68765793e+01,  8.40648346e+01,  2.05944805e+01],
         [ 8.56186752e+01,  1.99861389e+02,  2.36440994e+02, ...,
           1.45043137e+02,  1.75790390e+02,  5.05349960e+01],
         [ 1.28976334e+02,  2.86576477e+02,  3.69299866e+02, ...,
           1.91696091e+02,  1.68007248e+02,  1.06450577e+02],
         ...,
         [-1.00394936e+02, -1.29154480e+02,  4.40416641e+01, ...,
           2.79360870e+02,  1.37475708e+02, -8.79545593e+00],
         [-7.72440109e+01, -1.02695213e+02,  1.45854187e+01, ...,
           2.21251953e+02,  1.43000122e+02,  5.00971909e+01],
         [-2.31509476e+01, -1.62849274e+01,  4.50800934e+01, ...,
           1.12302444e+02,  6.52092896e+01,  3.40507126e+01]],

        [[ 5.02724152e+01,  1.14242676e+02,  1.04678833e+02, ...,
           2.68765793e+01,  8.40648346e+01,  2.05944805e+01],
         [ 8.56186752e+01,  1.99861389e+02,  2.36440994e+02, ...,
           1.45043137e+02,  1.75790390e+02,  5.05349960e+01],
         [ 1.28976334e+02,  2.86576477e+02,  3.69299866e+02, ...,
           1.91696091e+02,  1.68007248e+02,  1.06450577e+02],
         ...,
         [-1.00394936e+02, -1.29154480e+02,  4.40416641e+01, ...,
           2.79360870e+02,  1.37475708e+02, -8.79545593e+00],
         [-7.72440109e+01, -1.02695213e+02,  1.45854187e+01, ...,
           2.21251953e+02,  1.43000122e+02,  5.00971909e+01],
         [-2.31509476e+01, -1.62849274e+01,  4.50800934e+01, ...,
           1.12302444e+02,  6.52092896e+01,  3.40507126e+01]]]],
      dtype=float32), 'output_shape': (1, 128, 34, 34), 'from': [1], 'to': [3]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.78550625,  0.55228573, ..., -0.8452042 ,
          -0.36173368,  0.        ],
         [ 0.        ,  0.99953604,  0.78550625, ..., -0.5049568 ,
           0.10728151,  0.        ],
         ...,
         [ 0.        ,  0.9917241 ,  0.96539176, ...,  0.9647544 ,
           0.48685277,  0.        ],
         [ 0.        ,  0.32178873,  0.4678205 , ...,  0.25072637,
           0.53204226,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [1], 'to': [3]}

generate models:15

analyse output arrays in iter:18

pre layer res:
1:conv2d
{'name': 'conv2d', 'output': array([[[[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 585728., 588800., ..., 636928., 636928.,      0.],
         [     0., 573440., 579584., ..., 631808., 627712.,      0.],
         ...,
         [     0., 465920., 468992., ..., 309248., 235520.,      0.],
         [     0., 447488., 444416., ..., 231424., 205824.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 585728., 588800., ..., 636928., 636928.,      0.],
         [     0., 573440., 579584., ..., 631808., 627712.,      0.],
         ...,
         [     0., 465920., 468992., ..., 309248., 235520.,      0.],
         [     0., 447488., 444416., ..., 231424., 205824.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 585728., 588800., ..., 636928., 636928.,      0.],
         [     0., 573440., 579584., ..., 631808., 627712.,      0.],
         ...,
         [     0., 465920., 468992., ..., 309248., 235520.,      0.],
         [     0., 447488., 444416., ..., 231424., 205824.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        ...,

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 585728., 588800., ..., 636928., 636928.,      0.],
         [     0., 573440., 579584., ..., 631808., 627712.,      0.],
         ...,
         [     0., 465920., 468992., ..., 309248., 235520.,      0.],
         [     0., 447488., 444416., ..., 231424., 205824.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 585728., 588800., ..., 636928., 636928.,      0.],
         [     0., 573440., 579584., ..., 631808., 627712.,      0.],
         ...,
         [     0., 465920., 468992., ..., 309248., 235520.,      0.],
         [     0., 447488., 444416., ..., 231424., 205824.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]],

        [[     0.,      0.,      0., ...,      0.,      0.,      0.],
         [     0., 585728., 588800., ..., 636928., 636928.,      0.],
         [     0., 573440., 579584., ..., 631808., 627712.,      0.],
         ...,
         [     0., 465920., 468992., ..., 309248., 235520.,      0.],
         [     0., 447488., 444416., ..., 231424., 205824.,      0.],
         [     0.,      0.,      0., ...,      0.,      0.,      0.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [0], 'to': [22]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [1], 'to': [2]}
ms node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': (1, 128, 34, 34), 'from': [1], 'to': [2]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        , -0.04087537,  0.42297724, ...,  0.9978632 ,
           0.9978632 ,  0.        ],
         [ 0.        , -0.92846   , -0.83936673, ...,  0.7447473 ,
           0.20193754,  0.        ],
         ...,
         [ 0.        ,  0.18067819,  0.6125567 , ...,  0.81691486,
           0.8828732 ,  0.        ],
         [ 0.        , -0.44177598,  0.02003654, ...,  0.98907244,
          -0.55160946,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 34, 34]), 'from': [1], 'to': [2]}

generate models:17

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:4,distinct_bugs:2
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
log:1
sin:3
torch --> 

generate models:21

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:4,distinct_bugs:2
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
log:1
sin:3
torch --> 

generate models:27

analyse output arrays in iter:239

pre layer res:
15:pad
{'name': 'pad', 'output': array([[inf, inf, inf, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 331776]), 'from': [14], 'to': [5]}
tf node:
{'name': 'sin', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 331776]), 'from': [15], 'to': [16]}
ms node:
{'name': 'sin', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': (1, 331776), 'from': [15], 'to': [16]}
torch node:
{'name': 'sin', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 331776]), 'from': [15], 'to': [16]}

generate models:36

analyse output arrays in iter:335

pre layer res:
5:sum
{'name': 'sum', 'output': array([1.6404258e+13], dtype=float32), 'output_shape': torch.Size([1]), 'from': [11], 'to': [17]}
tf node:
{'name': 'cos', 'output': array([-0.37167135], dtype=float32), 'output_shape': torch.Size([1]), 'from': [5], 'to': [9]}
ms node:
{'name': 'cos', 'output': array([0.6689268], dtype=float32), 'output_shape': (1,), 'from': [5], 'to': [9]}
torch node:
{'name': 'cos', 'output': array([-0.37167135], dtype=float32), 'output_shape': torch.Size([1]), 'from': [5], 'to': [9]}

generate models:43

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:6,distinct_bugs:3
torch --> nums:1,distinct_bugs:1
tensorflow --> 
sin:1
mindspore --> 
log:1
sin:4
cos:1
torch --> 
sin:1

generate models:49

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:7

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:32

analyse output arrays in iter:55

pre layer res:
3:conv2d
{'name': 'conv2d', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [15], 'to': [6, 2, 11]}
tf node:
{'name': 'sin', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [3], 'to': [12]}
ms node:
{'name': 'sin', 'output': array([[[[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         ...,
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        [[      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         ...,
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.],
         [      0.,       0.,       0., ...,       0.,       0.,
                0.]],

        [[4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         ...,
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.]],

        [[4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         ...,
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.],
         [4199680., 4334592., 4386816., ..., 3605760., 3599360.,
          3791360.]]]], dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [3], 'to': [12]}
torch node:
{'name': 'sin', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [3], 'to': [12]}

generate models:35

analyse output arrays in iter:85

pre layer res:
11:transpose
{'name': 'transpose', 'output': array([[[[1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         ...,
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ]],

        [[1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         ...,
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ]],

        [[1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         ...,
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ]],

        [[1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         [1. , 1. , 1. , ..., 1. , 1. , 1. ],
         ...,
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ],
         [1. , 0.5, 1. , ..., 1. , 1. , 1. ]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [5], 'to': [8]}
tf node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [11], 'to': [6]}
ms node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 0.5       ,
          0.5       , 0.5       ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 0.5       ,
          0.5       , 0.5       ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]],

        [[1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 0.5       ,
          0.5       , 0.5       ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         ...,
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ],
         [1.        , 1.        , 1.        , ..., 1.        ,
          1.        , 1.        ]]]], dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [11], 'to': [6]}
torch node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.47942555, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [11], 'to': [6]}

generate models:44

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:2,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
torch --> 

generate models:53

analyse output arrays in iter:113

pre layer res:
10:exp
{'name': 'exp', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 30, 30]), 'from': [5], 'to': [14]}
tf node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 30, 30]), 'from': [10], 'to': [3]}
ms node:
{'name': 'log', 'output': array([[[[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]]]], dtype=float32), 'output_shape': (1, 4, 30, 30), 'from': [10], 'to': [3]}
torch node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 30, 30]), 'from': [10], 'to': [3]}

generate models:56

analyse the exceptions in iter:143
tensorflow exception:
{'id': 35, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([5.7405e+08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
        0.0000e+00], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 35, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([5.7405e+08, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
        0.0000e+00], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:61

analyse output arrays in iter:153

pre layer res:
4:flatten
{'name': 'flatten', 'output': array([[162., 228., 197., ..., 508., 508., 479.]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [1], 'to': [14]}
tf node:
{'name': 'sin', 'output': array([[-0.97845036,  0.97262305,  0.7958058 , ..., -0.8063828 ,
        -0.8063828 ,  0.99568975]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [4], 'to': [15]}
ms node:
{'name': 'sin', 'output': array([[ -0.97845036,   0.97262305,   0.7958059 , ..., 508.        ,
        508.        , 479.        ]], dtype=float32), 'output_shape': (1, 262144), 'from': [4], 'to': [15]}
torch node:
{'name': 'sin', 'output': array([[-0.97845036,  0.97262305,  0.7958058 , ..., -0.8063828 ,
        -0.8063828 ,  0.99568975]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [4], 'to': [15]}

generate models:63

analyse output arrays in iter:186

pre layer res:
6:add
{'name': 'add', 'output': array([[[[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [2, 22], 'to': [9, 5]}
12:reshape
{'name': 'reshape', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],

        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         ...,
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.],
         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [11], 'to': [9]}
tf node:
{'name': 'add', 'output': array([[[[      nan,       inf,       nan, ...,       nan,       nan,
                nan],
         [      nan,       nan,       inf, ...,       nan,       nan,
                nan],
         [      nan,       nan,       nan, ...,       nan,       nan,
                nan],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [6, 12], 'to': [10, 10]}
ms node:
{'name': 'add', 'output': array([[[[      nan,       inf,       nan, ...,       nan,       nan,
                nan],
         [      nan,       nan,       inf, ...,       nan,       nan,
                nan],
         [      nan,       nan,       nan, ...,       nan,       nan,
                nan],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]]]], dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [6, 12], 'to': [10, 10]}
torch node:
{'name': 'add', 'output': array([[[[      nan,       inf,       nan, ...,       nan,       nan,
                nan],
         [      nan,       nan,       inf, ...,       nan,       nan,
                nan],
         [      nan,       nan,       nan, ...,       nan,       nan,
                nan],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]],

        [[     -inf, 87031810.,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf, 86114300., ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         ...,
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf,      -inf,      -inf, ..., 83361790.,      -inf,
               -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [6, 12], 'to': [10, 10]}

pre layer res:
13:softmax
{'name': 'softmax', 'output': array([[[[0., 1., 0., ..., 0., 0., 0.],
         [0., 0., 1., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 1., 0., 0.]],

        [[0., 1., 0., ..., 0., 0., 0.],
         [0., 0., 1., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 1., 0., 0.]],

        [[0., 1., 0., ..., 0., 0., 0.],
         [0., 0., 1., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 1., 0., 0.]],

        [[0., 1., 0., ..., 0., 0., 0.],
         [0., 0., 1., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 1., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [14], 'to': [2]}
tf node:
{'name': 'log', 'output': array([[[[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]],

        [[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]],

        [[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]],

        [[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [13], 'to': [6]}
ms node:
{'name': 'log', 'output': array([[[[          -inf, -1.4305115e-06,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf, -1.4305115e-06, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         ...,
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.4305115e-06,           -inf,           -inf]],

        [[          -inf, -1.4305115e-06,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf, -1.4305115e-06, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         ...,
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.4305115e-06,           -inf,           -inf]],

        [[          -inf, -1.4305115e-06,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf, -1.4305115e-06, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         ...,
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.4305115e-06,           -inf,           -inf]],

        [[          -inf, -1.4305115e-06,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf, -1.4305115e-06, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         ...,
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
                    -inf,           -inf,           -inf],
         [          -inf,           -inf,           -inf, ...,
          -1.4305115e-06,           -inf,           -inf]]]],
      dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [13], 'to': [6]}
torch node:
{'name': 'log', 'output': array([[[[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]],

        [[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]],

        [[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]],

        [[-inf,   0., -inf, ..., -inf, -inf, -inf],
         [-inf, -inf,   0., ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         ...,
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ..., -inf, -inf, -inf],
         [-inf, -inf, -inf, ...,   0., -inf, -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [13], 'to': [6]}

generate models:75

analyse output arrays in iter:192

pre layer res:
10:add
{'name': 'add', 'output': array([[[[3.42360704e+08, 3.33447808e+08, 3.34496384e+08, ...,
          3.36069248e+08, 3.37117824e+08, 3.44982144e+08],
         [3.47603584e+08, 3.40263552e+08, 3.41836416e+08, ...,
          3.43933568e+08, 3.44457856e+08, 3.50749344e+08],
         [3.46030720e+08, 3.37117824e+08, 3.38166400e+08, ...,
          3.39739264e+08, 3.40263552e+08, 3.47603584e+08],
         ...,
         [2.02375552e+08, 2.06045568e+08, 2.14434208e+08, ...,
          1.24256496e+08, 1.08527824e+08, 1.03809224e+08],
         [1.85598304e+08, 1.95559808e+08, 2.01851264e+08, ...,
          1.25305072e+08, 1.03809224e+08, 9.07020000e+07],
         [1.73015360e+08, 1.78782560e+08, 1.85074016e+08, ...,
          1.21110760e+08, 1.02236352e+08, 8.96534240e+07]],

        [[3.42360704e+08, 3.33447808e+08, 3.34496384e+08, ...,
          3.36069248e+08, 3.37117824e+08, 3.44982144e+08],
         [3.47603584e+08, 3.40263552e+08, 3.41836416e+08, ...,
          3.43933568e+08, 3.44457856e+08, 3.50749344e+08],
         [3.46030720e+08, 3.37117824e+08, 3.38166400e+08, ...,
          3.39739264e+08, 3.40263552e+08, 3.47603584e+08],
         ...,
         [2.02375552e+08, 2.06045568e+08, 2.14434208e+08, ...,
          1.24256496e+08, 1.08527824e+08, 1.03809224e+08],
         [1.85598304e+08, 1.95559808e+08, 2.01851264e+08, ...,
          1.25305072e+08, 1.03809224e+08, 9.07020000e+07],
         [1.73015360e+08, 1.78782560e+08, 1.85074016e+08, ...,
          1.21110760e+08, 1.02236352e+08, 8.96534240e+07]],

        [[3.42360704e+08, 3.33447808e+08, 3.34496384e+08, ...,
          3.36069248e+08, 3.37117824e+08, 3.44982144e+08],
         [3.47603584e+08, 3.40263552e+08, 3.41836416e+08, ...,
          3.43933568e+08, 3.44457856e+08, 3.50749344e+08],
         [3.46030720e+08, 3.37117824e+08, 3.38166400e+08, ...,
          3.39739264e+08, 3.40263552e+08, 3.47603584e+08],
         ...,
         [2.02375552e+08, 2.06045568e+08, 2.14434208e+08, ...,
          1.24256496e+08, 1.08527824e+08, 1.03809224e+08],
         [1.85598304e+08, 1.95559808e+08, 2.01851264e+08, ...,
          1.25305072e+08, 1.03809224e+08, 9.07020000e+07],
         [1.73015360e+08, 1.78782560e+08, 1.85074016e+08, ...,
          1.21110760e+08, 1.02236352e+08, 8.96534240e+07]],

        [[3.42360704e+08, 3.33447808e+08, 3.34496384e+08, ...,
          3.36069248e+08, 3.37117824e+08, 3.44982144e+08],
         [3.47603584e+08, 3.40263552e+08, 3.41836416e+08, ...,
          3.43933568e+08, 3.44457856e+08, 3.50749344e+08],
         [3.46030720e+08, 3.37117824e+08, 3.38166400e+08, ...,
          3.39739264e+08, 3.40263552e+08, 3.47603584e+08],
         ...,
         [2.02375552e+08, 2.06045568e+08, 2.14434208e+08, ...,
          1.24256496e+08, 1.08527824e+08, 1.03809224e+08],
         [1.85598304e+08, 1.95559808e+08, 2.01851264e+08, ...,
          1.25305072e+08, 1.03809224e+08, 9.07020000e+07],
         [1.73015360e+08, 1.78782560e+08, 1.85074016e+08, ...,
          1.21110760e+08, 1.02236352e+08, 8.96534240e+07]]]],
      dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [13, 21], 'to': [23]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]],

        [[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]],

        [[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]],

        [[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [10], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[ 7.62356222e-01, -5.55009842e-01, -2.48904288e-01, ...,
           2.50977814e-01,  5.56789935e-01,  2.48785838e-02],
         [-7.29221761e-01,  9.99544084e-01,  8.60045671e-01, ...,
           3.53871465e-01,  1.92092746e-01, -6.66763186e-01],
         [-3.06910217e-01,  5.56789935e-01,  8.00028265e-01, ...,
           9.90463495e-01,  9.99544084e-01, -7.29221761e-01],
         ...,
         [ 1.01187968e+08,  1.03022984e+08,  1.07217304e+08, ...,
           6.21283640e+07,  5.42640160e+07,  5.19047120e+07],
         [ 9.27993280e+07,  9.77800880e+07,  1.00925824e+08, ...,
           6.26526560e+07,  5.19047120e+07,  4.53510840e+07],
         [ 8.65078480e+07,  8.93914480e+07,  9.25371840e+07, ...,
           6.05554960e+07,  5.11182760e+07,  4.48267960e+07]],

        [[ 1.71180688e+08,  1.66724224e+08,  1.67248512e+08, ...,
           1.68034944e+08,  1.68559232e+08,  1.72491408e+08],
         [ 1.73802128e+08,  1.70132112e+08,  1.70918544e+08, ...,
           1.71967120e+08,  1.72229264e+08,  1.75375008e+08],
         [ 1.73015696e+08,  1.68559232e+08,  1.69083520e+08, ...,
           1.69869952e+08,  1.70132112e+08,  1.73802128e+08],
         ...,
         [ 1.01187968e+08,  1.03022984e+08,  1.07217304e+08, ...,
           6.21283640e+07,  5.42640160e+07,  5.19047120e+07],
         [ 9.27993280e+07,  9.77800880e+07,  1.00925824e+08, ...,
           6.26526560e+07,  5.19047120e+07,  4.53510840e+07],
         [ 8.65078480e+07,  8.93914480e+07,  9.25371840e+07, ...,
           6.05554960e+07,  5.11182760e+07,  4.48267960e+07]],

        [[ 1.71180688e+08,  1.66724224e+08,  1.67248512e+08, ...,
           1.68034944e+08,  1.68559232e+08,  1.72491408e+08],
         [ 1.73802128e+08,  1.70132112e+08,  1.70918544e+08, ...,
           1.71967120e+08,  1.72229264e+08,  1.75375008e+08],
         [ 1.73015696e+08,  1.68559232e+08,  1.69083520e+08, ...,
           1.69869952e+08,  1.70132112e+08,  1.73802128e+08],
         ...,
         [ 1.01187968e+08,  1.03022984e+08,  1.07217304e+08, ...,
           6.21283640e+07,  5.42640160e+07,  5.19047120e+07],
         [ 9.27993280e+07,  9.77800880e+07,  1.00925824e+08, ...,
           6.26526560e+07,  5.19047120e+07,  4.53510840e+07],
         [ 8.65078480e+07,  8.93914480e+07,  9.25371840e+07, ...,
           6.05554960e+07,  5.11182760e+07,  4.48267960e+07]],

        [[ 1.71180688e+08,  1.66724224e+08,  1.67248512e+08, ...,
           1.68034944e+08,  1.68559232e+08,  1.72491408e+08],
         [ 1.73802128e+08,  1.70132112e+08,  1.70918544e+08, ...,
           1.71967120e+08,  1.72229264e+08,  1.75375008e+08],
         [ 1.73015696e+08,  1.68559232e+08,  1.69083520e+08, ...,
           1.69869952e+08,  1.70132112e+08,  1.73802128e+08],
         ...,
         [ 1.01187968e+08,  1.03022984e+08,  1.07217304e+08, ...,
           6.21283640e+07,  5.42640160e+07,  5.19047120e+07],
         [ 9.27993280e+07,  9.77800880e+07,  1.00925824e+08, ...,
           6.26526560e+07,  5.19047120e+07,  4.53510840e+07],
         [ 8.65078480e+07,  8.93914480e+07,  9.25371840e+07, ...,
           6.05554960e+07,  5.11182760e+07,  4.48267960e+07]]]],
      dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [10], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]],

        [[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]],

        [[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]],

        [[ 0.7623562 , -0.55500984, -0.24890429, ...,  0.2509778 ,
           0.55678993,  0.02487858],
         [-0.72922176,  0.9995441 ,  0.8600457 , ...,  0.35387146,
           0.19209275, -0.6667632 ],
         [-0.30691022,  0.55678993,  0.80002826, ...,  0.9904635 ,
           0.9995441 , -0.72922176],
         ...,
         [ 0.23801942, -0.8067109 ,  0.87990105, ..., -0.30709413,
          -0.81853694,  0.7629863 ],
         [-0.06951315,  0.65327144,  0.39745268, ..., -0.6043614 ,
           0.7629863 , -0.8027716 ],
         [-0.9878609 ,  0.8530449 ,  0.09868289, ...,  0.6642111 ,
          -0.97662026, -0.56059396]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [10], 'to': []}

generate models:78

analyse output arrays in iter:221

pre layer res:
1:conv2d
{'name': 'conv2d', 'output': array([[[[195072., 195840., 195840., ..., 195840., 195840., 195072.],
         [193536., 195840., 195072., ..., 195072., 195840., 193536.],
         [194304., 195840., 195072., ..., 195072., 195840., 194304.],
         ...,
         [105216.,  86272.,  68864., ..., 104960., 104960., 101376.],
         [ 96512.,  86016.,  66560., ...,  99584., 100096.,  97280.],
         [ 84224.,  78848.,  59136., ...,  95488.,  94720.,  92416.]],

        [[195072., 195840., 195840., ..., 195840., 195840., 195072.],
         [193536., 195840., 195072., ..., 195072., 195840., 193536.],
         [194304., 195840., 195072., ..., 195072., 195840., 194304.],
         ...,
         [105216.,  86272.,  68864., ..., 104960., 104960., 101376.],
         [ 96512.,  86016.,  66560., ...,  99584., 100096.,  97280.],
         [ 84224.,  78848.,  59136., ...,  95488.,  94720.,  92416.]],

        [[195072., 195840., 195840., ..., 195840., 195840., 195072.],
         [193536., 195840., 195072., ..., 195072., 195840., 193536.],
         [194304., 195840., 195072., ..., 195072., 195840., 194304.],
         ...,
         [105216.,  86272.,  68864., ..., 104960., 104960., 101376.],
         [ 96512.,  86016.,  66560., ...,  99584., 100096.,  97280.],
         [ 84224.,  78848.,  59136., ...,  95488.,  94720.,  92416.]],

        ...,

        [[195072., 195840., 195840., ..., 195840., 195840., 195072.],
         [193536., 195840., 195072., ..., 195072., 195840., 193536.],
         [194304., 195840., 195072., ..., 195072., 195840., 194304.],
         ...,
         [105216.,  86272.,  68864., ..., 104960., 104960., 101376.],
         [ 96512.,  86016.,  66560., ...,  99584., 100096.,  97280.],
         [ 84224.,  78848.,  59136., ...,  95488.,  94720.,  92416.]],

        [[195072., 195840., 195840., ..., 195840., 195840., 195072.],
         [193536., 195840., 195072., ..., 195072., 195840., 193536.],
         [194304., 195840., 195072., ..., 195072., 195840., 194304.],
         ...,
         [105216.,  86272.,  68864., ..., 104960., 104960., 101376.],
         [ 96512.,  86016.,  66560., ...,  99584., 100096.,  97280.],
         [ 84224.,  78848.,  59136., ...,  95488.,  94720.,  92416.]],

        [[195072., 195840., 195840., ..., 195840., 195840., 195072.],
         [193536., 195840., 195072., ..., 195072., 195840., 193536.],
         [194304., 195840., 195072., ..., 195072., 195840., 194304.],
         ...,
         [105216.,  86272.,  68864., ..., 104960., 104960., 101376.],
         [ 96512.,  86016.,  66560., ...,  99584., 100096.,  97280.],
         [ 84224.,  78848.,  59136., ...,  95488.,  94720.,  92416.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [0], 'to': [8]}
tf node:
{'name': 'sin', 'output': array([[[[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        ...,

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [3]}
ms node:
{'name': 'sin', 'output': array([[[[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [1], 'to': [3]}
torch node:
{'name': 'sin', 'output': array([[[[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        ...,

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]],

        [[-0.88540316, -0.5669837 , -0.5669837 , ..., -0.5669837 ,
          -0.5669837 , -0.88540316],
         [ 0.9702275 , -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.9702275 ],
         [ 0.35604477, -0.5669837 , -0.88540316, ..., -0.88540316,
          -0.5669837 ,  0.35604477],
         ...,
         [-0.79586726, -0.6624913 ,  0.28502578, ..., -0.5733234 ,
          -0.5733234 ,  0.0533134 ],
         [ 0.76298016, -0.72211534,  0.7977482 , ...,  0.97473377,
          -0.9894092 , -0.5509328 ],
         [-0.8636922 ,  0.3027533 , -0.97350997, ...,  0.6508518 ,
           0.8313288 ,  0.22903931]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [3]}

generate models:88

analyse output arrays in iter:226

pre layer res:
6:add
{'name': 'add', 'output': array([[[[19.42076 , 19.42076 , 19.41682 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42076 , 19.42076 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42207 , 19.42207 , ..., 19.423378, 19.423378,
          19.423378],
         ...,
         [19.423378, 19.423378, 19.423378, ..., 19.407568, 19.423378,
          19.419449],
         [19.423378, 19.423378, 19.423378, ..., 19.419449, 19.419449,
          19.423378],
         [19.423378, 19.423378, 19.423378, ..., 19.423378, 19.419449,
          19.423378]],

        [[19.42076 , 19.42076 , 19.41682 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42076 , 19.42076 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42207 , 19.42207 , ..., 19.423378, 19.423378,
          19.423378],
         ...,
         [19.423378, 19.423378, 19.423378, ..., 19.407568, 19.423378,
          19.419449],
         [19.423378, 19.423378, 19.423378, ..., 19.419449, 19.419449,
          19.423378],
         [19.423378, 19.423378, 19.423378, ..., 19.423378, 19.419449,
          19.423378]],

        [[19.42076 , 19.42076 , 19.41682 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42076 , 19.42076 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42207 , 19.42207 , ..., 19.423378, 19.423378,
          19.423378],
         ...,
         [19.423378, 19.423378, 19.423378, ..., 19.407568, 19.423378,
          19.419449],
         [19.423378, 19.423378, 19.423378, ..., 19.419449, 19.419449,
          19.423378],
         [19.423378, 19.423378, 19.423378, ..., 19.423378, 19.419449,
          19.423378]],

        [[19.42076 , 19.42076 , 19.41682 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42076 , 19.42076 , ..., 19.423378, 19.423378,
          19.423378],
         [19.42076 , 19.42207 , 19.42207 , ..., 19.423378, 19.423378,
          19.423378],
         ...,
         [19.423378, 19.423378, 19.423378, ..., 19.407568, 19.423378,
          19.419449],
         [19.423378, 19.423378, 19.423378, ..., 19.419449, 19.419449,
          19.423378],
         [19.423378, 19.423378, 19.423378, ..., 19.423378, 19.419449,
          19.423378]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [2, 5], 'to': [9, 11]}
11:square
{'name': 'square', 'output': array([[[[377.1659, 377.1659, 377.0129, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.1659, 377.1659, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.2168, 377.2168, ..., 377.2676, 377.2676,
          377.2676],
         ...,
         [377.2676, 377.2676, 377.2676, ..., 376.6537, 377.2676,
          377.115 ],
         [377.2676, 377.2676, 377.2676, ..., 377.115 , 377.115 ,
          377.2676],
         [377.2676, 377.2676, 377.2676, ..., 377.2676, 377.115 ,
          377.2676]],

        [[377.1659, 377.1659, 377.0129, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.1659, 377.1659, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.2168, 377.2168, ..., 377.2676, 377.2676,
          377.2676],
         ...,
         [377.2676, 377.2676, 377.2676, ..., 376.6537, 377.2676,
          377.115 ],
         [377.2676, 377.2676, 377.2676, ..., 377.115 , 377.115 ,
          377.2676],
         [377.2676, 377.2676, 377.2676, ..., 377.2676, 377.115 ,
          377.2676]],

        [[377.1659, 377.1659, 377.0129, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.1659, 377.1659, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.2168, 377.2168, ..., 377.2676, 377.2676,
          377.2676],
         ...,
         [377.2676, 377.2676, 377.2676, ..., 376.6537, 377.2676,
          377.115 ],
         [377.2676, 377.2676, 377.2676, ..., 377.115 , 377.115 ,
          377.2676],
         [377.2676, 377.2676, 377.2676, ..., 377.2676, 377.115 ,
          377.2676]],

        [[377.1659, 377.1659, 377.0129, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.1659, 377.1659, ..., 377.2676, 377.2676,
          377.2676],
         [377.1659, 377.2168, 377.2168, ..., 377.2676, 377.2676,
          377.2676],
         ...,
         [377.2676, 377.2676, 377.2676, ..., 376.6537, 377.2676,
          377.115 ],
         [377.2676, 377.2676, 377.2676, ..., 377.115 , 377.115 ,
          377.2676],
         [377.2676, 377.2676, 377.2676, ..., 377.2676, 377.115 ,
          377.2676]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [6], 'to': [9]}
tf node:
{'name': 'add', 'output': array([[[[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [6, 11], 'to': [10, 10]}
ms node:
{'name': 'add', 'output': array([[[[396.58673, 396.58673, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.58673, 396.58673, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58673, 396.58673, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.58673, 396.58673, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58673, 396.58673, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.58673, 396.58673, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58673, 396.58673, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.58673, 396.58673, ..., 396.69098, 396.69098,
          396.69098],
         [396.58673, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]]]], dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [6, 11], 'to': [10, 10]}
torch node:
{'name': 'add', 'output': array([[[[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]],

        [[396.58664, 396.58664, 396.42972, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.58664, 396.58664, ..., 396.69098, 396.69098,
          396.69098],
         [396.58664, 396.63885, 396.63885, ..., 396.69098, 396.69098,
          396.69098],
         ...,
         [396.69098, 396.69098, 396.69098, ..., 396.06125, 396.69098,
          396.53442],
         [396.69098, 396.69098, 396.69098, ..., 396.53442, 396.53442,
          396.69098],
         [396.69098, 396.69098, 396.69098, ..., 396.69098, 396.53442,
          396.69098]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [6, 11], 'to': [10, 10]}

generate models:91

analyse output arrays in iter:228

pre layer res:
12:square
{'name': 'square', 'output': array([[[[16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         ...,
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.]],

        [[16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         ...,
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.]],

        [[16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         ...,
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.]],

        [[16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         ...,
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.],
         [16777216., 16777216., 16777216., ..., 16777216., 16777216.,
          16777216.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [11], 'to': [23]}
tf node:
{'name': 'sin', 'output': array([[[[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]],

        [[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]],

        [[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]],

        [[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [12], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[-7.7956367e-01, -7.7956367e-01, -7.7956367e-01, ...,
          -7.7956367e-01, -7.7956367e-01, -7.7956367e-01],
         [-7.7956367e-01, -7.7956367e-01, -7.7956367e-01, ...,
          -7.7956367e-01, -7.7956367e-01, -7.7956367e-01],
         [-7.7956367e-01, -7.7956367e-01, -7.7956367e-01, ...,
          -7.7956367e-01, -7.7956367e-01, -7.7956367e-01],
         ...,
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03]],

        [[ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         ...,
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03]],

        [[ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         ...,
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03]],

        [[ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         ...,
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03],
         [ 4.0960000e+03,  4.0960000e+03,  4.0960000e+03, ...,
           4.0960000e+03,  4.0960000e+03,  4.0960000e+03]]]],
      dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [12], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]],

        [[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]],

        [[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]],

        [[-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         ...,
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367],
         [-0.77956367, -0.77956367, -0.77956367, ..., -0.77956367,
          -0.77956367, -0.77956367]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [12], 'to': []}

generate models:92

analyse output arrays in iter:243

pre layer res:
12:exp
{'name': 'exp', 'output': array([[[[ 1.      ,  1.      ,  1.      , ...,       inf,  1.      ,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
                inf],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
           1.      ],
         ...,
         [23.140518,  1.      ,  1.      , ...,  1.      ,       inf,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ..., 23.140518,       inf,
           1.      ],
         [ 1.      , 23.140518,  1.      , ...,  1.      ,  1.      ,
                inf]],

        [[ 1.      ,  1.      ,  1.      , ...,       inf,  1.      ,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
                inf],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
           1.      ],
         ...,
         [23.140518,  1.      ,  1.      , ...,  1.      ,       inf,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ..., 23.140518,       inf,
           1.      ],
         [ 1.      , 23.140518,  1.      , ...,  1.      ,  1.      ,
                inf]],

        [[ 1.      ,  1.      ,  1.      , ...,       inf,  1.      ,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
                inf],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
           1.      ],
         ...,
         [23.140518,  1.      ,  1.      , ...,  1.      ,       inf,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ..., 23.140518,       inf,
           1.      ],
         [ 1.      , 23.140518,  1.      , ...,  1.      ,  1.      ,
                inf]],

        [[ 1.      ,  1.      ,  1.      , ...,       inf,  1.      ,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
                inf],
         [ 1.      ,  1.      ,  1.      , ...,  1.      ,  1.      ,
           1.      ],
         ...,
         [23.140518,  1.      ,  1.      , ...,  1.      ,       inf,
           1.      ],
         [ 1.      ,  1.      ,  1.      , ..., 23.140518,       inf,
           1.      ],
         [ 1.      , 23.140518,  1.      , ...,  1.      ,  1.      ,
                inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [10], 'to': [23]}
tf node:
{'name': 'log', 'output': array([[[[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]],

        [[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]],

        [[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]],

        [[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [12], 'to': []}
ms node:
{'name': 'log', 'output': array([[[[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           8.8722839e+01, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [ 3.1415851e+00, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           3.1415851e+00,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06,  3.1415851e+00, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           8.8722839e+01, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [ 3.1415851e+00, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           3.1415851e+00,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06,  3.1415851e+00, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           8.8722839e+01, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [ 3.1415851e+00, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           3.1415851e+00,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06,  3.1415851e+00, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           8.8722839e+01, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [ 3.1415851e+00, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
           3.1415851e+00,  8.8722839e+01, -1.4305115e-06],
         [-1.4305115e-06,  3.1415851e+00, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06,  8.8722839e+01]]]],
      dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [12], 'to': []}
torch node:
{'name': 'log', 'output': array([[[[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]],

        [[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]],

        [[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]],

        [[0.      , 0.      , 0.      , ...,      inf, 0.      ,
          0.      ],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
               inf],
         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,
          0.      ],
         ...,
         [3.141585, 0.      , 0.      , ..., 0.      ,      inf,
          0.      ],
         [0.      , 0.      , 0.      , ..., 3.141585,      inf,
          0.      ],
         [0.      , 3.141585, 0.      , ..., 0.      , 0.      ,
               inf]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [12], 'to': []}

generate models:99

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:2
mindspore --> nums:11,distinct_bugs:3
torch --> nums:3,distinct_bugs:2
tensorflow --> 
flatten:1
add:2
mindspore --> 
sin:6
log:3
add:2
torch --> 
flatten:1
add:2

generate models:100

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:16

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:18

analyse the exceptions in iter:173
tensorflow exception:
{'id': 13, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([56598.2969], grad_fn=<MeanBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 13, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([56598.2969], grad_fn=<MeanBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:23

analyse output arrays in iter:1714

pre layer res:
16:flatten
{'name': 'flatten', 'output': array([[202234.05, 202234.05, 202911.48, ..., 201191.95, 200765.36,
        199895.36]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [4], 'to': [10]}
tf node:
{'name': 'sin', 'output': array([[-0.29837102, -0.29837102,  0.7469931 , ..., -0.938409  ,
        -0.952318  ,  0.8621917 ]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [16], 'to': [12]}
ms node:
{'name': 'sin', 'output': array([[-8.36292267e-01, -8.36292267e-01,  5.59288859e-01, ...,
         1.00595984e+05,  1.00382492e+05,  9.99478359e+04]], dtype=float32), 'output_shape': (1, 262144), 'from': [16], 'to': [12]}
torch node:
{'name': 'sin', 'output': array([[-0.29837102, -0.29837102,  0.7469931 , ..., -0.938409  ,
        -0.952318  ,  0.8621917 ]], dtype=float32), 'output_shape': torch.Size([1, 262144]), 'from': [16], 'to': [12]}

generate models:44

analyse output arrays in iter:2165

pre layer res:
1:conv2d
{'name': 'conv2d', 'output': array([[[[21504., 22912., 23360., ..., 14016., 12864., 15360.],
         [24064., 25408., 25280., ..., 14016., 14400., 14592.],
         [24256., 25408., 24896., ..., 15488., 17088., 14144.],
         ...,
         [10880., 10880., 23168., ..., 17472., 17408., 15104.],
         [ 9920., 12608., 25536., ..., 18816., 18880., 15936.],
         [ 9792., 17408., 23872., ..., 20864., 20224., 14720.]],

        [[21504., 22912., 23360., ..., 14016., 12864., 15360.],
         [24064., 25408., 25280., ..., 14016., 14400., 14592.],
         [24256., 25408., 24896., ..., 15488., 17088., 14144.],
         ...,
         [10880., 10880., 23168., ..., 17472., 17408., 15104.],
         [ 9920., 12608., 25536., ..., 18816., 18880., 15936.],
         [ 9792., 17408., 23872., ..., 20864., 20224., 14720.]],

        [[21504., 22912., 23360., ..., 14016., 12864., 15360.],
         [24064., 25408., 25280., ..., 14016., 14400., 14592.],
         [24256., 25408., 24896., ..., 15488., 17088., 14144.],
         ...,
         [10880., 10880., 23168., ..., 17472., 17408., 15104.],
         [ 9920., 12608., 25536., ..., 18816., 18880., 15936.],
         [ 9792., 17408., 23872., ..., 20864., 20224., 14720.]],

        ...,

        [[21504., 22912., 23360., ..., 14016., 12864., 15360.],
         [24064., 25408., 25280., ..., 14016., 14400., 14592.],
         [24256., 25408., 24896., ..., 15488., 17088., 14144.],
         ...,
         [10880., 10880., 23168., ..., 17472., 17408., 15104.],
         [ 9920., 12608., 25536., ..., 18816., 18880., 15936.],
         [ 9792., 17408., 23872., ..., 20864., 20224., 14720.]],

        [[21504., 22912., 23360., ..., 14016., 12864., 15360.],
         [24064., 25408., 25280., ..., 14016., 14400., 14592.],
         [24256., 25408., 24896., ..., 15488., 17088., 14144.],
         ...,
         [10880., 10880., 23168., ..., 17472., 17408., 15104.],
         [ 9920., 12608., 25536., ..., 18816., 18880., 15936.],
         [ 9792., 17408., 23872., ..., 20864., 20224., 14720.]],

        [[21504., 22912., 23360., ..., 14016., 12864., 15360.],
         [24064., 25408., 25280., ..., 14016., 14400., 14592.],
         [24256., 25408., 24896., ..., 15488., 17088., 14144.],
         ...,
         [10880., 10880., 23168., ..., 17472., 17408., 15104.],
         [ 9920., 12608., 25536., ..., 18816., 18880., 15936.],
         [ 9792., 17408., 23872., ..., 20864., 20224., 14720.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [0], 'to': [3]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        ...,

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [1], 'to': [2]}
ms node:
{'name': 'sin', 'output': array([[[[ 2.0034871e-01, -3.5674131e-01, -7.7262914e-01, ...,
          -9.7684306e-01,  7.3245192e-01, -6.8420762e-01],
         [-5.6441671e-01, -9.3253905e-01,  3.8580796e-01, ...,
          -9.7684306e-01, -8.7270921e-01,  6.4259166e-01],
         [ 2.3466931e-01, -9.3253905e-01,  9.0087438e-01, ...,
          -5.1759060e-02, -7.6918012e-01,  5.2257943e-01],
         ...,
         [-6.1677629e-01, -6.1677629e-01,  9.4765836e-01, ...,
          -9.9947333e-01, -4.2150694e-01, -7.0148456e-01],
         [-9.1260046e-01, -7.0942438e-01,  9.0649688e-01, ...,
          -8.4233314e-01, -8.2592905e-01,  9.6343279e-01],
         [ 3.3753902e-01, -4.2150694e-01,  8.2066548e-01, ...,
          -6.3126832e-01, -9.9999636e-01, -9.9771452e-01]],

        [[ 2.0034871e-01, -3.5674131e-01, -7.7262914e-01, ...,
          -9.7684306e-01,  7.3245192e-01, -6.8420762e-01],
         [-5.6441671e-01, -9.3253905e-01,  3.8580796e-01, ...,
          -9.7684306e-01, -8.7270921e-01,  6.4259166e-01],
         [ 2.3466931e-01, -9.3253905e-01,  9.0087438e-01, ...,
          -5.1759060e-02, -7.6918012e-01,  5.2257943e-01],
         ...,
         [-6.1677629e-01, -6.1677629e-01,  9.4765836e-01, ...,
          -9.9947333e-01, -4.2150694e-01, -7.0148456e-01],
         [-9.1260046e-01, -7.0942438e-01,  9.0649688e-01, ...,
          -8.4233314e-01, -8.2592905e-01,  9.6343279e-01],
         [ 3.3753902e-01, -4.2150694e-01,  8.2066548e-01, ...,
          -6.3126832e-01, -9.9999636e-01, -9.9771452e-01]],

        [[ 2.0034871e-01, -3.5674131e-01, -7.7262914e-01, ...,
          -9.7684306e-01,  7.3245192e-01, -6.8420762e-01],
         [-5.6441671e-01, -9.3253905e-01,  3.8580796e-01, ...,
          -9.7684306e-01, -8.7270921e-01,  6.4259166e-01],
         [ 2.3466931e-01, -9.3253905e-01,  9.0087438e-01, ...,
          -5.1759060e-02, -7.6918012e-01,  5.2257943e-01],
         ...,
         [-6.1677629e-01, -6.1677629e-01,  9.4765836e-01, ...,
          -9.9947333e-01, -4.2150694e-01, -7.0148456e-01],
         [-9.1260046e-01, -7.0942438e-01,  9.0649688e-01, ...,
          -8.4233314e-01, -8.2592905e-01,  9.6343279e-01],
         [ 3.3753902e-01, -4.2150694e-01,  8.2066548e-01, ...,
          -6.3126832e-01, -9.9999636e-01, -9.9771452e-01]],

        ...,

        [[ 1.6325205e+04,  1.7372293e+04,  1.7701637e+04, ...,
           1.0690371e+04,  9.8537188e+03,  1.1703053e+04],
         [ 1.8232969e+04,  1.9235078e+04,  1.9160172e+04, ...,
           1.0690371e+04,  1.0980037e+04,  1.1148281e+04],
         [ 1.8389754e+04,  1.9235078e+04,  1.8880414e+04, ...,
           1.1809172e+04,  1.2997693e+04,  1.0810361e+04],
         ...,
         [ 8.3441318e+03,  8.3441318e+03,  1.7585162e+04, ...,
           1.3282008e+04,  1.3243256e+04,  1.1510776e+04],
         [ 7.6193984e+03,  9.6386494e+03,  1.9360504e+04, ...,
           1.4292522e+04,  1.4340785e+04,  1.2161415e+04],
         [ 7.5434004e+03,  1.3243256e+04,  1.8111131e+04, ...,
           1.5831899e+04,  1.5346000e+04,  1.1218037e+04]],

        [[ 1.6325205e+04,  1.7372293e+04,  1.7701637e+04, ...,
           1.0690371e+04,  9.8537188e+03,  1.1703053e+04],
         [ 1.8232969e+04,  1.9235078e+04,  1.9160172e+04, ...,
           1.0690371e+04,  1.0980037e+04,  1.1148281e+04],
         [ 1.8389754e+04,  1.9235078e+04,  1.8880414e+04, ...,
           1.1809172e+04,  1.2997693e+04,  1.0810361e+04],
         ...,
         [ 8.3441318e+03,  8.3441318e+03,  1.7585162e+04, ...,
           1.3282008e+04,  1.3243256e+04,  1.1510776e+04],
         [ 7.6193984e+03,  9.6386494e+03,  1.9360504e+04, ...,
           1.4292522e+04,  1.4340785e+04,  1.2161415e+04],
         [ 7.5434004e+03,  1.3243256e+04,  1.8111131e+04, ...,
           1.5831899e+04,  1.5346000e+04,  1.1218037e+04]],

        [[ 1.6325205e+04,  1.7372293e+04,  1.7701637e+04, ...,
           1.0690371e+04,  9.8537188e+03,  1.1703053e+04],
         [ 1.8232969e+04,  1.9235078e+04,  1.9160172e+04, ...,
           1.0690371e+04,  1.0980037e+04,  1.1148281e+04],
         [ 1.8389754e+04,  1.9235078e+04,  1.8880414e+04, ...,
           1.1809172e+04,  1.2997693e+04,  1.0810361e+04],
         ...,
         [ 8.3441318e+03,  8.3441318e+03,  1.7585162e+04, ...,
           1.3282008e+04,  1.3243256e+04,  1.1510776e+04],
         [ 7.6193984e+03,  9.6386494e+03,  1.9360504e+04, ...,
           1.4292522e+04,  1.4340785e+04,  1.2161415e+04],
         [ 7.5434004e+03,  1.3243256e+04,  1.8111131e+04, ...,
           1.5831899e+04,  1.5346000e+04,  1.1218037e+04]]]],
      dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [1], 'to': [2]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        ...,

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]],

        [[ 0.2003487 , -0.3567413 , -0.77262914, ..., -0.97684306,
           0.7324519 , -0.6842076 ],
         [-0.5644167 , -0.93253905,  0.38580796, ..., -0.97684306,
          -0.8727092 ,  0.64259166],
         [ 0.23466931, -0.93253905,  0.9008744 , ..., -0.05175906,
          -0.7691801 ,  0.52257943],
         ...,
         [-0.6167763 , -0.6167763 ,  0.94765836, ..., -0.99947333,
          -0.42150694, -0.70148456],
         [-0.9126005 , -0.7094244 ,  0.9064969 , ..., -0.84233314,
          -0.82592905,  0.9634328 ],
         [ 0.33753902, -0.42150694,  0.8206655 , ..., -0.6312683 ,
          -0.99999636, -0.9977145 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [1], 'to': [2]}

generate models:57

analyse output arrays in iter:2609

pre layer res:
9:add
{'name': 'add', 'output': array([[[[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          7.0362319e+13, 7.0021284e+13, 7.0367687e+13],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.4540895e+05, 4.3024483e+08, 1.0064012e+00],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.0000058e+00, 1.0112086e+01, 2.7090178e+03],
         ...,
         [1.0003932e+00, 1.0000004e+00, 1.0000001e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000010e+00, 1.0000000e+00, 1.0000297e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000196e+00, 1.0000004e+00, 1.0121070e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]],

        [[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          7.0362319e+13, 7.0021284e+13, 7.0367687e+13],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.4540895e+05, 4.3024483e+08, 1.0064012e+00],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.0000058e+00, 1.0112086e+01, 2.7090178e+03],
         ...,
         [1.0003932e+00, 1.0000004e+00, 1.0000001e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000010e+00, 1.0000000e+00, 1.0000297e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000196e+00, 1.0000004e+00, 1.0121070e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]],

        [[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          7.0362319e+13, 7.0021284e+13, 7.0367687e+13],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.4540895e+05, 4.3024483e+08, 1.0064012e+00],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.0000058e+00, 1.0112086e+01, 2.7090178e+03],
         ...,
         [1.0003932e+00, 1.0000004e+00, 1.0000001e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000010e+00, 1.0000000e+00, 1.0000297e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000196e+00, 1.0000004e+00, 1.0121070e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]],

        ...,

        [[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          7.0362319e+13, 7.0021284e+13, 7.0367687e+13],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.4540895e+05, 4.3024483e+08, 1.0064012e+00],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.0000058e+00, 1.0112086e+01, 2.7090178e+03],
         ...,
         [1.0003932e+00, 1.0000004e+00, 1.0000001e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000010e+00, 1.0000000e+00, 1.0000297e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000196e+00, 1.0000004e+00, 1.0121070e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]],

        [[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          7.0362319e+13, 7.0021284e+13, 7.0367687e+13],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.4540895e+05, 4.3024483e+08, 1.0064012e+00],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.0000058e+00, 1.0112086e+01, 2.7090178e+03],
         ...,
         [1.0003932e+00, 1.0000004e+00, 1.0000001e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000010e+00, 1.0000000e+00, 1.0000297e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000196e+00, 1.0000004e+00, 1.0121070e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]],

        [[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          7.0362319e+13, 7.0021284e+13, 7.0367687e+13],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.4540895e+05, 4.3024483e+08, 1.0064012e+00],
         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,
          1.0000058e+00, 1.0112086e+01, 2.7090178e+03],
         ...,
         [1.0003932e+00, 1.0000004e+00, 1.0000001e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000010e+00, 1.0000000e+00, 1.0000297e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],
         [1.0000196e+00, 1.0000004e+00, 1.0121070e+00, ...,
          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [7, 11], 'to': [25]}
tf node:
{'name': 'cos', 'output': array([[[[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        ...,

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [9], 'to': []}
ms node:
{'name': 'cos', 'output': array([[[[ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.0110579 ,
          -0.5851926 ,  0.43860552],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.09434176,
          -0.8208478 ,  0.53490496],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.5402974 ,
          -0.77295476,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5403015 ,  0.5403023 ,  0.5402773 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5402858 ,  0.540302  ,  0.53007525, ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ]],

        [[ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.0110579 ,
          -0.5851926 ,  0.43860552],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.09434176,
          -0.8208478 ,  0.53490496],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.5402974 ,
          -0.77295476,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5403015 ,  0.5403023 ,  0.5402773 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5402858 ,  0.540302  ,  0.53007525, ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ]],

        [[ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.0110579 ,
          -0.5851926 ,  0.43860552],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.09434176,
          -0.8208478 ,  0.53490496],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.5402974 ,
          -0.77295476,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5403015 ,  0.5403023 ,  0.5402773 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5402858 ,  0.540302  ,  0.53007525, ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ]],

        ...,

        [[ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.0110579 ,
          -0.5851926 ,  0.43860552],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.09434176,
          -0.8208478 ,  0.53490496],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.5402974 ,
          -0.77295476,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5403015 ,  0.5403023 ,  0.5402773 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5402858 ,  0.540302  ,  0.53007525, ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ]],

        [[ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.0110579 ,
          -0.5851926 ,  0.96936005],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.43711883,
           0.01597161,  0.53490496],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.5402974 ,
          -0.77295476,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5403015 ,  0.5403023 ,  0.5402773 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5402858 ,  0.540302  ,  0.53007525, ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ]],

        [[ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.0110579 ,
          -0.5851926 ,  0.96936005],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ..., -0.43711883,
           0.01597161,  0.53490496],
         [ 0.5403023 ,  0.5403023 ,  0.5403023 , ...,  0.5402974 ,
          -0.77295476,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5403015 ,  0.5403023 ,  0.5402773 , ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ],
         [ 0.5402858 ,  0.540302  ,  0.53007525, ...,  0.5403023 ,
           0.5403023 ,  0.5403023 ]]]], dtype=float32), 'output_shape': (1, 32, 32, 32), 'from': [9], 'to': []}
torch node:
{'name': 'cos', 'output': array([[[[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        ...,

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]],

        [[ 0.54030234,  0.54030234,  0.54030234, ..., -0.0110579 ,
          -0.5851926 ,  0.19490834],
         [ 0.54030234,  0.54030234,  0.54030234, ..., -0.9437001 ,
           0.01597161,  0.53490484],
         [ 0.54030234,  0.54030234,  0.54030234, ...,  0.5402974 ,
          -0.77295655,  0.56945395],
         ...,
         [ 0.5399714 ,  0.540302  ,  0.5403022 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5403015 ,  0.54030234,  0.5402773 , ...,  0.54030234,
           0.54030234,  0.54030234],
         [ 0.5402859 ,  0.540302  ,  0.53007525, ...,  0.54030234,
           0.54030234,  0.54030234]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [9], 'to': []}

generate models:67

analyse output arrays in iter:3389

pre layer res:
15:log
{'name': 'log', 'output': array([[[[11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         ...,
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876]],

        [[11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         ...,
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876]],

        [[11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         ...,
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876]],

        ...,

        [[11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         ...,
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876]],

        [[11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         ...,
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876]],

        [[11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         ...,
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876],
         [11.167876, 11.167876, 11.167876, ..., 11.167876, 11.167876,
          11.167876]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [5], 'to': [7]}
tf node:
{'name': 'sin', 'output': array([[[[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        ...,

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [15], 'to': [8]}
ms node:
{'name': 'sin', 'output': array([[[[-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         ...,
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01]],

        [[-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         ...,
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01]],

        [[-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         ...,
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01],
         [-9.851945e-01, -9.851945e-01, -9.851945e-01, ...,
          -9.851945e-01, -9.851945e-01, -9.851945e-01]],

        ...,

        [[ 7.081806e+04,  7.081806e+04,  7.081806e+04, ...,
           7.081806e+04,  7.081806e+04,  7.081806e+04],
         [ 7.081806e+04,  7.081806e+04,  7.081806e+04, ...,
           7.081806e+04,  7.081806e+04,  7.081806e+04],
         [ 7.081806e+04,  7.081806e+04,  7.081806e+04, ...,
           7.081806e+04,  7.081806e+04,  7.081806e+04],
         ...,
         [ 7.081806e+04,  7.081806e+04,  7.081806e+04, ...,
           7.081806e+04,  7.081806e+04,  7.081806e+04],
         [ 7.081806e+04,  7.081806e+04,  7.081806e+04, ...,
           7.081806e+04,  7.081806e+04,  7.081806e+04],
         [ 7.081806e+04,  7.081806e+04,  7.081806e+04, ...,
           7.081806e+04,  7.081806e+04,  7.081806e+04]],

        [[ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         ...,
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04]],

        [[ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         ...,
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04],
         [ 7.081812e+04,  7.081812e+04,  7.081812e+04, ...,
           7.081812e+04,  7.081812e+04,  7.081812e+04]]]], dtype=float32), 'output_shape': (1, 32, 32, 32), 'from': [15], 'to': [8]}
torch node:
{'name': 'sin', 'output': array([[[[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        ...,

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]],

        [[-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         ...,
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927],
         [-0.9851927, -0.9851927, -0.9851927, ..., -0.9851927,
          -0.9851927, -0.9851927]]]], dtype=float32), 'output_shape': torch.Size([1, 32, 32, 32]), 'from': [15], 'to': [8]}

generate models:86

analyse output arrays in iter:4112

pre layer res:
13:arctan
{'name': 'arctan', 'output': array([[[[ 0.743193  , -0.4846433 ,  0.5542045 , ...,  0.7826108 ,
          -0.14378509, -0.02124958],
         [ 0.56352556, -0.3953287 , -0.78308   , ...,  0.57469225,
          -0.5500107 , -0.17942849],
         [ 0.33106235,  0.36009836,  0.22120653, ...,  0.7802982 ,
          -0.4220134 ,  0.7776299 ],
         ...,
         [-0.27835268, -0.12950657, -0.7451506 , ...,  0.7353119 ,
           0.78539723, -0.75212455],
         [ 0.7696089 , -0.12950657,  0.69009155, ...,  0.70027137,
           0.78539723,  0.78539723],
         [ 0.7538466 ,  0.15089138,  0.76479113, ..., -0.6216961 ,
          -0.43284208,  0.5656566 ]],

        [[ 0.743193  , -0.4846433 ,  0.5542045 , ...,  0.7826108 ,
          -0.14378509, -0.02124958],
         [ 0.56352556, -0.3953287 , -0.78308   , ...,  0.57469225,
          -0.5500107 , -0.17942849],
         [ 0.33106235,  0.36009836,  0.22120653, ...,  0.7802982 ,
          -0.4220134 ,  0.7776299 ],
         ...,
         [-0.27835268, -0.12950657, -0.7451506 , ...,  0.7353119 ,
           0.78539723, -0.75212455],
         [ 0.7696089 , -0.12950657,  0.69009155, ...,  0.70027137,
           0.78539723,  0.78539723],
         [ 0.7538466 ,  0.15089138,  0.76479113, ..., -0.6216961 ,
          -0.43284208,  0.5656566 ]],

        [[ 0.743193  , -0.4846433 ,  0.5542045 , ...,  0.7826108 ,
          -0.14378509, -0.02124958],
         [ 0.56352556, -0.3953287 , -0.78308   , ...,  0.57469225,
          -0.5500107 , -0.17942849],
         [ 0.33106235,  0.36009836,  0.22120653, ...,  0.7802982 ,
          -0.4220134 ,  0.7776299 ],
         ...,
         [-0.27835268, -0.12950657, -0.7451506 , ...,  0.7353119 ,
           0.78539723, -0.75212455],
         [ 0.7696089 , -0.12950657,  0.69009155, ...,  0.70027137,
           0.78539723,  0.78539723],
         [ 0.7538466 ,  0.15089138,  0.76479113, ..., -0.6216961 ,
          -0.43284208,  0.5656566 ]],

        ...,

        [[ 0.743193  , -0.4846433 ,  0.5542045 , ...,  0.7826108 ,
          -0.14378509, -0.02124958],
         [ 0.56352556, -0.3953287 , -0.78308   , ...,  0.57469225,
          -0.5500107 , -0.17942849],
         [ 0.33106235,  0.36009836,  0.22120653, ...,  0.7802982 ,
          -0.4220134 ,  0.7776299 ],
         ...,
         [-0.27835268, -0.12950657, -0.7451506 , ...,  0.7353119 ,
           0.78539723, -0.75212455],
         [ 0.7696089 , -0.12950657,  0.69009155, ...,  0.70027137,
           0.78539723,  0.78539723],
         [ 0.7538466 ,  0.15089138,  0.76479113, ..., -0.6216961 ,
          -0.43284208,  0.5656566 ]],

        [[ 0.743193  , -0.4846433 ,  0.5542045 , ...,  0.7826108 ,
          -0.14378509, -0.02124958],
         [ 0.56352556, -0.3953287 , -0.78308   , ...,  0.57469225,
          -0.5500107 , -0.17942849],
         [ 0.33106235,  0.36009836,  0.22120653, ...,  0.7802982 ,
          -0.4220134 ,  0.7776299 ],
         ...,
         [-0.27835268, -0.12950657, -0.7451506 , ...,  0.7353119 ,
           0.78539723, -0.75212455],
         [ 0.7696089 , -0.12950657,  0.69009155, ...,  0.70027137,
           0.78539723,  0.78539723],
         [ 0.7538466 ,  0.15089138,  0.76479113, ..., -0.6216961 ,
          -0.43284208,  0.5656566 ]],

        [[ 0.743193  , -0.4846433 ,  0.5542045 , ...,  0.7826108 ,
          -0.14378509, -0.02124958],
         [ 0.56352556, -0.3953287 , -0.78308   , ...,  0.57469225,
          -0.5500107 , -0.17942849],
         [ 0.33106235,  0.36009836,  0.22120653, ...,  0.7802982 ,
          -0.4220134 ,  0.7776299 ],
         ...,
         [-0.27835268, -0.12950657, -0.7451506 , ...,  0.7353119 ,
           0.78539723, -0.75212455],
         [ 0.7696089 , -0.12950657,  0.69009155, ...,  0.70027137,
           0.78539723,  0.78539723],
         [ 0.7538466 ,  0.15089138,  0.76479113, ..., -0.6216961 ,
          -0.43284208,  0.5656566 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [6], 'to': [8]}
tf node:
{'name': 'log', 'output': array([[[[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        ...,

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [13], 'to': [3]}
ms node:
{'name': 'log', 'output': array([[[[-0.2967996 ,         nan, -0.5902209 , ..., -0.24512221,
                  nan,         nan],
         [-0.57354575,         nan,         nan, ..., -0.55392367,
                  nan,         nan],
         [-1.1054505 , -1.0213782 , -1.5086595 , ..., -0.24808139,
                  nan, -0.25150678],
         ...,
         [        nan,         nan,         nan, ..., -0.30746055,
          -0.24156807,         nan],
         [-0.26187503,         nan, -0.37092817, ..., -0.3562845 ,
          -0.24156807, -0.24156807],
         [-0.28256863, -1.8911965 , -0.26815474, ...,         nan,
                  nan, -0.56977123]],

        [[-0.2967996 ,         nan, -0.5902209 , ..., -0.24512221,
                  nan,         nan],
         [-0.57354575,         nan,         nan, ..., -0.55392367,
                  nan,         nan],
         [-1.1054505 , -1.0213782 , -1.5086595 , ..., -0.24808139,
                  nan, -0.25150678],
         ...,
         [        nan,         nan,         nan, ..., -0.30746055,
          -0.24156807,         nan],
         [-0.26187503,         nan, -0.37092817, ..., -0.3562845 ,
          -0.24156807, -0.24156807],
         [-0.28256863, -1.8911965 , -0.26815474, ...,         nan,
                  nan, -0.56977123]],

        [[-0.2967996 ,         nan, -0.5902209 , ..., -0.24512221,
                  nan,         nan],
         [-0.57354575,         nan,         nan, ..., -0.55392367,
                  nan,         nan],
         [-1.1054505 , -1.0213782 , -1.5086595 , ..., -0.24808139,
                  nan, -0.25150678],
         ...,
         [        nan,         nan,         nan, ..., -0.30746055,
          -0.24156807,         nan],
         [-0.26187503,         nan, -0.37092817, ..., -0.3562845 ,
          -0.24156807, -0.24156807],
         [-0.28256863, -1.8911965 , -0.26815474, ...,         nan,
                  nan, -0.56977123]],

        ...,

        [[-0.2967996 ,         nan, -0.5902209 , ..., -0.24512221,
                  nan,         nan],
         [-0.57354575,         nan,         nan, ..., -0.55392367,
                  nan,         nan],
         [-1.1054505 , -1.0213782 , -1.5086595 , ..., -0.24808139,
                  nan, -0.25150678],
         ...,
         [        nan,         nan,         nan, ..., -0.30746055,
          -0.24156807,         nan],
         [-0.26187503,         nan, -0.37092817, ..., -0.3562845 ,
          -0.24156807, -0.24156807],
         [-0.28256863, -1.8911965 , -0.26815474, ...,         nan,
                  nan, -0.56977123]],

        [[-0.2967996 ,         nan, -0.5902209 , ..., -0.24512221,
                  nan,         nan],
         [-0.57354575,         nan,         nan, ..., -0.55392367,
                  nan,         nan],
         [-1.1054505 , -1.0213782 , -1.5086595 , ..., -0.24808139,
                  nan, -0.25150678],
         ...,
         [        nan,         nan,         nan, ..., -0.30746055,
          -0.24156807,         nan],
         [-0.26187503,         nan, -0.37092817, ..., -0.3562845 ,
          -0.24156807, -0.24156807],
         [-0.28256863, -1.8911965 , -0.26815474, ...,         nan,
                  nan, -0.56977123]],

        [[-0.2967996 ,         nan, -0.5902209 , ..., -0.24512221,
                  nan,         nan],
         [-0.57354575,         nan,         nan, ..., -0.55392367,
                  nan,         nan],
         [-1.1054505 , -1.0213782 , -1.5086595 , ..., -0.24808139,
                  nan, -0.25150678],
         ...,
         [        nan,         nan,         nan, ..., -0.30746055,
          -0.24156807,         nan],
         [-0.26187503,         nan, -0.37092817, ..., -0.3562845 ,
          -0.24156807, -0.24156807],
         [-0.28256863, -1.8911965 , -0.26815474, ...,         nan,
                  nan, -0.56977123]]]], dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [13], 'to': [3]}
torch node:
{'name': 'log', 'output': array([[[[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        ...,

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]],

        [[-0.29679954,         nan, -0.59022146, ..., -0.2451198 ,
                  nan,         nan],
         [-0.5735426 ,         nan,         nan, ..., -0.5539206 ,
                  nan,         nan],
         [-1.1054486 , -1.021378  , -1.5086585 , ..., -0.24807917,
                  nan, -0.25150457],
         ...,
         [        nan,         nan,         nan, ..., -0.3074605 ,
          -0.24156566,         nan],
         [-0.2618728 ,         nan, -0.370931  , ..., -0.35628736,
          -0.24156566, -0.24156566],
         [-0.2825664 , -1.891195  , -0.2681525 , ...,         nan,
                  nan, -0.5697681 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [13], 'to': [3]}

generate models:95

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:5,distinct_bugs:3
torch --> nums:2,distinct_bugs:2
tensorflow --> 
flatten:1
log:1
mindspore --> 
sin:3
cos:1
log:1
torch --> 
flatten:1
log:1

generate models:100

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse output arrays in iter:14

pre layer res:
13:pad
{'name': 'pad', 'output': array([[inf, inf, inf, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [12], 'to': [15]}
tf node:
{'name': 'sin', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [13], 'to': [14]}
ms node:
{'name': 'sin', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': (1, 1048576), 'from': [13], 'to': [14]}
torch node:
{'name': 'sin', 'output': array([[nan, nan, nan, ...,  0.,  0.,  0.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [13], 'to': [14]}

generate models:14

analyse output arrays in iter:26

pre layer res:
0:log
{'name': 'log', 'output': array([[[[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 24.85728 , 24.739101, ..., 23.975435, 23.949795,
               -inf],
         [     -inf, 24.712843, 24.695145, ..., 23.454525, 23.282003,
               -inf],
         ...,
         [     -inf, 26.103539, 26.018229, ..., 25.503109, 25.538404,
               -inf],
         [     -inf, 26.10793 , 26.099138, ..., 25.57881 , 25.60718 ,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 24.85728 , 24.739101, ..., 23.975435, 23.949795,
               -inf],
         [     -inf, 24.712843, 24.695145, ..., 23.454525, 23.282003,
               -inf],
         ...,
         [     -inf, 26.103539, 26.018229, ..., 25.503109, 25.538404,
               -inf],
         [     -inf, 26.10793 , 26.099138, ..., 25.57881 , 25.60718 ,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 24.85728 , 24.739101, ..., 23.975435, 23.949795,
               -inf],
         [     -inf, 24.712843, 24.695145, ..., 23.454525, 23.282003,
               -inf],
         ...,
         [     -inf, 26.103539, 26.018229, ..., 25.503109, 25.538404,
               -inf],
         [     -inf, 26.10793 , 26.099138, ..., 25.57881 , 25.60718 ,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf]],

        ...,

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 24.85728 , 24.739101, ..., 23.975435, 23.949795,
               -inf],
         [     -inf, 24.712843, 24.695145, ..., 23.454525, 23.282003,
               -inf],
         ...,
         [     -inf, 26.103539, 26.018229, ..., 25.503109, 25.538404,
               -inf],
         [     -inf, 26.10793 , 26.099138, ..., 25.57881 , 25.60718 ,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 24.85728 , 24.739101, ..., 23.975435, 23.949795,
               -inf],
         [     -inf, 24.712843, 24.695145, ..., 23.454525, 23.282003,
               -inf],
         ...,
         [     -inf, 26.103539, 26.018229, ..., 25.503109, 25.538404,
               -inf],
         [     -inf, 26.10793 , 26.099138, ..., 25.57881 , 25.60718 ,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf]],

        [[     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf],
         [     -inf, 24.85728 , 24.739101, ..., 23.975435, 23.949795,
               -inf],
         [     -inf, 24.712843, 24.695145, ..., 23.454525, 23.282003,
               -inf],
         ...,
         [     -inf, 26.103539, 26.018229, ..., 25.503109, 25.538404,
               -inf],
         [     -inf, 26.10793 , 26.099138, ..., 25.57881 , 25.60718 ,
               -inf],
         [     -inf,      -inf,      -inf, ...,      -inf,      -inf,
               -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 34, 34]), 'from': [5], 'to': [2]}
tf node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 34, 34]), 'from': [0], 'to': [4]}
ms node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.27199194, -0.38355416, ..., -0.9157247 ,
          -0.9257244 ,         nan],
         [        nan, -0.4076693 , -0.42376718, ..., -0.99423605,
          -0.9610711 ,         nan],
         ...,
         [        nan,  0.8253351 ,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.8278063 ,  0.82284254, ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.27199194, -0.38355416, ..., -0.9157247 ,
          -0.9257244 ,         nan],
         [        nan, -0.4076693 , -0.42376718, ..., -0.99423605,
          -0.9610711 ,         nan],
         ...,
         [        nan,  0.8253351 ,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.8278063 ,  0.82284254, ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.27199194, -0.38355416, ..., -0.9157247 ,
          -0.9257244 ,         nan],
         [        nan, -0.4076693 , -0.42376718, ..., -0.99423605,
          -0.9610711 ,         nan],
         ...,
         [        nan,  0.8253351 ,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.8278063 ,  0.82284254, ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.27199194, -0.38355416, ..., -0.9157247 ,
          -0.9257244 ,         nan],
         [        nan, -0.4076693 , -0.42376718, ..., -0.99423605,
          -0.9610711 ,         nan],
         ...,
         [        nan,  0.8253351 ,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.8278063 ,  0.82284254, ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.27199194, -0.38355416, ..., -0.9157247 ,
          -0.9257244 ,         nan],
         [        nan, -0.4076693 , -0.42376718, ..., -0.99423605,
          -0.9610711 ,         nan],
         ...,
         [        nan,  0.8253351 ,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.8278063 ,  0.82284254, ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.27199194, -0.38355416, ..., -0.9157247 ,
          -0.9257244 ,         nan],
         [        nan, -0.4076693 , -0.42376718, ..., -0.99423605,
          -0.9610711 ,         nan],
         ...,
         [        nan,  0.8253351 ,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.8278063 ,  0.82284254, ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': (1, 1024, 34, 34), 'from': [0], 'to': [4]}
torch node:
{'name': 'sin', 'output': array([[[[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]],

        [[        nan,         nan,         nan, ...,         nan,
                  nan,         nan],
         [        nan, -0.2719901 , -0.3835524 , ..., -0.915724  ,
          -0.9257244 ,         nan],
         [        nan, -0.40766758, -0.42376375, ..., -0.99423605,
          -0.9610716 ,         nan],
         ...,
         [        nan,  0.82533616,  0.7742235 , ...,  0.36195827,
           0.39462826,         nan],
         [        nan,  0.82780737,  0.8228436 , ...,  0.43142208,
           0.45683897,         nan],
         [        nan,         nan,         nan, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 34, 34]), 'from': [0], 'to': [4]}

generate models:21

analyse output arrays in iter:44

pre layer res:
1:reshape
{'name': 'reshape', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [0], 'to': [3, 11]}
tf node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [1], 'to': [6]}
ms node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [1], 'to': [6]}
torch node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [1], 'to': [6]}

generate models:34

analyse output arrays in iter:49

pre layer res:
3:conv2d
{'name': 'conv2d', 'output': array([[[[783399.44, 783399.44, 783399.44, ..., 783399.44, 783399.44,
          783399.44],
         [783680.56, 774144.06, 783680.56, ..., 780304.  , 780304.  ,
          780304.  ],
         [783624.1 , 774144.06, 783624.1 , ..., 780301.9 , 780301.9 ,
          780301.9 ],
         ...,
         [783567.5 , 780298.06, 780298.06, ..., 780298.06, 780298.06,
          780298.06],
         [783909.44, 777216.56, 780314.56, ..., 780314.56, 780314.56,
          780314.56],
         [783394.5 , 783394.5 , 783394.5 , ..., 783394.5 , 783394.5 ,
          783394.5 ]],

        [[783399.44, 783399.44, 783399.44, ..., 783399.44, 783399.44,
          783399.44],
         [783680.56, 774144.06, 783680.56, ..., 780304.  , 780304.  ,
          780304.  ],
         [783624.1 , 774144.06, 783624.1 , ..., 780301.9 , 780301.9 ,
          780301.9 ],
         ...,
         [783567.5 , 780298.06, 780298.06, ..., 780298.06, 780298.06,
          780298.06],
         [783909.44, 777216.56, 780314.56, ..., 780314.56, 780314.56,
          780314.56],
         [783394.5 , 783394.5 , 783394.5 , ..., 783394.5 , 783394.5 ,
          783394.5 ]],

        [[783399.44, 783399.44, 783399.44, ..., 783399.44, 783399.44,
          783399.44],
         [783680.56, 774144.06, 783680.56, ..., 780304.  , 780304.  ,
          780304.  ],
         [783624.1 , 774144.06, 783624.1 , ..., 780301.9 , 780301.9 ,
          780301.9 ],
         ...,
         [783567.5 , 780298.06, 780298.06, ..., 780298.06, 780298.06,
          780298.06],
         [783909.44, 777216.56, 780314.56, ..., 780314.56, 780314.56,
          780314.56],
         [783394.5 , 783394.5 , 783394.5 , ..., 783394.5 , 783394.5 ,
          783394.5 ]],

        ...,

        [[783399.44, 783399.44, 783399.44, ..., 783399.44, 783399.44,
          783399.44],
         [783680.56, 774144.06, 783680.56, ..., 780304.  , 780304.  ,
          780304.  ],
         [783624.1 , 774144.06, 783624.1 , ..., 780301.9 , 780301.9 ,
          780301.9 ],
         ...,
         [783567.5 , 780298.06, 780298.06, ..., 780298.06, 780298.06,
          780298.06],
         [783909.44, 777216.56, 780314.56, ..., 780314.56, 780314.56,
          780314.56],
         [783394.5 , 783394.5 , 783394.5 , ..., 783394.5 , 783394.5 ,
          783394.5 ]],

        [[783399.44, 783399.44, 783399.44, ..., 783399.44, 783399.44,
          783399.44],
         [783680.56, 774144.06, 783680.56, ..., 780304.  , 780304.  ,
          780304.  ],
         [783624.1 , 774144.06, 783624.1 , ..., 780301.9 , 780301.9 ,
          780301.9 ],
         ...,
         [783567.5 , 780298.06, 780298.06, ..., 780298.06, 780298.06,
          780298.06],
         [783909.44, 777216.56, 780314.56, ..., 780314.56, 780314.56,
          780314.56],
         [783394.5 , 783394.5 , 783394.5 , ..., 783394.5 , 783394.5 ,
          783394.5 ]],

        [[783399.44, 783399.44, 783399.44, ..., 783399.44, 783399.44,
          783399.44],
         [783680.56, 774144.06, 783680.56, ..., 780304.  , 780304.  ,
          780304.  ],
         [783624.1 , 774144.06, 783624.1 , ..., 780301.9 , 780301.9 ,
          780301.9 ],
         ...,
         [783567.5 , 780298.06, 780298.06, ..., 780298.06, 780298.06,
          780298.06],
         [783909.44, 777216.56, 780314.56, ..., 780314.56, 780314.56,
          780314.56],
         [783394.5 , 783394.5 , 783394.5 , ..., 783394.5 , 783394.5 ,
          783394.5 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [4], 'to': [9]}
tf node:
{'name': 'cos', 'output': array([[[[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        ...,

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [3], 'to': [41]}
ms node:
{'name': 'cos', 'output': array([[[[ 0.20877928,  0.20877928,  0.20877928, ...,  0.20877928,
           0.20877928,  0.20877928],
         [-0.74831104,  0.608988  , -0.74831104, ...,  0.07085025,
           0.07085025,  0.07085025],
         [ 0.20176093,  0.608988  ,  0.20176093, ...,  0.99804044,
           0.99804044,  0.99804044],
         ...,
         [-0.53175944, -0.38921168, -0.38921168, ..., -0.38921168,
          -0.38921168, -0.38921168],
         [ 0.9653486 ,  0.524535  ,  0.9041186 , ...,  0.9041186 ,
           0.9041186 ,  0.9041186 ],
         [ 0.9998907 ,  0.9998907 ,  0.9998907 , ...,  0.9998907 ,
           0.9998907 ,  0.9998907 ]],

        [[ 0.20877928,  0.20877928,  0.20877928, ...,  0.20877928,
           0.20877928,  0.20877928],
         [-0.74831104,  0.608988  , -0.74831104, ...,  0.07085025,
           0.07085025,  0.07085025],
         [ 0.20176093,  0.608988  ,  0.20176093, ...,  0.99804044,
           0.99804044,  0.99804044],
         ...,
         [-0.53175944, -0.38921168, -0.38921168, ..., -0.38921168,
          -0.38921168, -0.38921168],
         [ 0.9653486 ,  0.524535  ,  0.9041186 , ...,  0.9041186 ,
           0.9041186 ,  0.9041186 ],
         [ 0.9998907 ,  0.9998907 ,  0.9998907 , ...,  0.9998907 ,
           0.9998907 ,  0.9998907 ]],

        [[ 0.20877928,  0.20877928,  0.20877928, ...,  0.20877928,
           0.20877928,  0.20877928],
         [-0.74831104,  0.608988  , -0.74831104, ...,  0.07085025,
           0.07085025,  0.07085025],
         [ 0.20176093,  0.608988  ,  0.20176093, ...,  0.99804044,
           0.99804044,  0.99804044],
         ...,
         [-0.53175944, -0.38921168, -0.38921168, ..., -0.38921168,
          -0.38921168, -0.38921168],
         [ 0.9653486 ,  0.524535  ,  0.9041186 , ...,  0.9041186 ,
           0.9041186 ,  0.9041186 ],
         [ 0.9998907 ,  0.9998907 ,  0.9998907 , ...,  0.9998907 ,
           0.9998907 ,  0.9998907 ]],

        ...,

        [[ 0.20877928,  0.20877928,  0.20877928, ...,  0.20877928,
           0.20877928,  0.20877928],
         [-0.74831104,  0.608988  , -0.74831104, ...,  0.07085025,
           0.07085025,  0.07085025],
         [ 0.20176093,  0.608988  ,  0.20176093, ...,  0.99804044,
           0.99804044,  0.99804044],
         ...,
         [-0.53175944, -0.38921168, -0.38921168, ..., -0.38921168,
          -0.38921168, -0.38921168],
         [ 0.9653486 ,  0.524535  ,  0.9041186 , ...,  0.9041186 ,
           0.9041186 ,  0.9041186 ],
         [ 0.9998907 ,  0.9998907 ,  0.9998907 , ...,  0.9998907 ,
           0.9998907 ,  0.9998907 ]],

        [[ 0.20877928,  0.20877928,  0.20877928, ...,  0.20877928,
           0.20877928,  0.20877928],
         [-0.74831104,  0.608988  , -0.74831104, ...,  0.07085025,
           0.07085025,  0.07085025],
         [ 0.20176093,  0.608988  ,  0.20176093, ...,  0.99804044,
           0.99804044,  0.99804044],
         ...,
         [-0.53175944, -0.38921168, -0.38921168, ..., -0.38921168,
          -0.38921168, -0.38921168],
         [ 0.9653486 ,  0.524535  ,  0.9041186 , ...,  0.9041186 ,
           0.9041186 ,  0.9041186 ],
         [ 0.9998907 ,  0.9998907 ,  0.9998907 , ...,  0.9998907 ,
           0.9998907 ,  0.9998907 ]],

        [[ 0.20877928,  0.20877928,  0.20877928, ...,  0.20877928,
           0.20877928,  0.20877928],
         [-0.74831104,  0.608988  , -0.74831104, ...,  0.07085025,
           0.07085025,  0.07085025],
         [ 0.20176093,  0.608988  ,  0.20176093, ...,  0.99804044,
           0.99804044,  0.99804044],
         ...,
         [-0.53175944, -0.38921168, -0.38921168, ..., -0.38921168,
          -0.38921168, -0.38921168],
         [ 0.9653486 ,  0.524535  ,  0.9041186 , ...,  0.9041186 ,
           0.9041186 ,  0.9041186 ],
         [ 0.9998907 ,  0.9998907 ,  0.9998907 , ...,  0.9998907 ,
           0.9998907 ,  0.9998907 ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [3], 'to': [41]}
torch node:
{'name': 'cos', 'output': array([[[[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        ...,

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]],

        [[ 0.781974  ,  0.781974  ,  0.781974  , ...,  0.781974  ,
           0.781974  ,  0.781974  ],
         [-0.6597697 ,  0.608988  , -0.6597697 , ...,  0.07085025,
           0.07085025,  0.07085025],
         [-0.57233006,  0.608988  , -0.57233006, ...,  0.8108968 ,
           0.8108968 ,  0.8108968 ],
         ...,
         [-0.63319695, -0.271331  , -0.271331  , ..., -0.271331  ,
          -0.271331  , -0.271331  ],
         [ 0.92528105,  0.62658906,  0.8756656 , ...,  0.8756656 ,
           0.8756656 ,  0.8756656 ],
         [ 0.78213245,  0.78213245,  0.78213245, ...,  0.78213245,
           0.78213245,  0.78213245]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [3], 'to': [41]}

generate models:37

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:2
mindspore --> nums:4,distinct_bugs:2
torch --> nums:3,distinct_bugs:2
tensorflow --> 
sin:2
cos:1
mindspore --> 
sin:2
cos:2
torch --> 
sin:2
cos:1

generate models:37

analyse output arrays in iter:55

pre layer res:
7:exp
{'name': 'exp', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [6], 'to': [101]}
tf node:
{'name': 'log', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [7], 'to': []}
ms node:
{'name': 'log', 'output': array([[[[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        ...,

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]],

        [[-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         ...,
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06],
         [-1.4305115e-06, -1.4305115e-06, -1.4305115e-06, ...,
          -1.4305115e-06, -1.4305115e-06, -1.4305115e-06]]]],
      dtype=float32), 'output_shape': (1, 512, 16, 16), 'from': [7], 'to': []}
torch node:
{'name': 'log', 'output': array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]],

        [[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         ...,
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 16, 16]), 'from': [7], 'to': []}

generate models:39

analyse the exceptions in iter:64
tensorflow exception:
{'id': 14, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([6.9145e+08], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 14, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([6.9145e+08], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:43

analyse output arrays in iter:65

pre layer res:
12:transpose
{'name': 'transpose', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [16], 'to': [0]}
tf node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [12], 'to': [15]}
ms node:
{'name': 'log', 'output': array([[[[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        ...,

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]],

        [[88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         ...,
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284],
         [88.72284, 88.72284, 88.72284, ..., 88.72284, 88.72284,
          88.72284]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [12], 'to': [15]}
torch node:
{'name': 'log', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [12], 'to': [15]}

generate models:44

analyse output arrays in iter:85

pre layer res:
2:flatten
{'name': 'flatten', 'output': array([[  3.,   3.,   3., ..., 128., 122., 127.]], dtype=float32), 'output_shape': torch.Size([1, 1048576]), 'from': [38], 'to': [7]}
tf node:
{'name': 'sum', 'output': array([1.6727142e+08], dtype=float32), 'output_shape': torch.Size([1]), 'from': [2], 'to': [8, 13]}
ms node:
{'name': 'sum', 'output': array([1.6698646e+08], dtype=float32), 'output_shape': (1,), 'from': [2], 'to': [8, 13]}
torch node:
{'name': 'sum', 'output': array([1.6727142e+08], dtype=float32), 'output_shape': torch.Size([1]), 'from': [2], 'to': [8, 13]}

generate models:52

analyse output arrays in iter:88

pre layer res:
6:cos
{'name': 'cos', 'output': array([[[[ 0.18027934, -0.9971889 ,  0.61095285, ..., -0.8623245 ,
          -0.78475285,  0.58622867],
         [-0.8884661 , -0.56787753, -0.8520057 , ...,  0.28242955,
          -0.67656815, -0.7218348 ],
         [ 0.02206358, -0.4607426 ,  0.48862273, ...,  0.953069  ,
          -0.67656815, -0.99949825],
         ...,
         [ 0.61949056,  0.02206358,  0.9816827 , ...,  0.08531915,
           0.8619135 , -0.99422866],
         [ 0.34260044,  0.9990618 , -0.6369724 , ..., -0.94655025,
           0.8971254 ,  0.8838235 ],
         [ 0.99862075,  0.8673542 , -0.06291056, ...,  0.5505944 ,
           0.7444766 , -0.7355564 ]],

        [[ 0.18027934, -0.9971889 ,  0.61095285, ..., -0.8623245 ,
          -0.78475285,  0.58622867],
         [-0.8884661 , -0.56787753, -0.8520057 , ...,  0.28242955,
          -0.67656815, -0.7218348 ],
         [ 0.02206358, -0.4607426 ,  0.48862273, ...,  0.953069  ,
          -0.67656815, -0.99949825],
         ...,
         [ 0.61949056,  0.02206358,  0.9816827 , ...,  0.08531915,
           0.8619135 , -0.99422866],
         [ 0.34260044,  0.9990618 , -0.6369724 , ..., -0.94655025,
           0.8971254 ,  0.8838235 ],
         [ 0.99862075,  0.8673542 , -0.06291056, ...,  0.5505944 ,
           0.7444766 , -0.7355564 ]],

        [[ 0.18027934, -0.9971889 ,  0.61095285, ..., -0.8623245 ,
          -0.78475285,  0.58622867],
         [-0.8884661 , -0.56787753, -0.8520057 , ...,  0.28242955,
          -0.67656815, -0.7218348 ],
         [ 0.02206358, -0.4607426 ,  0.48862273, ...,  0.953069  ,
          -0.67656815, -0.99949825],
         ...,
         [ 0.61949056,  0.02206358,  0.9816827 , ...,  0.08531915,
           0.8619135 , -0.99422866],
         [ 0.34260044,  0.9990618 , -0.6369724 , ..., -0.94655025,
           0.8971254 ,  0.8838235 ],
         [ 0.99862075,  0.8673542 , -0.06291056, ...,  0.5505944 ,
           0.7444766 , -0.7355564 ]],

        ...,

        [[ 0.18027934, -0.9971889 ,  0.61095285, ..., -0.8623245 ,
          -0.78475285,  0.58622867],
         [-0.8884661 , -0.56787753, -0.8520057 , ...,  0.28242955,
          -0.67656815, -0.7218348 ],
         [ 0.02206358, -0.4607426 ,  0.48862273, ...,  0.953069  ,
          -0.67656815, -0.99949825],
         ...,
         [ 0.61949056,  0.02206358,  0.9816827 , ...,  0.08531915,
           0.8619135 , -0.99422866],
         [ 0.34260044,  0.9990618 , -0.6369724 , ..., -0.94655025,
           0.8971254 ,  0.8838235 ],
         [ 0.99862075,  0.8673542 , -0.06291056, ...,  0.5505944 ,
           0.7444766 , -0.7355564 ]],

        [[ 0.18027934, -0.9971889 ,  0.61095285, ..., -0.8623245 ,
          -0.78475285,  0.58622867],
         [-0.8884661 , -0.56787753, -0.8520057 , ...,  0.28242955,
          -0.67656815, -0.7218348 ],
         [ 0.02206358, -0.4607426 ,  0.48862273, ...,  0.953069  ,
          -0.67656815, -0.99949825],
         ...,
         [ 0.61949056,  0.02206358,  0.9816827 , ...,  0.08531915,
           0.8619135 , -0.99422866],
         [ 0.34260044,  0.9990618 , -0.6369724 , ..., -0.94655025,
           0.8971254 ,  0.8838235 ],
         [ 0.99862075,  0.8673542 , -0.06291056, ...,  0.5505944 ,
           0.7444766 , -0.7355564 ]],

        [[ 0.18027934, -0.9971889 ,  0.61095285, ..., -0.8623245 ,
          -0.78475285,  0.58622867],
         [-0.8884661 , -0.56787753, -0.8520057 , ...,  0.28242955,
          -0.67656815, -0.7218348 ],
         [ 0.02206358, -0.4607426 ,  0.48862273, ...,  0.953069  ,
          -0.67656815, -0.99949825],
         ...,
         [ 0.61949056,  0.02206358,  0.9816827 , ...,  0.08531915,
           0.8619135 , -0.99422866],
         [ 0.34260044,  0.9990618 , -0.6369724 , ..., -0.94655025,
           0.8971254 ,  0.8838235 ],
         [ 0.99862075,  0.8673542 , -0.06291056, ...,  0.5505944 ,
           0.7444766 , -0.7355564 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [1], 'to': [12]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        ...,

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [6], 'to': [18]}
ms node:
{'name': 'sin', 'output': array([[[[ 1.7930439e-01, -8.3994883e-01,  5.7364821e-01, ...,
          -7.5935709e-01, -7.0665032e-01,  5.5322331e-01],
         [-7.7610540e-01, -5.3784394e-01, -7.5260264e-01, ...,
           2.7868977e-01, -6.2612081e-01, -6.6076297e-01],
         [ 2.2061793e-02, -4.4461340e-01,  4.6941024e-01, ...,
           8.1519681e-01, -6.2612081e-01, -8.4119976e-01],
         ...,
         [ 5.8062047e-01,  2.2061793e-02,  8.3143353e-01, ...,
           8.5215673e-02,  7.5908959e-01, -8.3833873e-01],
         [ 3.3593753e-01,  8.4096372e-01, -5.9476429e-01, ...,
          -8.1140399e-01,  7.8153682e-01,  7.7316940e-01],
         [ 8.4072495e-01,  7.6262021e-01, -6.2869065e-02, ...,
           5.2319390e-01,  6.7758697e-01, -6.7099983e-01]],

        [[ 1.7930439e-01, -8.3994883e-01,  5.7364821e-01, ...,
          -7.5935709e-01, -7.0665032e-01,  5.5322331e-01],
         [-7.7610540e-01, -5.3784394e-01, -7.5260264e-01, ...,
           2.7868977e-01, -6.2612081e-01, -6.6076297e-01],
         [ 2.2061793e-02, -4.4461340e-01,  4.6941024e-01, ...,
           8.1519681e-01, -6.2612081e-01, -8.4119976e-01],
         ...,
         [ 5.8062047e-01,  2.2061793e-02,  8.3143353e-01, ...,
           8.5215673e-02,  7.5908959e-01, -8.3833873e-01],
         [ 3.3593753e-01,  8.4096372e-01, -5.9476429e-01, ...,
          -8.1140399e-01,  7.8153682e-01,  7.7316940e-01],
         [ 8.4072495e-01,  7.6262021e-01, -6.2869065e-02, ...,
           5.2319390e-01,  6.7758697e-01, -6.7099983e-01]],

        [[ 1.7930439e-01, -8.3994883e-01,  5.7364821e-01, ...,
          -7.5935709e-01, -7.0665032e-01,  5.5322331e-01],
         [-7.7610540e-01, -5.3784394e-01, -7.5260264e-01, ...,
           2.7868977e-01, -6.2612081e-01, -6.6076297e-01],
         [ 2.2061793e-02, -4.4461340e-01,  4.6941024e-01, ...,
           8.1519681e-01, -6.2612081e-01, -8.4119976e-01],
         ...,
         [ 5.8062047e-01,  2.2061793e-02,  8.3143353e-01, ...,
           8.5215673e-02,  7.5908959e-01, -8.3833873e-01],
         [ 3.3593753e-01,  8.4096372e-01, -5.9476429e-01, ...,
          -8.1140399e-01,  7.8153682e-01,  7.7316940e-01],
         [ 8.4072495e-01,  7.6262021e-01, -6.2869065e-02, ...,
           5.2319390e-01,  6.7758697e-01, -6.7099983e-01]],

        ...,

        [[ 3.1436800e+05,  2.6316800e+05,  2.8876800e+05, ...,
           1.0444800e+05,  5.6320000e+04,  7.4752000e+04],
         [ 3.0003200e+05,  3.9014400e+05,  3.3996800e+05, ...,
           8.9088000e+04,  5.5296000e+04,  6.5536000e+04],
         [ 3.1334400e+05,  4.5772800e+05,  3.9731200e+05, ...,
           7.8848000e+04,  5.5296000e+04,  6.0416000e+04],
         ...,
         [ 2.0787200e+05,  3.1334400e+05,  2.4371200e+05, ...,
           1.9251200e+05,  4.0755200e+05,  5.0585600e+05],
         [ 2.0992000e+05,  3.2358400e+05,  2.5702400e+05, ...,
           2.2016000e+05,  4.4748800e+05,  5.2224000e+05],
         [ 2.0172800e+05,  3.2665600e+05,  2.7238400e+05, ...,
           2.4883200e+05,  4.8025600e+05,  5.0995200e+05]],

        [[ 3.1436800e+05,  2.6316800e+05,  2.8876800e+05, ...,
           1.0444800e+05,  5.6320000e+04,  7.4752000e+04],
         [ 3.0003200e+05,  3.9014400e+05,  3.3996800e+05, ...,
           8.9088000e+04,  5.5296000e+04,  6.5536000e+04],
         [ 3.1334400e+05,  4.5772800e+05,  3.9731200e+05, ...,
           7.8848000e+04,  5.5296000e+04,  6.0416000e+04],
         ...,
         [ 2.0787200e+05,  3.1334400e+05,  2.4371200e+05, ...,
           1.9251200e+05,  4.0755200e+05,  5.0585600e+05],
         [ 2.0992000e+05,  3.2358400e+05,  2.5702400e+05, ...,
           2.2016000e+05,  4.4748800e+05,  5.2224000e+05],
         [ 2.0172800e+05,  3.2665600e+05,  2.7238400e+05, ...,
           2.4883200e+05,  4.8025600e+05,  5.0995200e+05]],

        [[ 3.1436800e+05,  2.6316800e+05,  2.8876800e+05, ...,
           1.0444800e+05,  5.6320000e+04,  7.4752000e+04],
         [ 3.0003200e+05,  3.9014400e+05,  3.3996800e+05, ...,
           8.9088000e+04,  5.5296000e+04,  6.5536000e+04],
         [ 3.1334400e+05,  4.5772800e+05,  3.9731200e+05, ...,
           7.8848000e+04,  5.5296000e+04,  6.0416000e+04],
         ...,
         [ 2.0787200e+05,  3.1334400e+05,  2.4371200e+05, ...,
           1.9251200e+05,  4.0755200e+05,  5.0585600e+05],
         [ 2.0992000e+05,  3.2358400e+05,  2.5702400e+05, ...,
           2.2016000e+05,  4.4748800e+05,  5.2224000e+05],
         [ 2.0172800e+05,  3.2665600e+05,  2.7238400e+05, ...,
           2.4883200e+05,  4.8025600e+05,  5.0995200e+05]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [6], 'to': [18]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        ...,

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]],

        [[ 0.17930439, -0.83994883,  0.5736482 , ..., -0.7593571 ,
          -0.7066503 ,  0.5532233 ],
         [-0.7761054 , -0.53784394, -0.75260264, ...,  0.27868977,
          -0.6261208 , -0.66076297],
         [ 0.02206179, -0.4446134 ,  0.46941024, ...,  0.8151968 ,
          -0.6261208 , -0.84119976],
         ...,
         [ 0.58062047,  0.02206179,  0.8314335 , ...,  0.08521568,
           0.7590896 , -0.83833873],
         [ 0.33593753,  0.8409637 , -0.5947643 , ..., -0.811404  ,
           0.7815368 ,  0.7731694 ],
         [ 0.84072495,  0.7626202 , -0.06286906, ...,  0.5231939 ,
           0.677587  , -0.6709998 ]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [6], 'to': [18]}

generate models:54

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:3
mindspore --> nums:8,distinct_bugs:4
torch --> nums:4,distinct_bugs:3
tensorflow --> 
sin:2
cos:1
flatten:1
mindspore --> 
sin:3
cos:2
log:2
sum:1
torch --> 
sin:2
cos:1
flatten:1

generate models:56

analyse output arrays in iter:147

pre layer res:
7:transpose
{'name': 'transpose', 'output': array([[[[6.2978739e+08, 6.1929082e+08, 6.2243987e+08, ...,
          6.2453907e+08, 5.8990227e+08, 4.8914026e+08],
         [6.2558957e+08, 6.1509293e+08, 6.1719277e+08, ...,
          4.3560989e+08, 3.8837856e+08, 2.7921974e+08],
         [6.2873683e+08, 6.2034003e+08, 6.2453907e+08, ...,
          2.5507838e+08, 2.7082189e+08, 2.6662349e+08],
         ...,
         [3.6528678e+08, 3.5898976e+08, 3.5689002e+08, ...,
          3.4324490e+08, 3.4849306e+08, 3.6003869e+08],
         [3.6423709e+08, 3.6528678e+08, 3.6108845e+08, ...,
          3.5584010e+08, 3.4954294e+08, 3.4429466e+08],
         [3.7578336e+08, 3.6633680e+08, 3.6003869e+08, ...,
          3.6108845e+08, 3.6528678e+08, 3.9782429e+08]],

        [[6.2978739e+08, 6.1929082e+08, 6.2243987e+08, ...,
          6.2453907e+08, 5.8990227e+08, 4.8914026e+08],
         [6.2558957e+08, 6.1509293e+08, 6.1719277e+08, ...,
          4.3560989e+08, 3.8837856e+08, 2.7921974e+08],
         [6.2873683e+08, 6.2034003e+08, 6.2453907e+08, ...,
          2.5507838e+08, 2.7082189e+08, 2.6662349e+08],
         ...,
         [3.6528678e+08, 3.5898976e+08, 3.5689002e+08, ...,
          3.4324490e+08, 3.4849306e+08, 3.6003869e+08],
         [3.6423709e+08, 3.6528678e+08, 3.6108845e+08, ...,
          3.5584010e+08, 3.4954294e+08, 3.4429466e+08],
         [3.7578336e+08, 3.6633680e+08, 3.6003869e+08, ...,
          3.6108845e+08, 3.6528678e+08, 3.9782429e+08]],

        [[6.2978739e+08, 6.1929082e+08, 6.2243987e+08, ...,
          6.2453907e+08, 5.8990227e+08, 4.8914026e+08],
         [6.2558957e+08, 6.1509293e+08, 6.1719277e+08, ...,
          4.3560989e+08, 3.8837856e+08, 2.7921974e+08],
         [6.2873683e+08, 6.2034003e+08, 6.2453907e+08, ...,
          2.5507838e+08, 2.7082189e+08, 2.6662349e+08],
         ...,
         [3.6528678e+08, 3.5898976e+08, 3.5689002e+08, ...,
          3.4324490e+08, 3.4849306e+08, 3.6003869e+08],
         [3.6423709e+08, 3.6528678e+08, 3.6108845e+08, ...,
          3.5584010e+08, 3.4954294e+08, 3.4429466e+08],
         [3.7578336e+08, 3.6633680e+08, 3.6003869e+08, ...,
          3.6108845e+08, 3.6528678e+08, 3.9782429e+08]],

        ...,

        [[6.2978739e+08, 6.1929082e+08, 6.2243987e+08, ...,
          6.2453907e+08, 5.8990227e+08, 4.8914026e+08],
         [6.2558957e+08, 6.1509293e+08, 6.1719277e+08, ...,
          4.3560989e+08, 3.8837856e+08, 2.7921974e+08],
         [6.2873683e+08, 6.2034003e+08, 6.2453907e+08, ...,
          2.5507838e+08, 2.7082189e+08, 2.6662349e+08],
         ...,
         [3.6528678e+08, 3.5898976e+08, 3.5689002e+08, ...,
          3.4324490e+08, 3.4849306e+08, 3.6003869e+08],
         [3.6423709e+08, 3.6528678e+08, 3.6108845e+08, ...,
          3.5584010e+08, 3.4954294e+08, 3.4429466e+08],
         [3.7578336e+08, 3.6633680e+08, 3.6003869e+08, ...,
          3.6108845e+08, 3.6528678e+08, 3.9782429e+08]],

        [[6.2978739e+08, 6.1929082e+08, 6.2243987e+08, ...,
          6.2453907e+08, 5.8990227e+08, 4.8914026e+08],
         [6.2558957e+08, 6.1509293e+08, 6.1719277e+08, ...,
          4.3560989e+08, 3.8837856e+08, 2.7921974e+08],
         [6.2873683e+08, 6.2034003e+08, 6.2453907e+08, ...,
          2.5507838e+08, 2.7082189e+08, 2.6662349e+08],
         ...,
         [3.6528678e+08, 3.5898976e+08, 3.5689002e+08, ...,
          3.4324490e+08, 3.4849306e+08, 3.6003869e+08],
         [3.6423709e+08, 3.6528678e+08, 3.6108845e+08, ...,
          3.5584010e+08, 3.4954294e+08, 3.4429466e+08],
         [3.7578336e+08, 3.6633680e+08, 3.6003869e+08, ...,
          3.6108845e+08, 3.6528678e+08, 3.9782429e+08]],

        [[6.2978739e+08, 6.1929082e+08, 6.2243987e+08, ...,
          6.2453907e+08, 5.8990227e+08, 4.8914026e+08],
         [6.2558957e+08, 6.1509293e+08, 6.1719277e+08, ...,
          4.3560989e+08, 3.8837856e+08, 2.7921974e+08],
         [6.2873683e+08, 6.2034003e+08, 6.2453907e+08, ...,
          2.5507838e+08, 2.7082189e+08, 2.6662349e+08],
         ...,
         [3.6528678e+08, 3.5898976e+08, 3.5689002e+08, ...,
          3.4324490e+08, 3.4849306e+08, 3.6003869e+08],
         [3.6423709e+08, 3.6528678e+08, 3.6108845e+08, ...,
          3.5584010e+08, 3.4954294e+08, 3.4429466e+08],
         [3.7578336e+08, 3.6633680e+08, 3.6003869e+08, ...,
          3.6108845e+08, 3.6528678e+08, 3.9782429e+08]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [6], 'to': [1]}
tf node:
{'name': 'sin', 'output': array([[[[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        ...,

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [7], 'to': [4, 4]}
ms node:
{'name': 'sin', 'output': array([[[[ 6.6994202e-01,  6.2819469e-01,  9.9963647e-01, ...,
          -6.8574721e-01, -9.3096936e-01,  6.6937067e-02],
         [-8.1514889e-01, -4.4428432e-01,  4.5108572e-01, ...,
          -9.9997991e-01, -9.8424530e-01, -8.5004836e-01],
         [ 8.4090883e-01, -4.0959245e-01, -6.8574721e-01, ...,
          -9.2859823e-01, -8.4436333e-01, -2.9063642e-01],
         ...,
         [ 6.3665062e-01, -8.9560044e-01, -1.3723460e-01, ...,
          -9.5761198e-01,  6.8407726e-01, -9.7396624e-01],
         [ 7.9070888e-02,  6.3665062e-01,  9.1555601e-01, ...,
           7.5316286e-01, -8.5069096e-01,  9.9428368e-01],
         [ 9.8700970e-01, -8.8218826e-01, -9.7396624e-01, ...,
           9.1555601e-01,  6.3665062e-01, -3.6956269e-01]],

        [[ 6.6994202e-01,  6.2819469e-01,  9.9963647e-01, ...,
          -6.8574721e-01, -9.3096936e-01,  6.6937067e-02],
         [-8.1514889e-01, -4.4428432e-01,  4.5108572e-01, ...,
          -9.9997991e-01, -9.8424530e-01, -8.5004836e-01],
         [ 8.4090883e-01, -4.0959245e-01, -6.8574721e-01, ...,
          -9.2859823e-01, -8.4436333e-01, -2.9063642e-01],
         ...,
         [ 6.3665062e-01, -8.9560044e-01, -1.3723460e-01, ...,
          -9.5761198e-01,  6.8407726e-01, -9.7396624e-01],
         [ 7.9070888e-02,  6.3665062e-01,  9.1555601e-01, ...,
           7.5316286e-01, -8.5069096e-01,  9.9428368e-01],
         [ 9.8700970e-01, -8.8218826e-01, -9.7396624e-01, ...,
           9.1555601e-01,  6.3665062e-01, -3.6956269e-01]],

        [[ 6.6994202e-01,  6.2819469e-01,  9.9963647e-01, ...,
          -6.8574721e-01, -9.3096936e-01,  6.6937067e-02],
         [-8.1514889e-01, -4.4428432e-01,  4.5108572e-01, ...,
          -9.9997991e-01, -9.8424530e-01, -8.5004836e-01],
         [ 8.4090883e-01, -4.0959245e-01, -6.8574721e-01, ...,
          -9.2859823e-01, -8.4436333e-01, -2.9063642e-01],
         ...,
         [ 6.3665062e-01, -8.9560044e-01, -1.3723460e-01, ...,
          -9.5761198e-01,  6.8407726e-01, -9.7396624e-01],
         [ 7.9070888e-02,  6.3665062e-01,  9.1555601e-01, ...,
           7.5316286e-01, -8.5069096e-01,  9.9428368e-01],
         [ 9.8700970e-01, -8.8218826e-01, -9.7396624e-01, ...,
           9.1555601e-01,  6.3665062e-01, -3.6956269e-01]],

        ...,

        [[ 6.2978656e+08,  6.2558976e+08,  6.2873664e+08, ...,
           3.6528646e+08,  3.6423709e+08,  3.7578336e+08],
         [ 6.1929075e+08,  6.1509395e+08,  6.2033984e+08, ...,
           3.5898976e+08,  3.6528646e+08,  3.6633718e+08],
         [ 6.2243878e+08,  6.1719296e+08,  6.2453990e+08, ...,
           3.5688960e+08,  3.6108803e+08,  3.6003862e+08],
         ...,
         [ 6.2453990e+08,  4.3560982e+08,  2.5507838e+08, ...,
           3.4324486e+08,  3.5584006e+08,  3.6108803e+08],
         [ 5.8990336e+08,  3.8837827e+08,  2.7082240e+08, ...,
           3.4849267e+08,  3.4954339e+08,  3.6528646e+08],
         [ 4.8914125e+08,  2.7921987e+08,  2.6662400e+08, ...,
           3.6003862e+08,  3.4429427e+08,  3.9782464e+08]],

        [[ 6.2978656e+08,  6.2558976e+08,  6.2873664e+08, ...,
           3.6528646e+08,  3.6423709e+08,  3.7578336e+08],
         [ 6.1929075e+08,  6.1509395e+08,  6.2033984e+08, ...,
           3.5898976e+08,  3.6528646e+08,  3.6633718e+08],
         [ 6.2243878e+08,  6.1719296e+08,  6.2453990e+08, ...,
           3.5688960e+08,  3.6108803e+08,  3.6003862e+08],
         ...,
         [ 6.2453990e+08,  4.3560982e+08,  2.5507838e+08, ...,
           3.4324486e+08,  3.5584006e+08,  3.6108803e+08],
         [ 5.8990336e+08,  3.8837827e+08,  2.7082240e+08, ...,
           3.4849267e+08,  3.4954339e+08,  3.6528646e+08],
         [ 4.8914125e+08,  2.7921987e+08,  2.6662400e+08, ...,
           3.6003862e+08,  3.4429427e+08,  3.9782464e+08]],

        [[ 6.2978656e+08,  6.2558976e+08,  6.2873664e+08, ...,
           3.6528646e+08,  3.6423709e+08,  3.7578336e+08],
         [ 6.1929075e+08,  6.1509395e+08,  6.2033984e+08, ...,
           3.5898976e+08,  3.6528646e+08,  3.6633718e+08],
         [ 6.2243878e+08,  6.1719296e+08,  6.2453990e+08, ...,
           3.5688960e+08,  3.6108803e+08,  3.6003862e+08],
         ...,
         [ 6.2453990e+08,  4.3560982e+08,  2.5507838e+08, ...,
           3.4324486e+08,  3.5584006e+08,  3.6108803e+08],
         [ 5.8990336e+08,  3.8837827e+08,  2.7082240e+08, ...,
           3.4849267e+08,  3.4954339e+08,  3.6528646e+08],
         [ 4.8914125e+08,  2.7921987e+08,  2.6662400e+08, ...,
           3.6003862e+08,  3.4429427e+08,  3.9782464e+08]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [7], 'to': [4, 4]}
torch node:
{'name': 'sin', 'output': array([[[[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        ...,

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]],

        [[-0.21049128, -0.4696693 ,  0.5553789 , ...,  0.23145851,
          -0.18700953, -0.625905  ],
         [ 0.5564757 , -0.29663792, -0.738491  , ..., -0.39768466,
          -0.6608982 ,  0.20922108],
         [-0.97824144,  0.05912463,  0.23145851, ..., -0.9285982 ,
           0.88429326,  0.36580205],
         ...,
         [ 0.9055175 , -0.89560044,  0.92156816, ..., -0.64001757,
           0.02763813, -0.59021914],
         [ 0.07907089,  0.9055175 ,  0.62484634, ...,  0.99105334,
           0.7685328 ,  0.67290246],
         [ 0.9870097 , -0.34739617, -0.59021914, ...,  0.62484634,
           0.9055175 , -0.49701998]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [7], 'to': [4, 4]}

generate models:67

final statics:
total operators:28
tensorflow --> nums:4,distinct_bugs:3
mindspore --> nums:9,distinct_bugs:4
torch --> nums:4,distinct_bugs:3
tensorflow --> 
sin:2
cos:1
flatten:1
mindspore --> 
sin:4
cos:2
log:2
sum:1
torch --> 
sin:2
cos:1
flatten:1

generate models:77

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:10

analyse the exceptions in iter:27
tensorflow exception:
{'id': 14, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([48433672.], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 14, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([48433672.], grad_fn=<SumBackward1>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:27

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
flatten:1
mindspore --> 
torch --> 
flatten:1

generate models:35

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:0,distinct_bugs:0
torch --> nums:1,distinct_bugs:1
tensorflow --> 
flatten:1
mindspore --> 
torch --> 
flatten:1

generate models:46

analyse output arrays in iter:106

pre layer res:
1:transpose
{'name': 'transpose', 'output': array([[[[128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         ...,
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.]],

        [[128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         ...,
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.]],

        [[128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         ...,
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.]],

        ...,

        [[128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         ...,
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.]],

        [[128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         ...,
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.]],

        [[128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         ...,
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.],
         [128., 128., 128., ..., 128., 128., 128.]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [2], 'to': [3]}
tf node:
{'name': 'sin', 'output': array([[[[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        ...,

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [1], 'to': [15]}
ms node:
{'name': 'sin', 'output': array([[[[  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         ...,
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377]],

        [[  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         ...,
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377]],

        [[  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         ...,
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377],
         [  0.7210377,   0.7210377,   0.7210377, ...,   0.7210377,
            0.7210377,   0.7210377]],

        ...,

        [[128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         ...,
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ]],

        [[128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         ...,
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ]],

        [[128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         ...,
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ],
         [128.       , 128.       , 128.       , ..., 128.       ,
          128.       , 128.       ]]]], dtype=float32), 'output_shape': (1, 64, 32, 32), 'from': [1], 'to': [15]}
torch node:
{'name': 'sin', 'output': array([[[[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        ...,

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]],

        [[0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         ...,
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377],
         [0.7210377, 0.7210377, 0.7210377, ..., 0.7210377, 0.7210377,
          0.7210377]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [1], 'to': [15]}

generate models:47

analyse output arrays in iter:604

pre layer res:
32:add
{'name': 'add', 'output': array([[[[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        ...,

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [15, 0], 'to': [33, 33]}
32:add
{'name': 'add', 'output': array([[[[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        ...,

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]],

        [[2646015.8, 2883583.2, 3055616.8, ..., 2932736.5, 2834431.2,
          2555903. ],
         [2899969. , 4227072.5, 4726784. , ..., 4481024.5, 4046847.2,
          2793471.2],
         [3145728.8, 5021695. , 5742591.5, ..., 5505023. , 4808704. ,
          2949120.2],
         ...,
         [2801663. , 3694591.5, 4079616.2, ..., 3047423.5, 3203071. ,
          2711551.5],
         [2646015.8, 3112959.8, 3317759.5, ..., 3072000. , 3022849. ,
          2572288.8],
         [2457601. , 2555903. , 2637823. , ..., 2744320.5, 2605055.8,
          2449408.8]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [15, 0], 'to': [33, 33]}
tf node:
{'name': 'add', 'output': array([[[[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        ...,

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [32, 32], 'to': [13]}
ms node:
{'name': 'add', 'output': array([[[[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        ...,

        [[ 7938048. ,  8650752. ,  9166848. , ...,  8798208. ,
           8503296. ,  7667712. ],
         [ 8699904. , 12681216. , 14180352. , ..., 13443072. ,
          12140544. ,  8380416. ],
         [ 9437184. , 15065088. , 17227776. , ..., 16515072. ,
          14426112. ,  8847360. ],
         ...,
         [ 8404992. , 11083776. , 12238848. , ...,  9142272. ,
           9609216. ,  8134656. ],
         [ 7938048. ,  9338880. ,  9953280. , ...,  9216000. ,
           9068544. ,  7716864. ],
         [ 7372800. ,  7667712. ,  7913472. , ...,  8232960. ,
           7815168. ,  7348224. ]],

        [[ 7938048. ,  8650752. ,  9166848. , ...,  8798208. ,
           8503296. ,  7667712. ],
         [ 8699904. , 12681216. , 14180352. , ..., 13443072. ,
          12140544. ,  8380416. ],
         [ 9437184. , 15065088. , 17227776. , ..., 16515072. ,
          14426112. ,  8847360. ],
         ...,
         [ 8404992. , 11083776. , 12238848. , ...,  9142272. ,
           9609216. ,  8134656. ],
         [ 7938048. ,  9338880. ,  9953280. , ...,  9216000. ,
           9068544. ,  7716864. ],
         [ 7372800. ,  7667712. ,  7913472. , ...,  8232960. ,
           7815168. ,  7348224. ]],

        [[ 7938048. ,  8650752. ,  9166848. , ...,  8798208. ,
           8503296. ,  7667712. ],
         [ 8699904. , 12681216. , 14180352. , ..., 13443072. ,
          12140544. ,  8380416. ],
         [ 9437184. , 15065088. , 17227776. , ..., 16515072. ,
          14426112. ,  8847360. ],
         ...,
         [ 8404992. , 11083776. , 12238848. , ...,  9142272. ,
           9609216. ,  8134656. ],
         [ 7938048. ,  9338880. ,  9953280. , ...,  9216000. ,
           9068544. ,  7716864. ],
         [ 7372800. ,  7667712. ,  7913472. , ...,  8232960. ,
           7815168. ,  7348224. ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [32, 32], 'to': [13]}
torch node:
{'name': 'add', 'output': array([[[[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        ...,

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]],

        [[ 5292031.5,  5767166.5,  6111233.5, ...,  5865473. ,
           5668862.5,  5111806. ],
         [ 5799938. ,  8454145. ,  9453568. , ...,  8962049. ,
           8093694.5,  5586942.5],
         [ 6291457.5, 10043390. , 11485183. , ..., 11010046. ,
           9617408. ,  5898240.5],
         ...,
         [ 5603326. ,  7389183. ,  8159232.5, ...,  6094847. ,
           6406142. ,  5423103. ],
         [ 5292031.5,  6225919.5,  6635519. , ...,  6144000. ,
           6045698. ,  5144577.5],
         [ 4915202. ,  5111806. ,  5275646. , ...,  5488641. ,
           5210111.5,  4898817.5]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [32, 32], 'to': [13]}

pre layer res:
15:conv2d
{'name': 'conv2d', 'output': array([[[[2646016., 2883584., 3055616., ..., 2932736., 2834432.,
          2555904.],
         [2899968., 4227072., 4726784., ..., 4481024., 4046848.,
          2793472.],
         [3145728., 5021696., 5742592., ..., 5505024., 4808704.,
          2949120.],
         ...,
         [2801664., 3694592., 4079616., ..., 3047424., 3203072.,
          2711552.],
         [2646016., 3112960., 3317760., ..., 3072000., 3022848.,
          2572288.],
         [2457600., 2555904., 2637824., ..., 2744320., 2605056.,
          2449408.]],

        [[2646016., 2883584., 3055616., ..., 2932736., 2834432.,
          2555904.],
         [2899968., 4227072., 4726784., ..., 4481024., 4046848.,
          2793472.],
         [3145728., 5021696., 5742592., ..., 5505024., 4808704.,
          2949120.],
         ...,
         [2801664., 3694592., 4079616., ..., 3047424., 3203072.,
          2711552.],
         [2646016., 3112960., 3317760., ..., 3072000., 3022848.,
          2572288.],
         [2457600., 2555904., 2637824., ..., 2744320., 2605056.,
          2449408.]],

        [[2646016., 2883584., 3055616., ..., 2932736., 2834432.,
          2555904.],
         [2899968., 4227072., 4726784., ..., 4481024., 4046848.,
          2793472.],
         [3145728., 5021696., 5742592., ..., 5505024., 4808704.,
          2949120.],
         ...,
         [2801664., 3694592., 4079616., ..., 3047424., 3203072.,
          2711552.],
         [2646016., 3112960., 3317760., ..., 3072000., 3022848.,
          2572288.],
         [2457600., 2555904., 2637824., ..., 2744320., 2605056.,
          2449408.]],

        ...,

        [[2646016., 2883584., 3055616., ..., 2932736., 2834432.,
          2555904.],
         [2899968., 4227072., 4726784., ..., 4481024., 4046848.,
          2793472.],
         [3145728., 5021696., 5742592., ..., 5505024., 4808704.,
          2949120.],
         ...,
         [2801664., 3694592., 4079616., ..., 3047424., 3203072.,
          2711552.],
         [2646016., 3112960., 3317760., ..., 3072000., 3022848.,
          2572288.],
         [2457600., 2555904., 2637824., ..., 2744320., 2605056.,
          2449408.]],

        [[2646016., 2883584., 3055616., ..., 2932736., 2834432.,
          2555904.],
         [2899968., 4227072., 4726784., ..., 4481024., 4046848.,
          2793472.],
         [3145728., 5021696., 5742592., ..., 5505024., 4808704.,
          2949120.],
         ...,
         [2801664., 3694592., 4079616., ..., 3047424., 3203072.,
          2711552.],
         [2646016., 3112960., 3317760., ..., 3072000., 3022848.,
          2572288.],
         [2457600., 2555904., 2637824., ..., 2744320., 2605056.,
          2449408.]],

        [[2646016., 2883584., 3055616., ..., 2932736., 2834432.,
          2555904.],
         [2899968., 4227072., 4726784., ..., 4481024., 4046848.,
          2793472.],
         [3145728., 5021696., 5742592., ..., 5505024., 4808704.,
          2949120.],
         ...,
         [2801664., 3694592., 4079616., ..., 3047424., 3203072.,
          2711552.],
         [2646016., 3112960., 3317760., ..., 3072000., 3022848.,
          2572288.],
         [2457600., 2555904., 2637824., ..., 2744320., 2605056.,
          2449408.]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [17], 'to': [32, 0]}
tf node:
{'name': 'sin', 'output': array([[[[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        ...,

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [15], 'to': [32]}
ms node:
{'name': 'sin', 'output': array([[[[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [15], 'to': [32]}
torch node:
{'name': 'sin', 'output': array([[[[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        ...,

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]],

        [[-0.1620187 , -0.79938537,  0.6345599 , ...,  0.41903886,
          -0.7556612 , -0.99936587],
         [ 0.9987396 ,  0.5693093 ,  0.23971915, ...,  0.6832334 ,
          -0.75778186, -0.69731563],
         [ 0.847086  , -0.99843854, -0.57263833, ..., -0.98055226,
           0.07197925,  0.16121836],
         ...,
         [-0.88952595, -0.47904116,  0.3228281 , ..., -0.5532007 ,
          -0.99869853, -0.56597096],
         [-0.1620187 , -0.1772042 , -0.5673074 , ..., -0.09299292,
           0.9537671 ,  0.8080706 ],
         [ 0.9254172 , -0.99936587, -0.99097925, ...,  0.55387616,
          -0.24522671,  0.6333055 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [15], 'to': [32]}

generate models:68

analyse output arrays in iter:2509

pre layer res:
0:transpose
{'name': 'transpose', 'output': array([[[[97920., 97152., 97152., ..., 97152., 97152., 97152.],
         [97920., 97152., 97152., ..., 97280., 97152., 97152.],
         [97920., 97536., 97536., ..., 97664., 97536., 97536.],
         ...,
         [97920., 97536., 97536., ..., 97024., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.]],

        [[97920., 97152., 97152., ..., 97152., 97152., 97152.],
         [97920., 97152., 97152., ..., 97280., 97152., 97152.],
         [97920., 97536., 97536., ..., 97664., 97536., 97536.],
         ...,
         [97920., 97536., 97536., ..., 97024., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.]],

        [[97920., 97152., 97152., ..., 97152., 97152., 97152.],
         [97920., 97152., 97152., ..., 97280., 97152., 97152.],
         [97920., 97536., 97536., ..., 97664., 97536., 97536.],
         ...,
         [97920., 97536., 97536., ..., 97024., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.]],

        ...,

        [[97920., 97152., 97152., ..., 97152., 97152., 97152.],
         [97920., 97152., 97152., ..., 97280., 97152., 97152.],
         [97920., 97536., 97536., ..., 97664., 97536., 97536.],
         ...,
         [97920., 97536., 97536., ..., 97024., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.]],

        [[97920., 97152., 97152., ..., 97152., 97152., 97152.],
         [97920., 97152., 97152., ..., 97280., 97152., 97152.],
         [97920., 97536., 97536., ..., 97664., 97536., 97536.],
         ...,
         [97920., 97536., 97536., ..., 97024., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.]],

        [[97920., 97152., 97152., ..., 97152., 97152., 97152.],
         [97920., 97152., 97152., ..., 97280., 97152., 97152.],
         [97920., 97536., 97536., ..., 97664., 97536., 97536.],
         ...,
         [97920., 97536., 97536., ..., 97024., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.],
         [97920., 97536., 97536., ..., 97152., 97536., 97536.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [17], 'to': [4]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        ...,

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [0], 'to': [15]}
ms node:
{'name': 'sin', 'output': array([[[[ 2.9687625e-01,  9.8348081e-01,  9.8348081e-01, ...,
           9.8348081e-01,  9.8348081e-01,  9.8348081e-01],
         [ 2.9687625e-01,  9.8348081e-01,  9.8348081e-01, ...,
          -5.5093282e-01,  9.8348081e-01,  9.8348081e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
          -9.6597266e-01,  8.5581070e-01,  8.5581070e-01],
         ...,
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
          -8.1196660e-01,  8.5581070e-01,  8.5581070e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
           9.8348081e-01,  8.5581070e-01,  8.5581070e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
           9.8348081e-01,  8.5581070e-01,  8.5581070e-01]],

        [[ 2.9687625e-01,  9.8348081e-01,  9.8348081e-01, ...,
           9.8348081e-01,  9.8348081e-01,  9.8348081e-01],
         [ 2.9687625e-01,  9.8348081e-01,  9.8348081e-01, ...,
          -5.5093282e-01,  9.8348081e-01,  9.8348081e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
          -9.6597266e-01,  8.5581070e-01,  8.5581070e-01],
         ...,
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
          -8.1196660e-01,  8.5581070e-01,  8.5581070e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
           9.8348081e-01,  8.5581070e-01,  8.5581070e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
           9.8348081e-01,  8.5581070e-01,  8.5581070e-01]],

        [[ 2.9687625e-01,  9.8348081e-01,  9.8348081e-01, ...,
           9.8348081e-01,  9.8348081e-01,  9.8348081e-01],
         [ 2.9687625e-01,  9.8348081e-01,  9.8348081e-01, ...,
          -5.5093282e-01,  9.8348081e-01,  9.8348081e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
          -9.6597266e-01,  8.5581070e-01,  8.5581070e-01],
         ...,
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
          -8.1196660e-01,  8.5581070e-01,  8.5581070e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
           9.8348081e-01,  8.5581070e-01,  8.5581070e-01],
         [ 2.9687625e-01,  8.5581070e-01,  8.5581070e-01, ...,
           9.8348081e-01,  8.5581070e-01,  8.5581070e-01]],

        ...,

        [[ 9.7920000e+04,  9.7920000e+04,  9.7920000e+04, ...,
           9.7920000e+04,  9.7920000e+04,  9.7920000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         ...,
         [ 9.7152000e+04,  9.7280000e+04,  9.7664000e+04, ...,
           9.7024000e+04,  9.7152000e+04,  9.7152000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04]],

        [[ 9.7920000e+04,  9.7920000e+04,  9.7920000e+04, ...,
           9.7920000e+04,  9.7920000e+04,  9.7920000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         ...,
         [ 9.7152000e+04,  9.7280000e+04,  9.7664000e+04, ...,
           9.7024000e+04,  9.7152000e+04,  9.7152000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04]],

        [[ 9.7920000e+04,  9.7920000e+04,  9.7920000e+04, ...,
           9.7920000e+04,  9.7920000e+04,  9.7920000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         ...,
         [ 9.7152000e+04,  9.7280000e+04,  9.7664000e+04, ...,
           9.7024000e+04,  9.7152000e+04,  9.7152000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04],
         [ 9.7152000e+04,  9.7152000e+04,  9.7536000e+04, ...,
           9.7536000e+04,  9.7536000e+04,  9.7536000e+04]]]],
      dtype=float32), 'output_shape': (1, 64, 32, 32), 'from': [0], 'to': [15]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        ...,

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]],

        [[ 0.29687625,  0.9834808 ,  0.9834808 , ...,  0.9834808 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.9834808 ,  0.9834808 , ..., -0.5509328 ,
           0.9834808 ,  0.9834808 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.96597266,
           0.8558107 ,  0.8558107 ],
         ...,
         [ 0.29687625,  0.8558107 ,  0.8558107 , ..., -0.8119666 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ],
         [ 0.29687625,  0.8558107 ,  0.8558107 , ...,  0.9834808 ,
           0.8558107 ,  0.8558107 ]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [0], 'to': [15]}

generate models:89

analyse output arrays in iter:4730

pre layer res:
6:exp
{'name': 'exp', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [2], 'to': [1]}
tf node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [6], 'to': [47]}
ms node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [6], 'to': [47]}
torch node:
{'name': 'cos', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [6], 'to': [47]}

generate models:99

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:2
mindspore --> nums:5,distinct_bugs:3
torch --> nums:2,distinct_bugs:2
tensorflow --> 
flatten:1
cos:1
mindspore --> 
sin:3
add:1
cos:1
torch --> 
flatten:1
cos:1

generate models:99

analyse output arrays in iter:9

pre layer res:
4:flatten
{'name': 'flatten', 'output': array([[4.7118926, 4.7118673, 4.7118754, ..., 3.141253 , 3.141255 ,
        3.1412559]], dtype=float32), 'output_shape': torch.Size([1, 3211264]), 'from': [0], 'to': [15]}
tf node:
{'name': 'sum', 'output': array([13175135.], dtype=float32), 'output_shape': torch.Size([1]), 'from': [4], 'to': [16]}
ms node:
{'name': 'sum', 'output': array([13150205.], dtype=float32), 'output_shape': (1,), 'from': [4], 'to': [16]}
torch node:
{'name': 'sum', 'output': array([13175135.], dtype=float32), 'output_shape': torch.Size([1]), 'from': [4], 'to': [16]}

generate models:10

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sum:1
torch --> 

generate models:10

analyse output arrays in iter:45

pre layer res:
2:cos
{'name': 'cos', 'output': array([[[[-0.99559104,  0.3819499 ,  0.03236564, ..., -0.8419109 ,
           0.7630044 ,  0.18670624],
         [-0.11631392,  0.98743653,  0.9394406 , ..., -0.74606556,
          -0.5639068 , -0.8070736 ],
         [ 0.87662435, -0.99698144,  0.04857211, ..., -0.5639068 ,
           0.8902971 , -0.74606556],
         ...,
         [ 0.99120444,  0.49244994, -0.5639068 , ...,  0.24372044,
          -0.92420924,  0.18032846],
         [-0.9986604 , -0.6966849 , -0.623898  , ...,  0.7587946 ,
           0.88732386,  0.9325926 ],
         [ 0.39986464, -0.95872766,  0.68976986, ..., -0.8989313 ,
          -0.571917  , -0.31828386]],

        [[-0.99559104,  0.3819499 ,  0.03236564, ..., -0.8419109 ,
           0.7630044 ,  0.18670624],
         [-0.11631392,  0.98743653,  0.9394406 , ..., -0.74606556,
          -0.5639068 , -0.8070736 ],
         [ 0.87662435, -0.99698144,  0.04857211, ..., -0.5639068 ,
           0.8902971 , -0.74606556],
         ...,
         [ 0.99120444,  0.49244994, -0.5639068 , ...,  0.24372044,
          -0.92420924,  0.18032846],
         [-0.9986604 , -0.6966849 , -0.623898  , ...,  0.7587946 ,
           0.88732386,  0.9325926 ],
         [ 0.39986464, -0.95872766,  0.68976986, ..., -0.8989313 ,
          -0.571917  , -0.31828386]],

        [[-0.99559104,  0.3819499 ,  0.03236564, ..., -0.8419109 ,
           0.7630044 ,  0.18670624],
         [-0.11631392,  0.98743653,  0.9394406 , ..., -0.74606556,
          -0.5639068 , -0.8070736 ],
         [ 0.87662435, -0.99698144,  0.04857211, ..., -0.5639068 ,
           0.8902971 , -0.74606556],
         ...,
         [ 0.99120444,  0.49244994, -0.5639068 , ...,  0.24372044,
          -0.92420924,  0.18032846],
         [-0.9986604 , -0.6966849 , -0.623898  , ...,  0.7587946 ,
           0.88732386,  0.9325926 ],
         [ 0.39986464, -0.95872766,  0.68976986, ..., -0.8989313 ,
          -0.571917  , -0.31828386]],

        ...,

        [[-0.99559104,  0.3819499 ,  0.03236564, ..., -0.8419109 ,
           0.7630044 ,  0.18670624],
         [-0.11631392,  0.98743653,  0.9394406 , ..., -0.74606556,
          -0.5639068 , -0.8070736 ],
         [ 0.87662435, -0.99698144,  0.04857211, ..., -0.5639068 ,
           0.8902971 , -0.74606556],
         ...,
         [ 0.99120444,  0.49244994, -0.5639068 , ...,  0.24372044,
          -0.92420924,  0.18032846],
         [-0.9986604 , -0.6966849 , -0.623898  , ...,  0.7587946 ,
           0.88732386,  0.9325926 ],
         [ 0.39986464, -0.95872766,  0.68976986, ..., -0.8989313 ,
          -0.571917  , -0.31828386]],

        [[-0.99559104,  0.3819499 ,  0.03236564, ..., -0.8419109 ,
           0.7630044 ,  0.18670624],
         [-0.11631392,  0.98743653,  0.9394406 , ..., -0.74606556,
          -0.5639068 , -0.8070736 ],
         [ 0.87662435, -0.99698144,  0.04857211, ..., -0.5639068 ,
           0.8902971 , -0.74606556],
         ...,
         [ 0.99120444,  0.49244994, -0.5639068 , ...,  0.24372044,
          -0.92420924,  0.18032846],
         [-0.9986604 , -0.6966849 , -0.623898  , ...,  0.7587946 ,
           0.88732386,  0.9325926 ],
         [ 0.39986464, -0.95872766,  0.68976986, ..., -0.8989313 ,
          -0.571917  , -0.31828386]],

        [[-0.99559104,  0.3819499 ,  0.03236564, ..., -0.8419109 ,
           0.7630044 ,  0.18670624],
         [-0.11631392,  0.98743653,  0.9394406 , ..., -0.74606556,
          -0.5639068 , -0.8070736 ],
         [ 0.87662435, -0.99698144,  0.04857211, ..., -0.5639068 ,
           0.8902971 , -0.74606556],
         ...,
         [ 0.99120444,  0.49244994, -0.5639068 , ...,  0.24372044,
          -0.92420924,  0.18032846],
         [-0.9986604 , -0.6966849 , -0.623898  , ...,  0.7587946 ,
           0.88732386,  0.9325926 ],
         [ 0.39986464, -0.95872766,  0.68976986, ..., -0.8989313 ,
          -0.571917  , -0.31828386]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [3], 'to': [1, 5]}
tf node:
{'name': 'log', 'output': array([[[[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [2], 'to': [0]}
ms node:
{'name': 'log', 'output': array([[[[        nan, -0.962468  , -3.4306545 , ...,         nan,
          -0.2704937 , -1.6782188 ],
         [        nan, -0.01264449, -0.06247066, ...,         nan,
                  nan,         nan],
         [-0.1316777 ,         nan, -3.024708  , ...,         nan,
          -0.11620102,         nan],
         ...,
         [-0.00883596, -0.7083639 ,         nan, ..., -1.4117348 ,
                  nan, -1.7129754 ],
         [        nan,         nan,         nan, ..., -0.27602637,
          -0.11954623, -0.06978684],
         [-0.9166316 ,         nan, -0.37139443, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.962468  , -3.4306545 , ...,         nan,
          -0.2704937 , -1.6782188 ],
         [        nan, -0.01264449, -0.06247066, ...,         nan,
                  nan,         nan],
         [-0.1316777 ,         nan, -3.024708  , ...,         nan,
          -0.11620102,         nan],
         ...,
         [-0.00883596, -0.7083639 ,         nan, ..., -1.4117348 ,
                  nan, -1.7129754 ],
         [        nan,         nan,         nan, ..., -0.27602637,
          -0.11954623, -0.06978684],
         [-0.9166316 ,         nan, -0.37139443, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.962468  , -3.4306545 , ...,         nan,
          -0.2704937 , -1.6782188 ],
         [        nan, -0.01264449, -0.06247066, ...,         nan,
                  nan,         nan],
         [-0.1316777 ,         nan, -3.024708  , ...,         nan,
          -0.11620102,         nan],
         ...,
         [-0.00883596, -0.7083639 ,         nan, ..., -1.4117348 ,
                  nan, -1.7129754 ],
         [        nan,         nan,         nan, ..., -0.27602637,
          -0.11954623, -0.06978684],
         [-0.9166316 ,         nan, -0.37139443, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan, -0.962468  , -3.4306545 , ...,         nan,
          -0.2704937 , -1.6782188 ],
         [        nan, -0.01264449, -0.06247066, ...,         nan,
                  nan,         nan],
         [-0.1316777 ,         nan, -3.024708  , ...,         nan,
          -0.11620102,         nan],
         ...,
         [-0.00883596, -0.7083639 ,         nan, ..., -1.4117348 ,
                  nan, -1.7129754 ],
         [        nan,         nan,         nan, ..., -0.27602637,
          -0.11954623, -0.06978684],
         [-0.9166316 ,         nan, -0.37139443, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.962468  , -3.4306545 , ...,         nan,
          -0.2704937 , -1.6782188 ],
         [        nan, -0.01264449, -0.06247066, ...,         nan,
                  nan,         nan],
         [-0.1316777 ,         nan, -3.024708  , ...,         nan,
          -0.11620102,         nan],
         ...,
         [-0.00883596, -0.7083639 ,         nan, ..., -1.4117348 ,
                  nan, -1.7129754 ],
         [        nan,         nan,         nan, ..., -0.27602637,
          -0.11954623, -0.06978684],
         [-0.9166316 ,         nan, -0.37139443, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.962468  , -3.4306545 , ...,         nan,
          -0.2704937 , -1.6782188 ],
         [        nan, -0.01264449, -0.06247066, ...,         nan,
                  nan,         nan],
         [-0.1316777 ,         nan, -3.024708  , ...,         nan,
          -0.11620102,         nan],
         ...,
         [-0.00883596, -0.7083639 ,         nan, ..., -1.4117348 ,
                  nan, -1.7129754 ],
         [        nan,         nan,         nan, ..., -0.27602637,
          -0.11954623, -0.06978684],
         [-0.9166316 ,         nan, -0.37139443, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [2], 'to': [0]}
torch node:
{'name': 'log', 'output': array([[[[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        ...,

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]],

        [[        nan, -0.9624658 , -3.4306579 , ...,         nan,
          -0.27049145, -1.6782188 ],
         [        nan, -0.01264306, -0.06247068, ...,         nan,
                  nan,         nan],
         [-0.13167672,         nan, -3.024706  , ...,         nan,
          -0.11620004,         nan],
         ...,
         [-0.00883447, -0.70836246,         nan, ..., -1.4117334 ,
                  nan, -1.7129753 ],
         [        nan,         nan,         nan, ..., -0.27602416,
          -0.11954525, -0.06978686],
         [-0.9166292 ,         nan, -0.37139726, ...,         nan,
                  nan,         nan]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [2], 'to': [0]}

generate models:36

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:2,distinct_bugs:2
torch --> nums:1,distinct_bugs:1
tensorflow --> 
log:1
mindspore --> 
sum:1
log:1
torch --> 
log:1

generate models:38

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:2,distinct_bugs:2
torch --> nums:1,distinct_bugs:1
tensorflow --> 
log:1
mindspore --> 
sum:1
log:1
torch --> 
log:1

generate models:55

analyse output arrays in iter:166

pre layer res:
31:add
{'name': 'add', 'output': array([[[[ 501758.06,  602111.4 ,  628737.94, ..., 1560574.1 ,
          1566718.6 , 1554430.  ],
         [ 552961.7 ,  757758.56,  884736.7 , ..., 1556478.  ,
          1564670.5 , 1536000.  ],
         [ 849920.2 ,  987134.06,  888832.06, ..., 1445889.2 ,
          1533952.2 , 1550334.1 ],
         ...,
         [ 886784.4 ,  823294.2 ,  749566.  , ...,  139265.97,
           147457.78,  241664.12],
         [ 774144.94,  921598.9 , 1140734.8 , ...,  135169.77,
           147457.78,  239616.44],
         [ 356350.9 ,  589822.06,  915454.25, ...,  126976.86,
           149505.62,  225281.95]],

        [[ 501758.06,  602111.4 ,  628737.94, ..., 1560574.1 ,
          1566718.6 , 1554430.  ],
         [ 552961.7 ,  757758.56,  884736.7 , ..., 1556478.  ,
          1564670.5 , 1536000.  ],
         [ 849920.2 ,  987134.06,  888832.06, ..., 1445889.2 ,
          1533952.2 , 1550334.1 ],
         ...,
         [ 886784.4 ,  823294.2 ,  749566.  , ...,  139265.97,
           147457.78,  241664.12],
         [ 774144.94,  921598.9 , 1140734.8 , ...,  135169.77,
           147457.78,  239616.44],
         [ 356350.9 ,  589822.06,  915454.25, ...,  126976.86,
           149505.62,  225281.95]],

        [[ 501758.06,  602111.4 ,  628737.94, ..., 1560574.1 ,
          1566718.6 , 1554430.  ],
         [ 552961.7 ,  757758.56,  884736.7 , ..., 1556478.  ,
          1564670.5 , 1536000.  ],
         [ 849920.2 ,  987134.06,  888832.06, ..., 1445889.2 ,
          1533952.2 , 1550334.1 ],
         ...,
         [ 886784.4 ,  823294.2 ,  749566.  , ...,  139265.97,
           147457.78,  241664.12],
         [ 774144.94,  921598.9 , 1140734.8 , ...,  135169.77,
           147457.78,  239616.44],
         [ 356350.9 ,  589822.06,  915454.25, ...,  126976.86,
           149505.62,  225281.95]],

        ...,

        [[ 501758.06,  602111.4 ,  628737.94, ..., 1560574.1 ,
          1566718.6 , 1554430.  ],
         [ 552961.7 ,  757758.56,  884736.7 , ..., 1556478.  ,
          1564670.5 , 1536000.  ],
         [ 849920.2 ,  987134.06,  888832.06, ..., 1445889.2 ,
          1533952.2 , 1550334.1 ],
         ...,
         [ 886784.4 ,  823294.2 ,  749566.  , ...,  139265.97,
           147457.78,  241664.12],
         [ 774144.94,  921598.9 , 1140734.8 , ...,  135169.77,
           147457.78,  239616.44],
         [ 356350.9 ,  589822.06,  915454.25, ...,  126976.86,
           149505.62,  225281.95]],

        [[ 501758.06,  602111.4 ,  628737.94, ..., 1560574.1 ,
          1566718.6 , 1554430.  ],
         [ 552961.7 ,  757758.56,  884736.7 , ..., 1556478.  ,
          1564670.5 , 1536000.  ],
         [ 849920.2 ,  987134.06,  888832.06, ..., 1445889.2 ,
          1533952.2 , 1550334.1 ],
         ...,
         [ 886784.4 ,  823294.2 ,  749566.  , ...,  139265.97,
           147457.78,  241664.12],
         [ 774144.94,  921598.9 , 1140734.8 , ...,  135169.77,
           147457.78,  239616.44],
         [ 356350.9 ,  589822.06,  915454.25, ...,  126976.86,
           149505.62,  225281.95]],

        [[ 501758.06,  602111.4 ,  628737.94, ..., 1560574.1 ,
          1566718.6 , 1554430.  ],
         [ 552961.7 ,  757758.56,  884736.7 , ..., 1556478.  ,
          1564670.5 , 1536000.  ],
         [ 849920.2 ,  987134.06,  888832.06, ..., 1445889.2 ,
          1533952.2 , 1550334.1 ],
         ...,
         [ 886784.4 ,  823294.2 ,  749566.  , ...,  139265.97,
           147457.78,  241664.12],
         [ 774144.94,  921598.9 , 1140734.8 , ...,  135169.77,
           147457.78,  239616.44],
         [ 356350.9 ,  589822.06,  915454.25, ...,  126976.86,
           149505.62,  225281.95]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [30, 30], 'to': [32, 0]}
tf node:
{'name': 'square', 'output': array([[[[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        ...,

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [31], 'to': [32, 2]}
ms node:
{'name': 'square', 'output': array([[[[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        ...,

        [[2.5225506e+11, 3.6324730e+11, 3.9608143e+11, ...,
          2.4401564e+12, 2.4594080e+12, 2.4209803e+12],
         [3.0636225e+11, 5.7532226e+11, 7.8428733e+11, ...,
          2.4273640e+12, 2.4529823e+12, 2.3639063e+12],
         [7.2377559e+11, 9.7634163e+11, 7.9156609e+11, ...,
          2.0946772e+12, 2.3576067e+12, 2.4082385e+12],
         ...,
         [7.8792255e+11, 6.7914079e+11, 5.6295011e+11, ...,
          1.9432360e+10, 2.1785760e+10, 5.8515612e+10],
         [6.0047000e+11, 8.5100626e+11, 1.3038214e+12, ...,
          1.8306091e+10, 2.1785760e+10, 5.7528021e+10],
         [1.2723489e+11, 3.4857216e+11, 8.3969730e+11, ...,
          1.6154410e+10, 2.2395122e+10, 5.0850251e+10]],

        [[2.5225506e+11, 3.6324730e+11, 3.9608143e+11, ...,
          2.4401564e+12, 2.4594080e+12, 2.4209803e+12],
         [3.0636225e+11, 5.7532226e+11, 7.8428733e+11, ...,
          2.4273640e+12, 2.4529823e+12, 2.3639063e+12],
         [7.2377559e+11, 9.7634163e+11, 7.9156609e+11, ...,
          2.0946772e+12, 2.3576067e+12, 2.4082385e+12],
         ...,
         [7.8792255e+11, 6.7914079e+11, 5.6295011e+11, ...,
          1.9432360e+10, 2.1785760e+10, 5.8515612e+10],
         [6.0047000e+11, 8.5100626e+11, 1.3038214e+12, ...,
          1.8306091e+10, 2.1785760e+10, 5.7528021e+10],
         [1.2723489e+11, 3.4857216e+11, 8.3969730e+11, ...,
          1.6154410e+10, 2.2395122e+10, 5.0850251e+10]],

        [[2.5225506e+11, 3.6324730e+11, 3.9608143e+11, ...,
          2.4401564e+12, 2.4594080e+12, 2.4209803e+12],
         [3.0636225e+11, 5.7532226e+11, 7.8428733e+11, ...,
          2.4273640e+12, 2.4529823e+12, 2.3639063e+12],
         [7.2377559e+11, 9.7634163e+11, 7.9156609e+11, ...,
          2.0946772e+12, 2.3576067e+12, 2.4082385e+12],
         ...,
         [7.8792255e+11, 6.7914079e+11, 5.6295011e+11, ...,
          1.9432360e+10, 2.1785760e+10, 5.8515612e+10],
         [6.0047000e+11, 8.5100626e+11, 1.3038214e+12, ...,
          1.8306091e+10, 2.1785760e+10, 5.7528021e+10],
         [1.2723489e+11, 3.4857216e+11, 8.3969730e+11, ...,
          1.6154410e+10, 2.2395122e+10, 5.0850251e+10]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [31], 'to': [32, 2]}
torch node:
{'name': 'square', 'output': array([[[[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        ...,

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]],

        [[2.5176115e+11, 3.6253811e+11, 3.9531138e+11, ...,
          2.4353917e+12, 2.4546074e+12, 2.4162526e+12],
         [3.0576663e+11, 5.7419805e+11, 7.8275903e+11, ...,
          2.4226237e+12, 2.4481937e+12, 2.3592960e+12],
         [7.2236433e+11, 9.7443368e+11, 7.9002246e+11, ...,
          2.0905958e+12, 2.3530095e+12, 2.4035359e+12],
         ...,
         [7.8638652e+11, 6.7781329e+11, 5.6184917e+11, ...,
          1.9395011e+10, 2.1743798e+10, 5.8401550e+10],
         [5.9930037e+11, 8.4934446e+11, 1.3012757e+12, ...,
          1.8270865e+10, 2.1743798e+10, 5.7416036e+10],
         [1.2698597e+11, 3.4789006e+11, 8.3805648e+11, ...,
          1.6123123e+10, 2.2351931e+10, 5.0751959e+10]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [31], 'to': [32, 2]}

pre layer res:
15:conv2d
{'name': 'conv2d', 'output': array([[[[250880., 301056., 314368., ..., 780288., 783360., 777216.],
         [276480., 378880., 442368., ..., 778240., 782336., 768000.],
         [424960., 493568., 444416., ..., 722944., 766976., 775168.],
         ...,
         [443392., 411648., 374784., ...,  69632.,  73728., 120832.],
         [387072., 460800., 570368., ...,  67584.,  73728., 119808.],
         [178176., 294912., 457728., ...,  63488.,  74752., 112640.]],

        [[250880., 301056., 314368., ..., 780288., 783360., 777216.],
         [276480., 378880., 442368., ..., 778240., 782336., 768000.],
         [424960., 493568., 444416., ..., 722944., 766976., 775168.],
         ...,
         [443392., 411648., 374784., ...,  69632.,  73728., 120832.],
         [387072., 460800., 570368., ...,  67584.,  73728., 119808.],
         [178176., 294912., 457728., ...,  63488.,  74752., 112640.]],

        [[250880., 301056., 314368., ..., 780288., 783360., 777216.],
         [276480., 378880., 442368., ..., 778240., 782336., 768000.],
         [424960., 493568., 444416., ..., 722944., 766976., 775168.],
         ...,
         [443392., 411648., 374784., ...,  69632.,  73728., 120832.],
         [387072., 460800., 570368., ...,  67584.,  73728., 119808.],
         [178176., 294912., 457728., ...,  63488.,  74752., 112640.]],

        ...,

        [[250880., 301056., 314368., ..., 780288., 783360., 777216.],
         [276480., 378880., 442368., ..., 778240., 782336., 768000.],
         [424960., 493568., 444416., ..., 722944., 766976., 775168.],
         ...,
         [443392., 411648., 374784., ...,  69632.,  73728., 120832.],
         [387072., 460800., 570368., ...,  67584.,  73728., 119808.],
         [178176., 294912., 457728., ...,  63488.,  74752., 112640.]],

        [[250880., 301056., 314368., ..., 780288., 783360., 777216.],
         [276480., 378880., 442368., ..., 778240., 782336., 768000.],
         [424960., 493568., 444416., ..., 722944., 766976., 775168.],
         ...,
         [443392., 411648., 374784., ...,  69632.,  73728., 120832.],
         [387072., 460800., 570368., ...,  67584.,  73728., 119808.],
         [178176., 294912., 457728., ...,  63488.,  74752., 112640.]],

        [[250880., 301056., 314368., ..., 780288., 783360., 777216.],
         [276480., 378880., 442368., ..., 778240., 782336., 768000.],
         [424960., 493568., 444416., ..., 722944., 766976., 775168.],
         ...,
         [443392., 411648., 374784., ...,  69632.,  73728., 120832.],
         [387072., 460800., 570368., ...,  67584.,  73728., 119808.],
         [178176., 294912., 457728., ...,  63488.,  74752., 112640.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [36], 'to': [30, 7, 9]}
tf node:
{'name': 'sin', 'output': array([[[[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        ...,

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [15], 'to': [30]}
ms node:
{'name': 'sin', 'output': array([[[[-9.6517992e-01, -3.1228667e-01,  9.8361546e-01, ...,
          -9.3485481e-01, -6.6704452e-01, -9.9343276e-01],
         [ 8.3980733e-01, -7.0638961e-01,  3.3202356e-01, ...,
          -9.9900842e-01, -7.7671903e-01, -2.3279766e-02],
         [ 9.6507996e-02, -9.7316796e-01,  2.0036539e-02, ...,
           6.4311254e-01,  1.3550505e-01, -9.0767789e-01],
         ...,
         [ 1.7828470e-01, -9.2019767e-01, -9.8883200e-01, ...,
           9.8564738e-01,  8.9283705e-01,  6.3315250e-02],
         [ 4.6996942e-01, -5.7642704e-01, -6.5382588e-01, ...,
           8.8325375e-01,  8.9283705e-01,  2.2072984e-01],
         [-5.4186261e-01, -9.5593536e-01, -8.8753378e-01, ...,
           4.3130291e-01,  8.1014562e-01,  9.7279346e-01]],

        [[-9.6517992e-01, -3.1228667e-01,  9.8361546e-01, ...,
          -9.3485481e-01, -6.6704452e-01, -9.9343276e-01],
         [ 8.3980733e-01, -7.0638961e-01,  3.3202356e-01, ...,
          -9.9900842e-01, -7.7671903e-01, -2.3279766e-02],
         [ 9.6507996e-02, -9.7316796e-01,  2.0036539e-02, ...,
           6.4311254e-01,  1.3550505e-01, -9.0767789e-01],
         ...,
         [ 1.7828470e-01, -9.2019767e-01, -9.8883200e-01, ...,
           9.8564738e-01,  8.9283705e-01,  6.3315250e-02],
         [ 4.6996942e-01, -5.7642704e-01, -6.5382588e-01, ...,
           8.8325375e-01,  8.9283705e-01,  2.2072984e-01],
         [-5.4186261e-01, -9.5593536e-01, -8.8753378e-01, ...,
           4.3130291e-01,  8.1014562e-01,  9.7279346e-01]],

        [[-9.6517992e-01, -3.1228667e-01,  9.8361546e-01, ...,
          -9.3485481e-01, -6.6704452e-01, -9.9343276e-01],
         [ 8.3980733e-01, -7.0638961e-01,  3.3202356e-01, ...,
          -9.9900842e-01, -7.7671903e-01, -2.3279766e-02],
         [ 9.6507996e-02, -9.7316796e-01,  2.0036539e-02, ...,
           6.4311254e-01,  1.3550505e-01, -9.0767789e-01],
         ...,
         [ 1.7828470e-01, -9.2019767e-01, -9.8883200e-01, ...,
           9.8564738e-01,  8.9283705e-01,  6.3315250e-02],
         [ 4.6996942e-01, -5.7642704e-01, -6.5382588e-01, ...,
           8.8325375e-01,  8.9283705e-01,  2.2072984e-01],
         [-5.4186261e-01, -9.5593536e-01, -8.8753378e-01, ...,
           4.3130291e-01,  8.1014562e-01,  9.7279346e-01]],

        ...,

        [[ 2.4500000e+02,  2.9400000e+02,  3.0700000e+02, ...,
           7.6200000e+02,  7.6500000e+02,  7.5900000e+02],
         [ 2.7000000e+02,  3.7000000e+02,  4.3200000e+02, ...,
           7.6000000e+02,  7.6400000e+02,  7.5000000e+02],
         [ 4.1500000e+02,  4.8200000e+02,  4.3400000e+02, ...,
           7.0600000e+02,  7.4900000e+02,  7.5700000e+02],
         ...,
         [ 4.3300000e+02,  4.0200000e+02,  3.6600000e+02, ...,
           6.8000000e+01,  7.2000000e+01,  1.1800000e+02],
         [ 3.7800000e+02,  4.5000000e+02,  5.5700000e+02, ...,
           6.6000000e+01,  7.2000000e+01,  1.1700000e+02],
         [ 1.7400000e+02,  2.8800000e+02,  4.4700000e+02, ...,
           6.2000000e+01,  7.3000000e+01,  1.1000000e+02]],

        [[ 2.4500000e+02,  2.9400000e+02,  3.0700000e+02, ...,
           7.6200000e+02,  7.6500000e+02,  7.5900000e+02],
         [ 2.7000000e+02,  3.7000000e+02,  4.3200000e+02, ...,
           7.6000000e+02,  7.6400000e+02,  7.5000000e+02],
         [ 4.1500000e+02,  4.8200000e+02,  4.3400000e+02, ...,
           7.0600000e+02,  7.4900000e+02,  7.5700000e+02],
         ...,
         [ 4.3300000e+02,  4.0200000e+02,  3.6600000e+02, ...,
           6.8000000e+01,  7.2000000e+01,  1.1800000e+02],
         [ 3.7800000e+02,  4.5000000e+02,  5.5700000e+02, ...,
           6.6000000e+01,  7.2000000e+01,  1.1700000e+02],
         [ 1.7400000e+02,  2.8800000e+02,  4.4700000e+02, ...,
           6.2000000e+01,  7.3000000e+01,  1.1000000e+02]],

        [[ 2.4500000e+02,  2.9400000e+02,  3.0700000e+02, ...,
           7.6200000e+02,  7.6500000e+02,  7.5900000e+02],
         [ 2.7000000e+02,  3.7000000e+02,  4.3200000e+02, ...,
           7.6000000e+02,  7.6400000e+02,  7.5000000e+02],
         [ 4.1500000e+02,  4.8200000e+02,  4.3400000e+02, ...,
           7.0600000e+02,  7.4900000e+02,  7.5700000e+02],
         ...,
         [ 4.3300000e+02,  4.0200000e+02,  3.6600000e+02, ...,
           6.8000000e+01,  7.2000000e+01,  1.1800000e+02],
         [ 3.7800000e+02,  4.5000000e+02,  5.5700000e+02, ...,
           6.6000000e+01,  7.2000000e+01,  1.1700000e+02],
         [ 1.7400000e+02,  2.8800000e+02,  4.4700000e+02, ...,
           6.2000000e+01,  7.3000000e+01,  1.1000000e+02]]]],
      dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [15], 'to': [30]}
torch node:
{'name': 'sin', 'output': array([[[[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        ...,

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]],

        [[-0.9651799 , -0.31228667,  0.98361546, ..., -0.9348548 ,
          -0.6670445 , -0.99343276],
         [ 0.83980733, -0.7063896 ,  0.33202356, ..., -0.9990084 ,
          -0.77671903, -0.02327977],
         [ 0.096508  , -0.97316796,  0.02003654, ...,  0.64311254,
           0.13550505, -0.9076779 ],
         ...,
         [ 0.1782847 , -0.92019767, -0.988832  , ...,  0.9856474 ,
           0.89283705,  0.06331525],
         [ 0.46996942, -0.57642704, -0.6538259 , ...,  0.88325375,
           0.89283705,  0.22072984],
         [-0.5418626 , -0.95593536, -0.88753384, ...,  0.4313029 ,
           0.8101456 ,  0.97279346]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [15], 'to': [30]}

generate models:63

analyse output arrays in iter:170

pre layer res:
5:conv2d
{'name': 'conv2d', 'output': array([[[[4.53223481e+11, 4.57281438e+11, 4.52288283e+11, ...,
          4.05002289e+11, 4.07458447e+11, 4.02763317e+11],
         [4.31476146e+11, 4.37951365e+11, 4.30540915e+11, ...,
          4.00169304e+11, 3.97793362e+11, 3.90681100e+11],
         [4.19396289e+11, 4.28286116e+11, 4.28124897e+11, ...,
          3.88088168e+11, 3.92960147e+11, 3.89875761e+11],
         ...,
         [1.41519569e+11, 1.41550911e+11, 1.37362498e+11, ...,
          2.14113386e+11, 2.18181075e+11, 2.11873776e+11],
         [1.34270755e+11, 1.35912718e+11, 1.33335532e+11, ...,
          1.99615103e+11, 2.02071818e+11, 1.92543572e+11],
         [1.34270755e+11, 1.35912718e+11, 1.35751475e+11, ...,
          1.82701490e+11, 1.94823307e+11, 1.94960163e+11]],

        [[4.53223481e+11, 4.57281438e+11, 4.52288283e+11, ...,
          4.05002289e+11, 4.07458447e+11, 4.02763317e+11],
         [4.31476146e+11, 4.37951365e+11, 4.30540915e+11, ...,
          4.00169304e+11, 3.97793362e+11, 3.90681100e+11],
         [4.19396289e+11, 4.28286116e+11, 4.28124897e+11, ...,
          3.88088168e+11, 3.92960147e+11, 3.89875761e+11],
         ...,
         [1.41519569e+11, 1.41550911e+11, 1.37362498e+11, ...,
          2.14113386e+11, 2.18181075e+11, 2.11873776e+11],
         [1.34270755e+11, 1.35912718e+11, 1.33335532e+11, ...,
          1.99615103e+11, 2.02071818e+11, 1.92543572e+11],
         [1.34270755e+11, 1.35912718e+11, 1.35751475e+11, ...,
          1.82701490e+11, 1.94823307e+11, 1.94960163e+11]],

        [[4.53223481e+11, 4.57281438e+11, 4.52288283e+11, ...,
          4.05002289e+11, 4.07458447e+11, 4.02763317e+11],
         [4.31476146e+11, 4.37951365e+11, 4.30540915e+11, ...,
          4.00169304e+11, 3.97793362e+11, 3.90681100e+11],
         [4.19396289e+11, 4.28286116e+11, 4.28124897e+11, ...,
          3.88088168e+11, 3.92960147e+11, 3.89875761e+11],
         ...,
         [1.41519569e+11, 1.41550911e+11, 1.37362498e+11, ...,
          2.14113386e+11, 2.18181075e+11, 2.11873776e+11],
         [1.34270755e+11, 1.35912718e+11, 1.33335532e+11, ...,
          1.99615103e+11, 2.02071818e+11, 1.92543572e+11],
         [1.34270755e+11, 1.35912718e+11, 1.35751475e+11, ...,
          1.82701490e+11, 1.94823307e+11, 1.94960163e+11]],

        ...,

        [[4.53223481e+11, 4.57281438e+11, 4.52288283e+11, ...,
          4.05002289e+11, 4.07458447e+11, 4.02763317e+11],
         [4.31476146e+11, 4.37951365e+11, 4.30540915e+11, ...,
          4.00169304e+11, 3.97793362e+11, 3.90681100e+11],
         [4.19396289e+11, 4.28286116e+11, 4.28124897e+11, ...,
          3.88088168e+11, 3.92960147e+11, 3.89875761e+11],
         ...,
         [1.41519569e+11, 1.41550911e+11, 1.37362498e+11, ...,
          2.14113386e+11, 2.18181075e+11, 2.11873776e+11],
         [1.34270755e+11, 1.35912718e+11, 1.33335532e+11, ...,
          1.99615103e+11, 2.02071818e+11, 1.92543572e+11],
         [1.34270755e+11, 1.35912718e+11, 1.35751475e+11, ...,
          1.82701490e+11, 1.94823307e+11, 1.94960163e+11]],

        [[4.53223481e+11, 4.57281438e+11, 4.52288283e+11, ...,
          4.05002289e+11, 4.07458447e+11, 4.02763317e+11],
         [4.31476146e+11, 4.37951365e+11, 4.30540915e+11, ...,
          4.00169304e+11, 3.97793362e+11, 3.90681100e+11],
         [4.19396289e+11, 4.28286116e+11, 4.28124897e+11, ...,
          3.88088168e+11, 3.92960147e+11, 3.89875761e+11],
         ...,
         [1.41519569e+11, 1.41550911e+11, 1.37362498e+11, ...,
          2.14113386e+11, 2.18181075e+11, 2.11873776e+11],
         [1.34270755e+11, 1.35912718e+11, 1.33335532e+11, ...,
          1.99615103e+11, 2.02071818e+11, 1.92543572e+11],
         [1.34270755e+11, 1.35912718e+11, 1.35751475e+11, ...,
          1.82701490e+11, 1.94823307e+11, 1.94960163e+11]],

        [[4.53223481e+11, 4.57281438e+11, 4.52288283e+11, ...,
          4.05002289e+11, 4.07458447e+11, 4.02763317e+11],
         [4.31476146e+11, 4.37951365e+11, 4.30540915e+11, ...,
          4.00169304e+11, 3.97793362e+11, 3.90681100e+11],
         [4.19396289e+11, 4.28286116e+11, 4.28124897e+11, ...,
          3.88088168e+11, 3.92960147e+11, 3.89875761e+11],
         ...,
         [1.41519569e+11, 1.41550911e+11, 1.37362498e+11, ...,
          2.14113386e+11, 2.18181075e+11, 2.11873776e+11],
         [1.34270755e+11, 1.35912718e+11, 1.33335532e+11, ...,
          1.99615103e+11, 2.02071818e+11, 1.92543572e+11],
         [1.34270755e+11, 1.35912718e+11, 1.35751475e+11, ...,
          1.82701490e+11, 1.94823307e+11, 1.94960163e+11]]]],
      dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [27], 'to': [4]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        ...,

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [5], 'to': [1]}
ms node:
{'name': 'sin', 'output': array([[[[-0.68292093, -0.95565486,  0.7321576 , ...,  0.9091429 ,
           0.40843713,  0.56034786],
         [-0.50399005,  0.10172976,  0.8649374 , ...,  0.27244005,
           0.9394796 , -0.9628318 ],
         [-0.79780686, -0.9997891 , -0.89958036, ..., -0.59536785,
           0.9309534 , -0.6979302 ],
         ...,
         [ 0.20242569,  0.1343435 ,  0.36458296, ...,  0.8594022 ,
           0.38430247,  0.2833252 ],
         [ 0.95214653,  0.99112946, -0.99987364, ...,  0.9710523 ,
          -0.1476174 ,  0.87419313],
         [ 0.95214653,  0.99112946,  0.7590811 , ..., -0.9951045 ,
          -0.9632957 ,  0.6677704 ]],

        [[-0.68292093, -0.95565486,  0.7321576 , ...,  0.9091429 ,
           0.40843713,  0.56034786],
         [-0.50399005,  0.10172976,  0.8649374 , ...,  0.27244005,
           0.9394796 , -0.9628318 ],
         [-0.79780686, -0.9997891 , -0.89958036, ..., -0.59536785,
           0.9309534 , -0.6979302 ],
         ...,
         [ 0.20242569,  0.1343435 ,  0.36458296, ...,  0.8594022 ,
           0.38430247,  0.2833252 ],
         [ 0.95214653,  0.99112946, -0.99987364, ...,  0.9710523 ,
          -0.1476174 ,  0.87419313],
         [ 0.95214653,  0.99112946,  0.7590811 , ..., -0.9951045 ,
          -0.9632957 ,  0.6677704 ]],

        [[-0.68292093, -0.95565486,  0.7321576 , ...,  0.9091429 ,
           0.40843713,  0.56034786],
         [-0.50399005,  0.10172976,  0.8649374 , ...,  0.27244005,
           0.9394796 , -0.9628318 ],
         [-0.79780686, -0.9997891 , -0.89958036, ..., -0.59536785,
           0.9309534 , -0.6979302 ],
         ...,
         [ 0.20242569,  0.1343435 ,  0.36458296, ...,  0.8594022 ,
           0.38430247,  0.2833252 ],
         [ 0.95214653,  0.99112946, -0.99987364, ...,  0.9710523 ,
          -0.1476174 ,  0.87419313],
         [ 0.95214653,  0.99112946,  0.7590811 , ..., -0.9951045 ,
          -0.9632957 ,  0.6677704 ]],

        ...,

        [[-0.68292093, -0.95565486,  0.7321576 , ...,  0.9091429 ,
           0.40843713,  0.56034786],
         [-0.50399005,  0.10172976,  0.8649374 , ...,  0.27244005,
           0.9394796 , -0.9628318 ],
         [-0.79780686, -0.9997891 , -0.89958036, ..., -0.59536785,
           0.9309534 , -0.6979302 ],
         ...,
         [ 0.20242569,  0.1343435 ,  0.36458296, ...,  0.8594022 ,
           0.38430247,  0.2833252 ],
         [ 0.95214653,  0.99112946, -0.99987364, ...,  0.9710523 ,
          -0.1476174 ,  0.87419313],
         [ 0.95214653,  0.99112946,  0.7590811 , ..., -0.9951045 ,
          -0.9632957 ,  0.6677704 ]],

        [[-0.7585896 ,  0.7496937 ,  0.46303308, ...,  0.99599713,
          -0.89478606,  0.2519897 ],
         [-0.23394594,  0.84282476, -0.9716755 , ...,  0.9943613 ,
          -0.4410441 ,  0.19168748],
         [ 0.99314004, -0.9997891 , -0.89958036, ..., -0.4499355 ,
          -0.95836544, -0.4797118 ],
         ...,
         [ 0.20242569,  0.1343435 , -0.78361005, ..., -0.5727222 ,
           0.19853151, -0.771739  ],
         [ 0.95214653,  0.1631291 , -0.99987364, ..., -0.86625093,
          -0.1476174 ,  0.77941823],
         [ 0.95214653,  0.1631291 ,  0.8447253 , ..., -0.9951045 ,
          -0.27677113,  0.77181464]],

        [[-0.7585896 ,  0.7496937 ,  0.46303308, ...,  0.99599713,
          -0.89478606,  0.2519897 ],
         [-0.23394594,  0.84282476, -0.9716755 , ...,  0.9943613 ,
          -0.4410441 ,  0.19168748],
         [ 0.99314004, -0.9997891 , -0.89958036, ..., -0.4499355 ,
          -0.95836544, -0.4797118 ],
         ...,
         [ 0.20242569,  0.1343435 , -0.78361005, ..., -0.5727222 ,
           0.19853151, -0.771739  ],
         [ 0.95214653,  0.1631291 , -0.99987364, ..., -0.86625093,
          -0.1476174 ,  0.77941823],
         [ 0.95214653,  0.1631291 ,  0.8447253 , ..., -0.9951045 ,
          -0.27677113,  0.77181464]]]], dtype=float32), 'output_shape': (1, 64, 32, 32), 'from': [5], 'to': [1]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        ...,

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]],

        [[ 0.9759269 ,  0.08182491,  0.8227978 , ...,  0.44781974,
          -0.6236167 ,  0.6297783 ],
         [ 0.81486064, -0.93315023, -0.5816447 , ...,  0.42986307,
          -0.97062016,  0.50528073],
         [ 0.4788746 , -0.39191446, -0.89958036, ..., -0.12950234,
          -0.99888384,  0.34427908],
         ...,
         [ 0.20242569,  0.1343435 ,  0.9456913 , ..., -0.10116641,
           0.36302876, -0.8778711 ],
         [-0.79517907,  0.9927923 ,  0.9370265 , ...,  0.4365094 ,
           0.23027994,  0.985331  ],
         [-0.79517907,  0.9927923 ,  0.57161266, ..., -0.9951045 ,
          -0.46381113,  0.86747456]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [5], 'to': [1]}

generate models:66

analyse output arrays in iter:175

pre layer res:
36:conv2d
{'name': 'conv2d', 'output': array([[[[249., 222., 206., ...,  68.,  86.,  77.],
         [184., 238., 238., ...,  90., 119., 125.],
         [ 99., 183., 203., ...,  71.,  98., 122.],
         ...,
         [622., 637., 627., ..., 600., 591., 581.],
         [603., 618., 610., ..., 565., 570., 571.],
         [547., 582., 569., ..., 567., 551., 552.]],

        [[249., 222., 206., ...,  68.,  86.,  77.],
         [184., 238., 238., ...,  90., 119., 125.],
         [ 99., 183., 203., ...,  71.,  98., 122.],
         ...,
         [622., 637., 627., ..., 600., 591., 581.],
         [603., 618., 610., ..., 565., 570., 571.],
         [547., 582., 569., ..., 567., 551., 552.]],

        [[249., 222., 206., ...,  68.,  86.,  77.],
         [184., 238., 238., ...,  90., 119., 125.],
         [ 99., 183., 203., ...,  71.,  98., 122.],
         ...,
         [622., 637., 627., ..., 600., 591., 581.],
         [603., 618., 610., ..., 565., 570., 571.],
         [547., 582., 569., ..., 567., 551., 552.]],

        ...,

        [[249., 222., 206., ...,  68.,  86.,  77.],
         [184., 238., 238., ...,  90., 119., 125.],
         [ 99., 183., 203., ...,  71.,  98., 122.],
         ...,
         [622., 637., 627., ..., 600., 591., 581.],
         [603., 618., 610., ..., 565., 570., 571.],
         [547., 582., 569., ..., 567., 551., 552.]],

        [[249., 222., 206., ...,  68.,  86.,  77.],
         [184., 238., 238., ...,  90., 119., 125.],
         [ 99., 183., 203., ...,  71.,  98., 122.],
         ...,
         [622., 637., 627., ..., 600., 591., 581.],
         [603., 618., 610., ..., 565., 570., 571.],
         [547., 582., 569., ..., 567., 551., 552.]],

        [[249., 222., 206., ...,  68.,  86.,  77.],
         [184., 238., 238., ...,  90., 119., 125.],
         [ 99., 183., 203., ...,  71.,  98., 122.],
         ...,
         [622., 637., 627., ..., 600., 591., 581.],
         [603., 618., 610., ..., 565., 570., 571.],
         [547., 582., 569., ..., 567., 551., 552.]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [], 'to': [11]}
tf node:
{'name': 'sin', 'output': array([[[[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        ...,

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [36], 'to': [15]}
ms node:
{'name': 'sin', 'output': array([[[[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.9333097 , ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960369 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.9333097 , ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960369 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.9333097 , ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960369 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        ...,

        [[        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         ...,
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf]],

        [[        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         ...,
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf]],

        [[        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         ...,
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf],
         [        inf,         inf,         inf, ...,         inf,
                  inf,         inf]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [36], 'to': [15]}
torch node:
{'name': 'sin', 'output': array([[[[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        ...,

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]],

        [[-0.7271632 ,  0.86895084, -0.9746419 , ..., -0.8979277 ,
          -0.92345846,  0.9995202 ],
         [ 0.9765844 , -0.6896761 , -0.6896761 , ...,  0.89399666,
          -0.3714041 , -0.61604047],
         [-0.99920684,  0.7086804 ,  0.93330973, ...,  0.95105463,
          -0.5733819 ,  0.49871317],
         ...,
         [-0.03533805,  0.6767276 , -0.9683494 , ...,  0.04418245,
           0.37146008,  0.19341424],
         [-0.1847225 ,  0.7794283 ,  0.50641763, ..., -0.46769187,
          -0.9802516 , -0.6960368 ],
         [ 0.35496655, -0.72107947, -0.36322755, ...,  0.99834883,
          -0.9395404 , -0.7957876 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [36], 'to': [15]}

generate models:69

analyse output arrays in iter:274

pre layer res:
0:softmax
{'name': 'softmax', 'output': array([[[[0. , 0. , 0.5, ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         ...,
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ]],

        [[0. , 0. , 0.5, ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         ...,
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ]],

        [[0. , 0. , 0.5, ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         ...,
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ]],

        ...,

        [[0. , 0. , 0.5, ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         ...,
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ]],

        [[0. , 0. , 0.5, ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         ...,
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ]],

        [[0. , 0. , 0.5, ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         ...,
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ],
         [0. , 0. , 0. , ..., 0. , 0. , 0. ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [31], 'to': [10, 11]}
tf node:
{'name': 'sin', 'output': array([[[[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        ...,

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [0], 'to': [32]}
ms node:
{'name': 'sin', 'output': array([[[[0.0000000e+00, 0.0000000e+00, 4.7942555e-01, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 4.7942555e-01, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 4.7942555e-01, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        ...,

        [[1.5298560e+06, 1.5257600e+06, 1.5380480e+06, ...,
          7.4956800e+05, 5.2838400e+05, 5.4886400e+05],
         [1.5503360e+06, 1.5503360e+06, 1.5544320e+06, ...,
          4.2188800e+05, 3.4201600e+05, 2.9491200e+05],
         [1.5298560e+06, 1.5298560e+06, 1.5237120e+06, ...,
          4.7718400e+05, 3.6454400e+05, 2.9081600e+05],
         ...,
         [3.1129600e+05, 3.2563200e+05, 3.3382400e+05, ...,
          3.9116800e+05, 3.9116800e+05, 3.6864000e+05],
         [3.3177600e+05, 3.4201600e+05, 3.3792000e+05, ...,
          3.7068800e+05, 3.7273600e+05, 3.4611200e+05],
         [3.4201600e+05, 3.5020800e+05, 3.5020800e+05, ...,
          3.4406400e+05, 3.2153600e+05, 2.9286400e+05]],

        [[1.5298560e+06, 1.5257600e+06, 1.5380480e+06, ...,
          7.4956800e+05, 5.2838400e+05, 5.4886400e+05],
         [1.5503360e+06, 1.5503360e+06, 1.5544320e+06, ...,
          4.2188800e+05, 3.4201600e+05, 2.9491200e+05],
         [1.5298560e+06, 1.5298560e+06, 1.5237120e+06, ...,
          4.7718400e+05, 3.6454400e+05, 2.9081600e+05],
         ...,
         [3.1129600e+05, 3.2563200e+05, 3.3382400e+05, ...,
          3.9116800e+05, 3.9116800e+05, 3.6864000e+05],
         [3.3177600e+05, 3.4201600e+05, 3.3792000e+05, ...,
          3.7068800e+05, 3.7273600e+05, 3.4611200e+05],
         [3.4201600e+05, 3.5020800e+05, 3.5020800e+05, ...,
          3.4406400e+05, 3.2153600e+05, 2.9286400e+05]],

        [[1.5298560e+06, 1.5257600e+06, 1.5380480e+06, ...,
          7.4956800e+05, 5.2838400e+05, 5.4886400e+05],
         [1.5503360e+06, 1.5503360e+06, 1.5544320e+06, ...,
          4.2188800e+05, 3.4201600e+05, 2.9491200e+05],
         [1.5298560e+06, 1.5298560e+06, 1.5237120e+06, ...,
          4.7718400e+05, 3.6454400e+05, 2.9081600e+05],
         ...,
         [3.1129600e+05, 3.2563200e+05, 3.3382400e+05, ...,
          3.9116800e+05, 3.9116800e+05, 3.6864000e+05],
         [3.3177600e+05, 3.4201600e+05, 3.3792000e+05, ...,
          3.7068800e+05, 3.7273600e+05, 3.4611200e+05],
         [3.4201600e+05, 3.5020800e+05, 3.5020800e+05, ...,
          3.4406400e+05, 3.2153600e+05, 2.9286400e+05]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [0], 'to': [32]}
torch node:
{'name': 'sin', 'output': array([[[[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        ...,

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.47942555, ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [0], 'to': [32]}

generate models:78

analyse output arrays in iter:346

pre layer res:
9:add
{'name': 'add', 'output': array([[7.571812e+11, 7.571812e+11, 7.571812e+11, ..., 0.000000e+00,
        7.795207e-01, 0.000000e+00]], dtype=float32), 'output_shape': torch.Size([1, 2048]), 'from': [6, 12], 'to': [14]}
tf node:
{'name': 'log', 'output': array([[27.352869  , 27.352869  , 27.352869  , ...,        -inf,
        -0.24907605,        -inf]], dtype=float32), 'output_shape': torch.Size([1, 2048]), 'from': [9], 'to': [7]}
ms node:
{'name': 'log', 'output': array([[27.35287   , 27.35287   , 27.35287   , ...,        -inf,
        -0.24907827,        -inf]], dtype=float32), 'output_shape': (1, 2048), 'from': [9], 'to': [7]}
torch node:
{'name': 'log', 'output': array([[27.352869  , 27.352869  , 27.352869  , ...,        -inf,
        -0.24907605,        -inf]], dtype=float32), 'output_shape': torch.Size([1, 2048]), 'from': [9], 'to': [7]}

generate models:88

analyse output arrays in iter:423

pre layer res:
10:conv2d
{'name': 'conv2d', 'output': array([[[[ 32747.496  , -20071.998  , -30424.502  , ...,   1014.00183,
            2463.044  , -21854.248  ],
         [ 20752.598  ,  13107.624  ,  23726.518  , ...,  10125.124  ,
          -11494.001  ,  -5340.8755 ],
         [-26509.684  ,  32148.691  ,  28401.748  , ...,  31694.564  ,
           28962.441  ,  -5340.8755 ],
         ...,
         [-20753.352  , -25080.484  ,  -9848.874  , ...,  10125.124  ,
           30314.814  ,   7896.702  ],
         [ 28107.998  , -31619.748  , -30203.514  , ...,  -9848.874  ,
           14681.618  ,  18906.4    ],
         [ 20528.098  ,  -8177.876  , -18668.752  , ..., -32762.938  ,
           26847.002  ,  10675.207  ]],

        [[ 32747.496  , -20071.998  , -30424.502  , ...,   1014.00183,
            2463.044  , -21854.248  ],
         [ 20752.598  ,  13107.624  ,  23726.518  , ...,  10125.124  ,
          -11494.001  ,  -5340.8755 ],
         [-26509.684  ,  32148.691  ,  28401.748  , ...,  31694.564  ,
           28962.441  ,  -5340.8755 ],
         ...,
         [-20753.352  , -25080.484  ,  -9848.874  , ...,  10125.124  ,
           30314.814  ,   7896.702  ],
         [ 28107.998  , -31619.748  , -30203.514  , ...,  -9848.874  ,
           14681.618  ,  18906.4    ],
         [ 20528.098  ,  -8177.876  , -18668.752  , ..., -32762.938  ,
           26847.002  ,  10675.207  ]],

        [[ 32747.496  , -20071.998  , -30424.502  , ...,   1014.00183,
            2463.044  , -21854.248  ],
         [ 20752.598  ,  13107.624  ,  23726.518  , ...,  10125.124  ,
          -11494.001  ,  -5340.8755 ],
         [-26509.684  ,  32148.691  ,  28401.748  , ...,  31694.564  ,
           28962.441  ,  -5340.8755 ],
         ...,
         [-20753.352  , -25080.484  ,  -9848.874  , ...,  10125.124  ,
           30314.814  ,   7896.702  ],
         [ 28107.998  , -31619.748  , -30203.514  , ...,  -9848.874  ,
           14681.618  ,  18906.4    ],
         [ 20528.098  ,  -8177.876  , -18668.752  , ..., -32762.938  ,
           26847.002  ,  10675.207  ]],

        ...,

        [[ 32747.496  , -20071.998  , -30424.502  , ...,   1014.00183,
            2463.044  , -21854.248  ],
         [ 20752.598  ,  13107.624  ,  23726.518  , ...,  10125.124  ,
          -11494.001  ,  -5340.8755 ],
         [-26509.684  ,  32148.691  ,  28401.748  , ...,  31694.564  ,
           28962.441  ,  -5340.8755 ],
         ...,
         [-20753.352  , -25080.484  ,  -9848.874  , ...,  10125.124  ,
           30314.814  ,   7896.702  ],
         [ 28107.998  , -31619.748  , -30203.514  , ...,  -9848.874  ,
           14681.618  ,  18906.4    ],
         [ 20528.098  ,  -8177.876  , -18668.752  , ..., -32762.938  ,
           26847.002  ,  10675.207  ]],

        [[ 32747.496  , -20071.998  , -30424.502  , ...,   1014.00183,
            2463.044  , -21854.248  ],
         [ 20752.598  ,  13107.624  ,  23726.518  , ...,  10125.124  ,
          -11494.001  ,  -5340.8755 ],
         [-26509.684  ,  32148.691  ,  28401.748  , ...,  31694.564  ,
           28962.441  ,  -5340.8755 ],
         ...,
         [-20753.352  , -25080.484  ,  -9848.874  , ...,  10125.124  ,
           30314.814  ,   7896.702  ],
         [ 28107.998  , -31619.748  , -30203.514  , ...,  -9848.874  ,
           14681.618  ,  18906.4    ],
         [ 20528.098  ,  -8177.876  , -18668.752  , ..., -32762.938  ,
           26847.002  ,  10675.207  ]],

        [[ 32747.496  , -20071.998  , -30424.502  , ...,   1014.00183,
            2463.044  , -21854.248  ],
         [ 20752.598  ,  13107.624  ,  23726.518  , ...,  10125.124  ,
          -11494.001  ,  -5340.8755 ],
         [-26509.684  ,  32148.691  ,  28401.748  , ...,  31694.564  ,
           28962.441  ,  -5340.8755 ],
         ...,
         [-20753.352  , -25080.484  ,  -9848.874  , ...,  10125.124  ,
           30314.814  ,   7896.702  ],
         [ 28107.998  , -31619.748  , -30203.514  , ...,  -9848.874  ,
           14681.618  ,  18906.4    ],
         [ 20528.098  ,  -8177.876  , -18668.752  , ..., -32762.938  ,
           26847.002  ,  10675.207  ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [9], 'to': [2]}
tf node:
{'name': 'log', 'output': array([[[[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        ...,

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [10], 'to': [44]}
ms node:
{'name': 'log', 'output': array([[[[10.396581 ,        nan,        nan, ...,  6.9216576,
           7.809151 ,        nan],
         [ 9.940428 ,  9.480944 , 10.074348 , ...,  9.222774 ,
                 nan,        nan],
         [       nan, 10.378123 , 10.254202 , ..., 10.3639   ,
          10.273755 ,        nan],
         ...,
         [       nan,        nan,        nan, ...,  9.222774 ,
          10.319394 ,  8.974203 ],
         [10.243806 ,        nan,        nan, ...,        nan,
           9.594347 ,  9.847255 ],
         [ 9.929551 ,        nan,        nan, ...,        nan,
          10.197907 ,  9.275684 ]],

        [[10.396581 ,        nan,        nan, ...,  6.9216576,
           7.809151 ,        nan],
         [ 9.940428 ,  9.480944 , 10.074348 , ...,  9.222774 ,
                 nan,        nan],
         [       nan, 10.378123 , 10.254202 , ..., 10.3639   ,
          10.273755 ,        nan],
         ...,
         [       nan,        nan,        nan, ...,  9.222774 ,
          10.319394 ,  8.974203 ],
         [10.243806 ,        nan,        nan, ...,        nan,
           9.594347 ,  9.847255 ],
         [ 9.929551 ,        nan,        nan, ...,        nan,
          10.197907 ,  9.275684 ]],

        [[10.396581 ,        nan,        nan, ...,  6.9216576,
           7.809151 ,        nan],
         [ 9.940428 ,  9.480944 , 10.074348 , ...,  9.222774 ,
                 nan,        nan],
         [       nan, 10.378123 , 10.254202 , ..., 10.3639   ,
          10.273755 ,        nan],
         ...,
         [       nan,        nan,        nan, ...,  9.222774 ,
          10.319394 ,  8.974203 ],
         [10.243806 ,        nan,        nan, ...,        nan,
           9.594347 ,  9.847255 ],
         [ 9.929551 ,        nan,        nan, ...,        nan,
          10.197907 ,  9.275684 ]],

        ...,

        [[10.396581 ,        nan,        nan, ...,  6.9216576,
           7.809151 ,        nan],
         [ 9.940428 ,  9.480944 , 10.074348 , ...,  9.222774 ,
                 nan,        nan],
         [       nan, 10.378123 , 10.254202 , ..., 10.3639   ,
          10.273755 ,        nan],
         ...,
         [       nan,        nan,        nan, ...,  9.222774 ,
          10.319394 ,  8.974203 ],
         [10.243806 ,        nan,        nan, ...,        nan,
           9.594347 ,  9.847255 ],
         [ 9.929551 ,        nan,        nan, ...,        nan,
          10.197907 ,  9.275684 ]],

        [[10.396581 ,        nan,        nan, ...,  6.9216576,
           7.809151 ,        nan],
         [ 9.940428 ,  9.480944 , 10.074348 , ...,  9.222774 ,
                 nan,        nan],
         [       nan, 10.378123 , 10.254202 , ..., 10.3639   ,
          10.273755 ,        nan],
         ...,
         [       nan,        nan,        nan, ...,  9.222774 ,
          10.319394 ,  8.974203 ],
         [10.243806 ,        nan,        nan, ...,        nan,
           9.594347 ,  9.847255 ],
         [ 9.929551 ,        nan,        nan, ...,        nan,
          10.197907 ,  9.275684 ]],

        [[10.396581 ,        nan,        nan, ...,  6.9216576,
           7.809151 ,        nan],
         [ 9.940428 ,  9.480944 , 10.074348 , ...,  9.222774 ,
                 nan,        nan],
         [       nan, 10.378123 , 10.254202 , ..., 10.3639   ,
          10.273755 ,        nan],
         ...,
         [       nan,        nan,        nan, ...,  9.222774 ,
          10.319394 ,  8.974203 ],
         [10.243806 ,        nan,        nan, ...,        nan,
           9.594347 ,  9.847255 ],
         [ 9.929551 ,        nan,        nan, ...,        nan,
          10.197907 ,  9.275684 ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [10], 'to': [44]}
torch node:
{'name': 'log', 'output': array([[[[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        ...,

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]],

        [[10.396582,       nan,       nan, ...,  6.92166 ,  7.809153,
                nan],
         [ 9.940427,  9.480949, 10.074348, ...,  9.222775,       nan,
                nan],
         [      nan, 10.378127, 10.254206, ..., 10.3639  , 10.273755,
                nan],
         ...,
         [      nan,       nan,       nan, ...,  9.222775, 10.319392,
           8.9742  ],
         [10.24381 ,       nan,       nan, ...,       nan,  9.594352,
           9.847256],
         [ 9.92955 ,       nan,       nan, ...,       nan, 10.197909,
           9.27568 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [10], 'to': [44]}

generate models:96

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:9,distinct_bugs:4
torch --> nums:2,distinct_bugs:1
tensorflow --> 
log:2
mindspore --> 
sum:1
log:3
square:1
sin:4
torch --> 
log:2

generate models:100

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:10

analyse output arrays in iter:15

pre layer res:
8:reshape
{'name': 'reshape', 'output': array([[[[499., 497., 498., ..., 491., 487., 491.],
         [503., 499., 498., ..., 493., 490., 494.],
         [514., 508., 508., ..., 500., 500., 505.],
         ...,
         [520., 496., 514., ..., 346., 352., 350.],
         [504., 541., 563., ..., 349., 347., 352.],
         [511., 510., 500., ..., 402., 472., 549.]],

        [[499., 497., 498., ..., 491., 487., 491.],
         [503., 499., 498., ..., 493., 490., 494.],
         [514., 508., 508., ..., 500., 500., 505.],
         ...,
         [520., 496., 514., ..., 346., 352., 350.],
         [504., 541., 563., ..., 349., 347., 352.],
         [511., 510., 500., ..., 402., 472., 549.]],

        [[499., 497., 498., ..., 491., 487., 491.],
         [503., 499., 498., ..., 493., 490., 494.],
         [514., 508., 508., ..., 500., 500., 505.],
         ...,
         [520., 496., 514., ..., 346., 352., 350.],
         [504., 541., 563., ..., 349., 347., 352.],
         [511., 510., 500., ..., 402., 472., 549.]],

        ...,

        [[499., 497., 498., ..., 491., 487., 491.],
         [503., 499., 498., ..., 493., 490., 494.],
         [514., 508., 508., ..., 500., 500., 505.],
         ...,
         [520., 496., 514., ..., 346., 352., 350.],
         [504., 541., 563., ..., 349., 347., 352.],
         [511., 510., 500., ..., 402., 472., 549.]],

        [[499., 497., 498., ..., 491., 487., 491.],
         [503., 499., 498., ..., 493., 490., 494.],
         [514., 508., 508., ..., 500., 500., 505.],
         ...,
         [520., 496., 514., ..., 346., 352., 350.],
         [504., 541., 563., ..., 349., 347., 352.],
         [511., 510., 500., ..., 402., 472., 549.]],

        [[499., 497., 498., ..., 491., 487., 491.],
         [503., 499., 498., ..., 493., 490., 494.],
         [514., 508., 508., ..., 500., 500., 505.],
         ...,
         [520., 496., 514., ..., 346., 352., 350.],
         [504., 541., 563., ..., 349., 347., 352.],
         [511., 510., 500., ..., 402., 472., 549.]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [7], 'to': [4, 11]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        ...,

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [8], 'to': [14]}
ms node:
{'name': 'sin', 'output': array([[[[ 4.9099535e-01,  5.8781940e-01,  9.9834365e-01, ...,
           7.9045165e-01, -5.3113688e-02,  7.9045165e-01],
         [ 3.3836177e-01,  4.9099535e-01,  9.9834365e-01, ...,
           2.2802290e-01, -8.8338658e-02, -6.9610178e-01],
         [-9.3950939e-01, -8.0638278e-01, -8.0638278e-01, ...,
          -4.6777180e-01, -4.6777180e-01,  7.1485537e-01],
         ...,
         [-9.9779528e-01, -3.6314327e-01, -9.3950939e-01, ...,
           4.1214594e-01,  1.4114985e-01, -9.5893282e-01],
         [ 9.7465539e-01,  6.0204798e-01, -6.0909182e-01, ...,
          -2.7944446e-01,  9.8936266e-01,  1.4114985e-01],
         [ 8.8177037e-01,  8.7332666e-01, -4.6777180e-01, ...,
          -1.2354321e-01,  6.8971980e-01,  7.0236486e-01]],

        [[ 4.9099535e-01,  5.8781940e-01,  9.9834365e-01, ...,
           7.9045165e-01, -5.3113688e-02,  7.9045165e-01],
         [ 3.3836177e-01,  4.9099535e-01,  9.9834365e-01, ...,
           2.2802290e-01, -8.8338658e-02, -6.9610178e-01],
         [-9.3950939e-01, -8.0638278e-01, -8.0638278e-01, ...,
          -4.6777180e-01, -4.6777180e-01,  7.1485537e-01],
         ...,
         [-9.9779528e-01, -3.6314327e-01, -9.3950939e-01, ...,
           4.1214594e-01,  1.4114985e-01, -9.5893282e-01],
         [ 9.7465539e-01,  6.0204798e-01, -6.0909182e-01, ...,
          -2.7944446e-01,  9.8936266e-01,  1.4114985e-01],
         [ 8.8177037e-01,  8.7332666e-01, -4.6777180e-01, ...,
          -1.2354321e-01,  6.8971980e-01,  7.0236486e-01]],

        [[ 4.9099535e-01,  5.8781940e-01,  9.9834365e-01, ...,
           7.9045165e-01, -5.3113688e-02,  7.9045165e-01],
         [ 3.3836177e-01,  4.9099535e-01,  9.9834365e-01, ...,
           2.2802290e-01, -8.8338658e-02, -6.9610178e-01],
         [-9.3950939e-01, -8.0638278e-01, -8.0638278e-01, ...,
          -4.6777180e-01, -4.6777180e-01,  7.1485537e-01],
         ...,
         [-9.9779528e-01, -3.6314327e-01, -9.3950939e-01, ...,
           4.1214594e-01,  1.4114985e-01, -9.5893282e-01],
         [ 9.7465539e-01,  6.0204798e-01, -6.0909182e-01, ...,
          -2.7944446e-01,  9.8936266e-01,  1.4114985e-01],
         [ 8.8177037e-01,  8.7332666e-01, -4.6777180e-01, ...,
          -1.2354321e-01,  6.8971980e-01,  7.0236486e-01]],

        ...,

        [[ 4.9900000e+02,  4.9700000e+02,  4.9800000e+02, ...,
           4.9100000e+02,  4.8700000e+02,  4.9100000e+02],
         [ 5.0300000e+02,  4.9900000e+02,  4.9800000e+02, ...,
           4.9300000e+02,  4.9000000e+02,  4.9400000e+02],
         [ 5.1400000e+02,  5.0800000e+02,  5.0800000e+02, ...,
           5.0000000e+02,  5.0000000e+02,  5.0500000e+02],
         ...,
         [ 5.2000000e+02,  4.9600000e+02,  5.1400000e+02, ...,
           3.4600000e+02,  3.5200000e+02,  3.5000000e+02],
         [ 5.0400000e+02,  5.4100000e+02,  5.6300000e+02, ...,
           3.4900000e+02,  3.4700000e+02,  3.5200000e+02],
         [ 5.1100000e+02,  5.1000000e+02,  5.0000000e+02, ...,
           4.0200000e+02,  4.7200000e+02,  5.4900000e+02]],

        [[ 4.9900000e+02,  4.9700000e+02,  4.9800000e+02, ...,
           4.9100000e+02,  4.8700000e+02,  4.9100000e+02],
         [ 5.0300000e+02,  4.9900000e+02,  4.9800000e+02, ...,
           4.9300000e+02,  4.9000000e+02,  4.9400000e+02],
         [ 5.1400000e+02,  5.0800000e+02,  5.0800000e+02, ...,
           5.0000000e+02,  5.0000000e+02,  5.0500000e+02],
         ...,
         [ 5.2000000e+02,  4.9600000e+02,  5.1400000e+02, ...,
           3.4600000e+02,  3.5200000e+02,  3.5000000e+02],
         [ 5.0400000e+02,  5.4100000e+02,  5.6300000e+02, ...,
           3.4900000e+02,  3.4700000e+02,  3.5200000e+02],
         [ 5.1100000e+02,  5.1000000e+02,  5.0000000e+02, ...,
           4.0200000e+02,  4.7200000e+02,  5.4900000e+02]],

        [[ 4.9900000e+02,  4.9700000e+02,  4.9800000e+02, ...,
           4.9100000e+02,  4.8700000e+02,  4.9100000e+02],
         [ 5.0300000e+02,  4.9900000e+02,  4.9800000e+02, ...,
           4.9300000e+02,  4.9000000e+02,  4.9400000e+02],
         [ 5.1400000e+02,  5.0800000e+02,  5.0800000e+02, ...,
           5.0000000e+02,  5.0000000e+02,  5.0500000e+02],
         ...,
         [ 5.2000000e+02,  4.9600000e+02,  5.1400000e+02, ...,
           3.4600000e+02,  3.5200000e+02,  3.5000000e+02],
         [ 5.0400000e+02,  5.4100000e+02,  5.6300000e+02, ...,
           3.4900000e+02,  3.4700000e+02,  3.5200000e+02],
         [ 5.1100000e+02,  5.1000000e+02,  5.0000000e+02, ...,
           4.0200000e+02,  4.7200000e+02,  5.4900000e+02]]]],
      dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [8], 'to': [14]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        ...,

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]],

        [[ 0.49099535,  0.5878194 ,  0.99834365, ...,  0.79045165,
          -0.05311369,  0.79045165],
         [ 0.33836177,  0.49099535,  0.99834365, ...,  0.2280229 ,
          -0.08833866, -0.6961018 ],
         [-0.9395094 , -0.8063828 , -0.8063828 , ..., -0.4677718 ,
          -0.4677718 ,  0.7148554 ],
         ...,
         [-0.9977953 , -0.3631433 , -0.9395094 , ...,  0.41214594,
           0.14114985, -0.9589328 ],
         [ 0.9746554 ,  0.602048  , -0.6090918 , ..., -0.27944446,
           0.98936266,  0.14114985],
         [ 0.8817704 ,  0.87332666, -0.4677718 , ..., -0.12354321,
           0.6897198 ,  0.70236486]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [8], 'to': [14]}

generate models:14

analyse output arrays in iter:39

pre layer res:
4:add
{'name': 'add', 'output': array([[[[4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         ...,
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376]],

        [[4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         ...,
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376]],

        [[4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         ...,
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376]],

        ...,

        [[4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         ...,
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376]],

        [[4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         ...,
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376]],

        [[4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         ...,
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376],
         [4.4898376, 4.4898376, 4.4898376, ..., 4.4898376, 4.4898376,
          4.4898376]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10, 10], 'to': [26]}
tf node:
{'name': 'sin', 'output': array([[[[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        ...,

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [4], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        ...,

        [[ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         ...,
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188]],

        [[ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         ...,
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188]],

        [[ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         ...,
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188],
         [ 2.2449188,  2.2449188,  2.2449188, ...,  2.2449188,
           2.2449188,  2.2449188]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [4], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        ...,

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]],

        [[-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         ...,
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375],
         [-0.9753375, -0.9753375, -0.9753375, ..., -0.9753375,
          -0.9753375, -0.9753375]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [4], 'to': []}

generate models:27

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:2,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
torch --> 

generate models:30

analyse output arrays in iter:55

pre layer res:
9:add
{'name': 'add', 'output': array([[[[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        ...,

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]],

        [[inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         ...,
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf],
         [inf, inf, inf, ..., inf, inf, inf]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [4, 15], 'to': [10, 17]}
tf node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [9], 'to': [10]}
ms node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [9], 'to': [10]}
torch node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [9], 'to': [10]}

generate models:32

analyse output arrays in iter:57

pre layer res:
2:exp
{'name': 'exp', 'output': array([[[[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf, 4.6071865e+28, 1.4093490e+22],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 7.4984170e+33, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf, 4.6071865e+28, 1.4093490e+22],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 7.4984170e+33, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf, 4.6071865e+28, 1.4093490e+22],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 7.4984170e+33, ...,
                    inf,           inf,           inf]],

        ...,

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf, 4.6071865e+28, 1.4093490e+22],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 7.4984170e+33, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf, 4.6071865e+28, 1.4093490e+22],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 7.4984170e+33, ...,
                    inf,           inf,           inf]],

        [[          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         ...,
         [          inf,           inf,           inf, ...,
                    inf, 4.6071865e+28, 1.4093490e+22],
         [          inf,           inf,           inf, ...,
                    inf,           inf,           inf],
         [          inf,           inf, 7.4984170e+33, ...,
                    inf,           inf,           inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [0], 'to': [4]}
tf node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [2], 'to': [8]}
ms node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan,  0.,  0.],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan,  0., ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan,  0.,  0.],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan,  0., ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan,  0.,  0.],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan,  0., ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan,  0.,  0.],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan,  0., ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan,  0.,  0.],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan,  0., ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan,  0.,  0.],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan,  0., ..., nan, nan, nan]]]], dtype=float32), 'output_shape': (1, 512, 32, 32), 'from': [2], 'to': [8]}
torch node:
{'name': 'softmax', 'output': array([[[[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        ...,

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]],

        [[nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         ...,
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan],
         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 32, 32]), 'from': [2], 'to': [8]}

generate models:34

analyse output arrays in iter:62

pre layer res:
3:add
{'name': 'add', 'output': array([[[[104340., 102638., 102120., ..., 102342.,  93832.,  93758.],
         [107300., 103156.,  98938., ..., 101602.,  94498.,  96866.],
         [ 97014.,  90650.,  87024., ..., 102268.,  96644.,  99826.],
         ...,
         [ 82008.,  80064.,  79848., ..., 102528., 101736., 100584.],
         [ 76320.,  73872.,  73008., ...,  90504.,  83448.,  82944.],
         [ 95256.,  92664.,  92088., ..., 104328.,  96912.,  96984.]],

        [[104340., 102638., 102120., ..., 102342.,  93832.,  93758.],
         [107300., 103156.,  98938., ..., 101602.,  94498.,  96866.],
         [ 97014.,  90650.,  87024., ..., 102268.,  96644.,  99826.],
         ...,
         [ 82008.,  80064.,  79848., ..., 102528., 101736., 100584.],
         [ 76320.,  73872.,  73008., ...,  90504.,  83448.,  82944.],
         [ 95256.,  92664.,  92088., ..., 104328.,  96912.,  96984.]],

        [[104340., 102638., 102120., ..., 102342.,  93832.,  93758.],
         [107300., 103156.,  98938., ..., 101602.,  94498.,  96866.],
         [ 97014.,  90650.,  87024., ..., 102268.,  96644.,  99826.],
         ...,
         [ 82008.,  80064.,  79848., ..., 102528., 101736., 100584.],
         [ 76320.,  73872.,  73008., ...,  90504.,  83448.,  82944.],
         [ 95256.,  92664.,  92088., ..., 104328.,  96912.,  96984.]],

        ...,

        [[104340., 102638., 102120., ..., 102342.,  93832.,  93758.],
         [107300., 103156.,  98938., ..., 101602.,  94498.,  96866.],
         [ 97014.,  90650.,  87024., ..., 102268.,  96644.,  99826.],
         ...,
         [ 82008.,  80064.,  79848., ..., 102528., 101736., 100584.],
         [ 76320.,  73872.,  73008., ...,  90504.,  83448.,  82944.],
         [ 95256.,  92664.,  92088., ..., 104328.,  96912.,  96984.]],

        [[104340., 102638., 102120., ..., 102342.,  93832.,  93758.],
         [107300., 103156.,  98938., ..., 101602.,  94498.,  96866.],
         [ 97014.,  90650.,  87024., ..., 102268.,  96644.,  99826.],
         ...,
         [ 82008.,  80064.,  79848., ..., 102528., 101736., 100584.],
         [ 76320.,  73872.,  73008., ...,  90504.,  83448.,  82944.],
         [ 95256.,  92664.,  92088., ..., 104328.,  96912.,  96984.]],

        [[104340., 102638., 102120., ..., 102342.,  93832.,  93758.],
         [107300., 103156.,  98938., ..., 101602.,  94498.,  96866.],
         [ 97014.,  90650.,  87024., ..., 102268.,  96644.,  99826.],
         ...,
         [ 82008.,  80064.,  79848., ..., 102528., 101736., 100584.],
         [ 76320.,  73872.,  73008., ...,  90504.,  83448.,  82944.],
         [ 95256.,  92664.,  92088., ..., 104328.,  96912.,  96984.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [1, 1], 'to': [6, 5]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        ...,

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [3], 'to': [6]}
ms node:
{'name': 'sin', 'output': array([[[[ 9.8935986e-01,  8.2690728e-01, -5.7352102e-01, ...,
           9.9567121e-01, -8.8633883e-01,  3.0395970e-01],
         [ 8.8988060e-01, -9.7264850e-01,  1.7650986e-01, ...,
           2.4547508e-01, -8.9436960e-01, -9.5619404e-01],
         [ 9.9884528e-01,  6.0996729e-01,  9.5150667e-01, ...,
           2.6253876e-01,  7.2759002e-01, -9.4840294e-01],
         ...,
         [-1.3422298e-01, -4.8924449e-01,  9.5833534e-01, ...,
          -8.5097688e-01, -9.7267652e-01,  3.6347002e-01],
         [-9.6074253e-01,  5.5664641e-01, -5.0408590e-01, ...,
           8.4084117e-01,  8.4997368e-01, -3.2332402e-01],
         [ 2.2880457e-01, -4.0493733e-01,  9.9786597e-01, ...,
           9.1294074e-01,  1.4926219e-01,  1.0660601e-01]],

        [[ 9.8935986e-01,  8.2690728e-01, -5.7352102e-01, ...,
           9.9567121e-01, -8.8633883e-01,  3.0395970e-01],
         [ 8.8988060e-01, -9.7264850e-01,  1.7650986e-01, ...,
           2.4547508e-01, -8.9436960e-01, -9.5619404e-01],
         [ 9.9884528e-01,  6.0996729e-01,  9.5150667e-01, ...,
           2.6253876e-01,  7.2759002e-01, -9.4840294e-01],
         ...,
         [-1.3422298e-01, -4.8924449e-01,  9.5833534e-01, ...,
          -8.5097688e-01, -9.7267652e-01,  3.6347002e-01],
         [-9.6074253e-01,  5.5664641e-01, -5.0408590e-01, ...,
           8.4084117e-01,  8.4997368e-01, -3.2332402e-01],
         [ 2.2880457e-01, -4.0493733e-01,  9.9786597e-01, ...,
           9.1294074e-01,  1.4926219e-01,  1.0660601e-01]],

        [[ 9.8935986e-01,  8.2690728e-01, -5.7352102e-01, ...,
           9.9567121e-01, -8.8633883e-01,  3.0395970e-01],
         [ 8.8988060e-01, -9.7264850e-01,  1.7650986e-01, ...,
           2.4547508e-01, -8.9436960e-01, -9.5619404e-01],
         [ 9.9884528e-01,  6.0996729e-01,  9.5150667e-01, ...,
           2.6253876e-01,  7.2759002e-01, -9.4840294e-01],
         ...,
         [-1.3422298e-01, -4.8924449e-01,  9.5833534e-01, ...,
          -8.5097688e-01, -9.7267652e-01,  3.6347002e-01],
         [-9.6074253e-01,  5.5664641e-01, -5.0408590e-01, ...,
           8.4084117e-01,  8.4997368e-01, -3.2332402e-01],
         [ 2.2880457e-01, -4.0493733e-01,  9.9786597e-01, ...,
           9.1294074e-01,  1.4926219e-01,  1.0660601e-01]],

        ...,

        [[ 5.2170000e+04,  5.1319000e+04,  5.1060000e+04, ...,
           5.1171000e+04,  4.6916000e+04,  4.6879000e+04],
         [ 5.3650000e+04,  5.1578000e+04,  4.9469000e+04, ...,
           5.0801000e+04,  4.7249000e+04,  4.8433000e+04],
         [ 4.8507000e+04,  4.5325000e+04,  4.3512000e+04, ...,
           5.1134000e+04,  4.8322000e+04,  4.9913000e+04],
         ...,
         [ 4.1004000e+04,  4.0032000e+04,  3.9924000e+04, ...,
           5.1264000e+04,  5.0868000e+04,  5.0292000e+04],
         [ 3.8160000e+04,  3.6936000e+04,  3.6504000e+04, ...,
           4.5252000e+04,  4.1724000e+04,  4.1472000e+04],
         [ 4.7628000e+04,  4.6332000e+04,  4.6044000e+04, ...,
           5.2164000e+04,  4.8456000e+04,  4.8492000e+04]],

        [[ 5.2170000e+04,  5.1319000e+04,  5.1060000e+04, ...,
           5.1171000e+04,  4.6916000e+04,  4.6879000e+04],
         [ 5.3650000e+04,  5.1578000e+04,  4.9469000e+04, ...,
           5.0801000e+04,  4.7249000e+04,  4.8433000e+04],
         [ 4.8507000e+04,  4.5325000e+04,  4.3512000e+04, ...,
           5.1134000e+04,  4.8322000e+04,  4.9913000e+04],
         ...,
         [ 4.1004000e+04,  4.0032000e+04,  3.9924000e+04, ...,
           5.1264000e+04,  5.0868000e+04,  5.0292000e+04],
         [ 3.8160000e+04,  3.6936000e+04,  3.6504000e+04, ...,
           4.5252000e+04,  4.1724000e+04,  4.1472000e+04],
         [ 4.7628000e+04,  4.6332000e+04,  4.6044000e+04, ...,
           5.2164000e+04,  4.8456000e+04,  4.8492000e+04]],

        [[ 5.2170000e+04,  5.1319000e+04,  5.1060000e+04, ...,
           5.1171000e+04,  4.6916000e+04,  4.6879000e+04],
         [ 5.3650000e+04,  5.1578000e+04,  4.9469000e+04, ...,
           5.0801000e+04,  4.7249000e+04,  4.8433000e+04],
         [ 4.8507000e+04,  4.5325000e+04,  4.3512000e+04, ...,
           5.1134000e+04,  4.8322000e+04,  4.9913000e+04],
         ...,
         [ 4.1004000e+04,  4.0032000e+04,  3.9924000e+04, ...,
           5.1264000e+04,  5.0868000e+04,  5.0292000e+04],
         [ 3.8160000e+04,  3.6936000e+04,  3.6504000e+04, ...,
           4.5252000e+04,  4.1724000e+04,  4.1472000e+04],
         [ 4.7628000e+04,  4.6332000e+04,  4.6044000e+04, ...,
           5.2164000e+04,  4.8456000e+04,  4.8492000e+04]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [3], 'to': [6]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        ...,

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]],

        [[ 0.98935986,  0.8269073 , -0.573521  , ...,  0.9956712 ,
          -0.88633883,  0.3039597 ],
         [ 0.8898806 , -0.9726485 ,  0.17650986, ...,  0.24547508,
          -0.8943696 , -0.95619404],
         [ 0.9988453 ,  0.6099673 ,  0.9515067 , ...,  0.26253876,
           0.72759   , -0.94840294],
         ...,
         [-0.13422298, -0.4892445 ,  0.95833534, ..., -0.8509769 ,
          -0.9726765 ,  0.36347002],
         [-0.96074253,  0.5566464 , -0.5040859 , ...,  0.8408412 ,
           0.8499737 , -0.32332402],
         [ 0.22880457, -0.40493733,  0.997866  , ...,  0.91294074,
           0.14926219,  0.10660601]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [3], 'to': [6]}

generate models:38

analyse output arrays in iter:69

pre layer res:
10:add
{'name': 'add', 'output': array([[[[477., 474., 476., ..., 473., 471., 471.],
         [483., 480., 483., ..., 479., 479., 479.],
         [480., 477., 479., ..., 475., 473., 473.],
         ...,
         [308., 305., 317., ..., 287., 302., 302.],
         [296., 290., 287., ..., 302., 305., 305.],
         [290., 290., 284., ..., 308., 308., 311.]],

        [[477., 474., 476., ..., 473., 471., 471.],
         [483., 480., 483., ..., 479., 479., 479.],
         [480., 477., 479., ..., 475., 473., 473.],
         ...,
         [308., 305., 317., ..., 287., 302., 302.],
         [296., 290., 287., ..., 302., 305., 305.],
         [290., 290., 284., ..., 308., 308., 311.]],

        [[477., 474., 476., ..., 473., 471., 471.],
         [483., 480., 483., ..., 479., 479., 479.],
         [480., 477., 479., ..., 475., 473., 473.],
         ...,
         [308., 305., 317., ..., 287., 302., 302.],
         [296., 290., 287., ..., 302., 305., 305.],
         [290., 290., 284., ..., 308., 308., 311.]],

        ...,

        [[477., 474., 476., ..., 473., 471., 471.],
         [483., 480., 483., ..., 479., 479., 479.],
         [480., 477., 479., ..., 475., 473., 473.],
         ...,
         [308., 305., 317., ..., 287., 302., 302.],
         [296., 290., 287., ..., 302., 305., 305.],
         [290., 290., 284., ..., 308., 308., 311.]],

        [[477., 474., 476., ..., 473., 471., 471.],
         [483., 480., 483., ..., 479., 479., 479.],
         [480., 477., 479., ..., 475., 473., 473.],
         ...,
         [308., 305., 317., ..., 287., 302., 302.],
         [296., 290., 287., ..., 302., 305., 305.],
         [290., 290., 284., ..., 308., 308., 311.]],

        [[477., 474., 476., ..., 473., 471., 471.],
         [483., 480., 483., ..., 479., 479., 479.],
         [480., 477., 479., ..., 475., 473., 473.],
         ...,
         [308., 305., 317., ..., 287., 302., 302.],
         [296., 290., 287., ..., 302., 305., 305.],
         [290., 290., 284., ..., 308., 308., 311.]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [8, 13], 'to': [26]}
tf node:
{'name': 'sin', 'output': array([[[[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        ...,

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[-4.9868703e-01,  3.7137613e-01, -9.9881375e-01, ...,
           9.8194647e-01, -2.3663211e-01, -2.3663211e-01],
         [-7.2101682e-01,  6.1601669e-01, -7.2101682e-01, ...,
           9.9568981e-01,  9.9568981e-01,  9.9568981e-01],
         [ 6.1601669e-01, -4.9868703e-01,  9.9568981e-01, ...,
          -5.8063573e-01,  9.8194647e-01,  9.8194647e-01],
         ...,
         [ 1.2360304e-01, -2.6240394e-01,  2.9633978e-01, ...,
          -8.9794093e-01,  3.9595282e-01,  3.9595282e-01],
         [ 6.3676125e-01,  8.2684565e-01, -8.9794093e-01, ...,
           3.9595282e-01, -2.6240394e-01, -2.6240394e-01],
         [ 8.2684565e-01,  8.2684565e-01,  9.5106399e-01, ...,
           1.2360304e-01,  1.2360304e-01,  1.7671786e-02]],

        [[-4.9868703e-01,  3.7137613e-01, -9.9881375e-01, ...,
           9.8194647e-01, -2.3663211e-01, -2.3663211e-01],
         [-7.2101682e-01,  6.1601669e-01, -7.2101682e-01, ...,
           9.9568981e-01,  9.9568981e-01,  9.9568981e-01],
         [ 6.1601669e-01, -4.9868703e-01,  9.9568981e-01, ...,
          -5.8063573e-01,  9.8194647e-01,  9.8194647e-01],
         ...,
         [ 1.2360304e-01, -2.6240394e-01,  2.9633978e-01, ...,
          -8.9794093e-01,  3.9595282e-01,  3.9595282e-01],
         [ 6.3676125e-01,  8.2684565e-01, -8.9794093e-01, ...,
           3.9595282e-01, -2.6240394e-01, -2.6240394e-01],
         [ 8.2684565e-01,  8.2684565e-01,  9.5106399e-01, ...,
           1.2360304e-01,  1.2360304e-01,  1.7671786e-02]],

        [[-4.9868703e-01,  3.7137613e-01, -9.9881375e-01, ...,
           9.8194647e-01, -2.3663211e-01, -2.3663211e-01],
         [-7.2101682e-01,  6.1601669e-01, -7.2101682e-01, ...,
           9.9568981e-01,  9.9568981e-01,  9.9568981e-01],
         [ 6.1601669e-01, -4.9868703e-01,  9.9568981e-01, ...,
          -5.8063573e-01,  9.8194647e-01,  9.8194647e-01],
         ...,
         [ 1.2360304e-01, -2.6240394e-01,  2.9633978e-01, ...,
          -8.9794093e-01,  3.9595282e-01,  3.9595282e-01],
         [ 6.3676125e-01,  8.2684565e-01, -8.9794093e-01, ...,
           3.9595282e-01, -2.6240394e-01, -2.6240394e-01],
         [ 8.2684565e-01,  8.2684565e-01,  9.5106399e-01, ...,
           1.2360304e-01,  1.2360304e-01,  1.7671786e-02]],

        ...,

        [[ 4.7700000e+02,  4.7400000e+02,  4.7600000e+02, ...,
           4.7300000e+02,  4.7100000e+02,  4.7100000e+02],
         [ 4.8300000e+02,  4.8000000e+02,  4.8300000e+02, ...,
           4.7900000e+02,  4.7900000e+02,  4.7900000e+02],
         [ 4.8000000e+02,  4.7700000e+02,  4.7900000e+02, ...,
           4.7500000e+02,  4.7300000e+02,  4.7300000e+02],
         ...,
         [ 3.0800000e+02,  3.0500000e+02,  3.1700000e+02, ...,
           2.8700000e+02,  3.0200000e+02,  3.0200000e+02],
         [ 2.9600000e+02,  2.9000000e+02,  2.8700000e+02, ...,
           3.0200000e+02,  3.0500000e+02,  3.0500000e+02],
         [ 2.9000000e+02,  2.9000000e+02,  2.8400000e+02, ...,
           3.0800000e+02,  3.0800000e+02,  3.1100000e+02]],

        [[ 4.7700000e+02,  4.7400000e+02,  4.7600000e+02, ...,
           4.7300000e+02,  4.7100000e+02,  4.7100000e+02],
         [ 4.8300000e+02,  4.8000000e+02,  4.8300000e+02, ...,
           4.7900000e+02,  4.7900000e+02,  4.7900000e+02],
         [ 4.8000000e+02,  4.7700000e+02,  4.7900000e+02, ...,
           4.7500000e+02,  4.7300000e+02,  4.7300000e+02],
         ...,
         [ 3.0800000e+02,  3.0500000e+02,  3.1700000e+02, ...,
           2.8700000e+02,  3.0200000e+02,  3.0200000e+02],
         [ 2.9600000e+02,  2.9000000e+02,  2.8700000e+02, ...,
           3.0200000e+02,  3.0500000e+02,  3.0500000e+02],
         [ 2.9000000e+02,  2.9000000e+02,  2.8400000e+02, ...,
           3.0800000e+02,  3.0800000e+02,  3.1100000e+02]],

        [[ 4.7700000e+02,  4.7400000e+02,  4.7600000e+02, ...,
           4.7300000e+02,  4.7100000e+02,  4.7100000e+02],
         [ 4.8300000e+02,  4.8000000e+02,  4.8300000e+02, ...,
           4.7900000e+02,  4.7900000e+02,  4.7900000e+02],
         [ 4.8000000e+02,  4.7700000e+02,  4.7900000e+02, ...,
           4.7500000e+02,  4.7300000e+02,  4.7300000e+02],
         ...,
         [ 3.0800000e+02,  3.0500000e+02,  3.1700000e+02, ...,
           2.8700000e+02,  3.0200000e+02,  3.0200000e+02],
         [ 2.9600000e+02,  2.9000000e+02,  2.8700000e+02, ...,
           3.0200000e+02,  3.0500000e+02,  3.0500000e+02],
         [ 2.9000000e+02,  2.9000000e+02,  2.8400000e+02, ...,
           3.0800000e+02,  3.0800000e+02,  3.1100000e+02]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [10], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        ...,

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]],

        [[-0.49868703,  0.37137613, -0.99881375, ...,  0.98194647,
          -0.23663211, -0.23663211],
         [-0.7210168 ,  0.6160167 , -0.7210168 , ...,  0.99568975,
           0.99568975,  0.99568975],
         [ 0.6160167 , -0.49868703,  0.99568975, ..., -0.5806357 ,
           0.98194647,  0.98194647],
         ...,
         [ 0.12360304, -0.26240394,  0.29633978, ..., -0.89794093,
           0.39595282,  0.39595282],
         [ 0.63676125,  0.82684565, -0.89794093, ...,  0.39595282,
          -0.26240394, -0.26240394],
         [ 0.82684565,  0.82684565,  0.951064  , ...,  0.12360304,
           0.12360304,  0.01767179]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': []}

generate models:44

analyse output arrays in iter:78

pre layer res:
1:conv2d
{'name': 'conv2d', 'output': array([[[[169472., 139776., 154624., ..., 294912., 271872., 208896.],
         [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
         [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
         ...,
         [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
         [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
         [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

        [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
         [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
         [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
         ...,
         [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
         [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
         [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

        [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
         [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
         [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
         ...,
         [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
         [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
         [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

        ...,

        [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
         [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
         [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
         ...,
         [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
         [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
         [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

        [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
         [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
         [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
         ...,
         [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
         [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
         [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]],

        [[169472., 139776., 154624., ..., 294912., 271872., 208896.],
         [115200.,  67584.,  79872., ..., 261120., 241152., 164352.],
         [ 91648.,  70656.,  73728., ..., 268800., 251904., 167424.],
         ...,
         [ 70144.,  59904.,  86528., ..., 204288., 183296., 144896.],
         [ 41472.,  47104.,  65536., ..., 188928., 173056., 129536.],
         [ 72704.,  59392.,  66048., ..., 125952., 115712., 127488.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [0], 'to': [2, 5]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        ...,

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [1], 'to': [3]}
ms node:
{'name': 'sin', 'output': array([[[[ 9.3761230e-01,  2.5674856e-01,  8.8790721e-01, ...,
          -9.5593536e-01, -9.8985630e-01, -8.7328655e-01],
         [-8.0695933e-01,  8.8325375e-01,  1.4783132e-01, ...,
          -2.4101503e-01, -2.0485719e-01,  4.0746143e-01],
         [ 9.9376953e-01,  9.9994564e-01,  8.9283705e-01, ...,
          -8.1377971e-01, -9.9444413e-01,  7.8163809e-01],
         ...,
         [-9.9595028e-01,  1.1105181e-01,  7.7483737e-01, ...,
           3.3865306e-01,  2.2152075e-01, -5.1101816e-01],
         [ 1.6387752e-01, -8.6252970e-01,  6.9206548e-01, ...,
          -8.9075404e-01, -9.7964334e-01,  9.6080333e-01],
         [ 9.5294613e-01, -1.8972680e-01, -7.4727315e-01, ...,
          -6.6885519e-01,  7.5743985e-01,  8.2571882e-01]],

        [[ 9.3761230e-01,  2.5674856e-01,  8.8790721e-01, ...,
          -9.5593536e-01, -9.8985630e-01, -8.7328655e-01],
         [-8.0695933e-01,  8.8325375e-01,  1.4783132e-01, ...,
          -2.4101503e-01, -2.0485719e-01,  4.0746143e-01],
         [ 9.9376953e-01,  9.9994564e-01,  8.9283705e-01, ...,
          -8.1377971e-01, -9.9444413e-01,  7.8163809e-01],
         ...,
         [-9.9595028e-01,  1.1105181e-01,  7.7483737e-01, ...,
           3.3865306e-01,  2.2152075e-01, -5.1101816e-01],
         [ 1.6387752e-01, -8.6252970e-01,  6.9206548e-01, ...,
          -8.9075404e-01, -9.7964334e-01,  9.6080333e-01],
         [ 9.5294613e-01, -1.8972680e-01, -7.4727315e-01, ...,
          -6.6885519e-01,  7.5743985e-01,  8.2571882e-01]],

        [[ 9.3761230e-01,  2.5674856e-01,  8.8790721e-01, ...,
          -9.5593536e-01, -9.8985630e-01, -8.7328655e-01],
         [-8.0695933e-01,  8.8325375e-01,  1.4783132e-01, ...,
          -2.4101503e-01, -2.0485719e-01,  4.0746143e-01],
         [ 9.9376953e-01,  9.9994564e-01,  8.9283705e-01, ...,
          -8.1377971e-01, -9.9444413e-01,  7.8163809e-01],
         ...,
         [-9.9595028e-01,  1.1105181e-01,  7.7483737e-01, ...,
           3.3865306e-01,  2.2152075e-01, -5.1101816e-01],
         [ 1.6387752e-01, -8.6252970e-01,  6.9206548e-01, ...,
          -8.9075404e-01, -9.7964334e-01,  9.6080333e-01],
         [ 9.5294613e-01, -1.8972680e-01, -7.4727315e-01, ...,
          -6.6885519e-01,  7.5743985e-01,  8.2571882e-01]],

        ...,

        [[ 1.1863060e+06,  9.7843400e+05,  1.0823700e+06, ...,
           2.0643860e+06,  1.9031060e+06,  1.4622740e+06],
         [ 8.0640200e+05,  4.7309000e+05,  5.5910600e+05, ...,
           1.8278420e+06,  1.6880660e+06,  1.1504660e+06],
         [ 6.4153800e+05,  4.9459400e+05,  5.1609800e+05, ...,
           1.8816020e+06,  1.7633300e+06,  1.1719700e+06],
         ...,
         [ 4.9101000e+05,  4.1933000e+05,  6.0569800e+05, ...,
           1.4300180e+06,  1.2830740e+06,  1.0142740e+06],
         [ 2.9030600e+05,  3.2973000e+05,  4.5875400e+05, ...,
           1.3224980e+06,  1.2113940e+06,  9.0675400e+05],
         [ 5.0893000e+05,  4.1574600e+05,  4.6233800e+05, ...,
           8.8166600e+05,  8.0998600e+05,  8.9241800e+05]],

        [[ 1.1863060e+06,  9.7843400e+05,  1.0823700e+06, ...,
           2.0643860e+06,  1.9031060e+06,  1.4622740e+06],
         [ 8.0640200e+05,  4.7309000e+05,  5.5910600e+05, ...,
           1.8278420e+06,  1.6880660e+06,  1.1504660e+06],
         [ 6.4153800e+05,  4.9459400e+05,  5.1609800e+05, ...,
           1.8816020e+06,  1.7633300e+06,  1.1719700e+06],
         ...,
         [ 4.9101000e+05,  4.1933000e+05,  6.0569800e+05, ...,
           1.4300180e+06,  1.2830740e+06,  1.0142740e+06],
         [ 2.9030600e+05,  3.2973000e+05,  4.5875400e+05, ...,
           1.3224980e+06,  1.2113940e+06,  9.0675400e+05],
         [ 5.0893000e+05,  4.1574600e+05,  4.6233800e+05, ...,
           8.8166600e+05,  8.0998600e+05,  8.9241800e+05]],

        [[ 1.1863060e+06,  9.7843400e+05,  1.0823700e+06, ...,
           2.0643860e+06,  1.9031060e+06,  1.4622740e+06],
         [ 8.0640200e+05,  4.7309000e+05,  5.5910600e+05, ...,
           1.8278420e+06,  1.6880660e+06,  1.1504660e+06],
         [ 6.4153800e+05,  4.9459400e+05,  5.1609800e+05, ...,
           1.8816020e+06,  1.7633300e+06,  1.1719700e+06],
         ...,
         [ 4.9101000e+05,  4.1933000e+05,  6.0569800e+05, ...,
           1.4300180e+06,  1.2830740e+06,  1.0142740e+06],
         [ 2.9030600e+05,  3.2973000e+05,  4.5875400e+05, ...,
           1.3224980e+06,  1.2113940e+06,  9.0675400e+05],
         [ 5.0893000e+05,  4.1574600e+05,  4.6233800e+05, ...,
           8.8166600e+05,  8.0998600e+05,  8.9241800e+05]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [1], 'to': [3]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        ...,

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]],

        [[ 0.9376123 ,  0.25674856,  0.8879072 , ..., -0.95593536,
          -0.9898563 , -0.87328655],
         [-0.80695933,  0.88325375,  0.14783132, ..., -0.24101503,
          -0.20485719,  0.40746143],
         [ 0.9937695 ,  0.99994564,  0.89283705, ..., -0.8137797 ,
          -0.99444413,  0.7816381 ],
         ...,
         [-0.9959503 ,  0.11105181,  0.7748374 , ...,  0.33865306,
           0.22152075, -0.51101816],
         [ 0.16387752, -0.8625297 ,  0.6920655 , ..., -0.89075404,
          -0.97964334,  0.96080333],
         [ 0.9529461 , -0.1897268 , -0.74727315, ..., -0.6688552 ,
           0.75743985,  0.8257188 ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [1], 'to': [3]}

generate models:47

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:7,distinct_bugs:2
torch --> nums:2,distinct_bugs:1
tensorflow --> 
softmax:2
mindspore --> 
sin:5
softmax:2
torch --> 
softmax:2

generate models:56

analyse output arrays in iter:114

pre layer res:
9:add
{'name': 'add', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [6, 8], 'to': [10, 7]}
tf node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [9], 'to': [4]}
ms node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]],

        [[0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         ...,
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ],
         [0.        , 0.        , 0.        , ..., 0.        ,
          0.        , 0.        ]]]], dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [9], 'to': [4]}
torch node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [9], 'to': [4]}

generate models:61

analyse output arrays in iter:130

pre layer res:
10:add
{'name': 'add', 'output': array([[[[3.9669318e+10, 3.3224387e+10, 2.7350405e+10, ...,
          3.3037998e+10, 3.1202953e+10, 2.9596240e+10],
         [3.4925474e+10, 3.7062246e+10, 2.2659756e+10, ...,
          2.8375935e+10, 2.8375935e+10, 3.0662664e+10],
         [3.0305092e+10, 3.2297689e+10, 3.3786696e+10, ...,
          3.5309261e+10, 3.6277899e+10, 3.3598734e+10],
         ...,
         [3.7259649e+10, 3.2113922e+10, 3.4543784e+10, ...,
          3.9873532e+10, 4.4931949e+10, 4.4498883e+10],
         [3.6669026e+10, 3.2113922e+10, 3.7656019e+10, ...,
          3.7457568e+10, 4.3425386e+10, 4.2154488e+10],
         [4.0078270e+10, 3.7259649e+10, 4.1944506e+10, ...,
          3.6473201e+10, 4.3639034e+10, 4.2576024e+10]],

        [[3.9669318e+10, 3.3224387e+10, 2.7350405e+10, ...,
          3.3037998e+10, 3.1202953e+10, 2.9596240e+10],
         [3.4925474e+10, 3.7062246e+10, 2.2659756e+10, ...,
          2.8375935e+10, 2.8375935e+10, 3.0662664e+10],
         [3.0305092e+10, 3.2297689e+10, 3.3786696e+10, ...,
          3.5309261e+10, 3.6277899e+10, 3.3598734e+10],
         ...,
         [3.7259649e+10, 3.2113922e+10, 3.4543784e+10, ...,
          3.9873532e+10, 4.4931949e+10, 4.4498883e+10],
         [3.6669026e+10, 3.2113922e+10, 3.7656019e+10, ...,
          3.7457568e+10, 4.3425386e+10, 4.2154488e+10],
         [4.0078270e+10, 3.7259649e+10, 4.1944506e+10, ...,
          3.6473201e+10, 4.3639034e+10, 4.2576024e+10]],

        [[3.9669318e+10, 3.3224387e+10, 2.7350405e+10, ...,
          3.3037998e+10, 3.1202953e+10, 2.9596240e+10],
         [3.4925474e+10, 3.7062246e+10, 2.2659756e+10, ...,
          2.8375935e+10, 2.8375935e+10, 3.0662664e+10],
         [3.0305092e+10, 3.2297689e+10, 3.3786696e+10, ...,
          3.5309261e+10, 3.6277899e+10, 3.3598734e+10],
         ...,
         [3.7259649e+10, 3.2113922e+10, 3.4543784e+10, ...,
          3.9873532e+10, 4.4931949e+10, 4.4498883e+10],
         [3.6669026e+10, 3.2113922e+10, 3.7656019e+10, ...,
          3.7457568e+10, 4.3425386e+10, 4.2154488e+10],
         [4.0078270e+10, 3.7259649e+10, 4.1944506e+10, ...,
          3.6473201e+10, 4.3639034e+10, 4.2576024e+10]],

        ...,

        [[3.9669318e+10, 3.3224387e+10, 2.7350405e+10, ...,
          3.3037998e+10, 3.1202953e+10, 2.9596240e+10],
         [3.4925474e+10, 3.7062246e+10, 2.2659756e+10, ...,
          2.8375935e+10, 2.8375935e+10, 3.0662664e+10],
         [3.0305092e+10, 3.2297689e+10, 3.3786696e+10, ...,
          3.5309261e+10, 3.6277899e+10, 3.3598734e+10],
         ...,
         [3.7259649e+10, 3.2113922e+10, 3.4543784e+10, ...,
          3.9873532e+10, 4.4931949e+10, 4.4498883e+10],
         [3.6669026e+10, 3.2113922e+10, 3.7656019e+10, ...,
          3.7457568e+10, 4.3425386e+10, 4.2154488e+10],
         [4.0078270e+10, 3.7259649e+10, 4.1944506e+10, ...,
          3.6473201e+10, 4.3639034e+10, 4.2576024e+10]],

        [[3.9669318e+10, 3.3224387e+10, 2.7350405e+10, ...,
          3.3037998e+10, 3.1202953e+10, 2.9596240e+10],
         [3.4925474e+10, 3.7062246e+10, 2.2659756e+10, ...,
          2.8375935e+10, 2.8375935e+10, 3.0662664e+10],
         [3.0305092e+10, 3.2297689e+10, 3.3786696e+10, ...,
          3.5309261e+10, 3.6277899e+10, 3.3598734e+10],
         ...,
         [3.7259649e+10, 3.2113922e+10, 3.4543784e+10, ...,
          3.9873532e+10, 4.4931949e+10, 4.4498883e+10],
         [3.6669026e+10, 3.2113922e+10, 3.7656019e+10, ...,
          3.7457568e+10, 4.3425386e+10, 4.2154488e+10],
         [4.0078270e+10, 3.7259649e+10, 4.1944506e+10, ...,
          3.6473201e+10, 4.3639034e+10, 4.2576024e+10]],

        [[3.9669318e+10, 3.3224387e+10, 2.7350405e+10, ...,
          3.3037998e+10, 3.1202953e+10, 2.9596240e+10],
         [3.4925474e+10, 3.7062246e+10, 2.2659756e+10, ...,
          2.8375935e+10, 2.8375935e+10, 3.0662664e+10],
         [3.0305092e+10, 3.2297689e+10, 3.3786696e+10, ...,
          3.5309261e+10, 3.6277899e+10, 3.3598734e+10],
         ...,
         [3.7259649e+10, 3.2113922e+10, 3.4543784e+10, ...,
          3.9873532e+10, 4.4931949e+10, 4.4498883e+10],
         [3.6669026e+10, 3.2113922e+10, 3.7656019e+10, ...,
          3.7457568e+10, 4.3425386e+10, 4.2154488e+10],
         [4.0078270e+10, 3.7259649e+10, 4.1944506e+10, ...,
          3.6473201e+10, 4.3639034e+10, 4.2576024e+10]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [7, 8], 'to': [12]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        ...,

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': [2]}
ms node:
{'name': 'sin', 'output': array([[[[ 9.76299345e-01,  9.82207358e-01,  5.15070736e-01, ...,
           9.64478850e-01,  6.29877448e-01, -3.81195128e-01],
         [-8.95966768e-01, -8.08287978e-01, -9.99987125e-01, ...,
           9.76458609e-01,  9.76458609e-01, -1.48093805e-01],
         [ 3.31656337e-01, -9.50337589e-01,  9.73940194e-01, ...,
           9.98362541e-01, -7.88489699e-01,  9.61666346e-01],
         ...,
         [ 2.40853027e-01,  4.39864062e-02, -8.03899020e-02, ...,
           3.32778513e-01, -1.76813617e-01,  6.44595027e-02],
         [-8.02816808e-01,  4.39864062e-02,  5.86018443e-01, ...,
          -8.34543824e-01, -9.06060264e-02,  8.09886813e-01],
         [-4.84451115e-01,  2.40853027e-01,  1.04621276e-01, ...,
           9.97381806e-01, -3.85735422e-01,  1.41020417e-02]],

        [[ 9.76299345e-01,  9.82207358e-01,  5.15070736e-01, ...,
           9.64478850e-01,  6.29877448e-01, -3.81195128e-01],
         [-8.95966768e-01, -8.08287978e-01, -9.99987125e-01, ...,
           9.76458609e-01,  9.76458609e-01, -1.48093805e-01],
         [ 3.31656337e-01, -9.50337589e-01,  9.73940194e-01, ...,
           9.98362541e-01, -7.88489699e-01,  9.61666346e-01],
         ...,
         [ 2.40853027e-01,  4.39864062e-02, -8.03899020e-02, ...,
           3.32778513e-01, -1.76813617e-01,  6.44595027e-02],
         [-8.02816808e-01,  4.39864062e-02,  5.86018443e-01, ...,
          -8.34543824e-01, -9.06060264e-02,  8.09886813e-01],
         [-4.84451115e-01,  2.40853027e-01,  1.04621276e-01, ...,
           9.97381806e-01, -3.85735422e-01,  1.41020417e-02]],

        [[ 9.76299345e-01,  9.82207358e-01,  5.15070736e-01, ...,
           9.64478850e-01,  6.29877448e-01, -3.81195128e-01],
         [-8.95966768e-01, -8.08287978e-01, -9.99987125e-01, ...,
           9.76458609e-01,  9.76458609e-01, -1.48093805e-01],
         [ 3.31656337e-01, -9.50337589e-01,  9.73940194e-01, ...,
           9.98362541e-01, -7.88489699e-01,  9.61666346e-01],
         ...,
         [ 2.40853027e-01,  4.39864062e-02, -8.03899020e-02, ...,
           3.32778513e-01, -1.76813617e-01,  6.44595027e-02],
         [-8.02816808e-01,  4.39864062e-02,  5.86018443e-01, ...,
          -8.34543824e-01, -9.06060264e-02,  8.09886813e-01],
         [-4.84451115e-01,  2.40853027e-01,  1.04621276e-01, ...,
           9.97381806e-01, -3.85735422e-01,  1.41020417e-02]],

        ...,

        [[ 3.96685189e+10,  3.32236575e+10,  2.73497436e+10, ...,
           3.30372710e+10,  3.12022467e+10,  2.95955517e+10],
         [ 3.49247242e+10,  3.70614764e+10,  2.26591539e+10, ...,
           2.83752612e+10,  2.83752612e+10,  3.06619638e+10],
         [ 3.03043953e+10,  3.22969702e+10,  3.37859604e+10, ...,
           3.53085071e+10,  3.62771374e+10,  3.35980012e+10],
         ...,
         [ 3.72588749e+10,  3.21132052e+10,  3.45430385e+10, ...,
           3.98727332e+10,  4.49311007e+10,  4.44980388e+10],
         [ 3.66682604e+10,  3.21132052e+10,  3.76552407e+10, ...,
           3.74567936e+10,  4.34245509e+10,  4.21536645e+10],
         [ 4.00774676e+10,  3.72588749e+10,  4.19436872e+10, ...,
           3.64724347e+10,  4.36381983e+10,  4.25751962e+10]],

        [[ 3.96685189e+10,  3.32236575e+10,  2.73497436e+10, ...,
           3.30372710e+10,  3.12022467e+10,  2.95955517e+10],
         [ 3.49247242e+10,  3.70614764e+10,  2.26591539e+10, ...,
           2.83752612e+10,  2.83752612e+10,  3.06619638e+10],
         [ 3.03043953e+10,  3.22969702e+10,  3.37859604e+10, ...,
           3.53085071e+10,  3.62771374e+10,  3.35980012e+10],
         ...,
         [ 3.72588749e+10,  3.21132052e+10,  3.45430385e+10, ...,
           3.98727332e+10,  4.49311007e+10,  4.44980388e+10],
         [ 3.66682604e+10,  3.21132052e+10,  3.76552407e+10, ...,
           3.74567936e+10,  4.34245509e+10,  4.21536645e+10],
         [ 4.00774676e+10,  3.72588749e+10,  4.19436872e+10, ...,
           3.64724347e+10,  4.36381983e+10,  4.25751962e+10]],

        [[ 3.96685189e+10,  3.32236575e+10,  2.73497436e+10, ...,
           3.30372710e+10,  3.12022467e+10,  2.95955517e+10],
         [ 3.49247242e+10,  3.70614764e+10,  2.26591539e+10, ...,
           2.83752612e+10,  2.83752612e+10,  3.06619638e+10],
         [ 3.03043953e+10,  3.22969702e+10,  3.37859604e+10, ...,
           3.53085071e+10,  3.62771374e+10,  3.35980012e+10],
         ...,
         [ 3.72588749e+10,  3.21132052e+10,  3.45430385e+10, ...,
           3.98727332e+10,  4.49311007e+10,  4.44980388e+10],
         [ 3.66682604e+10,  3.21132052e+10,  3.76552407e+10, ...,
           3.74567936e+10,  4.34245509e+10,  4.21536645e+10],
         [ 4.00774676e+10,  3.72588749e+10,  4.19436872e+10, ...,
           3.64724347e+10,  4.36381983e+10,  4.25751962e+10]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [10], 'to': [2]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        ...,

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]],

        [[ 0.97629935,  0.98220736,  0.51507074, ...,  0.96447885,
           0.62987745, -0.38119513],
         [-0.89596677, -0.808288  , -0.9999871 , ...,  0.9764586 ,
           0.9764586 , -0.1480938 ],
         [ 0.33165634, -0.9503376 ,  0.9739402 , ...,  0.99836254,
          -0.7884897 ,  0.96166635],
         ...,
         [ 0.24085303,  0.04398641, -0.0803899 , ...,  0.3327785 ,
          -0.17681362,  0.0644595 ],
         [-0.8028168 ,  0.04398641,  0.58601844, ..., -0.8345438 ,
          -0.09060603,  0.8098868 ],
         [-0.48445112,  0.24085303,  0.10462128, ...,  0.9973818 ,
          -0.38573542,  0.01410204]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': [2]}

generate models:69

analyse output arrays in iter:134

pre layer res:
5:empty_seq_operator
{'name': 'empty_seq_operator', 'output': array([[[[57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         ...,
         [57344., 53248., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.]],

        [[57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         ...,
         [57344., 53248., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.]],

        [[57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         ...,
         [57344., 53248., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.]],

        ...,

        [[57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         ...,
         [57344., 53248., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.]],

        [[57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         ...,
         [57344., 53248., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.]],

        [[57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 57344., ..., 36864., 36864., 36864.],
         ...,
         [57344., 53248., 57344., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.],
         [57344., 57344., 61440., ..., 36864., 36864., 36864.]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': [2]}
tf node:
{'name': 'sin', 'output': array([[[[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        ...,

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [5], 'to': [7]}
ms node:
{'name': 'sin', 'output': array([[[[-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         ...,
         [-4.8756099e-01, -9.1116977e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01,  1.2718087e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01,  1.2718087e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01]],

        [[-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         ...,
         [-4.8756099e-01, -9.1116977e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01,  1.2718087e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01,  1.2718087e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01]],

        [[-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         ...,
         [-4.8756099e-01, -9.1116977e-01, -4.8756099e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01,  1.2718087e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01],
         [-4.8756099e-01, -4.8756099e-01,  1.2718087e-01, ...,
           5.2422327e-01,  5.2422327e-01,  5.2422327e-01]],

        ...,

        [[ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         ...,
         [ 2.8672000e+04,  2.6624000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  3.0720000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  3.0720000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04]],

        [[ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         ...,
         [ 2.8672000e+04,  2.6624000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  3.0720000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  3.0720000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04]],

        [[ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         ...,
         [ 2.8672000e+04,  2.6624000e+04,  2.8672000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  3.0720000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04],
         [ 2.8672000e+04,  2.8672000e+04,  3.0720000e+04, ...,
           1.8432000e+04,  1.8432000e+04,  1.8432000e+04]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [5], 'to': [7]}
torch node:
{'name': 'sin', 'output': array([[[[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        ...,

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]],

        [[-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  , -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         ...,
         [-0.487561  , -0.91116977, -0.487561  , ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327],
         [-0.487561  , -0.487561  ,  0.12718087, ...,  0.52422327,
           0.52422327,  0.52422327]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [5], 'to': [7]}

generate models:71

analyse output arrays in iter:140

pre layer res:
11:cos
{'name': 'cos', 'output': array([[[[-0.940213  , -0.86873686,  0.06300329, ..., -0.30771858,
           0.24846394, -0.9408712 ],
         [-0.86873686,  0.06300329, -0.940213  , ...,  0.7308276 ,
          -0.19578706, -0.7562227 ],
         [ 0.14195496,  0.9825048 ,  0.24846394, ..., -0.19281605,
           0.84746903, -0.92011756],
         ...,
         [-0.0055509 ,  0.20524369, -0.38951793, ..., -0.6650506 ,
          -0.49890178, -0.7960293 ],
         [-0.99913585,  0.998574  , -0.45159096, ..., -0.8880607 ,
          -0.06705038,  0.7605123 ],
         [ 0.86996055,  0.998574  , -0.99470204, ..., -0.91826373,
           0.7844682 , -0.14650705]],

        [[-0.940213  , -0.86873686,  0.06300329, ..., -0.30771858,
           0.24846394, -0.9408712 ],
         [-0.86873686,  0.06300329, -0.940213  , ...,  0.7308276 ,
          -0.19578706, -0.7562227 ],
         [ 0.14195496,  0.9825048 ,  0.24846394, ..., -0.19281605,
           0.84746903, -0.92011756],
         ...,
         [-0.0055509 ,  0.20524369, -0.38951793, ..., -0.6650506 ,
          -0.49890178, -0.7960293 ],
         [-0.99913585,  0.998574  , -0.45159096, ..., -0.8880607 ,
          -0.06705038,  0.7605123 ],
         [ 0.86996055,  0.998574  , -0.99470204, ..., -0.91826373,
           0.7844682 , -0.14650705]],

        [[-0.940213  , -0.86873686,  0.06300329, ..., -0.30771858,
           0.24846394, -0.9408712 ],
         [-0.86873686,  0.06300329, -0.940213  , ...,  0.7308276 ,
          -0.19578706, -0.7562227 ],
         [ 0.14195496,  0.9825048 ,  0.24846394, ..., -0.19281605,
           0.84746903, -0.92011756],
         ...,
         [-0.0055509 ,  0.20524369, -0.38951793, ..., -0.6650506 ,
          -0.49890178, -0.7960293 ],
         [-0.99913585,  0.998574  , -0.45159096, ..., -0.8880607 ,
          -0.06705038,  0.7605123 ],
         [ 0.86996055,  0.998574  , -0.99470204, ..., -0.91826373,
           0.7844682 , -0.14650705]],

        ...,

        [[-0.940213  , -0.86873686,  0.06300329, ..., -0.30771858,
           0.24846394, -0.9408712 ],
         [-0.86873686,  0.06300329, -0.940213  , ...,  0.7308276 ,
          -0.19578706, -0.7562227 ],
         [ 0.14195496,  0.9825048 ,  0.24846394, ..., -0.19281605,
           0.84746903, -0.92011756],
         ...,
         [-0.0055509 ,  0.20524369, -0.38951793, ..., -0.6650506 ,
          -0.49890178, -0.7960293 ],
         [-0.99913585,  0.998574  , -0.45159096, ..., -0.8880607 ,
          -0.06705038,  0.7605123 ],
         [ 0.86996055,  0.998574  , -0.99470204, ..., -0.91826373,
           0.7844682 , -0.14650705]],

        [[-0.940213  , -0.86873686,  0.06300329, ..., -0.30771858,
           0.24846394, -0.9408712 ],
         [-0.86873686,  0.06300329, -0.940213  , ...,  0.7308276 ,
          -0.19578706, -0.7562227 ],
         [ 0.14195496,  0.9825048 ,  0.24846394, ..., -0.19281605,
           0.84746903, -0.92011756],
         ...,
         [-0.0055509 ,  0.20524369, -0.38951793, ..., -0.6650506 ,
          -0.49890178, -0.7960293 ],
         [-0.99913585,  0.998574  , -0.45159096, ..., -0.8880607 ,
          -0.06705038,  0.7605123 ],
         [ 0.86996055,  0.998574  , -0.99470204, ..., -0.91826373,
           0.7844682 , -0.14650705]],

        [[-0.940213  , -0.86873686,  0.06300329, ..., -0.30771858,
           0.24846394, -0.9408712 ],
         [-0.86873686,  0.06300329, -0.940213  , ...,  0.7308276 ,
          -0.19578706, -0.7562227 ],
         [ 0.14195496,  0.9825048 ,  0.24846394, ..., -0.19281605,
           0.84746903, -0.92011756],
         ...,
         [-0.0055509 ,  0.20524369, -0.38951793, ..., -0.6650506 ,
          -0.49890178, -0.7960293 ],
         [-0.99913585,  0.998574  , -0.45159096, ..., -0.8880607 ,
          -0.06705038,  0.7605123 ],
         [ 0.86996055,  0.998574  , -0.99470204, ..., -0.91826373,
           0.7844682 , -0.14650705]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': [26]}
tf node:
{'name': 'log', 'output': array([[[[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        ...,

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [11], 'to': []}
ms node:
{'name': 'log', 'output': array([[[[           nan,            nan, -2.7645698e+00, ...,
                     nan, -1.3924589e+00,            nan],
         [           nan, -2.7645698e+00,            nan, ...,
          -3.1357771e-01,            nan,            nan],
         [-1.9522486e+00, -1.7651496e-02, -1.3924589e+00, ...,
                     nan, -1.6550426e-01,            nan],
         ...,
         [           nan, -1.5835596e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4284297e-03,            nan, ...,
                     nan,            nan, -2.7376524e-01],
         [-1.3930841e-01, -1.4284297e-03,            nan, ...,
                     nan, -2.4275169e-01,            nan]],

        [[           nan,            nan, -2.7645698e+00, ...,
                     nan, -1.3924589e+00,            nan],
         [           nan, -2.7645698e+00,            nan, ...,
          -3.1357771e-01,            nan,            nan],
         [-1.9522486e+00, -1.7651496e-02, -1.3924589e+00, ...,
                     nan, -1.6550426e-01,            nan],
         ...,
         [           nan, -1.5835596e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4284297e-03,            nan, ...,
                     nan,            nan, -2.7376524e-01],
         [-1.3930841e-01, -1.4284297e-03,            nan, ...,
                     nan, -2.4275169e-01,            nan]],

        [[           nan,            nan, -2.7645698e+00, ...,
                     nan, -1.3924589e+00,            nan],
         [           nan, -2.7645698e+00,            nan, ...,
          -3.1357771e-01,            nan,            nan],
         [-1.9522486e+00, -1.7651496e-02, -1.3924589e+00, ...,
                     nan, -1.6550426e-01,            nan],
         ...,
         [           nan, -1.5835596e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4284297e-03,            nan, ...,
                     nan,            nan, -2.7376524e-01],
         [-1.3930841e-01, -1.4284297e-03,            nan, ...,
                     nan, -2.4275169e-01,            nan]],

        ...,

        [[           nan,            nan, -2.7645698e+00, ...,
                     nan, -1.3924589e+00,            nan],
         [           nan, -2.7645698e+00,            nan, ...,
          -3.1357771e-01,            nan,            nan],
         [-1.9522486e+00, -1.7651496e-02, -1.3924589e+00, ...,
                     nan, -1.6550426e-01,            nan],
         ...,
         [           nan, -1.5835596e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4284297e-03,            nan, ...,
                     nan,            nan, -2.7376524e-01],
         [-1.3930841e-01, -1.4284297e-03,            nan, ...,
                     nan, -2.4275169e-01,            nan]],

        [[           nan,            nan, -2.7645698e+00, ...,
                     nan, -1.3924589e+00,            nan],
         [           nan, -2.7645698e+00,            nan, ...,
          -3.1357771e-01,            nan,            nan],
         [-1.9522486e+00, -1.7651496e-02, -1.3924589e+00, ...,
                     nan, -1.6550426e-01,            nan],
         ...,
         [           nan, -1.5835596e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4284297e-03,            nan, ...,
                     nan,            nan, -2.7376524e-01],
         [-1.3930841e-01, -1.4284297e-03,            nan, ...,
                     nan, -2.4275169e-01,            nan]],

        [[           nan,            nan, -2.7645698e+00, ...,
                     nan, -1.3924589e+00,            nan],
         [           nan, -2.7645698e+00,            nan, ...,
          -3.1357771e-01,            nan,            nan],
         [-1.9522486e+00, -1.7651496e-02, -1.3924589e+00, ...,
                     nan, -1.6550426e-01,            nan],
         ...,
         [           nan, -1.5835596e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4284297e-03,            nan, ...,
                     nan,            nan, -2.7376524e-01],
         [-1.3930841e-01, -1.4284297e-03,            nan, ...,
                     nan, -2.4275169e-01,            nan]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [11], 'to': []}
torch node:
{'name': 'log', 'output': array([[[[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        ...,

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]],

        [[           nan,            nan, -2.7645683e+00, ...,
                     nan, -1.3924575e+00,            nan],
         [           nan, -2.7645683e+00,            nan, ...,
          -3.1357765e-01,            nan,            nan],
         [-1.9522455e+00, -1.7650064e-02, -1.3924575e+00, ...,
                     nan, -1.6550098e-01,            nan],
         ...,
         [           nan, -1.5835572e+00,            nan, ...,
                     nan,            nan,            nan],
         [           nan, -1.4269992e-03,            nan, ...,
                     nan,            nan, -2.7376300e-01],
         [-1.3930741e-01, -1.4269992e-03,            nan, ...,
                     nan, -2.4274927e-01,            nan]]]],
      dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [11], 'to': []}

generate models:74

analyse output arrays in iter:188

pre layer res:
10:empty_merge_operator
{'name': 'empty_merge_operator', 'output': array([[[[1155076., 1159172., 1157124., ..., 1034244., 1048580.,
          1085444.],
         [1105924., 1114116., 1130500., ..., 1185796., 1146884.,
          1101828.],
         [1126404., 1134596., 1126404., ..., 1241092., 1222660.,
          1198084.],
         ...,
         [ 815108.,  843780.,  489476., ...,  821252.,  821252.,
           825348.],
         [ 800772.,  831492.,  557060., ...,  815108.,  806916.,
           802820.],
         [ 794628.,  819204.,  665604., ...,  813060.,  798724.,
           792580.]],

        [[1155076., 1159172., 1157124., ..., 1034244., 1048580.,
          1085444.],
         [1105924., 1114116., 1130500., ..., 1185796., 1146884.,
          1101828.],
         [1126404., 1134596., 1126404., ..., 1241092., 1222660.,
          1198084.],
         ...,
         [ 815108.,  843780.,  489476., ...,  821252.,  821252.,
           825348.],
         [ 800772.,  831492.,  557060., ...,  815108.,  806916.,
           802820.],
         [ 794628.,  819204.,  665604., ...,  813060.,  798724.,
           792580.]],

        [[1155076., 1159172., 1157124., ..., 1034244., 1048580.,
          1085444.],
         [1105924., 1114116., 1130500., ..., 1185796., 1146884.,
          1101828.],
         [1126404., 1134596., 1126404., ..., 1241092., 1222660.,
          1198084.],
         ...,
         [ 815108.,  843780.,  489476., ...,  821252.,  821252.,
           825348.],
         [ 800772.,  831492.,  557060., ...,  815108.,  806916.,
           802820.],
         [ 794628.,  819204.,  665604., ...,  813060.,  798724.,
           792580.]],

        ...,

        [[1155076., 1159172., 1157124., ..., 1034244., 1048580.,
          1085444.],
         [1105924., 1114116., 1130500., ..., 1185796., 1146884.,
          1101828.],
         [1126404., 1134596., 1126404., ..., 1241092., 1222660.,
          1198084.],
         ...,
         [ 815108.,  843780.,  489476., ...,  821252.,  821252.,
           825348.],
         [ 800772.,  831492.,  557060., ...,  815108.,  806916.,
           802820.],
         [ 794628.,  819204.,  665604., ...,  813060.,  798724.,
           792580.]],

        [[1155076., 1159172., 1157124., ..., 1034244., 1048580.,
          1085444.],
         [1105924., 1114116., 1130500., ..., 1185796., 1146884.,
          1101828.],
         [1126404., 1134596., 1126404., ..., 1241092., 1222660.,
          1198084.],
         ...,
         [ 815108.,  843780.,  489476., ...,  821252.,  821252.,
           825348.],
         [ 800772.,  831492.,  557060., ...,  815108.,  806916.,
           802820.],
         [ 794628.,  819204.,  665604., ...,  813060.,  798724.,
           792580.]],

        [[1155076., 1159172., 1157124., ..., 1034244., 1048580.,
          1085444.],
         [1105924., 1114116., 1130500., ..., 1185796., 1146884.,
          1101828.],
         [1126404., 1134596., 1126404., ..., 1241092., 1222660.,
          1198084.],
         ...,
         [ 815108.,  843780.,  489476., ...,  821252.,  821252.,
           825348.],
         [ 800772.,  831492.,  557060., ...,  815108.,  806916.,
           802820.],
         [ 794628.,  819204.,  665604., ...,  813060.,  798724.,
           792580.]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [9, 7], 'to': [26]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        ...,

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[ 3.3901465e-01, -2.8686333e-01,  2.7455742e-02, ...,
           2.7876866e-01, -9.3030131e-01, -9.8450994e-01],
         [ 9.9107134e-01,  4.1767675e-01, -8.5481715e-01, ...,
           9.6047127e-01,  9.9881375e-01,  7.1752673e-01],
         [-9.9584210e-01, -3.7868780e-01, -9.9584210e-01, ...,
          -4.4483137e-01,  6.7198604e-01, -5.7526536e-02],
         ...,
         [ 2.0368704e-01, -9.9877393e-01, -1.5596807e-01, ...,
           9.1694397e-01,  9.1694397e-01,  9.7448599e-01],
         [-8.9915907e-01,  3.7943825e-01, -7.9931188e-01, ...,
           2.0368704e-01, -8.7648803e-01, -9.9096286e-01],
         [-1.6189797e-01,  7.4593842e-01,  8.6626112e-01, ...,
          -1.1304552e-01, -7.1696162e-01,  1.5516695e-01]],

        [[ 3.3901465e-01, -2.8686333e-01,  2.7455742e-02, ...,
           2.7876866e-01, -9.3030131e-01, -9.8450994e-01],
         [ 9.9107134e-01,  4.1767675e-01, -8.5481715e-01, ...,
           9.6047127e-01,  9.9881375e-01,  7.1752673e-01],
         [-9.9584210e-01, -3.7868780e-01, -9.9584210e-01, ...,
          -4.4483137e-01,  6.7198604e-01, -5.7526536e-02],
         ...,
         [ 2.0368704e-01, -9.9877393e-01, -1.5596807e-01, ...,
           9.1694397e-01,  9.1694397e-01,  9.7448599e-01],
         [-8.9915907e-01,  3.7943825e-01, -7.9931188e-01, ...,
           2.0368704e-01, -8.7648803e-01, -9.9096286e-01],
         [-1.6189797e-01,  7.4593842e-01,  8.6626112e-01, ...,
          -1.1304552e-01, -7.1696162e-01,  1.5516695e-01]],

        [[ 3.3901465e-01, -2.8686333e-01,  2.7455742e-02, ...,
           2.7876866e-01, -9.3030131e-01, -9.8450994e-01],
         [ 9.9107134e-01,  4.1767675e-01, -8.5481715e-01, ...,
           9.6047127e-01,  9.9881375e-01,  7.1752673e-01],
         [-9.9584210e-01, -3.7868780e-01, -9.9584210e-01, ...,
          -4.4483137e-01,  6.7198604e-01, -5.7526536e-02],
         ...,
         [ 2.0368704e-01, -9.9877393e-01, -1.5596807e-01, ...,
           9.1694397e-01,  9.1694397e-01,  9.7448599e-01],
         [-8.9915907e-01,  3.7943825e-01, -7.9931188e-01, ...,
           2.0368704e-01, -8.7648803e-01, -9.9096286e-01],
         [-1.6189797e-01,  7.4593842e-01,  8.6626112e-01, ...,
          -1.1304552e-01, -7.1696162e-01,  1.5516695e-01]],

        ...,

        [[ 5.7753800e+05,  5.7958600e+05,  5.7856200e+05, ...,
           5.1712200e+05,  5.2429000e+05,  5.4272200e+05],
         [ 5.5296200e+05,  5.5705800e+05,  5.6525000e+05, ...,
           5.9289800e+05,  5.7344200e+05,  5.5091400e+05],
         [ 5.6320200e+05,  5.6729800e+05,  5.6320200e+05, ...,
           6.2054600e+05,  6.1133000e+05,  5.9904200e+05],
         ...,
         [ 4.0755400e+05,  4.2189000e+05,  2.4473800e+05, ...,
           4.1062600e+05,  4.1062600e+05,  4.1267400e+05],
         [ 4.0038600e+05,  4.1574600e+05,  2.7853000e+05, ...,
           4.0755400e+05,  4.0345800e+05,  4.0141000e+05],
         [ 3.9731400e+05,  4.0960200e+05,  3.3280200e+05, ...,
           4.0653000e+05,  3.9936200e+05,  3.9629000e+05]],

        [[ 5.7753800e+05,  5.7958600e+05,  5.7856200e+05, ...,
           5.1712200e+05,  5.2429000e+05,  5.4272200e+05],
         [ 5.5296200e+05,  5.5705800e+05,  5.6525000e+05, ...,
           5.9289800e+05,  5.7344200e+05,  5.5091400e+05],
         [ 5.6320200e+05,  5.6729800e+05,  5.6320200e+05, ...,
           6.2054600e+05,  6.1133000e+05,  5.9904200e+05],
         ...,
         [ 4.0755400e+05,  4.2189000e+05,  2.4473800e+05, ...,
           4.1062600e+05,  4.1062600e+05,  4.1267400e+05],
         [ 4.0038600e+05,  4.1574600e+05,  2.7853000e+05, ...,
           4.0755400e+05,  4.0345800e+05,  4.0141000e+05],
         [ 3.9731400e+05,  4.0960200e+05,  3.3280200e+05, ...,
           4.0653000e+05,  3.9936200e+05,  3.9629000e+05]],

        [[ 5.7753800e+05,  5.7958600e+05,  5.7856200e+05, ...,
           5.1712200e+05,  5.2429000e+05,  5.4272200e+05],
         [ 5.5296200e+05,  5.5705800e+05,  5.6525000e+05, ...,
           5.9289800e+05,  5.7344200e+05,  5.5091400e+05],
         [ 5.6320200e+05,  5.6729800e+05,  5.6320200e+05, ...,
           6.2054600e+05,  6.1133000e+05,  5.9904200e+05],
         ...,
         [ 4.0755400e+05,  4.2189000e+05,  2.4473800e+05, ...,
           4.1062600e+05,  4.1062600e+05,  4.1267400e+05],
         [ 4.0038600e+05,  4.1574600e+05,  2.7853000e+05, ...,
           4.0755400e+05,  4.0345800e+05,  4.0141000e+05],
         [ 3.9731400e+05,  4.0960200e+05,  3.3280200e+05, ...,
           4.0653000e+05,  3.9936200e+05,  3.9629000e+05]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [10], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        ...,

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]],

        [[ 0.33901465, -0.28686333,  0.02745574, ...,  0.27876866,
          -0.9303013 , -0.98450994],
         [ 0.99107134,  0.41767675, -0.85481715, ...,  0.9604713 ,
           0.99881375,  0.71752673],
         [-0.99584216, -0.3786878 , -0.99584216, ..., -0.44483137,
           0.67198604, -0.05752654],
         ...,
         [ 0.20368704, -0.99877393, -0.15596807, ...,  0.91694397,
           0.91694397,  0.974486  ],
         [-0.8991591 ,  0.37943825, -0.7993119 , ...,  0.20368704,
          -0.87648803, -0.99096286],
         [-0.16189797,  0.7459384 ,  0.8662611 , ..., -0.11304553,
          -0.7169616 ,  0.15516695]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10], 'to': []}

generate models:92

analyse output arrays in iter:194

pre layer res:
2:add
{'name': 'add', 'output': array([[[[1852417.6, 1846273.6, 1855489.6, ..., 1797121.6, 1778689.6,
          1778689.6],
         [1830913.6, 1824769.6, 1833985.6, ..., 1769473.6, 1751041.6,
          1757185.6],
         [1833985.6, 1824769.6, 1833985.6, ..., 1769473.6, 1751041.6,
          1760257.6],
         ...,
         [1806337.6, 1797121.6, 1806337.6, ..., 1296385.5, 1247233.5,
          1213441.5],
         [1806337.6, 1797121.6, 1806337.6, ..., 1299457.5, 1234945.5,
          1185793.5],
         [1806337.6, 1797121.6, 1806337.6, ..., 1296385.5, 1228801.5,
          1167361.5]],

        [[1852417.6, 1846273.6, 1855489.6, ..., 1797121.6, 1778689.6,
          1778689.6],
         [1830913.6, 1824769.6, 1833985.6, ..., 1769473.6, 1751041.6,
          1757185.6],
         [1833985.6, 1824769.6, 1833985.6, ..., 1769473.6, 1751041.6,
          1760257.6],
         ...,
         [1806337.6, 1797121.6, 1806337.6, ..., 1296385.5, 1247233.5,
          1213441.5],
         [1806337.6, 1797121.6, 1806337.6, ..., 1299457.5, 1234945.5,
          1185793.5],
         [1806337.6, 1797121.6, 1806337.6, ..., 1296385.5, 1228801.5,
          1167361.5]],

        [[1852417.6, 1846273.6, 1855489.6, ..., 1797121.6, 1778689.6,
          1778689.6],
         [1830913.6, 1824769.6, 1833985.6, ..., 1769473.6, 1751041.6,
          1757185.6],
         [1833985.6, 1824769.6, 1833985.6, ..., 1769473.6, 1751041.6,
          1760257.6],
         ...,
         [1806337.6, 1797121.6, 1806337.6, ..., 1296385.5, 1247233.5,
          1213441.5],
         [1806337.6, 1797121.6, 1806337.6, ..., 1299457.5, 1234945.5,
          1185793.5],
         [1806337.6, 1797121.6, 1806337.6, ..., 1296385.5, 1228801.5,
          1167361.5]],

        ...,

        [[1852416. , 1846272. , 1855488. , ..., 1797120. , 1778688. ,
          1778688. ],
         [1830912. , 1824768. , 1833984. , ..., 1769472. , 1751040. ,
          1757184. ],
         [1833984. , 1824768. , 1833984. , ..., 1769472. , 1751040. ,
          1760256. ],
         ...,
         [1806336. , 1797120. , 1806336. , ..., 1296384. , 1247232. ,
          1213440. ],
         [1806336. , 1797120. , 1806336. , ..., 1299456. , 1234944. ,
          1185792. ],
         [1806336. , 1797120. , 1806336. , ..., 1296384. , 1228800. ,
          1167360. ]],

        [[1852416. , 1846272. , 1855488. , ..., 1797120. , 1778688. ,
          1778688. ],
         [1830912. , 1824768. , 1833984. , ..., 1769472. , 1751040. ,
          1757184. ],
         [1833984. , 1824768. , 1833984. , ..., 1769472. , 1751040. ,
          1760256. ],
         ...,
         [1806336. , 1797120. , 1806336. , ..., 1296384. , 1247232. ,
          1213440. ],
         [1806336. , 1797120. , 1806336. , ..., 1299456. , 1234944. ,
          1185792. ],
         [1806336. , 1797120. , 1806336. , ..., 1296384. , 1228800. ,
          1167360. ]],

        [[1852416. , 1846272. , 1855488. , ..., 1797120. , 1778688. ,
          1778688. ],
         [1830912. , 1824768. , 1833984. , ..., 1769472. , 1751040. ,
          1757184. ],
         [1833984. , 1824768. , 1833984. , ..., 1769472. , 1751040. ,
          1760256. ],
         ...,
         [1806336. , 1797120. , 1806336. , ..., 1296384. , 1247232. ,
          1213440. ],
         [1806336. , 1797120. , 1806336. , ..., 1299456. , 1234944. ,
          1185792. ],
         [1806336. , 1797120. , 1806336. , ..., 1296384. , 1228800. ,
          1167360. ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [10, 3], 'to': [26]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.47242543, -0.44680405,  0.8246911 , ..., -0.9686517 ,
           0.99969125,  0.99969125],
         [-0.28626537,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9844003 ],
         [-0.6946563 ,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9551142 ],
         ...,
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
           0.6994472 ,  0.9729214 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.50613344,
          -0.90688723, -0.6028732 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
          -0.86768436,  0.7974148 ]],

        [[ 0.47242543, -0.44680405,  0.8246911 , ..., -0.9686517 ,
           0.99969125,  0.99969125],
         [-0.28626537,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9844003 ],
         [-0.6946563 ,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9551142 ],
         ...,
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
           0.6994472 ,  0.9729214 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.50613344,
          -0.90688723, -0.6028732 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
          -0.86768436,  0.7974148 ]],

        [[ 0.47242543, -0.44680405,  0.8246911 , ..., -0.9686517 ,
           0.99969125,  0.99969125],
         [-0.28626537,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9844003 ],
         [-0.6946563 ,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9551142 ],
         ...,
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
           0.6994472 ,  0.9729214 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.50613344,
          -0.90688723, -0.6028732 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
          -0.86768436,  0.7974148 ]],

        ...,

        [[ 0.8544816 ,  0.9175245 ,  0.52007335, ..., -0.19557902,
          -0.07897123, -0.07897123],
         [-0.9412341 , -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166, -0.12235292],
         [-0.68065083, -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166,  0.3475481 ],
         ...,
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
           0.76237094, -0.1617355 ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.8244923 ,
           0.3561672 , -0.838484  ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
          -0.55724776,  0.6583268 ]],

        [[ 0.8544816 ,  0.9175245 ,  0.52007335, ..., -0.19557902,
          -0.07897123, -0.07897123],
         [-0.9412341 , -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166, -0.12235292],
         [-0.68065083, -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166,  0.3475481 ],
         ...,
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
           0.76237094, -0.1617355 ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.8244923 ,
           0.3561672 , -0.838484  ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
          -0.55724776,  0.6583268 ]],

        [[ 0.8544816 ,  0.9175245 ,  0.52007335, ..., -0.19557902,
          -0.07897123, -0.07897123],
         [-0.9412341 , -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166, -0.12235292],
         [-0.68065083, -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166,  0.3475481 ],
         ...,
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
           0.76237094, -0.1617355 ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.8244923 ,
           0.3561672 , -0.838484  ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
          -0.55724776,  0.6583268 ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [2], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[ 4.7242543e-01, -4.4680405e-01,  8.2469112e-01, ...,
          -9.6865171e-01,  9.9969125e-01,  9.9969125e-01],
         [-2.8626537e-01,  6.1698329e-01, -6.9465631e-01, ...,
           1.6208237e-01, -4.2476469e-01, -9.8440027e-01],
         [-6.9465631e-01,  6.1698329e-01, -6.9465631e-01, ...,
           1.6208237e-01, -4.2476469e-01, -9.5511419e-01],
         ...,
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           8.4593225e-01,  6.9944721e-01,  9.7292137e-01],
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           5.0613344e-01, -9.0688723e-01, -6.0287321e-01],
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           8.4593225e-01, -8.6768436e-01,  7.9741478e-01]],

        [[ 4.7242543e-01, -4.4680405e-01,  8.2469112e-01, ...,
          -9.6865171e-01,  9.9969125e-01,  9.9969125e-01],
         [-2.8626537e-01,  6.1698329e-01, -6.9465631e-01, ...,
           1.6208237e-01, -4.2476469e-01, -9.8440027e-01],
         [-6.9465631e-01,  6.1698329e-01, -6.9465631e-01, ...,
           1.6208237e-01, -4.2476469e-01, -9.5511419e-01],
         ...,
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           8.4593225e-01,  6.9944721e-01,  9.7292137e-01],
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           5.0613344e-01, -9.0688723e-01, -6.0287321e-01],
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           8.4593225e-01, -8.6768436e-01,  7.9741478e-01]],

        [[ 4.7242543e-01, -4.4680405e-01,  8.2469112e-01, ...,
          -9.6865171e-01,  9.9969125e-01,  9.9969125e-01],
         [-2.8626537e-01,  6.1698329e-01, -6.9465631e-01, ...,
           1.6208237e-01, -4.2476469e-01, -9.8440027e-01],
         [-6.9465631e-01,  6.1698329e-01, -6.9465631e-01, ...,
           1.6208237e-01, -4.2476469e-01, -9.5511419e-01],
         ...,
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           8.4593225e-01,  6.9944721e-01,  9.7292137e-01],
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           5.0613344e-01, -9.0688723e-01, -6.0287321e-01],
         [-3.7926537e-01, -9.6865171e-01, -3.7926537e-01, ...,
           8.4593225e-01, -8.6768436e-01,  7.9741478e-01]],

        ...,

        [[ 3.0873600e+05,  3.0771200e+05,  3.0924800e+05, ...,
           2.9952000e+05,  2.9644800e+05,  2.9644800e+05],
         [ 3.0515200e+05,  3.0412800e+05,  3.0566400e+05, ...,
           2.9491200e+05,  2.9184000e+05,  2.9286400e+05],
         [ 3.0566400e+05,  3.0412800e+05,  3.0566400e+05, ...,
           2.9491200e+05,  2.9184000e+05,  2.9337600e+05],
         ...,
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1606400e+05,  2.0787200e+05,  2.0224000e+05],
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1657600e+05,  2.0582400e+05,  1.9763200e+05],
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1606400e+05,  2.0480000e+05,  1.9456000e+05]],

        [[ 3.0873600e+05,  3.0771200e+05,  3.0924800e+05, ...,
           2.9952000e+05,  2.9644800e+05,  2.9644800e+05],
         [ 3.0515200e+05,  3.0412800e+05,  3.0566400e+05, ...,
           2.9491200e+05,  2.9184000e+05,  2.9286400e+05],
         [ 3.0566400e+05,  3.0412800e+05,  3.0566400e+05, ...,
           2.9491200e+05,  2.9184000e+05,  2.9337600e+05],
         ...,
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1606400e+05,  2.0787200e+05,  2.0224000e+05],
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1657600e+05,  2.0582400e+05,  1.9763200e+05],
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1606400e+05,  2.0480000e+05,  1.9456000e+05]],

        [[ 3.0873600e+05,  3.0771200e+05,  3.0924800e+05, ...,
           2.9952000e+05,  2.9644800e+05,  2.9644800e+05],
         [ 3.0515200e+05,  3.0412800e+05,  3.0566400e+05, ...,
           2.9491200e+05,  2.9184000e+05,  2.9286400e+05],
         [ 3.0566400e+05,  3.0412800e+05,  3.0566400e+05, ...,
           2.9491200e+05,  2.9184000e+05,  2.9337600e+05],
         ...,
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1606400e+05,  2.0787200e+05,  2.0224000e+05],
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1657600e+05,  2.0582400e+05,  1.9763200e+05],
         [ 3.0105600e+05,  2.9952000e+05,  3.0105600e+05, ...,
           2.1606400e+05,  2.0480000e+05,  1.9456000e+05]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [2], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[ 0.47242543, -0.44680405,  0.8246911 , ..., -0.9686517 ,
           0.99969125,  0.99969125],
         [-0.28626537,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9844003 ],
         [-0.6946563 ,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9551142 ],
         ...,
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
           0.6994472 ,  0.9729214 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.50613344,
          -0.90688723, -0.6028732 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
          -0.86768436,  0.7974148 ]],

        [[ 0.47242543, -0.44680405,  0.8246911 , ..., -0.9686517 ,
           0.99969125,  0.99969125],
         [-0.28626537,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9844003 ],
         [-0.6946563 ,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9551142 ],
         ...,
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
           0.6994472 ,  0.9729214 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.50613344,
          -0.90688723, -0.6028732 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
          -0.86768436,  0.7974148 ]],

        [[ 0.47242543, -0.44680405,  0.8246911 , ..., -0.9686517 ,
           0.99969125,  0.99969125],
         [-0.28626537,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9844003 ],
         [-0.6946563 ,  0.6169833 , -0.6946563 , ...,  0.16208237,
          -0.4247647 , -0.9551142 ],
         ...,
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
           0.6994472 ,  0.9729214 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.50613344,
          -0.90688723, -0.6028732 ],
         [-0.37926537, -0.9686517 , -0.37926537, ...,  0.84593225,
          -0.86768436,  0.7974148 ]],

        ...,

        [[ 0.8544816 ,  0.9175245 ,  0.52007335, ..., -0.19557902,
          -0.07897123, -0.07897123],
         [-0.9412341 , -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166, -0.12235292],
         [-0.68065083, -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166,  0.3475481 ],
         ...,
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
           0.76237094, -0.1617355 ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.8244923 ,
           0.3561672 , -0.838484  ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
          -0.55724776,  0.6583268 ]],

        [[ 0.8544816 ,  0.9175245 ,  0.52007335, ..., -0.19557902,
          -0.07897123, -0.07897123],
         [-0.9412341 , -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166, -0.12235292],
         [-0.68065083, -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166,  0.3475481 ],
         ...,
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
           0.76237094, -0.1617355 ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.8244923 ,
           0.3561672 , -0.838484  ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
          -0.55724776,  0.6583268 ]],

        [[ 0.8544816 ,  0.9175245 ,  0.52007335, ..., -0.19557902,
          -0.07897123, -0.07897123],
         [-0.9412341 , -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166, -0.12235292],
         [-0.68065083, -0.8192468 , -0.68065083, ...,  0.9765468 ,
          -0.88096166,  0.3475481 ],
         ...,
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
           0.76237094, -0.1617355 ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.8244923 ,
           0.3561672 , -0.838484  ],
         [ 0.94447654, -0.19557902,  0.94447654, ..., -0.4721156 ,
          -0.55724776,  0.6583268 ]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [2], 'to': []}

generate models:97

analyse output arrays in iter:198

pre layer res:
6:add
{'name': 'add', 'output': array([[[[5.00000e-01, 5.00000e-01, 5.00000e-01, ..., 6.65700e+03,
          6.65700e+03, 6.65700e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 8.19300e+03,
          8.19300e+03, 8.19300e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 1.12650e+04,
          1.12650e+04, 1.12650e+04],
         ...,
         [4.81290e+04, 5.01770e+04, 5.47850e+04, ..., 1.17761e+05,
          1.19297e+05, 1.17761e+05],
         [4.45450e+04, 4.81290e+04, 5.06890e+04, ..., 1.16737e+05,
          1.14177e+05, 1.10593e+05],
         [3.84010e+04, 4.40330e+04, 5.01770e+04, ..., 1.02913e+05,
          1.02913e+05, 1.00353e+05]],

        [[5.00000e-01, 5.00000e-01, 5.00000e-01, ..., 6.65700e+03,
          6.65700e+03, 6.65700e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 8.19300e+03,
          8.19300e+03, 8.19300e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 1.12650e+04,
          1.12650e+04, 1.12650e+04],
         ...,
         [4.81290e+04, 5.01770e+04, 5.47850e+04, ..., 1.17761e+05,
          1.19297e+05, 1.17761e+05],
         [4.45450e+04, 4.81290e+04, 5.06890e+04, ..., 1.16737e+05,
          1.14177e+05, 1.10593e+05],
         [3.84010e+04, 4.40330e+04, 5.01770e+04, ..., 1.02913e+05,
          1.02913e+05, 1.00353e+05]],

        [[5.00000e-01, 5.00000e-01, 5.00000e-01, ..., 6.65700e+03,
          6.65700e+03, 6.65700e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 8.19300e+03,
          8.19300e+03, 8.19300e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 1.12650e+04,
          1.12650e+04, 1.12650e+04],
         ...,
         [4.81290e+04, 5.01770e+04, 5.47850e+04, ..., 1.17761e+05,
          1.19297e+05, 1.17761e+05],
         [4.45450e+04, 4.81290e+04, 5.06890e+04, ..., 1.16737e+05,
          1.14177e+05, 1.10593e+05],
         [3.84010e+04, 4.40330e+04, 5.01770e+04, ..., 1.02913e+05,
          1.02913e+05, 1.00353e+05]],

        ...,

        [[5.00000e-01, 5.00000e-01, 5.00000e-01, ..., 6.65700e+03,
          6.65700e+03, 6.65700e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 8.19300e+03,
          8.19300e+03, 8.19300e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 1.12650e+04,
          1.12650e+04, 1.12650e+04],
         ...,
         [4.81290e+04, 5.01770e+04, 5.47850e+04, ..., 1.17761e+05,
          1.19297e+05, 1.17761e+05],
         [4.45450e+04, 4.81290e+04, 5.06890e+04, ..., 1.16737e+05,
          1.14177e+05, 1.10593e+05],
         [3.84010e+04, 4.40330e+04, 5.01770e+04, ..., 1.02913e+05,
          1.02913e+05, 1.00353e+05]],

        [[5.00000e-01, 5.00000e-01, 5.00000e-01, ..., 6.65700e+03,
          6.65700e+03, 6.65700e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 8.19300e+03,
          8.19300e+03, 8.19300e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 1.12650e+04,
          1.12650e+04, 1.12650e+04],
         ...,
         [4.81290e+04, 5.01770e+04, 5.47850e+04, ..., 1.17761e+05,
          1.19297e+05, 1.17761e+05],
         [4.45450e+04, 4.81290e+04, 5.06890e+04, ..., 1.16737e+05,
          1.14177e+05, 1.10593e+05],
         [3.84010e+04, 4.40330e+04, 5.01770e+04, ..., 1.02913e+05,
          1.02913e+05, 1.00353e+05]],

        [[5.00000e-01, 5.00000e-01, 5.00000e-01, ..., 6.65700e+03,
          6.65700e+03, 6.65700e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 8.19300e+03,
          8.19300e+03, 8.19300e+03],
         [5.00000e-01, 5.00000e-01, 1.53700e+03, ..., 1.12650e+04,
          1.12650e+04, 1.12650e+04],
         ...,
         [4.81290e+04, 5.01770e+04, 5.47850e+04, ..., 1.17761e+05,
          1.19297e+05, 1.17761e+05],
         [4.45450e+04, 4.81290e+04, 5.06890e+04, ..., 1.16737e+05,
          1.14177e+05, 1.10593e+05],
         [3.84010e+04, 4.40330e+04, 5.01770e+04, ..., 1.02913e+05,
          1.02913e+05, 1.00353e+05]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [3, 7], 'to': [8, 2]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        ...,

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [6], 'to': [8]}
ms node:
{'name': 'sin', 'output': array([[[[ 4.7942555e-01,  4.7942555e-01,  4.7942555e-01, ...,
           3.4825914e-02,  3.4825914e-02,  3.4825914e-02],
         [ 4.7942555e-01,  4.7942555e-01, -6.8978524e-01, ...,
          -2.7023834e-01, -2.7023834e-01, -2.7023834e-01],
         [ 4.7942555e-01,  4.7942555e-01, -6.8978524e-01, ...,
          -6.8255705e-01, -6.8255705e-01, -6.8255705e-01],
         ...,
         [-1.9813320e-01, -4.9502459e-01,  9.4391268e-01, ...,
           9.9955529e-01, -9.6413511e-01,  9.9955529e-01],
         [-3.5018140e-01, -1.9813320e-01,  5.6254900e-01, ...,
           9.9164188e-01, -8.6412144e-01,  4.6725577e-01],
         [-9.6695292e-01,  4.2355603e-01, -4.9502459e-01, ...,
           6.5020460e-01,  6.5020460e-01, -8.9385295e-01]],

        [[ 4.7942555e-01,  4.7942555e-01,  4.7942555e-01, ...,
           3.4825914e-02,  3.4825914e-02,  3.4825914e-02],
         [ 4.7942555e-01,  4.7942555e-01, -6.8978524e-01, ...,
          -2.7023834e-01, -2.7023834e-01, -2.7023834e-01],
         [ 4.7942555e-01,  4.7942555e-01, -6.8978524e-01, ...,
          -6.8255705e-01, -6.8255705e-01, -6.8255705e-01],
         ...,
         [-1.9813320e-01, -4.9502459e-01,  9.4391268e-01, ...,
           9.9955529e-01, -9.6413511e-01,  9.9955529e-01],
         [-3.5018140e-01, -1.9813320e-01,  5.6254900e-01, ...,
           9.9164188e-01, -8.6412144e-01,  4.6725577e-01],
         [-9.6695292e-01,  4.2355603e-01, -4.9502459e-01, ...,
           6.5020460e-01,  6.5020460e-01, -8.9385295e-01]],

        [[ 4.7942555e-01,  4.7942555e-01,  4.7942555e-01, ...,
           3.4825914e-02,  3.4825914e-02,  3.4825914e-02],
         [ 4.7942555e-01,  4.7942555e-01, -6.8978524e-01, ...,
          -2.7023834e-01, -2.7023834e-01, -2.7023834e-01],
         [ 4.7942555e-01,  4.7942555e-01, -6.8978524e-01, ...,
          -6.8255705e-01, -6.8255705e-01, -6.8255705e-01],
         ...,
         [-1.9813320e-01, -4.9502459e-01,  9.4391268e-01, ...,
           9.9955529e-01, -9.6413511e-01,  9.9955529e-01],
         [-3.5018140e-01, -1.9813320e-01,  5.6254900e-01, ...,
           9.9164188e-01, -8.6412144e-01,  4.6725577e-01],
         [-9.6695292e-01,  4.2355603e-01, -4.9502459e-01, ...,
           6.5020460e-01,  6.5020460e-01, -8.9385295e-01]],

        ...,

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           6.6560000e+03,  6.6560000e+03,  6.6560000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  1.5360000e+03, ...,
           8.1920000e+03,  8.1920000e+03,  8.1920000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  1.5360000e+03, ...,
           1.1264000e+04,  1.1264000e+04,  1.1264000e+04],
         ...,
         [ 4.8128000e+04,  5.0176000e+04,  5.4784000e+04, ...,
           1.1776000e+05,  1.1929600e+05,  1.1776000e+05],
         [ 4.4544000e+04,  4.8128000e+04,  5.0688000e+04, ...,
           1.1673600e+05,  1.1417600e+05,  1.1059200e+05],
         [ 3.8400000e+04,  4.4032000e+04,  5.0176000e+04, ...,
           1.0291200e+05,  1.0291200e+05,  1.0035200e+05]],

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           6.6560000e+03,  6.6560000e+03,  6.6560000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  1.5360000e+03, ...,
           8.1920000e+03,  8.1920000e+03,  8.1920000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  1.5360000e+03, ...,
           1.1264000e+04,  1.1264000e+04,  1.1264000e+04],
         ...,
         [ 4.8128000e+04,  5.0176000e+04,  5.4784000e+04, ...,
           1.1776000e+05,  1.1929600e+05,  1.1776000e+05],
         [ 4.4544000e+04,  4.8128000e+04,  5.0688000e+04, ...,
           1.1673600e+05,  1.1417600e+05,  1.1059200e+05],
         [ 3.8400000e+04,  4.4032000e+04,  5.0176000e+04, ...,
           1.0291200e+05,  1.0291200e+05,  1.0035200e+05]],

        [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,
           6.6560000e+03,  6.6560000e+03,  6.6560000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  1.5360000e+03, ...,
           8.1920000e+03,  8.1920000e+03,  8.1920000e+03],
         [ 0.0000000e+00,  0.0000000e+00,  1.5360000e+03, ...,
           1.1264000e+04,  1.1264000e+04,  1.1264000e+04],
         ...,
         [ 4.8128000e+04,  5.0176000e+04,  5.4784000e+04, ...,
           1.1776000e+05,  1.1929600e+05,  1.1776000e+05],
         [ 4.4544000e+04,  4.8128000e+04,  5.0688000e+04, ...,
           1.1673600e+05,  1.1417600e+05,  1.1059200e+05],
         [ 3.8400000e+04,  4.4032000e+04,  5.0176000e+04, ...,
           1.0291200e+05,  1.0291200e+05,  1.0035200e+05]]]],
      dtype=float32), 'output_shape': (1, 128, 32, 32), 'from': [6], 'to': [8]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        ...,

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]],

        [[ 0.47942555,  0.47942555,  0.47942555, ...,  0.03482591,
           0.03482591,  0.03482591],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.27023834,
          -0.27023834, -0.27023834],
         [ 0.47942555,  0.47942555, -0.68978524, ..., -0.68255705,
          -0.68255705, -0.68255705],
         ...,
         [-0.1981332 , -0.4950246 ,  0.9439127 , ...,  0.9995553 ,
          -0.9641351 ,  0.9995553 ],
         [-0.3501814 , -0.1981332 ,  0.562549  , ...,  0.9916419 ,
          -0.86412144,  0.46725577],
         [-0.9669529 ,  0.42355603, -0.4950246 , ...,  0.6502046 ,
           0.6502046 , -0.89385295]]]], dtype=float32), 'output_shape': torch.Size([1, 128, 32, 32]), 'from': [6], 'to': [8]}

generate models:98

final statics:
total operators:28
tensorflow --> nums:3,distinct_bugs:2
mindspore --> nums:14,distinct_bugs:3
torch --> nums:3,distinct_bugs:2
tensorflow --> 
softmax:2
log:1
mindspore --> 
sin:11
softmax:2
log:1
torch --> 
softmax:2
log:1

generate models:100

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

analyse output arrays in iter:15

pre layer res:
2:add
{'name': 'add', 'output': array([[[[1021952.  , 1017856.1 , 1019904.  , ..., 1005568.  ,
           997376.06, 1005568.1 ],
         [1030144.  , 1021952.1 , 1019904.  , ..., 1009664.  ,
          1003520.06, 1011712.1 ],
         [1052672.  , 1040384.1 , 1040384.  , ..., 1024000.  ,
          1024000.06, 1034240.1 ],
         ...,
         [1064960.  , 1015808.06, 1052672.  , ...,  708608.06,
           720896.06,  716800.06],
         [1032192.06, 1107968.  , 1153026.  , ...,  714752.06,
           710656.06,  720896.06],
         [1046528.06, 1044480.06, 1024000.06, ...,  823296.06,
           966656.06, 1124354.  ]],

        [[1021952.06, 1017856.06, 1019904.06, ..., 1005568.06,
           997376.06, 1005568.06],
         [1030144.06, 1021952.06, 1019904.06, ..., 1009664.06,
          1003520.06, 1011712.06],
         [1052672.  , 1040384.06, 1040384.06, ..., 1024000.06,
          1024000.06, 1034240.06],
         ...,
         [1064960.  , 1015808.06, 1052672.  , ...,  708608.06,
           720896.06,  716800.06],
         [1032192.06, 1107968.  , 1153026.  , ...,  714752.06,
           710656.06,  720896.06],
         [1046528.06, 1044480.06, 1024000.06, ...,  823296.06,
           966656.06, 1124354.  ]],

        [[1021952.06, 1017856.06, 1019904.06, ..., 1005568.06,
           997376.06, 1005568.06],
         [1030144.06, 1021952.06, 1019904.06, ..., 1009664.06,
          1003520.06, 1011712.06],
         [1052672.  , 1040384.06, 1040384.06, ..., 1024000.06,
          1024000.06, 1034240.06],
         ...,
         [1064960.  , 1015808.06, 1052672.  , ...,  708608.06,
           720896.06,  716800.06],
         [1032192.06, 1107968.  , 1153026.  , ...,  714752.06,
           710656.06,  720896.06],
         [1046528.06, 1044480.06, 1024000.06, ...,  823296.06,
           966656.06, 1124354.  ]],

        [[1021952.06, 1017856.06, 1019904.06, ..., 1005568.06,
           997376.06, 1005568.06],
         [1030144.06, 1021952.06, 1019904.06, ..., 1009664.06,
          1003520.06, 1011712.06],
         [1052672.  , 1040384.06, 1040384.06, ..., 1024000.06,
          1024000.06, 1034240.06],
         ...,
         [1064960.  , 1015808.06, 1052672.  , ...,  708608.06,
           720896.06,  716800.06],
         [1032192.06, 1107968.  , 1153026.  , ...,  714752.06,
           710656.06,  720896.06],
         [1046528.06, 1044480.06, 1024000.06, ...,  823296.06,
           966656.06, 1124354.  ]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [7, 7], 'to': [4]}
tf node:
{'name': 'sin', 'output': array([[[[-0.9722269 , -0.8650285 , -0.9966252 , ...,  0.6744752 ,
           0.874885  ,  0.7612598 ],
         [-0.06088696, -0.9938202 , -0.9966252 , ...,  0.10324906,
           0.9006069 , -0.0898554 ],
         [-0.2955147 ,  0.9864725 ,  0.9992132 , ..., -0.85008943,
          -0.8813231 ,  0.43577185],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]],

        [[-0.98494667, -0.8946768 , -0.98955226, ...,  0.7192719 ,
           0.874885  ,  0.7192719 ],
         [-0.12311151, -0.98494667, -0.98955226, ...,  0.16517298,
           0.9006069 , -0.15188661],
         [-0.2955147 ,  0.99478513,  0.99478513, ..., -0.8813231 ,
          -0.8813231 ,  0.49113795],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]],

        [[-0.98494667, -0.8946768 , -0.98955226, ...,  0.7192719 ,
           0.874885  ,  0.7192719 ],
         [-0.12311151, -0.98494667, -0.98955226, ...,  0.16517298,
           0.9006069 , -0.15188661],
         [-0.2955147 ,  0.99478513,  0.99478513, ..., -0.8813231 ,
          -0.8813231 ,  0.49113795],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]],

        [[-0.98494667, -0.8946768 , -0.98955226, ...,  0.7192719 ,
           0.874885  ,  0.7192719 ],
         [-0.12311151, -0.98494667, -0.98955226, ...,  0.16517298,
           0.9006069 , -0.15188661],
         [-0.2955147 ,  0.99478513,  0.99478513, ..., -0.8813231 ,
          -0.8813231 ,  0.49113795],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [2], 'to': [6, 6]}
ms node:
{'name': 'sin', 'output': array([[[[-9.8494667e-01, -8.6502850e-01, -9.9662519e-01, ...,
           6.7447519e-01,  8.7488502e-01,  7.6125979e-01],
         [-1.2311151e-01, -9.9382019e-01, -9.9662519e-01, ...,
           1.0324906e-01,  9.0060687e-01, -8.9855395e-02],
         [-2.9551470e-01,  9.8647249e-01,  9.9921322e-01, ...,
          -8.5008943e-01, -8.8132310e-01,  4.3577185e-01],
         ...,
         [-8.0229950e-01, -7.0985830e-01, -2.9551470e-01, ...,
           1.5108497e-01,  8.8170600e-01,  9.8943496e-01],
         [ 1.9375232e-01, -5.0355613e-01, -9.7249669e-01, ...,
           8.9431423e-01,  4.5295393e-01,  8.8170600e-01],
         [ 6.5768105e-01,  8.6044699e-01, -8.8132310e-01, ...,
          -7.6234072e-01,  5.3909397e-01,  1.9569963e-02]],

        [[-9.8494667e-01, -8.9467680e-01, -9.8955226e-01, ...,
           7.1927190e-01,  8.7488502e-01,  7.1927190e-01],
         [-1.2311151e-01, -9.8494667e-01, -9.8955226e-01, ...,
           1.6517298e-01,  9.0060687e-01, -1.5188661e-01],
         [-2.9551470e-01,  9.9478513e-01,  9.9478513e-01, ...,
          -8.8132310e-01, -8.8132310e-01,  4.9113795e-01],
         ...,
         [-8.0229950e-01, -7.0985830e-01, -2.9551470e-01, ...,
           1.5108497e-01,  8.8170600e-01,  9.8943496e-01],
         [ 1.9375232e-01, -5.0355613e-01, -9.7249669e-01, ...,
           8.9431423e-01,  4.5295393e-01,  8.8170600e-01],
         [ 6.5768105e-01,  8.6044699e-01, -8.8132310e-01, ...,
          -7.6234072e-01,  5.3909397e-01,  1.9569963e-02]],

        [[ 5.1097603e+05,  5.0892803e+05,  5.0995203e+05, ...,
           5.0278403e+05,  4.9868803e+05,  5.0278403e+05],
         [ 5.1507203e+05,  5.1097603e+05,  5.0995203e+05, ...,
           5.0483203e+05,  5.0176003e+05,  5.0585603e+05],
         [ 5.2633600e+05,  5.2019203e+05,  5.2019203e+05, ...,
           5.1200003e+05,  5.1200003e+05,  5.1712003e+05],
         ...,
         [ 5.3248000e+05,  5.0790403e+05,  5.2633600e+05, ...,
           3.5430403e+05,  3.6044803e+05,  3.5840003e+05],
         [ 5.1609603e+05,  5.5398400e+05,  5.7651300e+05, ...,
           3.5737603e+05,  3.5532803e+05,  3.6044803e+05],
         [ 5.2326403e+05,  5.2224003e+05,  5.1200003e+05, ...,
           4.1164803e+05,  4.8332803e+05,  5.6217700e+05]],

        [[ 5.1097603e+05,  5.0892803e+05,  5.0995203e+05, ...,
           5.0278403e+05,  4.9868803e+05,  5.0278403e+05],
         [ 5.1507203e+05,  5.1097603e+05,  5.0995203e+05, ...,
           5.0483203e+05,  5.0176003e+05,  5.0585603e+05],
         [ 5.2633600e+05,  5.2019203e+05,  5.2019203e+05, ...,
           5.1200003e+05,  5.1200003e+05,  5.1712003e+05],
         ...,
         [ 5.3248000e+05,  5.0790403e+05,  5.2633600e+05, ...,
           3.5430403e+05,  3.6044803e+05,  3.5840003e+05],
         [ 5.1609603e+05,  5.5398400e+05,  5.7651300e+05, ...,
           3.5737603e+05,  3.5532803e+05,  3.6044803e+05],
         [ 5.2326403e+05,  5.2224003e+05,  5.1200003e+05, ...,
           4.1164803e+05,  4.8332803e+05,  5.6217700e+05]]]],
      dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [2], 'to': [6, 6]}
torch node:
{'name': 'sin', 'output': array([[[[-0.9722269 , -0.8650285 , -0.9966252 , ...,  0.6744752 ,
           0.874885  ,  0.7612598 ],
         [-0.06088696, -0.9938202 , -0.9966252 , ...,  0.10324906,
           0.9006069 , -0.0898554 ],
         [-0.2955147 ,  0.9864725 ,  0.9992132 , ..., -0.85008943,
          -0.8813231 ,  0.43577185],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]],

        [[-0.98494667, -0.8946768 , -0.98955226, ...,  0.7192719 ,
           0.874885  ,  0.7192719 ],
         [-0.12311151, -0.98494667, -0.98955226, ...,  0.16517298,
           0.9006069 , -0.15188661],
         [-0.2955147 ,  0.99478513,  0.99478513, ..., -0.8813231 ,
          -0.8813231 ,  0.49113795],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]],

        [[-0.98494667, -0.8946768 , -0.98955226, ...,  0.7192719 ,
           0.874885  ,  0.7192719 ],
         [-0.12311151, -0.98494667, -0.98955226, ...,  0.16517298,
           0.9006069 , -0.15188661],
         [-0.2955147 ,  0.99478513,  0.99478513, ..., -0.8813231 ,
          -0.8813231 ,  0.49113795],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]],

        [[-0.98494667, -0.8946768 , -0.98955226, ...,  0.7192719 ,
           0.874885  ,  0.7192719 ],
         [-0.12311151, -0.98494667, -0.98955226, ...,  0.16517298,
           0.9006069 , -0.15188661],
         [-0.2955147 ,  0.99478513,  0.99478513, ..., -0.8813231 ,
          -0.8813231 ,  0.49113795],
         ...,
         [-0.8022995 , -0.7098583 , -0.2955147 , ...,  0.15108497,
           0.881706  ,  0.98943496],
         [ 0.19375232, -0.50355613, -0.9724967 , ...,  0.8943142 ,
           0.45295393,  0.881706  ],
         [ 0.65768105,  0.860447  , -0.8813231 , ..., -0.7623407 ,
           0.539094  ,  0.01956996]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [2], 'to': [6, 6]}

pre layer res:
12:reshape
{'name': 'reshape', 'output': array([[[[16214016., 16284673., 16461825., ...,  8740865., 10210305.,
          10823681.],
         [16214016., 16284673., 16461825., ...,  8740865., 10210305.,
          10823681.],
         [16214016., 16284673., 16461825., ...,  8740865., 10210305.,
          10823681.],
         ...,
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.]],

        [[       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         ...,
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.]],

        [[       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         ...,
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.]],

        [[       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         ...,
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.],
         [       0.,        0.,        0., ...,        0.,        0.,
                 0.]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [11], 'to': [14]}
tf node:
{'name': 'sin', 'output': array([[[[-0.9624193 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         [-0.9624193 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         [-0.9624193 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [12], 'to': [5]}
ms node:
{'name': 'sin', 'output': array([[[[-0.2914808 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         [-0.2914808 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         [-0.2914808 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': (1, 4, 32, 32), 'from': [12], 'to': [5]}
torch node:
{'name': 'sin', 'output': array([[[[-0.9624193 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         [-0.9624193 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         [-0.9624193 ,  0.9595632 , -0.9019611 , ..., -0.72183734,
          -0.07047591,  0.865187  ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': torch.Size([1, 4, 32, 32]), 'from': [12], 'to': [5]}

generate models:14

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:2,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
torch --> 

generate models:24

analyse output arrays in iter:69

pre layer res:
16:add
{'name': 'add', 'output': array([[[[3.8173019e+12, 3.9139517e+12, 3.8654745e+12, ...,
          1.5915616e+12, 1.4699550e+12, 1.4109664e+12],
         [3.7694496e+12, 3.8654695e+12, 3.8173150e+12, ...,
          1.5606988e+12, 1.4109623e+12, 1.4109623e+12],
         [3.8013134e+12, 3.9139389e+12, 3.8493770e+12, ...,
          1.6859322e+12, 1.3819297e+12, 1.3531903e+12],
         ...,
         [3.7535547e+12, 3.8493912e+12, 3.7853683e+12, ...,
          1.3819289e+12, 1.5301479e+12, 1.5915525e+12],
         [3.7218851e+12, 3.8493786e+12, 3.7535595e+12, ...,
          1.5301479e+12, 1.5607075e+12, 1.5915609e+12],
         [3.7218718e+12, 3.8493786e+12, 3.7535545e+12, ...,
          1.5301529e+12, 1.5607045e+12, 1.6227066e+12]],

        [[3.8173019e+12, 3.9139517e+12, 3.8654745e+12, ...,
          1.5915616e+12, 1.4699550e+12, 1.4109664e+12],
         [3.7694496e+12, 3.8654695e+12, 3.8173150e+12, ...,
          1.5606988e+12, 1.4109623e+12, 1.4109623e+12],
         [3.8013134e+12, 3.9139389e+12, 3.8493770e+12, ...,
          1.6859322e+12, 1.3819297e+12, 1.3531903e+12],
         ...,
         [3.7535547e+12, 3.8493912e+12, 3.7853683e+12, ...,
          1.3819289e+12, 1.5301479e+12, 1.5915525e+12],
         [3.7218851e+12, 3.8493786e+12, 3.7535595e+12, ...,
          1.5301479e+12, 1.5607075e+12, 1.5915609e+12],
         [3.7218718e+12, 3.8493786e+12, 3.7535545e+12, ...,
          1.5301529e+12, 1.5607045e+12, 1.6227066e+12]],

        [[3.8173019e+12, 3.9139517e+12, 3.8654745e+12, ...,
          1.5915616e+12, 1.4699550e+12, 1.4109664e+12],
         [3.7694496e+12, 3.8654695e+12, 3.8173150e+12, ...,
          1.5606988e+12, 1.4109623e+12, 1.4109623e+12],
         [3.8013134e+12, 3.9139389e+12, 3.8493770e+12, ...,
          1.6859322e+12, 1.3819297e+12, 1.3531903e+12],
         ...,
         [3.7535547e+12, 3.8493912e+12, 3.7853683e+12, ...,
          1.3819289e+12, 1.5301479e+12, 1.5915525e+12],
         [3.7218851e+12, 3.8493786e+12, 3.7535595e+12, ...,
          1.5301479e+12, 1.5607075e+12, 1.5915609e+12],
         [3.7218718e+12, 3.8493786e+12, 3.7535545e+12, ...,
          1.5301529e+12, 1.5607045e+12, 1.6227066e+12]],

        ...,

        [[6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         ...,
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00]],

        [[6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         ...,
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00]],

        [[6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         ...,
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00],
         [6.0000000e+00, 6.0000000e+00, 6.0000000e+00, ...,
          6.0000000e+00, 6.0000000e+00, 6.0000000e+00]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [11, 15], 'to': [27]}
tf node:
{'name': 'sin', 'output': array([[[[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.41853103, ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        [[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.41853103, ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        [[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.41853103, ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        ...,

        [[-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         ...,
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ]],

        [[-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         ...,
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ]],

        [[-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         ...,
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [16], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.418531  , ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        [[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.418531  , ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        [[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.418531  , ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        ...,

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]],

        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         ...,
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ],
         [ 0.        ,  0.        ,  0.        , ...,  0.        ,
           0.        ,  0.        ]]]], dtype=float32), 'output_shape': (1, 1024, 32, 32), 'from': [16], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.41853103, ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        [[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.41853103, ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        [[-0.96211326, -0.82404983,  0.06618245, ...,  0.38682136,
           0.53035414, -0.8638502 ],
         [ 0.9515593 , -0.9954569 ,  0.7020058 , ..., -0.62001693,
           0.9657864 ,  0.9657864 ],
         [-0.9253718 , -0.9278267 ,  0.12597321, ...,  0.94313693,
           0.93684953, -0.49256602],
         ...,
         [-0.92986596, -0.99924237, -0.72471106, ..., -0.81970227,
          -0.2020108 ,  0.9871133 ],
         [-0.63109505,  0.59039474, -0.41853103, ..., -0.2020108 ,
          -0.30123386, -0.82096434],
         [ 0.45286408,  0.59039474,  0.89562833, ..., -0.98485106,
           0.7885256 ,  0.95290804]],

        ...,

        [[-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         ...,
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ]],

        [[-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         ...,
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ]],

        [[-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         ...,
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ],
         [-0.2794155 , -0.2794155 , -0.2794155 , ..., -0.2794155 ,
          -0.2794155 , -0.2794155 ]]]], dtype=float32), 'output_shape': torch.Size([1, 1024, 32, 32]), 'from': [16], 'to': []}

generate models:32

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:3,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:3
torch --> 

generate models:46

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:9

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:0,distinct_bugs:0
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
torch --> 

generate models:26

analyse output arrays in iter:65

pre layer res:
25:sigmoid
{'name': 'sigmoid', 'output': array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        ...,

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]],

        [[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         ...,
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [0], 'to': [2]}
tf node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [25], 'to': [4, 4]}
ms node:
{'name': 'sin', 'output': array([[[[  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         ...,
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096]],

        [[  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         ...,
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096]],

        [[  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         ...,
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096],
         [  0.84147096,   0.84147096,   0.84147096, ...,   0.84147096,
            0.84147096,   0.84147096]],

        ...,

        [[463.        , 433.        , 456.        , ..., 441.        ,
          383.        , 422.        ],
         [592.        , 504.        , 541.        , ..., 567.        ,
          510.        , 436.        ],
         [600.        , 583.        , 631.        , ..., 561.        ,
          531.        , 450.        ],
         ...,
         [519.        , 496.        , 493.        , ..., 429.        ,
          380.        , 385.        ],
         [491.        , 419.        , 365.        , ..., 324.        ,
          325.        , 386.        ],
         [482.        , 460.        , 409.        , ..., 405.        ,
          409.        , 497.        ]],

        [[463.        , 433.        , 456.        , ..., 441.        ,
          383.        , 422.        ],
         [592.        , 504.        , 541.        , ..., 567.        ,
          510.        , 436.        ],
         [600.        , 583.        , 631.        , ..., 561.        ,
          531.        , 450.        ],
         ...,
         [519.        , 496.        , 493.        , ..., 429.        ,
          380.        , 385.        ],
         [491.        , 419.        , 365.        , ..., 324.        ,
          325.        , 386.        ],
         [482.        , 460.        , 409.        , ..., 405.        ,
          409.        , 497.        ]],

        [[463.        , 433.        , 456.        , ..., 441.        ,
          383.        , 422.        ],
         [592.        , 504.        , 541.        , ..., 567.        ,
          510.        , 436.        ],
         [600.        , 583.        , 631.        , ..., 561.        ,
          531.        , 450.        ],
         ...,
         [519.        , 496.        , 493.        , ..., 429.        ,
          380.        , 385.        ],
         [491.        , 419.        , 365.        , ..., 324.        ,
          325.        , 386.        ],
         [482.        , 460.        , 409.        , ..., 405.        ,
          409.        , 497.        ]]]], dtype=float32), 'output_shape': (1, 64, 32, 32), 'from': [25], 'to': [4, 4]}
torch node:
{'name': 'sin', 'output': array([[[[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        ...,

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]],

        [[0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         ...,
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096],
         [0.84147096, 0.84147096, 0.84147096, ..., 0.84147096,
          0.84147096, 0.84147096]]]], dtype=float32), 'output_shape': torch.Size([1, 64, 32, 32]), 'from': [25], 'to': [4, 4]}

generate models:30

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:1
torch --> 

generate models:42

analyse output arrays in iter:161

pre layer res:
8:add
{'name': 'add', 'output': array([[[[1652446., 1652446., 1652446., ..., 1597134., 1569478.,
          1559107.],
         [1704301., 1704301., 1697387., ..., 1687016., 1666274.,
          1638618.],
         [1745785., 1749242., 1776898., ..., 1704301., 1680102.,
          1659360.],
         ...,
         [ 480523.,  791653., 1023272., ...,  359528.,  404469.,
           459781.],
         [ 359528.,  314587.,  546206., ...,  290388.,  238533.,
            86425.],
         [ 331872.,  172850.,  501265., ...,  190135.,  241990.,
           238533.]],

        [[1652446., 1652446., 1652446., ..., 1597134., 1569478.,
          1559107.],
         [1704301., 1704301., 1697387., ..., 1687016., 1666274.,
          1638618.],
         [1745785., 1749242., 1776898., ..., 1704301., 1680102.,
          1659360.],
         ...,
         [ 480523.,  791653., 1023272., ...,  359528.,  404469.,
           459781.],
         [ 359528.,  314587.,  546206., ...,  290388.,  238533.,
            86425.],
         [ 331872.,  172850.,  501265., ...,  190135.,  241990.,
           238533.]],

        [[1652446., 1652446., 1652446., ..., 1597134., 1569478.,
          1559107.],
         [1704301., 1704301., 1697387., ..., 1687016., 1666274.,
          1638618.],
         [1745785., 1749242., 1776898., ..., 1704301., 1680102.,
          1659360.],
         ...,
         [ 480523.,  791653., 1023272., ...,  359528.,  404469.,
           459781.],
         [ 359528.,  314587.,  546206., ...,  290388.,  238533.,
            86425.],
         [ 331872.,  172850.,  501265., ...,  190135.,  241990.,
           238533.]],

        ...,

        [[1651968., 1651968., 1651968., ..., 1596672., 1569024.,
          1558656.],
         [1703808., 1703808., 1696896., ..., 1686528., 1665792.,
          1638144.],
         [1745280., 1748736., 1776384., ..., 1703808., 1679616.,
          1658880.],
         ...,
         [ 480384.,  791424., 1022976., ...,  359424.,  404352.,
           459648.],
         [ 359424.,  314496.,  546048., ...,  290304.,  238464.,
            86400.],
         [ 331776.,  172800.,  501120., ...,  190080.,  241920.,
           238464.]],

        [[1651968., 1651968., 1651968., ..., 1596672., 1569024.,
          1558656.],
         [1703808., 1703808., 1696896., ..., 1686528., 1665792.,
          1638144.],
         [1745280., 1748736., 1776384., ..., 1703808., 1679616.,
          1658880.],
         ...,
         [ 480384.,  791424., 1022976., ...,  359424.,  404352.,
           459648.],
         [ 359424.,  314496.,  546048., ...,  290304.,  238464.,
            86400.],
         [ 331776.,  172800.,  501120., ...,  190080.,  241920.,
           238464.]],

        [[1651968., 1651968., 1651968., ..., 1596672., 1569024.,
          1558656.],
         [1703808., 1703808., 1696896., ..., 1686528., 1665792.,
          1638144.],
         [1745280., 1748736., 1776384., ..., 1703808., 1679616.,
          1658880.],
         ...,
         [ 480384.,  791424., 1022976., ...,  359424.,  404352.,
           459648.],
         [ 359424.,  314496.,  546048., ...,  290304.,  238464.,
            86400.],
         [ 331776.,  172800.,  501120., ...,  190080.,  241920.,
           238464.]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [2, 13], 'to': [5]}
tf node:
{'name': 'sin', 'output': array([[[[-0.31443527, -0.31443527, -0.31443527, ..., -0.99140644,
           0.9095166 , -0.5136806 ],
         [-0.4333457 , -0.4333457 , -0.19595252, ..., -0.3944064 ,
          -0.999203  ,  0.82545024],
         [ 0.9242981 , -0.06883407,  0.58814156, ..., -0.4333457 ,
          -0.23771113,  0.8222153 ],
         ...,
         [-0.6409    ,  0.0743022 , -0.95684445, ..., -0.83883005,
           0.99828494,  0.48785502],
         [-0.83883005,  0.46003988,  0.6620352 , ..., -0.91928136,
          -0.96209717, -0.21227287],
         [ 0.42164624, -0.41487053, -0.9459857 , ..., -0.45340383,
          -0.5637514 , -0.96209717]],

        [[-0.31443527, -0.31443527, -0.31443527, ..., -0.99140644,
           0.9095166 , -0.5136806 ],
         [-0.4333457 , -0.4333457 , -0.19595252, ..., -0.3944064 ,
          -0.999203  ,  0.82545024],
         [ 0.9242981 , -0.06883407,  0.58814156, ..., -0.4333457 ,
          -0.23771113,  0.8222153 ],
         ...,
         [-0.6409    ,  0.0743022 , -0.95684445, ..., -0.83883005,
           0.99828494,  0.48785502],
         [-0.83883005,  0.46003988,  0.6620352 , ..., -0.91928136,
          -0.96209717, -0.21227287],
         [ 0.42164624, -0.41487053, -0.9459857 , ..., -0.45340383,
          -0.5637514 , -0.96209717]],

        [[-0.31443527, -0.31443527, -0.31443527, ..., -0.99140644,
           0.9095166 , -0.5136806 ],
         [-0.4333457 , -0.4333457 , -0.19595252, ..., -0.3944064 ,
          -0.999203  ,  0.82545024],
         [ 0.9242981 , -0.06883407,  0.58814156, ..., -0.4333457 ,
          -0.23771113,  0.8222153 ],
         ...,
         [-0.6409    ,  0.0743022 , -0.95684445, ..., -0.83883005,
           0.99828494,  0.48785502],
         [-0.83883005,  0.46003988,  0.6620352 , ..., -0.91928136,
          -0.96209717, -0.21227287],
         [ 0.42164624, -0.41487053, -0.9459857 , ..., -0.45340383,
          -0.5637514 , -0.96209717]],

        ...,

        [[-0.7158065 , -0.7158065 , -0.7158065 , ...,  0.99850506,
          -0.45158258, -0.9365943 ],
         [ 0.21642895,  0.21642895,  0.6551018 , ...,  0.9937082 ,
           0.19332097, -0.9760486 ],
         [-0.37349632, -0.13428731,  0.96128786, ...,  0.21642895,
           0.92720115, -0.2970639 ],
         ...,
         [ 0.07418486,  0.25890943, -0.9228286 , ...,  0.6191722 ,
          -0.6824791 ,  0.9999675 ],
         [ 0.6191722 , -0.55155486,  0.99732924, ...,  0.9137174 ,
          -0.9870407 , -0.08106996],
         [-0.96795624, -0.16160622, -0.987769  , ...,  0.88105464,
          -0.99622536, -0.9870407 ]],

        [[-0.7158065 , -0.7158065 , -0.7158065 , ...,  0.99850506,
          -0.45158258, -0.9365943 ],
         [ 0.21642895,  0.21642895,  0.6551018 , ...,  0.9937082 ,
           0.19332097, -0.9760486 ],
         [-0.37349632, -0.13428731,  0.96128786, ...,  0.21642895,
           0.92720115, -0.2970639 ],
         ...,
         [ 0.07418486,  0.25890943, -0.9228286 , ...,  0.6191722 ,
          -0.6824791 ,  0.9999675 ],
         [ 0.6191722 , -0.55155486,  0.99732924, ...,  0.9137174 ,
          -0.9870407 , -0.08106996],
         [-0.96795624, -0.16160622, -0.987769  , ...,  0.88105464,
          -0.99622536, -0.9870407 ]],

        [[-0.7158065 , -0.7158065 , -0.7158065 , ...,  0.99850506,
          -0.45158258, -0.9365943 ],
         [ 0.21642895,  0.21642895,  0.6551018 , ...,  0.9937082 ,
           0.19332097, -0.9760486 ],
         [-0.37349632, -0.13428731,  0.96128786, ...,  0.21642895,
           0.92720115, -0.2970639 ],
         ...,
         [ 0.07418486,  0.25890943, -0.9228286 , ...,  0.6191722 ,
          -0.6824791 ,  0.9999675 ],
         [ 0.6191722 , -0.55155486,  0.99732924, ...,  0.9137174 ,
          -0.9870407 , -0.08106996],
         [-0.96795624, -0.16160622, -0.987769  , ...,  0.88105464,
          -0.99622536, -0.9870407 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [8], 'to': [23]}
ms node:
{'name': 'sin', 'output': array([[[[-3.1443527e-01, -3.1443527e-01, -3.1443527e-01, ...,
          -9.9140644e-01,  9.0951657e-01, -5.1368058e-01],
         [-4.3334571e-01, -4.3334571e-01, -1.9595252e-01, ...,
          -3.9440641e-01, -9.9920303e-01,  8.2545024e-01],
         [ 9.2429811e-01, -6.8834074e-02,  5.8814156e-01, ...,
          -4.3334571e-01, -2.3771113e-01,  8.2221532e-01],
         ...,
         [-6.4090002e-01,  7.4302204e-02, -9.5684445e-01, ...,
          -8.3883005e-01,  9.9828494e-01,  4.8785502e-01],
         [-8.3883005e-01,  4.6003988e-01,  6.6203523e-01, ...,
          -9.1928136e-01, -9.6209717e-01, -2.1227287e-01],
         [ 4.2164624e-01, -4.1487053e-01, -9.4598567e-01, ...,
          -4.5340383e-01, -5.6375140e-01, -9.6209717e-01]],

        [[-3.1443527e-01, -3.1443527e-01, -3.1443527e-01, ...,
          -9.9140644e-01,  9.0951657e-01, -5.1368058e-01],
         [-4.3334571e-01, -4.3334571e-01, -1.9595252e-01, ...,
          -3.9440641e-01, -9.9920303e-01,  8.2545024e-01],
         [ 9.2429811e-01, -6.8834074e-02,  5.8814156e-01, ...,
          -4.3334571e-01, -2.3771113e-01,  8.2221532e-01],
         ...,
         [-6.4090002e-01,  7.4302204e-02, -9.5684445e-01, ...,
          -8.3883005e-01,  9.9828494e-01,  4.8785502e-01],
         [-8.3883005e-01,  4.6003988e-01,  6.6203523e-01, ...,
          -9.1928136e-01, -9.6209717e-01, -2.1227287e-01],
         [ 4.2164624e-01, -4.1487053e-01, -9.4598567e-01, ...,
          -4.5340383e-01, -5.6375140e-01, -9.6209717e-01]],

        [[-3.1443527e-01, -3.1443527e-01, -3.1443527e-01, ...,
          -9.9140644e-01,  9.0951657e-01, -5.1368058e-01],
         [-4.3334571e-01, -4.3334571e-01, -1.9595252e-01, ...,
          -3.9440641e-01, -9.9920303e-01,  8.2545024e-01],
         [ 9.2429811e-01, -6.8834074e-02,  5.8814156e-01, ...,
          -4.3334571e-01, -2.3771113e-01,  8.2221532e-01],
         ...,
         [-6.4090002e-01,  7.4302204e-02, -9.5684445e-01, ...,
          -8.3883005e-01,  9.9828494e-01,  4.8785502e-01],
         [-8.3883005e-01,  4.6003988e-01,  6.6203523e-01, ...,
          -9.1928136e-01, -9.6209717e-01, -2.1227287e-01],
         [ 4.2164624e-01, -4.1487053e-01, -9.4598567e-01, ...,
          -4.5340383e-01, -5.6375140e-01, -9.6209717e-01]],

        ...,

        [[ 1.1013120e+06,  1.1013120e+06,  1.1013120e+06, ...,
           1.0644480e+06,  1.0460160e+06,  1.0391040e+06],
         [ 1.1358720e+06,  1.1358720e+06,  1.1312640e+06, ...,
           1.1243520e+06,  1.1105280e+06,  1.0920960e+06],
         [ 1.1635200e+06,  1.1658240e+06,  1.1842560e+06, ...,
           1.1358720e+06,  1.1197440e+06,  1.1059200e+06],
         ...,
         [ 3.2025600e+05,  5.2761600e+05,  6.8198400e+05, ...,
           2.3961600e+05,  2.6956800e+05,  3.0643200e+05],
         [ 2.3961600e+05,  2.0966400e+05,  3.6403200e+05, ...,
           1.9353600e+05,  1.5897600e+05,  5.7600000e+04],
         [ 2.2118400e+05,  1.1520000e+05,  3.3408000e+05, ...,
           1.2672000e+05,  1.6128000e+05,  1.5897600e+05]],

        [[ 1.1013120e+06,  1.1013120e+06,  1.1013120e+06, ...,
           1.0644480e+06,  1.0460160e+06,  1.0391040e+06],
         [ 1.1358720e+06,  1.1358720e+06,  1.1312640e+06, ...,
           1.1243520e+06,  1.1105280e+06,  1.0920960e+06],
         [ 1.1635200e+06,  1.1658240e+06,  1.1842560e+06, ...,
           1.1358720e+06,  1.1197440e+06,  1.1059200e+06],
         ...,
         [ 3.2025600e+05,  5.2761600e+05,  6.8198400e+05, ...,
           2.3961600e+05,  2.6956800e+05,  3.0643200e+05],
         [ 2.3961600e+05,  2.0966400e+05,  3.6403200e+05, ...,
           1.9353600e+05,  1.5897600e+05,  5.7600000e+04],
         [ 2.2118400e+05,  1.1520000e+05,  3.3408000e+05, ...,
           1.2672000e+05,  1.6128000e+05,  1.5897600e+05]],

        [[ 1.1013120e+06,  1.1013120e+06,  1.1013120e+06, ...,
           1.0644480e+06,  1.0460160e+06,  1.0391040e+06],
         [ 1.1358720e+06,  1.1358720e+06,  1.1312640e+06, ...,
           1.1243520e+06,  1.1105280e+06,  1.0920960e+06],
         [ 1.1635200e+06,  1.1658240e+06,  1.1842560e+06, ...,
           1.1358720e+06,  1.1197440e+06,  1.1059200e+06],
         ...,
         [ 3.2025600e+05,  5.2761600e+05,  6.8198400e+05, ...,
           2.3961600e+05,  2.6956800e+05,  3.0643200e+05],
         [ 2.3961600e+05,  2.0966400e+05,  3.6403200e+05, ...,
           1.9353600e+05,  1.5897600e+05,  5.7600000e+04],
         [ 2.2118400e+05,  1.1520000e+05,  3.3408000e+05, ...,
           1.2672000e+05,  1.6128000e+05,  1.5897600e+05]]]],
      dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [8], 'to': [23]}
torch node:
{'name': 'sin', 'output': array([[[[-0.31443527, -0.31443527, -0.31443527, ..., -0.99140644,
           0.9095166 , -0.5136806 ],
         [-0.4333457 , -0.4333457 , -0.19595252, ..., -0.3944064 ,
          -0.999203  ,  0.82545024],
         [ 0.9242981 , -0.06883407,  0.58814156, ..., -0.4333457 ,
          -0.23771113,  0.8222153 ],
         ...,
         [-0.6409    ,  0.0743022 , -0.95684445, ..., -0.83883005,
           0.99828494,  0.48785502],
         [-0.83883005,  0.46003988,  0.6620352 , ..., -0.91928136,
          -0.96209717, -0.21227287],
         [ 0.42164624, -0.41487053, -0.9459857 , ..., -0.45340383,
          -0.5637514 , -0.96209717]],

        [[-0.31443527, -0.31443527, -0.31443527, ..., -0.99140644,
           0.9095166 , -0.5136806 ],
         [-0.4333457 , -0.4333457 , -0.19595252, ..., -0.3944064 ,
          -0.999203  ,  0.82545024],
         [ 0.9242981 , -0.06883407,  0.58814156, ..., -0.4333457 ,
          -0.23771113,  0.8222153 ],
         ...,
         [-0.6409    ,  0.0743022 , -0.95684445, ..., -0.83883005,
           0.99828494,  0.48785502],
         [-0.83883005,  0.46003988,  0.6620352 , ..., -0.91928136,
          -0.96209717, -0.21227287],
         [ 0.42164624, -0.41487053, -0.9459857 , ..., -0.45340383,
          -0.5637514 , -0.96209717]],

        [[-0.31443527, -0.31443527, -0.31443527, ..., -0.99140644,
           0.9095166 , -0.5136806 ],
         [-0.4333457 , -0.4333457 , -0.19595252, ..., -0.3944064 ,
          -0.999203  ,  0.82545024],
         [ 0.9242981 , -0.06883407,  0.58814156, ..., -0.4333457 ,
          -0.23771113,  0.8222153 ],
         ...,
         [-0.6409    ,  0.0743022 , -0.95684445, ..., -0.83883005,
           0.99828494,  0.48785502],
         [-0.83883005,  0.46003988,  0.6620352 , ..., -0.91928136,
          -0.96209717, -0.21227287],
         [ 0.42164624, -0.41487053, -0.9459857 , ..., -0.45340383,
          -0.5637514 , -0.96209717]],

        ...,

        [[-0.7158065 , -0.7158065 , -0.7158065 , ...,  0.99850506,
          -0.45158258, -0.9365943 ],
         [ 0.21642895,  0.21642895,  0.6551018 , ...,  0.9937082 ,
           0.19332097, -0.9760486 ],
         [-0.37349632, -0.13428731,  0.96128786, ...,  0.21642895,
           0.92720115, -0.2970639 ],
         ...,
         [ 0.07418486,  0.25890943, -0.9228286 , ...,  0.6191722 ,
          -0.6824791 ,  0.9999675 ],
         [ 0.6191722 , -0.55155486,  0.99732924, ...,  0.9137174 ,
          -0.9870407 , -0.08106996],
         [-0.96795624, -0.16160622, -0.987769  , ...,  0.88105464,
          -0.99622536, -0.9870407 ]],

        [[-0.7158065 , -0.7158065 , -0.7158065 , ...,  0.99850506,
          -0.45158258, -0.9365943 ],
         [ 0.21642895,  0.21642895,  0.6551018 , ...,  0.9937082 ,
           0.19332097, -0.9760486 ],
         [-0.37349632, -0.13428731,  0.96128786, ...,  0.21642895,
           0.92720115, -0.2970639 ],
         ...,
         [ 0.07418486,  0.25890943, -0.9228286 , ...,  0.6191722 ,
          -0.6824791 ,  0.9999675 ],
         [ 0.6191722 , -0.55155486,  0.99732924, ...,  0.9137174 ,
          -0.9870407 , -0.08106996],
         [-0.96795624, -0.16160622, -0.987769  , ...,  0.88105464,
          -0.99622536, -0.9870407 ]],

        [[-0.7158065 , -0.7158065 , -0.7158065 , ...,  0.99850506,
          -0.45158258, -0.9365943 ],
         [ 0.21642895,  0.21642895,  0.6551018 , ...,  0.9937082 ,
           0.19332097, -0.9760486 ],
         [-0.37349632, -0.13428731,  0.96128786, ...,  0.21642895,
           0.92720115, -0.2970639 ],
         ...,
         [ 0.07418486,  0.25890943, -0.9228286 , ...,  0.6191722 ,
          -0.6824791 ,  0.9999675 ],
         [ 0.6191722 , -0.55155486,  0.99732924, ...,  0.9137174 ,
          -0.9870407 , -0.08106996],
         [-0.96795624, -0.16160622, -0.987769  , ...,  0.88105464,
          -0.99622536, -0.9870407 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [8], 'to': [23]}

generate models:58

analyse output arrays in iter:163

pre layer res:
10:add
{'name': 'add', 'output': array([[[[1.7556250e+08, 1.9650432e+08, 1.9650432e+08, ...,
          1.5262131e+08, 1.5580032e+08, 1.3721779e+08],
         [1.6225664e+08, 1.7051136e+08, 1.3423539e+08, ...,
          1.2122010e+08, 1.0621363e+08, 1.0100250e+08],
         [1.5901210e+08, 1.7218688e+08, 1.2692275e+08, ...,
          1.1981491e+08, 6.0996096e+07, 7.3582080e+07],
         ...,
         [3.8110848e+08, 2.7483008e+08, 1.7726259e+08, ...,
          4.3806490e+08, 4.7637427e+08, 5.8845056e+08],
         [4.5428659e+08, 4.3806490e+08, 4.3806490e+08, ...,
          5.8845056e+08, 6.7860250e+08, 7.1235610e+08],
         [6.7860250e+08, 6.3272371e+08, 6.7860250e+08, ...,
          7.6098739e+08, 7.4692890e+08, 8.1853210e+08]],

        [[1.7556250e+08, 1.9650432e+08, 1.9650432e+08, ...,
          1.5262131e+08, 1.5580032e+08, 1.3721779e+08],
         [1.6225664e+08, 1.7051136e+08, 1.3423539e+08, ...,
          1.2122010e+08, 1.0621363e+08, 1.0100250e+08],
         [1.5901210e+08, 1.7218688e+08, 1.2692275e+08, ...,
          1.1981491e+08, 6.0996096e+07, 7.3582080e+07],
         ...,
         [3.8110848e+08, 2.7483008e+08, 1.7726259e+08, ...,
          4.3806490e+08, 4.7637427e+08, 5.8845056e+08],
         [4.5428659e+08, 4.3806490e+08, 4.3806490e+08, ...,
          5.8845056e+08, 6.7860250e+08, 7.1235610e+08],
         [6.7860250e+08, 6.3272371e+08, 6.7860250e+08, ...,
          7.6098739e+08, 7.4692890e+08, 8.1853210e+08]],

        [[1.7556250e+08, 1.9650432e+08, 1.9650432e+08, ...,
          1.5262131e+08, 1.5580032e+08, 1.3721779e+08],
         [1.6225664e+08, 1.7051136e+08, 1.3423539e+08, ...,
          1.2122010e+08, 1.0621363e+08, 1.0100250e+08],
         [1.5901210e+08, 1.7218688e+08, 1.2692275e+08, ...,
          1.1981491e+08, 6.0996096e+07, 7.3582080e+07],
         ...,
         [3.8110848e+08, 2.7483008e+08, 1.7726259e+08, ...,
          4.3806490e+08, 4.7637427e+08, 5.8845056e+08],
         [4.5428659e+08, 4.3806490e+08, 4.3806490e+08, ...,
          5.8845056e+08, 6.7860250e+08, 7.1235610e+08],
         [6.7860250e+08, 6.3272371e+08, 6.7860250e+08, ...,
          7.6098739e+08, 7.4692890e+08, 8.1853210e+08]],

        ...,

        [[1.7556250e+08, 1.9650432e+08, 1.9650432e+08, ...,
          1.5262131e+08, 1.5580032e+08, 1.3721779e+08],
         [1.6225664e+08, 1.7051136e+08, 1.3423539e+08, ...,
          1.2122010e+08, 1.0621363e+08, 1.0100250e+08],
         [1.5901210e+08, 1.7218688e+08, 1.2692275e+08, ...,
          1.1981491e+08, 6.0996096e+07, 7.3582080e+07],
         ...,
         [3.8110848e+08, 2.7483008e+08, 1.7726259e+08, ...,
          4.3806490e+08, 4.7637427e+08, 5.8845056e+08],
         [4.5428659e+08, 4.3806490e+08, 4.3806490e+08, ...,
          5.8845056e+08, 6.7860250e+08, 7.1235610e+08],
         [6.7860250e+08, 6.3272371e+08, 6.7860250e+08, ...,
          7.6098739e+08, 7.4692890e+08, 8.1853210e+08]],

        [[1.7556250e+08, 1.9650432e+08, 1.9650432e+08, ...,
          1.5262131e+08, 1.5580032e+08, 1.3721779e+08],
         [1.6225664e+08, 1.7051136e+08, 1.3423539e+08, ...,
          1.2122010e+08, 1.0621363e+08, 1.0100250e+08],
         [1.5901210e+08, 1.7218688e+08, 1.2692275e+08, ...,
          1.1981491e+08, 6.0996096e+07, 7.3582080e+07],
         ...,
         [3.8110848e+08, 2.7483008e+08, 1.7726259e+08, ...,
          4.3806490e+08, 4.7637427e+08, 5.8845056e+08],
         [4.5428659e+08, 4.3806490e+08, 4.3806490e+08, ...,
          5.8845056e+08, 6.7860250e+08, 7.1235610e+08],
         [6.7860250e+08, 6.3272371e+08, 6.7860250e+08, ...,
          7.6098739e+08, 7.4692890e+08, 8.1853210e+08]],

        [[1.7556250e+08, 1.9650432e+08, 1.9650432e+08, ...,
          1.5262131e+08, 1.5580032e+08, 1.3721779e+08],
         [1.6225664e+08, 1.7051136e+08, 1.3423539e+08, ...,
          1.2122010e+08, 1.0621363e+08, 1.0100250e+08],
         [1.5901210e+08, 1.7218688e+08, 1.2692275e+08, ...,
          1.1981491e+08, 6.0996096e+07, 7.3582080e+07],
         ...,
         [3.8110848e+08, 2.7483008e+08, 1.7726259e+08, ...,
          4.3806490e+08, 4.7637427e+08, 5.8845056e+08],
         [4.5428659e+08, 4.3806490e+08, 4.3806490e+08, ...,
          5.8845056e+08, 6.7860250e+08, 7.1235610e+08],
         [6.7860250e+08, 6.3272371e+08, 6.7860250e+08, ...,
          7.6098739e+08, 7.4692890e+08, 8.1853210e+08]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [9, 5], 'to': [2]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        ...,

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [10], 'to': [23]}
ms node:
{'name': 'sin', 'output': array([[[[ 3.6783889e-01, -7.4211425e-01, -7.4211425e-01, ...,
           9.8862380e-01,  3.8731718e-01, -6.9836545e-01],
         [ 9.3985027e-01, -9.5612186e-01,  8.9008695e-01, ...,
           1.2237738e-01, -3.4784669e-01, -1.8970225e-02],
         [ 5.3478128e-01,  5.2287894e-01,  7.2193384e-01, ...,
          -5.7833106e-03,  9.2437834e-01, -9.9950987e-01],
         ...,
         [ 3.3140469e-01, -9.9884230e-01, -9.9876267e-01, ...,
          -5.5393422e-01,  8.1123841e-01,  6.4131814e-01],
         [-9.4541389e-01, -5.5393422e-01, -5.5393422e-01, ...,
           6.4131814e-01, -7.4131233e-01, -4.8150736e-01],
         [-7.4131233e-01,  7.0151901e-01, -7.4131233e-01, ...,
           4.1099805e-01, -3.8806263e-01,  8.3673692e-01]],

        [[ 3.6783889e-01, -7.4211425e-01, -7.4211425e-01, ...,
           9.8862380e-01,  3.8731718e-01, -6.9836545e-01],
         [ 9.3985027e-01, -9.5612186e-01,  8.9008695e-01, ...,
           1.2237738e-01, -3.4784669e-01, -1.8970225e-02],
         [ 5.3478128e-01,  5.2287894e-01,  7.2193384e-01, ...,
          -5.7833106e-03,  9.2437834e-01, -9.9950987e-01],
         ...,
         [ 3.3140469e-01, -9.9884230e-01, -9.9876267e-01, ...,
          -5.5393422e-01,  8.1123841e-01,  6.4131814e-01],
         [-9.4541389e-01, -5.5393422e-01, -5.5393422e-01, ...,
           6.4131814e-01, -7.4131233e-01, -4.8150736e-01],
         [-7.4131233e-01,  7.0151901e-01, -7.4131233e-01, ...,
           4.1099805e-01, -3.8806263e-01,  8.3673692e-01]],

        [[ 3.6783889e-01, -7.4211425e-01, -7.4211425e-01, ...,
           9.8862380e-01,  3.8731718e-01, -6.9836545e-01],
         [ 9.3985027e-01, -9.5612186e-01,  8.9008695e-01, ...,
           1.2237738e-01, -3.4784669e-01, -1.8970225e-02],
         [ 5.3478128e-01,  5.2287894e-01,  7.2193384e-01, ...,
          -5.7833106e-03,  9.2437834e-01, -9.9950987e-01],
         ...,
         [ 3.3140469e-01, -9.9884230e-01, -9.9876267e-01, ...,
          -5.5393422e-01,  8.1123841e-01,  6.4131814e-01],
         [-9.4541389e-01, -5.5393422e-01, -5.5393422e-01, ...,
           6.4131814e-01, -7.4131233e-01, -4.8150736e-01],
         [-7.4131233e-01,  7.0151901e-01, -7.4131233e-01, ...,
           4.1099805e-01, -3.8806263e-01,  8.3673692e-01]],

        ...,

        [[ 1.7556250e+08,  1.9650432e+08,  1.9650432e+08, ...,
           1.5262131e+08,  1.5580032e+08,  1.3721779e+08],
         [ 1.6225664e+08,  1.7051136e+08,  1.3423539e+08, ...,
           1.2122010e+08,  1.0621363e+08,  1.0100250e+08],
         [ 1.5901210e+08,  1.7218688e+08,  1.2692275e+08, ...,
           1.1981491e+08,  6.0996096e+07,  7.3582080e+07],
         ...,
         [ 3.8110848e+08,  2.7483008e+08,  1.7726259e+08, ...,
           4.3806490e+08,  4.7637427e+08,  5.8845056e+08],
         [ 4.5428659e+08,  4.3806490e+08,  4.3806490e+08, ...,
           5.8845056e+08,  6.7860250e+08,  7.1235610e+08],
         [ 6.7860250e+08,  6.3272371e+08,  6.7860250e+08, ...,
           7.6098739e+08,  7.4692890e+08,  8.1853210e+08]],

        [[ 1.7556250e+08,  1.9650432e+08,  1.9650432e+08, ...,
           1.5262131e+08,  1.5580032e+08,  1.3721779e+08],
         [ 1.6225664e+08,  1.7051136e+08,  1.3423539e+08, ...,
           1.2122010e+08,  1.0621363e+08,  1.0100250e+08],
         [ 1.5901210e+08,  1.7218688e+08,  1.2692275e+08, ...,
           1.1981491e+08,  6.0996096e+07,  7.3582080e+07],
         ...,
         [ 3.8110848e+08,  2.7483008e+08,  1.7726259e+08, ...,
           4.3806490e+08,  4.7637427e+08,  5.8845056e+08],
         [ 4.5428659e+08,  4.3806490e+08,  4.3806490e+08, ...,
           5.8845056e+08,  6.7860250e+08,  7.1235610e+08],
         [ 6.7860250e+08,  6.3272371e+08,  6.7860250e+08, ...,
           7.6098739e+08,  7.4692890e+08,  8.1853210e+08]],

        [[ 1.7556250e+08,  1.9650432e+08,  1.9650432e+08, ...,
           1.5262131e+08,  1.5580032e+08,  1.3721779e+08],
         [ 1.6225664e+08,  1.7051136e+08,  1.3423539e+08, ...,
           1.2122010e+08,  1.0621363e+08,  1.0100250e+08],
         [ 1.5901210e+08,  1.7218688e+08,  1.2692275e+08, ...,
           1.1981491e+08,  6.0996096e+07,  7.3582080e+07],
         ...,
         [ 3.8110848e+08,  2.7483008e+08,  1.7726259e+08, ...,
           4.3806490e+08,  4.7637427e+08,  5.8845056e+08],
         [ 4.5428659e+08,  4.3806490e+08,  4.3806490e+08, ...,
           5.8845056e+08,  6.7860250e+08,  7.1235610e+08],
         [ 6.7860250e+08,  6.3272371e+08,  6.7860250e+08, ...,
           7.6098739e+08,  7.4692890e+08,  8.1853210e+08]]]],
      dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [10], 'to': [23]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        ...,

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]],

        [[ 0.3678389 , -0.74211425, -0.74211425, ...,  0.9886238 ,
           0.38731718, -0.69836545],
         [ 0.9398503 , -0.95612186,  0.89008695, ...,  0.12237738,
          -0.3478467 , -0.01897023],
         [ 0.5347813 ,  0.52287894,  0.72193384, ..., -0.00578331,
           0.92437834, -0.9995099 ],
         ...,
         [ 0.3314047 , -0.9988423 , -0.99876267, ..., -0.5539342 ,
           0.8112384 ,  0.64131814],
         [-0.9454139 , -0.5539342 , -0.5539342 , ...,  0.64131814,
          -0.7413123 , -0.48150736],
         [-0.7413123 ,  0.701519  , -0.7413123 , ...,  0.41099805,
          -0.38806263,  0.8367369 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [10], 'to': [23]}

generate models:59

analyse output arrays in iter:168

pre layer res:
10:add
{'name': 'add', 'output': array([[[[1.21482768e+08, 1.22458560e+08, 1.22550576e+08, ...,
          1.19578672e+08, 1.20244520e+08, 1.20930744e+08],
         [1.21634208e+08, 1.22587456e+08, 1.22699120e+08, ...,
          1.19578672e+08, 1.20243936e+08, 1.20919184e+08],
         [1.21626696e+08, 1.22573584e+08, 1.22702584e+08, ...,
          1.19579248e+08, 1.20243360e+08, 1.20913984e+08],
         ...,
         [3.79055400e+06, 4.72588200e+06, 4.82020600e+06, ...,
          2.12112000e+06, 2.80835400e+06, 3.49515800e+06],
         [3.81136200e+06, 4.75536000e+06, 4.84968400e+06, ...,
          2.14828600e+06, 2.82800600e+06, 3.48995600e+06],
         [3.84315200e+06, 4.80969200e+06, 4.90170400e+06, ...,
          2.17256200e+06, 2.84765800e+06, 3.51596600e+06]],

        [[3.93678800e+06, 4.91257600e+06, 5.00458800e+06, ...,
          2.03268600e+06, 2.69853400e+06, 3.38476000e+06],
         [4.08822400e+06, 5.04147000e+06, 5.15313400e+06, ...,
          2.03268600e+06, 2.69795600e+06, 3.37320000e+06],
         [4.08071000e+06, 5.02759800e+06, 5.15660200e+06, ...,
          2.03326400e+06, 2.69737800e+06, 3.36799800e+06],
         ...,
         [3.79055400e+06, 4.72588200e+06, 4.82020600e+06, ...,
          2.12112000e+06, 2.80835400e+06, 3.49515800e+06],
         [3.81136200e+06, 4.75536000e+06, 4.84968400e+06, ...,
          2.14828600e+06, 2.82800600e+06, 3.48995600e+06],
         [3.84315200e+06, 4.80969200e+06, 4.90170400e+06, ...,
          2.17256200e+06, 2.84765800e+06, 3.51596600e+06]],

        [[3.93678800e+06, 4.91257600e+06, 5.00458800e+06, ...,
          2.03268600e+06, 2.69853400e+06, 3.38476000e+06],
         [4.08822400e+06, 5.04147000e+06, 5.15313400e+06, ...,
          2.03268600e+06, 2.69795600e+06, 3.37320000e+06],
         [4.08071000e+06, 5.02759800e+06, 5.15660200e+06, ...,
          2.03326400e+06, 2.69737800e+06, 3.36799800e+06],
         ...,
         [3.79055400e+06, 4.72588200e+06, 4.82020600e+06, ...,
          2.12112000e+06, 2.80835400e+06, 3.49515800e+06],
         [3.81136200e+06, 4.75536000e+06, 4.84968400e+06, ...,
          2.14828600e+06, 2.82800600e+06, 3.48995600e+06],
         [3.84315200e+06, 4.80969200e+06, 4.90170400e+06, ...,
          2.17256200e+06, 2.84765800e+06, 3.51596600e+06]],

        ...,

        [[2.63808000e+05, 2.76480000e+05, 2.70720000e+05, ...,
          3.16800000e+04, 2.93760000e+04, 5.29920000e+04],
         [4.14720000e+05, 4.04928000e+05, 4.18752000e+05, ...,
          3.16800000e+04, 2.88000000e+04, 4.14720000e+04],
         [4.07232000e+05, 3.91104000e+05, 4.22208000e+05, ...,
          3.22560000e+04, 2.82240000e+04, 3.62880000e+04],
         ...,
         [1.18080000e+05, 9.04320000e+04, 8.69760000e+04, ...,
          1.19808000e+05, 1.38816000e+05, 1.63008000e+05],
         [1.38816000e+05, 1.19808000e+05, 1.16352000e+05, ...,
          1.46880000e+05, 1.58400000e+05, 1.57824000e+05],
         [1.70496000e+05, 1.73952000e+05, 1.68192000e+05, ...,
          1.71072000e+05, 1.77984000e+05, 1.83744000e+05]],

        [[2.63808000e+05, 2.76480000e+05, 2.70720000e+05, ...,
          3.16800000e+04, 2.93760000e+04, 5.29920000e+04],
         [4.14720000e+05, 4.04928000e+05, 4.18752000e+05, ...,
          3.16800000e+04, 2.88000000e+04, 4.14720000e+04],
         [4.07232000e+05, 3.91104000e+05, 4.22208000e+05, ...,
          3.22560000e+04, 2.82240000e+04, 3.62880000e+04],
         ...,
         [1.18080000e+05, 9.04320000e+04, 8.69760000e+04, ...,
          1.19808000e+05, 1.38816000e+05, 1.63008000e+05],
         [1.38816000e+05, 1.19808000e+05, 1.16352000e+05, ...,
          1.46880000e+05, 1.58400000e+05, 1.57824000e+05],
         [1.70496000e+05, 1.73952000e+05, 1.68192000e+05, ...,
          1.71072000e+05, 1.77984000e+05, 1.83744000e+05]],

        [[2.63808000e+05, 2.76480000e+05, 2.70720000e+05, ...,
          3.16800000e+04, 2.93760000e+04, 5.29920000e+04],
         [4.14720000e+05, 4.04928000e+05, 4.18752000e+05, ...,
          3.16800000e+04, 2.88000000e+04, 4.14720000e+04],
         [4.07232000e+05, 3.91104000e+05, 4.22208000e+05, ...,
          3.22560000e+04, 2.82240000e+04, 3.62880000e+04],
         ...,
         [1.18080000e+05, 9.04320000e+04, 8.69760000e+04, ...,
          1.19808000e+05, 1.38816000e+05, 1.63008000e+05],
         [1.38816000e+05, 1.19808000e+05, 1.16352000e+05, ...,
          1.46880000e+05, 1.58400000e+05, 1.57824000e+05],
         [1.70496000e+05, 1.73952000e+05, 1.68192000e+05, ...,
          1.71072000e+05, 1.77984000e+05, 1.83744000e+05]]]],
      dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [9, 15], 'to': [23]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.17307977,  0.80124927, -0.31403822, ..., -0.9967497 ,
          -0.9970211 , -0.9031631 ],
         [ 0.2954347 , -0.5006903 ,  0.24244297, ..., -0.9967497 ,
          -0.9666395 , -0.8154731 ],
         [-0.68301004, -0.9744004 , -0.9888879 , ...,  0.5336412 ,
           0.6752322 ,  0.9989    ],
         ...,
         [ 0.5560573 ,  0.12053804, -0.64523953, ..., -0.9942276 ,
           0.47595146, -0.8840218 ],
         [ 0.59897524,  0.31010124,  0.9075733 , ...,  0.8572838 ,
           0.7459141 , -0.9999598 ],
         [-0.7618466 ,  0.9991534 ,  0.47528037, ..., -0.11614201,
          -0.8201852 ,  0.7347785 ]],

        [[ 0.99203193, -0.99972767, -0.4908761 , ...,  0.15428497,
           0.15768509,  0.9756698 ],
         [ 0.3568047 , -0.72487175, -0.9999565 , ...,  0.15428497,
           0.2098233 ,  0.28479293],
         [ 0.86964   ,  0.44601682, -0.94681066, ...,  0.10167943,
           0.2613712 , -0.18752708],
         ...,
         [ 0.5560573 ,  0.12053804, -0.64523953, ..., -0.9942276 ,
           0.47595146, -0.8840218 ],
         [ 0.59897524,  0.31010124,  0.9075733 , ...,  0.8572838 ,
           0.7459141 , -0.9999598 ],
         [-0.7618466 ,  0.9991534 ,  0.47528037, ..., -0.11614201,
          -0.8201852 ,  0.7347785 ]],

        [[ 0.99203193, -0.99972767, -0.4908761 , ...,  0.15428497,
           0.15768509,  0.9756698 ],
         [ 0.3568047 , -0.72487175, -0.9999565 , ...,  0.15428497,
           0.2098233 ,  0.28479293],
         [ 0.86964   ,  0.44601682, -0.94681066, ...,  0.10167943,
           0.2613712 , -0.18752708],
         ...,
         [ 0.5560573 ,  0.12053804, -0.64523953, ..., -0.9942276 ,
           0.47595146, -0.8840218 ],
         [ 0.59897524,  0.31010124,  0.9075733 , ...,  0.8572838 ,
           0.7459141 , -0.9999598 ],
         [-0.7618466 ,  0.9991534 ,  0.47528037, ..., -0.11614201,
          -0.8201852 ,  0.7347785 ]],

        ...,

        [[ 0.8191342 ,  0.83980733,  0.44729427, ...,  0.17871591,
           0.8587903 , -0.3754486 ],
         [-0.99715847,  0.9640645 ,  0.30465382, ...,  0.17871591,
          -0.85218364,  0.16387752],
         [-0.08919553,  0.7495416 ,  0.06145515, ..., -0.95457363,
          -0.06834653,  0.51133853],
         ...,
         [ 0.09836286, -0.95069414, -0.8454383 , ...,  0.22072984,
           0.9998686 , -0.18098037],
         [ 0.9998686 ,  0.22072984, -0.02551558, ..., -0.8995187 ,
           0.78233504,  0.1889948 ],
         [ 0.9808742 ,  0.9030517 , -0.52618223, ..., -0.28246096,
           0.20826773, -0.9950367 ]],

        [[ 0.8191342 ,  0.83980733,  0.44729427, ...,  0.17871591,
           0.8587903 , -0.3754486 ],
         [-0.99715847,  0.9640645 ,  0.30465382, ...,  0.17871591,
          -0.85218364,  0.16387752],
         [-0.08919553,  0.7495416 ,  0.06145515, ..., -0.95457363,
          -0.06834653,  0.51133853],
         ...,
         [ 0.09836286, -0.95069414, -0.8454383 , ...,  0.22072984,
           0.9998686 , -0.18098037],
         [ 0.9998686 ,  0.22072984, -0.02551558, ..., -0.8995187 ,
           0.78233504,  0.1889948 ],
         [ 0.9808742 ,  0.9030517 , -0.52618223, ..., -0.28246096,
           0.20826773, -0.9950367 ]],

        [[ 0.8191342 ,  0.83980733,  0.44729427, ...,  0.17871591,
           0.8587903 , -0.3754486 ],
         [-0.99715847,  0.9640645 ,  0.30465382, ...,  0.17871591,
          -0.85218364,  0.16387752],
         [-0.08919553,  0.7495416 ,  0.06145515, ..., -0.95457363,
          -0.06834653,  0.51133853],
         ...,
         [ 0.09836286, -0.95069414, -0.8454383 , ...,  0.22072984,
           0.9998686 , -0.18098037],
         [ 0.9998686 ,  0.22072984, -0.02551558, ..., -0.8995187 ,
           0.78233504,  0.1889948 ],
         [ 0.9808742 ,  0.9030517 , -0.52618223, ..., -0.28246096,
           0.20826773, -0.9950367 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [10], 'to': []}
ms node:
{'name': 'sin', 'output': array([[[[ 1.7307977e-01,  8.0124927e-01, -3.1403822e-01, ...,
          -9.9674970e-01, -9.9702108e-01, -9.0316308e-01],
         [ 2.9543471e-01, -5.0069028e-01,  2.4244297e-01, ...,
          -9.9674970e-01, -9.6663952e-01, -8.1547308e-01],
         [-6.8301004e-01, -9.7440040e-01, -9.8888791e-01, ...,
           5.3364122e-01,  6.7523217e-01,  9.9890000e-01],
         ...,
         [ 5.5605727e-01,  1.2053804e-01, -6.4523953e-01, ...,
          -9.9422759e-01,  4.7595146e-01, -8.8402182e-01],
         [ 5.9897524e-01,  3.1010124e-01,  9.0757328e-01, ...,
           8.5728377e-01,  7.4591410e-01, -9.9995983e-01],
         [-7.6184660e-01,  9.9915338e-01,  4.7528037e-01, ...,
          -1.1614201e-01, -8.2018518e-01,  7.3477852e-01]],

        [[ 9.9203193e-01, -9.9972767e-01, -4.9087611e-01, ...,
           1.5428497e-01,  1.5768509e-01,  9.7566980e-01],
         [ 3.5680470e-01, -7.2487175e-01, -9.9995649e-01, ...,
           1.5428497e-01,  2.0982330e-01,  2.8479293e-01],
         [ 8.6963999e-01,  4.4601682e-01, -9.4681066e-01, ...,
           1.0167943e-01,  2.6137120e-01, -1.8752708e-01],
         ...,
         [ 5.5605727e-01,  1.2053804e-01, -6.4523953e-01, ...,
          -9.9422759e-01,  4.7595146e-01, -8.8402182e-01],
         [ 5.9897524e-01,  3.1010124e-01,  9.0757328e-01, ...,
           8.5728377e-01,  7.4591410e-01, -9.9995983e-01],
         [-7.6184660e-01,  9.9915338e-01,  4.7528037e-01, ...,
          -1.1614201e-01, -8.2018518e-01,  7.3477852e-01]],

        [[ 9.9203193e-01, -9.9972767e-01, -4.9087611e-01, ...,
           1.5428497e-01,  1.5768509e-01,  9.7566980e-01],
         [ 3.5680470e-01, -7.2487175e-01, -9.9995649e-01, ...,
           1.5428497e-01,  2.0982330e-01,  2.8479293e-01],
         [ 8.6963999e-01,  4.4601682e-01, -9.4681066e-01, ...,
           1.0167943e-01,  2.6137120e-01, -1.8752708e-01],
         ...,
         [ 5.5605727e-01,  1.2053804e-01, -6.4523953e-01, ...,
          -9.9422759e-01,  4.7595146e-01, -8.8402182e-01],
         [ 5.9897524e-01,  3.1010124e-01,  9.0757328e-01, ...,
           8.5728377e-01,  7.4591410e-01, -9.9995983e-01],
         [-7.6184660e-01,  9.9915338e-01,  4.7528037e-01, ...,
          -1.1614201e-01, -8.2018518e-01,  7.3477852e-01]],

        ...,

        [[ 1.1724800e+05,  1.2288000e+05,  1.2032000e+05, ...,
           1.4080000e+04,  1.3056000e+04,  2.3552000e+04],
         [ 1.8432000e+05,  1.7996800e+05,  1.8611200e+05, ...,
           1.4080000e+04,  1.2800000e+04,  1.8432000e+04],
         [ 1.8099200e+05,  1.7382400e+05,  1.8764800e+05, ...,
           1.4336000e+04,  1.2544000e+04,  1.6128000e+04],
         ...,
         [ 5.2480000e+04,  4.0192000e+04,  3.8656000e+04, ...,
           5.3248000e+04,  6.1696000e+04,  7.2448000e+04],
         [ 6.1696000e+04,  5.3248000e+04,  5.1712000e+04, ...,
           6.5280000e+04,  7.0400000e+04,  7.0144000e+04],
         [ 7.5776000e+04,  7.7312000e+04,  7.4752000e+04, ...,
           7.6032000e+04,  7.9104000e+04,  8.1664000e+04]],

        [[ 1.1724800e+05,  1.2288000e+05,  1.2032000e+05, ...,
           1.4080000e+04,  1.3056000e+04,  2.3552000e+04],
         [ 1.8432000e+05,  1.7996800e+05,  1.8611200e+05, ...,
           1.4080000e+04,  1.2800000e+04,  1.8432000e+04],
         [ 1.8099200e+05,  1.7382400e+05,  1.8764800e+05, ...,
           1.4336000e+04,  1.2544000e+04,  1.6128000e+04],
         ...,
         [ 5.2480000e+04,  4.0192000e+04,  3.8656000e+04, ...,
           5.3248000e+04,  6.1696000e+04,  7.2448000e+04],
         [ 6.1696000e+04,  5.3248000e+04,  5.1712000e+04, ...,
           6.5280000e+04,  7.0400000e+04,  7.0144000e+04],
         [ 7.5776000e+04,  7.7312000e+04,  7.4752000e+04, ...,
           7.6032000e+04,  7.9104000e+04,  8.1664000e+04]],

        [[ 1.1724800e+05,  1.2288000e+05,  1.2032000e+05, ...,
           1.4080000e+04,  1.3056000e+04,  2.3552000e+04],
         [ 1.8432000e+05,  1.7996800e+05,  1.8611200e+05, ...,
           1.4080000e+04,  1.2800000e+04,  1.8432000e+04],
         [ 1.8099200e+05,  1.7382400e+05,  1.8764800e+05, ...,
           1.4336000e+04,  1.2544000e+04,  1.6128000e+04],
         ...,
         [ 5.2480000e+04,  4.0192000e+04,  3.8656000e+04, ...,
           5.3248000e+04,  6.1696000e+04,  7.2448000e+04],
         [ 6.1696000e+04,  5.3248000e+04,  5.1712000e+04, ...,
           6.5280000e+04,  7.0400000e+04,  7.0144000e+04],
         [ 7.5776000e+04,  7.7312000e+04,  7.4752000e+04, ...,
           7.6032000e+04,  7.9104000e+04,  8.1664000e+04]]]],
      dtype=float32), 'output_shape': (1, 256, 32, 32), 'from': [10], 'to': []}
torch node:
{'name': 'sin', 'output': array([[[[ 0.17307977,  0.80124927, -0.31403822, ..., -0.9967497 ,
          -0.9970211 , -0.9031631 ],
         [ 0.2954347 , -0.5006903 ,  0.24244297, ..., -0.9967497 ,
          -0.9666395 , -0.8154731 ],
         [-0.68301004, -0.9744004 , -0.9888879 , ...,  0.5336412 ,
           0.6752322 ,  0.9989    ],
         ...,
         [ 0.5560573 ,  0.12053804, -0.64523953, ..., -0.9942276 ,
           0.47595146, -0.8840218 ],
         [ 0.59897524,  0.31010124,  0.9075733 , ...,  0.8572838 ,
           0.7459141 , -0.9999598 ],
         [-0.7618466 ,  0.9991534 ,  0.47528037, ..., -0.11614201,
          -0.8201852 ,  0.7347785 ]],

        [[ 0.99203193, -0.99972767, -0.4908761 , ...,  0.15428497,
           0.15768509,  0.9756698 ],
         [ 0.3568047 , -0.72487175, -0.9999565 , ...,  0.15428497,
           0.2098233 ,  0.28479293],
         [ 0.86964   ,  0.44601682, -0.94681066, ...,  0.10167943,
           0.2613712 , -0.18752708],
         ...,
         [ 0.5560573 ,  0.12053804, -0.64523953, ..., -0.9942276 ,
           0.47595146, -0.8840218 ],
         [ 0.59897524,  0.31010124,  0.9075733 , ...,  0.8572838 ,
           0.7459141 , -0.9999598 ],
         [-0.7618466 ,  0.9991534 ,  0.47528037, ..., -0.11614201,
          -0.8201852 ,  0.7347785 ]],

        [[ 0.99203193, -0.99972767, -0.4908761 , ...,  0.15428497,
           0.15768509,  0.9756698 ],
         [ 0.3568047 , -0.72487175, -0.9999565 , ...,  0.15428497,
           0.2098233 ,  0.28479293],
         [ 0.86964   ,  0.44601682, -0.94681066, ...,  0.10167943,
           0.2613712 , -0.18752708],
         ...,
         [ 0.5560573 ,  0.12053804, -0.64523953, ..., -0.9942276 ,
           0.47595146, -0.8840218 ],
         [ 0.59897524,  0.31010124,  0.9075733 , ...,  0.8572838 ,
           0.7459141 , -0.9999598 ],
         [-0.7618466 ,  0.9991534 ,  0.47528037, ..., -0.11614201,
          -0.8201852 ,  0.7347785 ]],

        ...,

        [[ 0.8191342 ,  0.83980733,  0.44729427, ...,  0.17871591,
           0.8587903 , -0.3754486 ],
         [-0.99715847,  0.9640645 ,  0.30465382, ...,  0.17871591,
          -0.85218364,  0.16387752],
         [-0.08919553,  0.7495416 ,  0.06145515, ..., -0.95457363,
          -0.06834653,  0.51133853],
         ...,
         [ 0.09836286, -0.95069414, -0.8454383 , ...,  0.22072984,
           0.9998686 , -0.18098037],
         [ 0.9998686 ,  0.22072984, -0.02551558, ..., -0.8995187 ,
           0.78233504,  0.1889948 ],
         [ 0.9808742 ,  0.9030517 , -0.52618223, ..., -0.28246096,
           0.20826773, -0.9950367 ]],

        [[ 0.8191342 ,  0.83980733,  0.44729427, ...,  0.17871591,
           0.8587903 , -0.3754486 ],
         [-0.99715847,  0.9640645 ,  0.30465382, ...,  0.17871591,
          -0.85218364,  0.16387752],
         [-0.08919553,  0.7495416 ,  0.06145515, ..., -0.95457363,
          -0.06834653,  0.51133853],
         ...,
         [ 0.09836286, -0.95069414, -0.8454383 , ...,  0.22072984,
           0.9998686 , -0.18098037],
         [ 0.9998686 ,  0.22072984, -0.02551558, ..., -0.8995187 ,
           0.78233504,  0.1889948 ],
         [ 0.9808742 ,  0.9030517 , -0.52618223, ..., -0.28246096,
           0.20826773, -0.9950367 ]],

        [[ 0.8191342 ,  0.83980733,  0.44729427, ...,  0.17871591,
           0.8587903 , -0.3754486 ],
         [-0.99715847,  0.9640645 ,  0.30465382, ...,  0.17871591,
          -0.85218364,  0.16387752],
         [-0.08919553,  0.7495416 ,  0.06145515, ..., -0.95457363,
          -0.06834653,  0.51133853],
         ...,
         [ 0.09836286, -0.95069414, -0.8454383 , ...,  0.22072984,
           0.9998686 , -0.18098037],
         [ 0.9998686 ,  0.22072984, -0.02551558, ..., -0.8995187 ,
           0.78233504,  0.1889948 ],
         [ 0.9808742 ,  0.9030517 , -0.52618223, ..., -0.28246096,
           0.20826773, -0.9950367 ]]]], dtype=float32), 'output_shape': torch.Size([1, 256, 32, 32]), 'from': [10], 'to': []}

generate models:64

analyse output arrays in iter:6

pre layer res:
10:reshape
{'name': 'reshape', 'output': array([[[[   0.     ,    0.     ,    0.     , ...,  688.73376,
           774.6778 ,  845.1426 ],
         [ 873.0336 ,  843.3575 ,  843.2324 , ...,  905.19336,
           873.17   ,  883.0602 ],
         [ 906.875  ,  905.7989 ,  756.74805, ...,  349.     ,
           290.     ,  218.     ],
         ...,
         [1002.40564,  998.19336,  993.17   , ...,  226.     ,
           208.     ,   68.     ],
         [  53.     ,  119.     ,  172.     , ...,  569.6017 ,
           645.5001 ,  764.1719 ],
         [ 696.6256 ,  709.58545,  758.48425, ...,  682.422  ,
           753.6406 ,  829.545  ]]]], dtype=float32), 'output_shape': torch.Size([1, 1, 112, 112]), 'from': [9], 'to': [15]}
tf node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ..., -0.6631156 ,
           0.96236914, -0.05412784],
         [-0.32321733,  0.98720425,  0.95960385, ...,  0.40289262,
          -0.19158302, -0.2692797 ],
         [ 0.8650635 ,  0.85221523,  0.36700067, ..., -0.27944446,
           0.82684565, -0.94252455],
         ...,
         [-0.23535436, -0.74002296,  0.41387293, ..., -0.19344382,
           0.6090679 , -0.8979277 ],
         [ 0.39592516, -0.3714041 ,  0.7086591 , ..., -0.82681096,
          -0.9952829 , -0.6924361 ],
         [-0.7228782 , -0.4027236 , -0.97795314, ..., -0.6414534 ,
          -0.33500624,  0.16378117]]]], dtype=float32), 'output_shape': torch.Size([1, 1, 112, 112]), 'from': [10], 'to': [7]}
ms node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ..., -0.6631156 ,
           0.96236914, -0.05412784],
         [-0.32321733,  0.98720425,  0.95960385, ...,  0.40216628,
          -0.19236171, -0.26804507],
         [ 0.8650635 ,  0.85221523,  0.36700067, ..., -0.27944446,
           0.82684565, -0.94252455],
         ...,
         [-0.23482044, -0.74055636,  0.4131505 , ..., -0.19344382,
           0.6090679 , -0.8979277 ],
         [ 0.39592516, -0.3714041 ,  0.7086591 , ..., -0.826811  ,
          -0.99530065, -0.69248015],
         [-0.72245634, -0.4031705 , -0.9779276 , ..., -0.6414534 ,
          -0.33500624,  0.16378117]]]], dtype=float32), 'output_shape': (1, 1, 112, 112), 'from': [10], 'to': [7]}
torch node:
{'name': 'sin', 'output': array([[[[ 0.        ,  0.        ,  0.        , ..., -0.6631156 ,
           0.96236914, -0.05412784],
         [-0.32321733,  0.98720425,  0.95960385, ...,  0.40289262,
          -0.19158302, -0.2692797 ],
         [ 0.8650635 ,  0.85221523,  0.36700067, ..., -0.27944446,
           0.82684565, -0.94252455],
         ...,
         [-0.23535436, -0.74002296,  0.41387293, ..., -0.19344382,
           0.6090679 , -0.8979277 ],
         [ 0.39592516, -0.3714041 ,  0.7086591 , ..., -0.82681096,
          -0.9952829 , -0.6924361 ],
         [-0.7228782 , -0.4027236 , -0.97795314, ..., -0.6414534 ,
          -0.33500624,  0.16378117]]]], dtype=float32), 'output_shape': torch.Size([1, 1, 112, 112]), 'from': [10], 'to': [7]}

generate models:6

analyse output arrays in iter:9

pre layer res:
20:reshape
{'name': 'reshape', 'output': array([[179704.89,      0.  ,      0.  , ...,      0.  ,      0.  ,
             0.  ]], dtype=float32), 'output_shape': torch.Size([1, 82944]), 'from': [19], 'to': [14]}
tf node:
{'name': 'sin', 'output': array([[-0.47269422,  0.        ,  0.        , ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': torch.Size([1, 82944]), 'from': [20], 'to': [7]}
ms node:
{'name': 'sin', 'output': array([[0.02069121, 0.        , 0.        , ..., 0.        , 0.        ,
        0.        ]], dtype=float32), 'output_shape': (1, 82944), 'from': [20], 'to': [7]}
torch node:
{'name': 'sin', 'output': array([[-0.47269422,  0.        ,  0.        , ...,  0.        ,
         0.        ,  0.        ]], dtype=float32), 'output_shape': torch.Size([1, 82944]), 'from': [20], 'to': [7]}

generate models:8

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:2,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
torch --> 

generate models:8

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:2,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
sin:2
torch --> 

generate models:18

analyse output arrays in iter:8

pre layer res:
3:conv2d
{'name': 'conv2d', 'output': array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 1.8788985e-12, 5.4601661e-09, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 5.7475942e-19, 1.3534398e-11, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 1.1544351e-17, 4.9790272e-12, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.2469293e-18, 2.4789117e-13, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 1.8788985e-12, 5.4601661e-09, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 5.7475942e-19, 1.3534398e-11, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 1.1544351e-17, 4.9790272e-12, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.2469293e-18, 2.4789117e-13, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 1.8788985e-12, 5.4601661e-09, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 5.7475942e-19, 1.3534398e-11, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 1.1544351e-17, 4.9790272e-12, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.2469293e-18, 2.4789117e-13, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        ...,

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 1.8788985e-12, 5.4601661e-09, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 5.7475942e-19, 1.3534398e-11, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 1.1544351e-17, 4.9790272e-12, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.2469293e-18, 2.4789117e-13, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 1.8788985e-12, 5.4601661e-09, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 5.7475942e-19, 1.3534398e-11, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 1.1544351e-17, 4.9790272e-12, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.2469293e-18, 2.4789117e-13, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],

        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 1.8788985e-12, 5.4601661e-09, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 5.7475942e-19, 1.3534398e-11, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         ...,
         [0.0000000e+00, 1.1544351e-17, 4.9790272e-12, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 4.2469293e-18, 2.4789117e-13, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,
          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 18, 18]), 'from': [11], 'to': [6, 14]}
tf node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 18, 18]), 'from': [3], 'to': [6]}
ms node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000332, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.02579 , ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000332, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.02579 , ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000332, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.02579 , ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000332, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.02579 , ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000332, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.02579 , ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000332, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.02579 , ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': (1, 512, 18, 18), 'from': [3], 'to': [6]}
torch node:
{'name': 'log', 'output': array([[[[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        ...,

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]],

        [[      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf],
         [      -inf, -27.000336, -19.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -42.000336, -25.025787, ...,       -inf,
                -inf,       -inf],
         ...,
         [      -inf, -39.000336, -26.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf, -40.000336, -29.025787, ...,       -inf,
                -inf,       -inf],
         [      -inf,       -inf,       -inf, ...,       -inf,
                -inf,       -inf]]]], dtype=float32), 'output_shape': torch.Size([1, 512, 18, 18]), 'from': [3], 'to': [6]}

generate models:8

final statics:
total operators:28
tensorflow --> nums:0,distinct_bugs:0
mindspore --> nums:1,distinct_bugs:1
torch --> nums:0,distinct_bugs:0
tensorflow --> 
mindspore --> 
log:1
torch --> 

generate models:9

analyse the exceptions in iter:47
tensorflow exception:
{'id': 10, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([87609920.], grad_fn=<AddBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 10, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([87609920.], grad_fn=<AddBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:20

final statics:
total operators:28
tensorflow --> nums:1,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:1,distinct_bugs:1
tensorflow --> 
flatten:1
mindspore --> 
log:1
torch --> 
flatten:1

generate models:20

analyse the exceptions in iter:62
tensorflow exception:
{'id': 21, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([164267.4062,      0.0000,      0.0000,  ...,      0.0000,
             0.0000,      0.0000], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)
torch exception:
{'id': 21, 'name': 'flatten', 'frame_work': 'torch', 'input_datas': [tensor([164267.4062,      0.0000,      0.0000,  ...,      0.0000,
             0.0000,      0.0000], grad_fn=<ConstantPadNdBackward0>)]}
Dimension out of range (expected to be in range of [-1, 0], but got 1)

generate models:21

final statics:
total operators:28
tensorflow --> nums:2,distinct_bugs:1
mindspore --> nums:1,distinct_bugs:1
torch --> nums:2,distinct_bugs:1
tensorflow --> 
flatten:2
mindspore --> 
log:1
torch --> 
flatten:2

generate models:23
